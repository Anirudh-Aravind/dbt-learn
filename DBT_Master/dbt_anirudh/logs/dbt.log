[0m16:55:33.501092 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x759e6a90d820>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x759e6ba3bd10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x759e6cde8ce0>]}


============================== 16:55:33.503309 | dfd06b5c-086f-4b7a-875b-ed5a1b9c844a ==============================
[0m16:55:33.503309 [info ] [MainThread]: Running with dbt=1.10.10
[0m16:55:33.503719 [debug] [MainThread]: running dbt with arguments {'log_format': 'default', 'debug': 'False', 'quiet': 'False', 'fail_fast': 'False', 'send_anonymous_usage_stats': 'True', 'use_colors': 'True', 'partial_parse': 'True', 'introspect': 'True', 'printer_width': '80', 'use_experimental_parser': 'False', 'target_path': 'None', 'cache_selected_only': 'False', 'empty': 'None', 'profiles_dir': '/home/aniruth/.dbt', 'static_parser': 'True', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'no_print': 'None', 'indirect_selection': 'eager', 'warn_error': 'None', 'version_check': 'True', 'invocation_command': 'dbt debug', 'log_cache_events': 'False', 'write_json': 'True', 'log_path': '/home/aniruth/AI/DBT/DBT_Master/dbt_anirudh/logs'}
[0m16:55:33.509454 [info ] [MainThread]: dbt version: 1.10.10
[0m16:55:33.509778 [info ] [MainThread]: python version: 3.12.3
[0m16:55:33.510004 [info ] [MainThread]: python path: /home/aniruth/AI/DBT/.venv/bin/python3
[0m16:55:33.510215 [info ] [MainThread]: os info: Linux-6.14.0-28-generic-x86_64-with-glibc2.39
[0m16:55:34.081791 [debug] [MainThread]: Spark adapter: Setting pyhive.hive logging to ERROR
[0m16:55:34.082194 [debug] [MainThread]: Spark adapter: Setting thrift.transport logging to ERROR
[0m16:55:34.082505 [debug] [MainThread]: Spark adapter: Setting thrift.protocol logging to ERROR
[0m16:55:34.486422 [info ] [MainThread]: Using profiles dir at /home/aniruth/.dbt
[0m16:55:34.486795 [info ] [MainThread]: Using profiles.yml file at /home/aniruth/.dbt/profiles.yml
[0m16:55:34.487053 [info ] [MainThread]: Using dbt_project.yml file at /home/aniruth/AI/DBT/DBT_Master/dbt_anirudh/dbt_project.yml
[0m16:55:34.487305 [info ] [MainThread]: adapter type: databricks
[0m16:55:34.487529 [info ] [MainThread]: adapter version: 1.10.9
[0m16:55:34.564920 [info ] [MainThread]: Configuration:
[0m16:55:34.565296 [info ] [MainThread]:   profiles.yml file [[32mOK found and valid[0m]
[0m16:55:34.565563 [info ] [MainThread]:   dbt_project.yml file [[32mOK found and valid[0m]
[0m16:55:34.565778 [info ] [MainThread]: Required dependencies:
[0m16:55:34.566004 [debug] [MainThread]: Executing "git --help"
[0m16:55:34.567316 [debug] [MainThread]: STDOUT: "b"usage: git [-v | --version] [-h | --help] [-C <path>] [-c <name>=<value>]\n           [--exec-path[=<path>]] [--html-path] [--man-path] [--info-path]\n           [-p | --paginate | -P | --no-pager] [--no-replace-objects] [--bare]\n           [--git-dir=<path>] [--work-tree=<path>] [--namespace=<name>]\n           [--config-env=<name>=<envvar>] <command> [<args>]\n\nThese are common Git commands used in various situations:\n\nstart a working area (see also: git help tutorial)\n   clone     Clone a repository into a new directory\n   init      Create an empty Git repository or reinitialize an existing one\n\nwork on the current change (see also: git help everyday)\n   add       Add file contents to the index\n   mv        Move or rename a file, a directory, or a symlink\n   restore   Restore working tree files\n   rm        Remove files from the working tree and from the index\n\nexamine the history and state (see also: git help revisions)\n   bisect    Use binary search to find the commit that introduced a bug\n   diff      Show changes between commits, commit and working tree, etc\n   grep      Print lines matching a pattern\n   log       Show commit logs\n   show      Show various types of objects\n   status    Show the working tree status\n\ngrow, mark and tweak your common history\n   branch    List, create, or delete branches\n   commit    Record changes to the repository\n   merge     Join two or more development histories together\n   rebase    Reapply commits on top of another base tip\n   reset     Reset current HEAD to the specified state\n   switch    Switch branches\n   tag       Create, list, delete or verify a tag object signed with GPG\n\ncollaborate (see also: git help workflows)\n   fetch     Download objects and refs from another repository\n   pull      Fetch from and integrate with another repository or a local branch\n   push      Update remote refs along with associated objects\n\n'git help -a' and 'git help -g' list available subcommands and some\nconcept guides. See 'git help <command>' or 'git help <concept>'\nto read about a specific subcommand or concept.\nSee 'git help git' for an overview of the system.\n""
[0m16:55:34.567633 [debug] [MainThread]: STDERR: "b''"
[0m16:55:34.567859 [info ] [MainThread]:  - git [[32mOK found[0m]

[0m16:55:34.568086 [info ] [MainThread]: Connection:
[0m16:55:34.568328 [info ] [MainThread]:   host: dbc-da390f9a-8fc8.cloud.databricks.com
[0m16:55:34.568542 [info ] [MainThread]:   http_path: /sql/1.0/warehouses/cd9c3d27e6f79760
[0m16:55:34.568745 [info ] [MainThread]:   catalog: dbt_learning
[0m16:55:34.568947 [info ] [MainThread]:   schema: default
[0m16:55:34.569250 [info ] [MainThread]: Registered adapter: databricks=1.10.9
[0m16:55:34.633947 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=debug) - Creating connection
[0m16:55:34.634287 [debug] [MainThread]: Acquiring new databricks connection 'debug'
[0m16:55:34.634553 [debug] [MainThread]: Using databricks connection "debug"
[0m16:55:34.634775 [debug] [MainThread]: On debug: select 1 as id
[0m16:55:34.634991 [debug] [MainThread]: Opening a new connection, currently in state init
[0m16:55:35.829610 [debug] [MainThread]: Databricks adapter: Connection(session-id=01f088b8-b5f8-129c-9b3a-9247171b1bc3) - Created
[0m16:55:36.510757 [debug] [MainThread]: SQL status: OK in 1.880 seconds
[0m16:55:36.513110 [debug] [MainThread]: Databricks adapter: Cursor(session-id=01f088b8-b5f8-129c-9b3a-9247171b1bc3, command-id=01f088b8-b627-17ee-a2a1-1342e3ed39e0) - Closing
[0m16:55:36.514129 [debug] [MainThread]: On debug: Close
[0m16:55:36.514946 [debug] [MainThread]: Databricks adapter: Connection(session-id=01f088b8-b5f8-129c-9b3a-9247171b1bc3) - Closing
[0m16:55:36.926490 [info ] [MainThread]:   Connection test: [[32mOK connection ok[0m]

[0m16:55:36.927072 [info ] [MainThread]: [32mAll checks passed![0m
[0m16:55:36.928099 [debug] [MainThread]: Resource report: {"command_name": "debug", "command_success": true, "command_wall_clock_time": 3.4670203, "process_in_blocks": "8", "process_kernel_time": 0.153437, "process_mem_max_rss": "233664", "process_out_blocks": "16", "process_user_time": 3.146463}
[0m16:55:36.928675 [debug] [MainThread]: Command `dbt debug` succeeded at 16:55:36.928565 after 3.47 seconds
[0m16:55:36.929143 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x759e6cde8ce0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x759e69f14e00>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x759e6a6ede20>]}
[0m16:55:36.929594 [debug] [MainThread]: Flushing usage events
[0m16:55:37.966235 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m17:05:27.003107 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7cef9ef68d10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7cef9f610e90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7cef9f05ea80>]}


============================== 17:05:27.005952 | c18245c4-f654-470e-a412-6a7e4857f83d ==============================
[0m17:05:27.005952 [info ] [MainThread]: Running with dbt=1.10.10
[0m17:05:27.006472 [debug] [MainThread]: running dbt with arguments {'no_print': 'None', 'warn_error': 'None', 'send_anonymous_usage_stats': 'True', 'invocation_command': 'dbt ', 'quiet': 'False', 'log_path': '/home/aniruth/AI/DBT/DBT_Master/dbt_anirudh/logs', 'static_parser': 'True', 'printer_width': '80', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'target_path': 'None', 'introspect': 'True', 'debug': 'False', 'write_json': 'True', 'log_format': 'default', 'log_cache_events': 'False', 'empty': 'None', 'indirect_selection': 'eager', 'fail_fast': 'False', 'use_experimental_parser': 'False', 'partial_parse': 'True', 'profiles_dir': '/home/aniruth/.dbt', 'cache_selected_only': 'False', 'version_check': 'True', 'use_colors': 'True'}
[0m17:05:27.102053 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'c18245c4-f654-470e-a412-6a7e4857f83d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7cef9eab0d70>]}
[0m17:05:27.120316 [info ] [MainThread]: Warning: No packages were found in packages.yml
[0m17:05:27.120893 [info ] [MainThread]: Warning: No packages were found in packages.yml
[0m17:05:27.121588 [debug] [MainThread]: Resource report: {"command_name": "deps", "command_success": true, "command_wall_clock_time": 0.17159498, "process_in_blocks": "312", "process_kernel_time": 0.100593, "process_mem_max_rss": "101008", "process_out_blocks": "192", "process_user_time": 1.114491}
[0m17:05:27.121954 [debug] [MainThread]: Command `cli deps` succeeded at 17:05:27.121878 after 0.17 seconds
[0m17:05:27.122227 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7cef9eeb3260>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7cef9ebcb350>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7cef9e691430>]}
[0m17:05:27.122537 [debug] [MainThread]: Flushing usage events
[0m17:05:28.195917 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m08:28:06.234779 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7196325f6c60>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7196340d9e80>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x71963201ba10>]}


============================== 08:28:06.241165 | e73546cd-6ec9-49f9-90d4-eda2f1f3b4a8 ==============================
[0m08:28:06.241165 [info ] [MainThread]: Running with dbt=1.10.10
[0m08:28:06.241907 [debug] [MainThread]: running dbt with arguments {'indirect_selection': 'eager', 'log_cache_events': 'False', 'invocation_command': 'dbt ', 'no_print': 'None', 'write_json': 'True', 'partial_parse': 'True', 'log_format': 'default', 'use_experimental_parser': 'False', 'cache_selected_only': 'False', 'profiles_dir': '/home/aniruth/.dbt', 'empty': 'None', 'debug': 'False', 'log_path': '/home/aniruth/AI/DBT/DBT_Master/dbt_anirudh/logs', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'fail_fast': 'False', 'introspect': 'True', 'send_anonymous_usage_stats': 'True', 'target_path': 'None', 'printer_width': '80', 'warn_error': 'None', 'quiet': 'False', 'version_check': 'True', 'use_colors': 'True', 'static_parser': 'True'}
[0m08:28:06.424789 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'e73546cd-6ec9-49f9-90d4-eda2f1f3b4a8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x719631fb5cd0>]}
[0m08:28:06.444471 [info ] [MainThread]: Warning: No packages were found in packages.yml
[0m08:28:06.446457 [info ] [MainThread]: Warning: No packages were found in packages.yml
[0m08:28:06.448507 [debug] [MainThread]: Resource report: {"command_name": "deps", "command_success": true, "command_wall_clock_time": 0.29941574, "process_in_blocks": "36488", "process_kernel_time": 0.221154, "process_mem_max_rss": "100564", "process_out_blocks": "8", "process_user_time": 2.261575}
[0m08:28:06.449445 [debug] [MainThread]: Command `cli deps` succeeded at 08:28:06.449264 after 0.30 seconds
[0m08:28:06.450124 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7196325cef00>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x719631795250>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7196317952b0>]}
[0m08:28:06.450846 [debug] [MainThread]: Flushing usage events
[0m08:28:07.663546 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m23:49:54.611324 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x76c346ee0830>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x76c344a236e0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x76c346b56420>]}


============================== 23:49:54.613654 | a2660097-df59-49fc-a440-d1b28fca3dc8 ==============================
[0m23:49:54.613654 [info ] [MainThread]: Running with dbt=1.10.10
[0m23:49:54.614069 [debug] [MainThread]: running dbt with arguments {'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'write_json': 'True', 'profiles_dir': '/home/aniruth/AI/DBT/DBT_Master/dbt_anirudh', 'use_colors': 'True', 'fail_fast': 'False', 'debug': 'False', 'introspect': 'True', 'quiet': 'False', 'indirect_selection': 'eager', 'invocation_command': 'dbt run', 'static_parser': 'True', 'use_experimental_parser': 'False', 'send_anonymous_usage_stats': 'True', 'target_path': 'None', 'version_check': 'True', 'partial_parse': 'True', 'no_print': 'None', 'printer_width': '80', 'cache_selected_only': 'False', 'empty': 'False', 'log_path': '/home/aniruth/AI/DBT/DBT_Master/dbt_anirudh/logs', 'warn_error': 'None', 'log_format': 'default', 'log_cache_events': 'False'}
[0m23:49:55.220802 [debug] [MainThread]: Spark adapter: Setting pyhive.hive logging to ERROR
[0m23:49:55.221222 [debug] [MainThread]: Spark adapter: Setting thrift.transport logging to ERROR
[0m23:49:55.221548 [debug] [MainThread]: Spark adapter: Setting thrift.protocol logging to ERROR
[0m23:49:55.731194 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'a2660097-df59-49fc-a440-d1b28fca3dc8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x76c3422a9d30>]}
[0m23:49:55.780632 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'a2660097-df59-49fc-a440-d1b28fca3dc8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x76c31f28bf80>]}
[0m23:49:55.781177 [info ] [MainThread]: Registered adapter: databricks=1.10.9
[0m23:49:55.865987 [debug] [MainThread]: checksum: 502a0dc23e9052e1ae09f7c44ee219ef7a02dfea7e7d66580d54c304c14d553b, vars: {}, profile: , target: , version: 1.10.10
[0m23:49:55.939706 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m23:49:55.940047 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m23:49:55.965979 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'a2660097-df59-49fc-a440-d1b28fca3dc8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x76c31f3167b0>]}
[0m23:49:56.022316 [debug] [MainThread]: Wrote artifact WritableManifest to /home/aniruth/AI/DBT/DBT_Master/dbt_anirudh/target/manifest.json
[0m23:49:56.024687 [debug] [MainThread]: Wrote artifact SemanticManifest to /home/aniruth/AI/DBT/DBT_Master/dbt_anirudh/target/semantic_manifest.json
[0m23:49:56.036424 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'a2660097-df59-49fc-a440-d1b28fca3dc8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x76c31ed869f0>]}
[0m23:49:56.036815 [info ] [MainThread]: Found 6 models, 6 sources, 685 macros
[0m23:49:56.037100 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'a2660097-df59-49fc-a440-d1b28fca3dc8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x76c31edb7800>]}
[0m23:49:56.038567 [info ] [MainThread]: 
[0m23:49:56.038860 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m23:49:56.039096 [info ] [MainThread]: 
[0m23:49:56.039504 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=master) - Creating connection
[0m23:49:56.039736 [debug] [MainThread]: Acquiring new databricks connection 'master'
[0m23:49:56.044958 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=list_dbt_learning) - Creating connection
[0m23:49:56.045365 [debug] [ThreadPool]: Acquiring new databricks connection 'list_dbt_learning'
[0m23:49:56.045659 [debug] [ThreadPool]: Using databricks connection "list_dbt_learning"
[0m23:49:56.045926 [debug] [ThreadPool]: On list_dbt_learning: GetSchemas(database=dbt_learning, schema=None)
[0m23:49:56.046175 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m23:49:57.273485 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f08f3b-ebe2-1588-b62e-eed526f94579) - Created
[0m23:49:58.081108 [debug] [ThreadPool]: SQL status: OK in 2.030 seconds
[0m23:49:58.083982 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01f08f3b-ebe2-1588-b62e-eed526f94579, command-id=01f08f3b-ec1b-1a11-87b3-8b5f80f3ed71) - Closing
[0m23:49:58.084981 [debug] [ThreadPool]: On list_dbt_learning: Close
[0m23:49:58.085855 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f08f3b-ebe2-1588-b62e-eed526f94579) - Closing
[0m23:49:58.406653 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=list_dbt_learning_default) - Creating connection
[0m23:49:58.408001 [debug] [ThreadPool]: Acquiring new databricks connection 'list_dbt_learning_default'
[0m23:49:58.430075 [debug] [ThreadPool]: Using databricks connection "list_dbt_learning_default"
[0m23:49:58.430529 [debug] [ThreadPool]: On list_dbt_learning_default: /* {"app": "dbt", "dbt_version": "1.10.10", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_anirudh", "target_name": "dev", "connection_name": "list_dbt_learning_default"} */

    
SELECT
  table_name,
  if(table_type IN ('EXTERNAL', 'MANAGED', 'MANAGED_SHALLOW_CLONE', 'EXTERNAL_SHALLOW_CLONE'), 'table', lower(table_type)) AS table_type,
  lower(data_source_format) AS file_format,
  table_owner,
  if(
    table_type IN (
      'EXTERNAL',
      'MANAGED',
      'MANAGED_SHALLOW_CLONE',
      'EXTERNAL_SHALLOW_CLONE'
    ),
    lower(table_type),
    NULL
  ) AS databricks_table_type
FROM `system`.`information_schema`.`tables`
WHERE table_catalog = 'dbt_learning' 
  AND table_schema = 'default'

  
[0m23:49:58.430833 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m23:49:59.604985 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f08f3b-ed48-1022-9147-ccaf0be95967) - Created
[0m23:50:00.433573 [debug] [ThreadPool]: SQL status: OK in 2.000 seconds
[0m23:50:00.441421 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01f08f3b-ed48-1022-9147-ccaf0be95967, command-id=01f08f3b-ed73-164d-bca5-3e201e124884) - Closing
[0m23:50:00.442646 [debug] [ThreadPool]: On list_dbt_learning_default: Close
[0m23:50:00.443574 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f08f3b-ed48-1022-9147-ccaf0be95967) - Closing
[0m23:50:00.755600 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'a2660097-df59-49fc-a440-d1b28fca3dc8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x76c344eab1a0>]}
[0m23:50:00.763497 [debug] [Thread-3 (]: Began running node model.dbt_anirudh.bronze_customer
[0m23:50:00.765530 [info ] [Thread-3 (]: 1 of 6 START sql table model default.bronze_customer ........................... [RUN]
[0m23:50:00.767479 [debug] [Thread-3 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.dbt_anirudh.bronze_customer) - Creating connection
[0m23:50:00.768384 [debug] [Thread-3 (]: Acquiring new databricks connection 'model.dbt_anirudh.bronze_customer'
[0m23:50:00.769196 [debug] [Thread-3 (]: Began compiling node model.dbt_anirudh.bronze_customer
[0m23:50:00.779506 [debug] [Thread-3 (]: Writing injected SQL for node "model.dbt_anirudh.bronze_customer"
[0m23:50:00.780225 [debug] [Thread-3 (]: Began executing node model.dbt_anirudh.bronze_customer
[0m23:50:00.795873 [debug] [Thread-3 (]: MATERIALIZING TABLE
[0m23:50:00.796427 [warn ] [Thread-3 (]: [[33mWARNING[0m]: Use revamped materializations based on separating create and insert.  This allows more performant column comments, as well as new column features.
You may opt into the new behavior sooner by setting `flags.use_materialization_v2` to `True` in `dbt_project.yml`.
Visit https://docs.getdbt.com/reference/global-configs/behavior-changes for more information.
[0m23:50:00.796891 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'BehaviorChangeEvent', 'label': 'a2660097-df59-49fc-a440-d1b28fca3dc8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x76c31ee2e9c0>]}
[0m23:50:00.831820 [debug] [Thread-3 (]: Writing runtime sql for node "model.dbt_anirudh.bronze_customer"
[0m23:50:00.832420 [debug] [Thread-3 (]: Using databricks connection "model.dbt_anirudh.bronze_customer"
[0m23:50:00.832760 [debug] [Thread-3 (]: On model.dbt_anirudh.bronze_customer: /* {"app": "dbt", "dbt_version": "1.10.10", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_anirudh", "target_name": "dev", "node_id": "model.dbt_anirudh.bronze_customer"} */

  
    
        create or replace table `dbt_learning`.`default`.`bronze_customer`
      
      
  using delta
      
      
      
      
      
      
      
      as
      SELECT 
    *
FROM
    `dbt_learning`.`source`.`dim_customer`
  
[0m23:50:00.833037 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m23:50:01.999890 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f08f3b-eeb3-1788-8eeb-8d1021c1ff81) - Created
[0m23:50:08.703632 [debug] [Thread-3 (]: SQL status: OK in 7.870 seconds
[0m23:50:08.706119 [debug] [Thread-3 (]: Databricks adapter: Cursor(session-id=01f08f3b-eeb3-1788-8eeb-8d1021c1ff81, command-id=01f08f3b-eee2-1077-812a-bf93a0fa55a3) - Closing
[0m23:50:09.062689 [debug] [Thread-3 (]: Applying tags to relation None
[0m23:50:09.076796 [debug] [Thread-3 (]: On model.dbt_anirudh.bronze_customer: Close
[0m23:50:09.077205 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f08f3b-eeb3-1788-8eeb-8d1021c1ff81) - Closing
[0m23:50:09.410838 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a2660097-df59-49fc-a440-d1b28fca3dc8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x76c346915d90>]}
[0m23:50:09.412628 [info ] [Thread-3 (]: 1 of 6 OK created sql table model default.bronze_customer ...................... [[32mOK[0m in 8.64s]
[0m23:50:09.414357 [debug] [Thread-3 (]: Finished running node model.dbt_anirudh.bronze_customer
[0m23:50:09.415591 [debug] [Thread-3 (]: Began running node model.dbt_anirudh.bronze_date
[0m23:50:09.416708 [info ] [Thread-3 (]: 2 of 6 START sql table model default.bronze_date ............................... [RUN]
[0m23:50:09.418294 [debug] [Thread-3 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.dbt_anirudh.bronze_date) - Creating connection
[0m23:50:09.419177 [debug] [Thread-3 (]: Acquiring new databricks connection 'model.dbt_anirudh.bronze_date'
[0m23:50:09.420131 [debug] [Thread-3 (]: Began compiling node model.dbt_anirudh.bronze_date
[0m23:50:09.425905 [debug] [Thread-3 (]: Writing injected SQL for node "model.dbt_anirudh.bronze_date"
[0m23:50:09.426722 [debug] [Thread-3 (]: Began executing node model.dbt_anirudh.bronze_date
[0m23:50:09.429492 [debug] [Thread-3 (]: MATERIALIZING TABLE
[0m23:50:09.432169 [debug] [Thread-3 (]: Writing runtime sql for node "model.dbt_anirudh.bronze_date"
[0m23:50:09.432683 [debug] [Thread-3 (]: Using databricks connection "model.dbt_anirudh.bronze_date"
[0m23:50:09.433011 [debug] [Thread-3 (]: On model.dbt_anirudh.bronze_date: /* {"app": "dbt", "dbt_version": "1.10.10", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_anirudh", "target_name": "dev", "node_id": "model.dbt_anirudh.bronze_date"} */

  
    
        create or replace table `dbt_learning`.`default`.`bronze_date`
      
      
  using delta
      
      
      
      
      
      
      
      as
      SELECT  
    *
FROM
    `dbt_learning`.`source`.`dim_date`
  
[0m23:50:09.433291 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m23:50:10.584631 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f08f3b-f3d2-1fdc-b9fe-1af1d129dcf5) - Created
[0m23:50:13.675105 [debug] [Thread-3 (]: SQL status: OK in 4.240 seconds
[0m23:50:13.678294 [debug] [Thread-3 (]: Databricks adapter: Cursor(session-id=01f08f3b-f3d2-1fdc-b9fe-1af1d129dcf5, command-id=01f08f3b-f400-12b3-8028-ce785a6f3ced) - Closing
[0m23:50:13.680326 [debug] [Thread-3 (]: Applying tags to relation None
[0m23:50:13.683350 [debug] [Thread-3 (]: On model.dbt_anirudh.bronze_date: Close
[0m23:50:13.683989 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f08f3b-f3d2-1fdc-b9fe-1af1d129dcf5) - Closing
[0m23:50:14.003050 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a2660097-df59-49fc-a440-d1b28fca3dc8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x76c31c48ed80>]}
[0m23:50:14.004915 [info ] [Thread-3 (]: 2 of 6 OK created sql table model default.bronze_date .......................... [[32mOK[0m in 4.58s]
[0m23:50:14.006616 [debug] [Thread-3 (]: Finished running node model.dbt_anirudh.bronze_date
[0m23:50:14.007684 [debug] [Thread-3 (]: Began running node model.dbt_anirudh.bronze_product
[0m23:50:14.008850 [info ] [Thread-3 (]: 3 of 6 START sql table model default.bronze_product ............................ [RUN]
[0m23:50:14.010464 [debug] [Thread-3 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.dbt_anirudh.bronze_product) - Creating connection
[0m23:50:14.011567 [debug] [Thread-3 (]: Acquiring new databricks connection 'model.dbt_anirudh.bronze_product'
[0m23:50:14.012787 [debug] [Thread-3 (]: Began compiling node model.dbt_anirudh.bronze_product
[0m23:50:14.025138 [debug] [Thread-3 (]: Writing injected SQL for node "model.dbt_anirudh.bronze_product"
[0m23:50:14.025964 [debug] [Thread-3 (]: Began executing node model.dbt_anirudh.bronze_product
[0m23:50:14.027582 [debug] [Thread-3 (]: MATERIALIZING TABLE
[0m23:50:14.029232 [debug] [Thread-3 (]: Writing runtime sql for node "model.dbt_anirudh.bronze_product"
[0m23:50:14.029605 [debug] [Thread-3 (]: Using databricks connection "model.dbt_anirudh.bronze_product"
[0m23:50:14.029938 [debug] [Thread-3 (]: On model.dbt_anirudh.bronze_product: /* {"app": "dbt", "dbt_version": "1.10.10", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_anirudh", "target_name": "dev", "node_id": "model.dbt_anirudh.bronze_product"} */

  
    
        create or replace table `dbt_learning`.`default`.`bronze_product`
      
      
  using delta
      
      
      
      
      
      
      
      as
      SELECT
    *
FROM
    `dbt_learning`.`source`.`dim_product`
  
[0m23:50:14.030244 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m23:50:15.176008 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f08f3b-f68f-1215-a31c-41eb534454c3) - Created
[0m23:50:18.057228 [debug] [Thread-3 (]: SQL status: OK in 4.030 seconds
[0m23:50:18.060601 [debug] [Thread-3 (]: Databricks adapter: Cursor(session-id=01f08f3b-f68f-1215-a31c-41eb534454c3, command-id=01f08f3b-f6bc-1a21-a1ea-12f1d4a2cf9b) - Closing
[0m23:50:18.062958 [debug] [Thread-3 (]: Applying tags to relation None
[0m23:50:18.065525 [debug] [Thread-3 (]: On model.dbt_anirudh.bronze_product: Close
[0m23:50:18.066077 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f08f3b-f68f-1215-a31c-41eb534454c3) - Closing
[0m23:50:18.394233 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a2660097-df59-49fc-a440-d1b28fca3dc8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x76c31ede39b0>]}
[0m23:50:18.396319 [info ] [Thread-3 (]: 3 of 6 OK created sql table model default.bronze_product ....................... [[32mOK[0m in 4.38s]
[0m23:50:18.397952 [debug] [Thread-3 (]: Finished running node model.dbt_anirudh.bronze_product
[0m23:50:18.398963 [debug] [Thread-3 (]: Began running node model.dbt_anirudh.bronze_returns
[0m23:50:18.400271 [info ] [Thread-3 (]: 4 of 6 START sql table model default.bronze_returns ............................ [RUN]
[0m23:50:18.401760 [debug] [Thread-3 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.dbt_anirudh.bronze_returns) - Creating connection
[0m23:50:18.402631 [debug] [Thread-3 (]: Acquiring new databricks connection 'model.dbt_anirudh.bronze_returns'
[0m23:50:18.403351 [debug] [Thread-3 (]: Began compiling node model.dbt_anirudh.bronze_returns
[0m23:50:18.407068 [debug] [Thread-3 (]: Writing injected SQL for node "model.dbt_anirudh.bronze_returns"
[0m23:50:18.407882 [debug] [Thread-3 (]: Began executing node model.dbt_anirudh.bronze_returns
[0m23:50:18.410513 [debug] [Thread-3 (]: MATERIALIZING TABLE
[0m23:50:18.412621 [debug] [Thread-3 (]: Writing runtime sql for node "model.dbt_anirudh.bronze_returns"
[0m23:50:18.413120 [debug] [Thread-3 (]: Using databricks connection "model.dbt_anirudh.bronze_returns"
[0m23:50:18.413460 [debug] [Thread-3 (]: On model.dbt_anirudh.bronze_returns: /* {"app": "dbt", "dbt_version": "1.10.10", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_anirudh", "target_name": "dev", "node_id": "model.dbt_anirudh.bronze_returns"} */

  
    
        create or replace table `dbt_learning`.`default`.`bronze_returns`
      
      
  using delta
      
      
      
      
      
      
      
      as
      SELECT
    *
FROM
    `dbt_learning`.`source`.`fact_returns`
  
[0m23:50:18.413737 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m23:50:19.512437 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f08f3b-f926-1e38-a37c-cfdaa2613e4a) - Created
[0m23:50:22.268172 [debug] [Thread-3 (]: SQL status: OK in 3.850 seconds
[0m23:50:22.270903 [debug] [Thread-3 (]: Databricks adapter: Cursor(session-id=01f08f3b-f926-1e38-a37c-cfdaa2613e4a, command-id=01f08f3b-f952-1201-b0a9-c0c2464c4b96) - Closing
[0m23:50:22.272910 [debug] [Thread-3 (]: Applying tags to relation None
[0m23:50:22.276486 [debug] [Thread-3 (]: On model.dbt_anirudh.bronze_returns: Close
[0m23:50:22.277506 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f08f3b-f926-1e38-a37c-cfdaa2613e4a) - Closing
[0m23:50:22.581865 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a2660097-df59-49fc-a440-d1b28fca3dc8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x76c31c4935c0>]}
[0m23:50:22.584143 [info ] [Thread-3 (]: 4 of 6 OK created sql table model default.bronze_returns ....................... [[32mOK[0m in 4.18s]
[0m23:50:22.585567 [debug] [Thread-3 (]: Finished running node model.dbt_anirudh.bronze_returns
[0m23:50:22.586500 [debug] [Thread-3 (]: Began running node model.dbt_anirudh.bronze_sales
[0m23:50:22.587681 [info ] [Thread-3 (]: 5 of 6 START sql table model default.bronze_sales .............................. [RUN]
[0m23:50:22.588586 [debug] [Thread-3 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.dbt_anirudh.bronze_sales) - Creating connection
[0m23:50:22.589207 [debug] [Thread-3 (]: Acquiring new databricks connection 'model.dbt_anirudh.bronze_sales'
[0m23:50:22.589805 [debug] [Thread-3 (]: Began compiling node model.dbt_anirudh.bronze_sales
[0m23:50:22.594820 [debug] [Thread-3 (]: Writing injected SQL for node "model.dbt_anirudh.bronze_sales"
[0m23:50:22.595391 [debug] [Thread-3 (]: Began executing node model.dbt_anirudh.bronze_sales
[0m23:50:22.597044 [debug] [Thread-3 (]: MATERIALIZING TABLE
[0m23:50:22.598950 [debug] [Thread-3 (]: Writing runtime sql for node "model.dbt_anirudh.bronze_sales"
[0m23:50:22.599482 [debug] [Thread-3 (]: Using databricks connection "model.dbt_anirudh.bronze_sales"
[0m23:50:22.599856 [debug] [Thread-3 (]: On model.dbt_anirudh.bronze_sales: /* {"app": "dbt", "dbt_version": "1.10.10", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_anirudh", "target_name": "dev", "node_id": "model.dbt_anirudh.bronze_sales"} */

  
    
        create or replace table `dbt_learning`.`default`.`bronze_sales`
      
      
  using delta
      
      
      
      
      
      
      
      as
      SELECT 
    * 
FROM
    
    `dbt_learning`.`source`.`fact_sales`
  
[0m23:50:22.600186 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m23:50:23.710924 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f08f3b-fba7-1aa3-8046-0595a9e89a86) - Created
[0m23:50:26.745196 [debug] [Thread-3 (]: SQL status: OK in 4.140 seconds
[0m23:50:26.747912 [debug] [Thread-3 (]: Databricks adapter: Cursor(session-id=01f08f3b-fba7-1aa3-8046-0595a9e89a86, command-id=01f08f3b-fbd3-175e-ba2d-71039c8d18b5) - Closing
[0m23:50:26.749712 [debug] [Thread-3 (]: Applying tags to relation None
[0m23:50:26.753177 [debug] [Thread-3 (]: On model.dbt_anirudh.bronze_sales: Close
[0m23:50:26.753871 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f08f3b-fba7-1aa3-8046-0595a9e89a86) - Closing
[0m23:50:27.074436 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a2660097-df59-49fc-a440-d1b28fca3dc8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x76c31c4bbb30>]}
[0m23:50:27.076367 [info ] [Thread-3 (]: 5 of 6 OK created sql table model default.bronze_sales ......................... [[32mOK[0m in 4.49s]
[0m23:50:27.078091 [debug] [Thread-3 (]: Finished running node model.dbt_anirudh.bronze_sales
[0m23:50:27.079079 [debug] [Thread-3 (]: Began running node model.dbt_anirudh.bronze_store
[0m23:50:27.080161 [info ] [Thread-3 (]: 6 of 6 START sql table model default.bronze_store .............................. [RUN]
[0m23:50:27.081507 [debug] [Thread-3 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.dbt_anirudh.bronze_store) - Creating connection
[0m23:50:27.082303 [debug] [Thread-3 (]: Acquiring new databricks connection 'model.dbt_anirudh.bronze_store'
[0m23:50:27.083199 [debug] [Thread-3 (]: Began compiling node model.dbt_anirudh.bronze_store
[0m23:50:27.088729 [debug] [Thread-3 (]: Writing injected SQL for node "model.dbt_anirudh.bronze_store"
[0m23:50:27.089327 [debug] [Thread-3 (]: Began executing node model.dbt_anirudh.bronze_store
[0m23:50:27.095612 [debug] [Thread-3 (]: MATERIALIZING TABLE
[0m23:50:27.097561 [debug] [Thread-3 (]: Writing runtime sql for node "model.dbt_anirudh.bronze_store"
[0m23:50:27.097962 [debug] [Thread-3 (]: Using databricks connection "model.dbt_anirudh.bronze_store"
[0m23:50:27.098289 [debug] [Thread-3 (]: On model.dbt_anirudh.bronze_store: /* {"app": "dbt", "dbt_version": "1.10.10", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_anirudh", "target_name": "dev", "node_id": "model.dbt_anirudh.bronze_store"} */

  
    
        create or replace table `dbt_learning`.`default`.`bronze_store`
      
      
  using delta
      
      
      
      
      
      
      
      as
      SELECT
    *
FROM
    `dbt_learning`.`source`.`dim_store`
  
[0m23:50:27.098584 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m23:50:28.235519 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f08f3b-fe58-158b-86eb-0ef536c11907) - Created
[0m23:50:31.127688 [debug] [Thread-3 (]: SQL status: OK in 4.030 seconds
[0m23:50:31.130304 [debug] [Thread-3 (]: Databricks adapter: Cursor(session-id=01f08f3b-fe58-158b-86eb-0ef536c11907, command-id=01f08f3b-fe85-190d-8168-aa556c4eff6c) - Closing
[0m23:50:31.132205 [debug] [Thread-3 (]: Applying tags to relation None
[0m23:50:31.137889 [debug] [Thread-3 (]: On model.dbt_anirudh.bronze_store: Close
[0m23:50:31.138787 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f08f3b-fe58-158b-86eb-0ef536c11907) - Closing
[0m23:50:31.461636 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a2660097-df59-49fc-a440-d1b28fca3dc8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x76c31c4d3740>]}
[0m23:50:31.463618 [info ] [Thread-3 (]: 6 of 6 OK created sql table model default.bronze_store ......................... [[32mOK[0m in 4.38s]
[0m23:50:31.465555 [debug] [Thread-3 (]: Finished running node model.dbt_anirudh.bronze_store
[0m23:50:31.468384 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=master) - Creating connection
[0m23:50:31.469508 [debug] [MainThread]: Acquiring new databricks connection 'master'
[0m23:50:31.471079 [info ] [MainThread]: 
[0m23:50:31.472347 [info ] [MainThread]: Finished running 6 table models in 0 hours 0 minutes and 35.43 seconds (35.43s).
[0m23:50:31.475685 [debug] [MainThread]: Command end result
[0m23:50:31.505189 [debug] [MainThread]: Wrote artifact WritableManifest to /home/aniruth/AI/DBT/DBT_Master/dbt_anirudh/target/manifest.json
[0m23:50:31.506535 [debug] [MainThread]: Wrote artifact SemanticManifest to /home/aniruth/AI/DBT/DBT_Master/dbt_anirudh/target/semantic_manifest.json
[0m23:50:31.511154 [debug] [MainThread]: Wrote artifact RunExecutionResult to /home/aniruth/AI/DBT/DBT_Master/dbt_anirudh/target/run_results.json
[0m23:50:31.511443 [info ] [MainThread]: 
[0m23:50:31.511742 [info ] [MainThread]: [32mCompleted successfully[0m
[0m23:50:31.511993 [info ] [MainThread]: 
[0m23:50:31.512296 [info ] [MainThread]: Done. PASS=6 WARN=0 ERROR=0 SKIP=0 NO-OP=0 TOTAL=6
[0m23:50:31.513227 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 36.944946, "process_in_blocks": "2992", "process_kernel_time": 0.22393, "process_mem_max_rss": "246936", "process_out_blocks": "3328", "process_user_time": 4.360654}
[0m23:50:31.513601 [debug] [MainThread]: Command `dbt run` succeeded at 23:50:31.513528 after 36.95 seconds
[0m23:50:31.513936 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x76c344256ba0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x76c3447a4f80>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x76c344f3a390>]}
[0m23:50:31.514285 [debug] [MainThread]: Flushing usage events
[0m23:50:32.759408 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m22:45:59.624437 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x77734b811940>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x77734ae9cfb0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x77734c29f170>]}


============================== 22:45:59.627735 | 9a5d7e2a-db07-469d-b099-3f22f14c0bf0 ==============================
[0m22:45:59.627735 [info ] [MainThread]: Running with dbt=1.10.10
[0m22:45:59.628202 [debug] [MainThread]: running dbt with arguments {'send_anonymous_usage_stats': 'True', 'profiles_dir': '/home/aniruth/AI/DBT/DBT_Master/dbt_anirudh', 'debug': 'False', 'fail_fast': 'False', 'log_format': 'default', 'partial_parse': 'True', 'warn_error': 'None', 'log_cache_events': 'False', 'empty': 'None', 'no_print': 'None', 'printer_width': '80', 'version_check': 'True', 'introspect': 'True', 'cache_selected_only': 'False', 'use_colors': 'True', 'static_parser': 'True', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'indirect_selection': 'eager', 'use_experimental_parser': 'False', 'log_path': '/home/aniruth/AI/DBT/DBT_Master/dbt_anirudh/logs', 'write_json': 'True', 'invocation_command': 'dbt clean', 'quiet': 'False'}
[0m22:45:59.717570 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '9a5d7e2a-db07-469d-b099-3f22f14c0bf0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x77734a66f5c0>]}
[0m22:45:59.732412 [debug] [MainThread]: Resource report: {"command_name": "clean", "command_success": true, "command_wall_clock_time": 0.14902419, "process_in_blocks": "78480", "process_kernel_time": 0.105938, "process_mem_max_rss": "100240", "process_out_blocks": "24", "process_user_time": 1.059383}
[0m22:45:59.732831 [debug] [MainThread]: Command `dbt clean` succeeded at 22:45:59.732747 after 0.15 seconds
[0m22:45:59.733133 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x77734b51dbb0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x77734a8f3710>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x77734c29f170>]}
[0m22:45:59.733526 [debug] [MainThread]: Flushing usage events
[0m22:46:00.933804 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m23:00:05.921654 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7732f0e579b0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7732f284a390>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7732f08d0fb0>]}


============================== 23:00:05.924817 | bef03264-1e67-421f-b8e3-b10726d9bcdf ==============================
[0m23:00:05.924817 [info ] [MainThread]: Running with dbt=1.10.10
[0m23:00:05.925289 [debug] [MainThread]: running dbt with arguments {'debug': 'False', 'empty': 'False', 'fail_fast': 'False', 'version_check': 'True', 'send_anonymous_usage_stats': 'True', 'cache_selected_only': 'False', 'introspect': 'True', 'partial_parse': 'True', 'no_print': 'None', 'invocation_command': 'dbt run', 'profiles_dir': '/home/aniruth/AI/DBT/DBT_Master/dbt_anirudh', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'target_path': 'None', 'log_cache_events': 'False', 'printer_width': '80', 'log_format': 'default', 'indirect_selection': 'eager', 'warn_error': 'None', 'write_json': 'True', 'quiet': 'False', 'log_path': '/home/aniruth/AI/DBT/DBT_Master/dbt_anirudh/logs', 'use_experimental_parser': 'False', 'use_colors': 'True', 'static_parser': 'True'}
[0m23:00:06.545758 [debug] [MainThread]: Spark adapter: Setting pyhive.hive logging to ERROR
[0m23:00:06.546155 [debug] [MainThread]: Spark adapter: Setting thrift.transport logging to ERROR
[0m23:00:06.546437 [debug] [MainThread]: Spark adapter: Setting thrift.protocol logging to ERROR
[0m23:00:07.262045 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'bef03264-1e67-421f-b8e3-b10726d9bcdf', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7732cb483bc0>]}
[0m23:00:07.307459 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'bef03264-1e67-421f-b8e3-b10726d9bcdf', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7732cbcb8470>]}
[0m23:00:07.308028 [info ] [MainThread]: Registered adapter: databricks=1.10.9
[0m23:00:07.395529 [debug] [MainThread]: checksum: 502a0dc23e9052e1ae09f7c44ee219ef7a02dfea7e7d66580d54c304c14d553b, vars: {}, profile: , target: , version: 1.10.10
[0m23:00:07.467047 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m23:00:07.467365 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m23:00:07.493192 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'bef03264-1e67-421f-b8e3-b10726d9bcdf', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7732caf56750>]}
[0m23:00:07.544838 [debug] [MainThread]: Wrote artifact WritableManifest to /home/aniruth/AI/DBT/DBT_Master/dbt_anirudh/target/manifest.json
[0m23:00:07.546364 [debug] [MainThread]: Wrote artifact SemanticManifest to /home/aniruth/AI/DBT/DBT_Master/dbt_anirudh/target/semantic_manifest.json
[0m23:00:07.553391 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'bef03264-1e67-421f-b8e3-b10726d9bcdf', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7732ca9e5c10>]}
[0m23:00:07.553757 [info ] [MainThread]: Found 6 models, 6 sources, 685 macros
[0m23:00:07.554040 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'bef03264-1e67-421f-b8e3-b10726d9bcdf', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7732cabd3ec0>]}
[0m23:00:07.555493 [info ] [MainThread]: 
[0m23:00:07.555803 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m23:00:07.556043 [info ] [MainThread]: 
[0m23:00:07.556453 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=master) - Creating connection
[0m23:00:07.556694 [debug] [MainThread]: Acquiring new databricks connection 'master'
[0m23:00:07.561840 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=list_dbt_learning) - Creating connection
[0m23:00:07.562223 [debug] [ThreadPool]: Acquiring new databricks connection 'list_dbt_learning'
[0m23:00:07.562546 [debug] [ThreadPool]: Using databricks connection "list_dbt_learning"
[0m23:00:07.562806 [debug] [ThreadPool]: On list_dbt_learning: GetSchemas(database=dbt_learning, schema=None)
[0m23:00:07.563055 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m23:00:09.087242 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f08ffe-2109-1307-85fe-095219ab0915) - Created
[0m23:01:11.029918 [debug] [ThreadPool]: SQL status: OK in 63.470 seconds
[0m23:01:11.033115 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01f08ffe-2109-1307-85fe-095219ab0915, command-id=01f08ffe-4546-10fd-869c-36ab90a1e4d6) - Closing
[0m23:01:11.034255 [debug] [ThreadPool]: On list_dbt_learning: Close
[0m23:01:11.035043 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f08ffe-2109-1307-85fe-095219ab0915) - Closing
[0m23:01:11.448064 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=list_dbt_learning_default) - Creating connection
[0m23:01:11.449092 [debug] [ThreadPool]: Acquiring new databricks connection 'list_dbt_learning_default'
[0m23:01:11.469833 [debug] [ThreadPool]: Using databricks connection "list_dbt_learning_default"
[0m23:01:11.470301 [debug] [ThreadPool]: On list_dbt_learning_default: /* {"app": "dbt", "dbt_version": "1.10.10", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_anirudh", "target_name": "dev", "connection_name": "list_dbt_learning_default"} */

    
SELECT
  table_name,
  if(table_type IN ('EXTERNAL', 'MANAGED', 'MANAGED_SHALLOW_CLONE', 'EXTERNAL_SHALLOW_CLONE'), 'table', lower(table_type)) AS table_type,
  lower(data_source_format) AS file_format,
  table_owner,
  if(
    table_type IN (
      'EXTERNAL',
      'MANAGED',
      'MANAGED_SHALLOW_CLONE',
      'EXTERNAL_SHALLOW_CLONE'
    ),
    lower(table_type),
    NULL
  ) AS databricks_table_type
FROM `system`.`information_schema`.`tables`
WHERE table_catalog = 'dbt_learning' 
  AND table_schema = 'default'

  
[0m23:01:11.470631 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m23:01:12.574496 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f08ffe-46fc-1ef7-96ce-e6e66c751f96) - Created
[0m23:01:15.678006 [debug] [ThreadPool]: SQL status: OK in 4.210 seconds
[0m23:01:15.688276 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01f08ffe-46fc-1ef7-96ce-e6e66c751f96, command-id=01f08ffe-4727-137a-ba09-2ee5da22442e) - Closing
[0m23:01:15.689715 [debug] [ThreadPool]: On list_dbt_learning_default: Close
[0m23:01:15.690450 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f08ffe-46fc-1ef7-96ce-e6e66c751f96) - Closing
[0m23:01:15.981108 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'bef03264-1e67-421f-b8e3-b10726d9bcdf', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7732f26c4710>]}
[0m23:01:15.986954 [debug] [Thread-3 (]: Began running node model.dbt_anirudh.bronze_customer
[0m23:01:15.988356 [info ] [Thread-3 (]: 1 of 6 START sql table model default.bronze_customer ........................... [RUN]
[0m23:01:15.989968 [debug] [Thread-3 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.dbt_anirudh.bronze_customer) - Creating connection
[0m23:01:15.990925 [debug] [Thread-3 (]: Acquiring new databricks connection 'model.dbt_anirudh.bronze_customer'
[0m23:01:15.991758 [debug] [Thread-3 (]: Began compiling node model.dbt_anirudh.bronze_customer
[0m23:01:16.000864 [debug] [Thread-3 (]: Writing injected SQL for node "model.dbt_anirudh.bronze_customer"
[0m23:01:16.001722 [debug] [Thread-3 (]: Began executing node model.dbt_anirudh.bronze_customer
[0m23:01:16.014692 [debug] [Thread-3 (]: MATERIALIZING TABLE
[0m23:01:16.015220 [warn ] [Thread-3 (]: [[33mWARNING[0m]: Use revamped materializations based on separating create and insert.  This allows more performant column comments, as well as new column features.
You may opt into the new behavior sooner by setting `flags.use_materialization_v2` to `True` in `dbt_project.yml`.
Visit https://docs.getdbt.com/reference/global-configs/behavior-changes for more information.
[0m23:01:16.015616 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'BehaviorChangeEvent', 'label': 'bef03264-1e67-421f-b8e3-b10726d9bcdf', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7732caa742f0>]}
[0m23:01:16.050396 [debug] [Thread-3 (]: Writing runtime sql for node "model.dbt_anirudh.bronze_customer"
[0m23:01:16.050982 [debug] [Thread-3 (]: Using databricks connection "model.dbt_anirudh.bronze_customer"
[0m23:01:16.051327 [debug] [Thread-3 (]: On model.dbt_anirudh.bronze_customer: /* {"app": "dbt", "dbt_version": "1.10.10", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_anirudh", "target_name": "dev", "node_id": "model.dbt_anirudh.bronze_customer"} */

  
    
        create or replace table `dbt_learning`.`default`.`bronze_customer`
      
      
  using delta
      
      
      
      
      
      
      
      as
      SELECT 
    *
FROM
    `dbt_learning`.`source`.`dim_customer`
  
[0m23:01:16.051621 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m23:01:17.108733 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f08ffe-49b0-1877-a084-59ae182b4c47) - Created
[0m23:01:28.710833 [debug] [Thread-3 (]: SQL status: OK in 12.660 seconds
[0m23:01:28.713119 [debug] [Thread-3 (]: Databricks adapter: Cursor(session-id=01f08ffe-49b0-1877-a084-59ae182b4c47, command-id=01f08ffe-49d9-1ced-b73a-28e7e55aef16) - Closing
[0m23:01:29.078046 [debug] [Thread-3 (]: Applying tags to relation None
[0m23:01:29.091472 [debug] [Thread-3 (]: On model.dbt_anirudh.bronze_customer: Close
[0m23:01:29.091876 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f08ffe-49b0-1877-a084-59ae182b4c47) - Closing
[0m23:01:29.392500 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'bef03264-1e67-421f-b8e3-b10726d9bcdf', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7732f25f9dc0>]}
[0m23:01:29.394124 [info ] [Thread-3 (]: 1 of 6 OK created sql table model default.bronze_customer ...................... [[32mOK[0m in 13.40s]
[0m23:01:29.395634 [debug] [Thread-3 (]: Finished running node model.dbt_anirudh.bronze_customer
[0m23:01:29.396923 [debug] [Thread-3 (]: Began running node model.dbt_anirudh.bronze_date
[0m23:01:29.398149 [info ] [Thread-3 (]: 2 of 6 START sql view model default.bronze_date ................................ [RUN]
[0m23:01:29.399479 [debug] [Thread-3 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.dbt_anirudh.bronze_date) - Creating connection
[0m23:01:29.400296 [debug] [Thread-3 (]: Acquiring new databricks connection 'model.dbt_anirudh.bronze_date'
[0m23:01:29.401115 [debug] [Thread-3 (]: Began compiling node model.dbt_anirudh.bronze_date
[0m23:01:29.405727 [debug] [Thread-3 (]: Writing injected SQL for node "model.dbt_anirudh.bronze_date"
[0m23:01:29.406454 [debug] [Thread-3 (]: Began executing node model.dbt_anirudh.bronze_date
[0m23:01:29.425127 [debug] [Thread-3 (]: MATERIALIZING VIEW
[0m23:01:29.431193 [debug] [Thread-3 (]: Dropping relation `dbt_learning`.`default`.`bronze_date` because it is of type table
[0m23:01:29.436122 [debug] [Thread-3 (]: Applying DROP to: `dbt_learning`.`default`.`bronze_date`
[0m23:01:29.439829 [debug] [Thread-3 (]: Using databricks connection "model.dbt_anirudh.bronze_date"
[0m23:01:29.440135 [debug] [Thread-3 (]: On model.dbt_anirudh.bronze_date: /* {"app": "dbt", "dbt_version": "1.10.10", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_anirudh", "target_name": "dev", "node_id": "model.dbt_anirudh.bronze_date"} */
drop table if exists `dbt_learning`.`default`.`bronze_date`
[0m23:01:29.440415 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m23:01:30.577863 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f08ffe-51b4-18cf-98c1-985cf35d16c7) - Created
[0m23:01:31.675096 [debug] [Thread-3 (]: SQL status: OK in 2.230 seconds
[0m23:01:31.676342 [debug] [Thread-3 (]: Databricks adapter: Cursor(session-id=01f08ffe-51b4-18cf-98c1-985cf35d16c7, command-id=01f08ffe-51e2-1fba-a191-b1425f81b7f9) - Closing
[0m23:01:31.685179 [debug] [Thread-3 (]: Creating view `dbt_learning`.`default`.`bronze_date`
[0m23:01:31.685976 [debug] [Thread-3 (]: Writing runtime sql for node "model.dbt_anirudh.bronze_date"
[0m23:01:31.686384 [debug] [Thread-3 (]: Using databricks connection "model.dbt_anirudh.bronze_date"
[0m23:01:31.686694 [debug] [Thread-3 (]: On model.dbt_anirudh.bronze_date: /* {"app": "dbt", "dbt_version": "1.10.10", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_anirudh", "target_name": "dev", "node_id": "model.dbt_anirudh.bronze_date"} */

  
  
  create or replace view `dbt_learning`.`default`.`bronze_date`
  
  as (
    SELECT  
    *
FROM
    `dbt_learning`.`source`.`dim_date`
  )

[0m23:01:32.883561 [debug] [Thread-3 (]: SQL status: OK in 1.200 seconds
[0m23:01:32.885832 [debug] [Thread-3 (]: Databricks adapter: Cursor(session-id=01f08ffe-51b4-18cf-98c1-985cf35d16c7, command-id=01f08ffe-528c-1050-94bd-abff1ae5f2c6) - Closing
[0m23:01:32.887690 [debug] [Thread-3 (]: Applying tags to relation None
[0m23:01:32.889465 [debug] [Thread-3 (]: On model.dbt_anirudh.bronze_date: Close
[0m23:01:32.890246 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f08ffe-51b4-18cf-98c1-985cf35d16c7) - Closing
[0m23:01:33.205889 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'bef03264-1e67-421f-b8e3-b10726d9bcdf', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7732c813b530>]}
[0m23:01:33.207560 [info ] [Thread-3 (]: 2 of 6 OK created sql view model default.bronze_date ........................... [[32mOK[0m in 3.81s]
[0m23:01:33.209158 [debug] [Thread-3 (]: Finished running node model.dbt_anirudh.bronze_date
[0m23:01:33.210639 [debug] [Thread-3 (]: Began running node model.dbt_anirudh.bronze_product
[0m23:01:33.211972 [info ] [Thread-3 (]: 3 of 6 START sql table model default.bronze_product ............................ [RUN]
[0m23:01:33.213249 [debug] [Thread-3 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.dbt_anirudh.bronze_product) - Creating connection
[0m23:01:33.213978 [debug] [Thread-3 (]: Acquiring new databricks connection 'model.dbt_anirudh.bronze_product'
[0m23:01:33.214607 [debug] [Thread-3 (]: Began compiling node model.dbt_anirudh.bronze_product
[0m23:01:33.218228 [debug] [Thread-3 (]: Writing injected SQL for node "model.dbt_anirudh.bronze_product"
[0m23:01:33.218869 [debug] [Thread-3 (]: Began executing node model.dbt_anirudh.bronze_product
[0m23:01:33.220896 [debug] [Thread-3 (]: MATERIALIZING TABLE
[0m23:01:33.222793 [debug] [Thread-3 (]: Writing runtime sql for node "model.dbt_anirudh.bronze_product"
[0m23:01:33.223167 [debug] [Thread-3 (]: Using databricks connection "model.dbt_anirudh.bronze_product"
[0m23:01:33.223498 [debug] [Thread-3 (]: On model.dbt_anirudh.bronze_product: /* {"app": "dbt", "dbt_version": "1.10.10", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_anirudh", "target_name": "dev", "node_id": "model.dbt_anirudh.bronze_product"} */

  
    
        create or replace table `dbt_learning`.`default`.`bronze_product`
      
      
  using delta
      
      
      
      
      
      
      
      as
      SELECT
    *
FROM
    `dbt_learning`.`source`.`dim_product`
  
[0m23:01:33.223780 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m23:01:34.341978 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f08ffe-53f1-1b43-9524-a5eab910b7bd) - Created
[0m23:01:37.913688 [debug] [Thread-3 (]: SQL status: OK in 4.690 seconds
[0m23:01:37.916103 [debug] [Thread-3 (]: Databricks adapter: Cursor(session-id=01f08ffe-53f1-1b43-9524-a5eab910b7bd, command-id=01f08ffe-5420-1d2c-b605-9bbcf6a83641) - Closing
[0m23:01:37.918218 [debug] [Thread-3 (]: Applying tags to relation None
[0m23:01:37.920497 [debug] [Thread-3 (]: On model.dbt_anirudh.bronze_product: Close
[0m23:01:37.921000 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f08ffe-53f1-1b43-9524-a5eab910b7bd) - Closing
[0m23:01:38.212771 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'bef03264-1e67-421f-b8e3-b10726d9bcdf', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7732caa8cbf0>]}
[0m23:01:38.214358 [info ] [Thread-3 (]: 3 of 6 OK created sql table model default.bronze_product ....................... [[32mOK[0m in 5.00s]
[0m23:01:38.215827 [debug] [Thread-3 (]: Finished running node model.dbt_anirudh.bronze_product
[0m23:01:38.216864 [debug] [Thread-3 (]: Began running node model.dbt_anirudh.bronze_returns
[0m23:01:38.218050 [info ] [Thread-3 (]: 4 of 6 START sql table model default.bronze_returns ............................ [RUN]
[0m23:01:38.219268 [debug] [Thread-3 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.dbt_anirudh.bronze_returns) - Creating connection
[0m23:01:38.219914 [debug] [Thread-3 (]: Acquiring new databricks connection 'model.dbt_anirudh.bronze_returns'
[0m23:01:38.220554 [debug] [Thread-3 (]: Began compiling node model.dbt_anirudh.bronze_returns
[0m23:01:38.227761 [debug] [Thread-3 (]: Writing injected SQL for node "model.dbt_anirudh.bronze_returns"
[0m23:01:38.228386 [debug] [Thread-3 (]: Began executing node model.dbt_anirudh.bronze_returns
[0m23:01:38.230228 [debug] [Thread-3 (]: MATERIALIZING TABLE
[0m23:01:38.232156 [debug] [Thread-3 (]: Writing runtime sql for node "model.dbt_anirudh.bronze_returns"
[0m23:01:38.232601 [debug] [Thread-3 (]: Using databricks connection "model.dbt_anirudh.bronze_returns"
[0m23:01:38.232919 [debug] [Thread-3 (]: On model.dbt_anirudh.bronze_returns: /* {"app": "dbt", "dbt_version": "1.10.10", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_anirudh", "target_name": "dev", "node_id": "model.dbt_anirudh.bronze_returns"} */

  
    
        create or replace table `dbt_learning`.`default`.`bronze_returns`
      
      
  using delta
      
      
      
      
      
      
      
      as
      SELECT
    *
FROM
    `dbt_learning`.`source`.`fact_returns`
  
[0m23:01:38.233180 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m23:01:39.336502 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f08ffe-56f0-11ed-9122-e1ccc3853515) - Created
[0m23:01:42.770726 [debug] [Thread-3 (]: SQL status: OK in 4.540 seconds
[0m23:01:42.773170 [debug] [Thread-3 (]: Databricks adapter: Cursor(session-id=01f08ffe-56f0-11ed-9122-e1ccc3853515, command-id=01f08ffe-571b-1612-a48f-06dedd18383a) - Closing
[0m23:01:42.776627 [debug] [Thread-3 (]: Applying tags to relation None
[0m23:01:42.781869 [debug] [Thread-3 (]: On model.dbt_anirudh.bronze_returns: Close
[0m23:01:42.782905 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f08ffe-56f0-11ed-9122-e1ccc3853515) - Closing
[0m23:01:43.091863 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'bef03264-1e67-421f-b8e3-b10726d9bcdf', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7732c815ddf0>]}
[0m23:01:43.093696 [info ] [Thread-3 (]: 4 of 6 OK created sql table model default.bronze_returns ....................... [[32mOK[0m in 4.87s]
[0m23:01:43.095266 [debug] [Thread-3 (]: Finished running node model.dbt_anirudh.bronze_returns
[0m23:01:43.096310 [debug] [Thread-3 (]: Began running node model.dbt_anirudh.bronze_sales
[0m23:01:43.097520 [info ] [Thread-3 (]: 5 of 6 START sql table model default.bronze_sales .............................. [RUN]
[0m23:01:43.099072 [debug] [Thread-3 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.dbt_anirudh.bronze_sales) - Creating connection
[0m23:01:43.100043 [debug] [Thread-3 (]: Acquiring new databricks connection 'model.dbt_anirudh.bronze_sales'
[0m23:01:43.101152 [debug] [Thread-3 (]: Began compiling node model.dbt_anirudh.bronze_sales
[0m23:01:43.106428 [debug] [Thread-3 (]: Writing injected SQL for node "model.dbt_anirudh.bronze_sales"
[0m23:01:43.107320 [debug] [Thread-3 (]: Began executing node model.dbt_anirudh.bronze_sales
[0m23:01:43.114089 [debug] [Thread-3 (]: MATERIALIZING TABLE
[0m23:01:43.115717 [debug] [Thread-3 (]: Writing runtime sql for node "model.dbt_anirudh.bronze_sales"
[0m23:01:43.116088 [debug] [Thread-3 (]: Using databricks connection "model.dbt_anirudh.bronze_sales"
[0m23:01:43.116392 [debug] [Thread-3 (]: On model.dbt_anirudh.bronze_sales: /* {"app": "dbt", "dbt_version": "1.10.10", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_anirudh", "target_name": "dev", "node_id": "model.dbt_anirudh.bronze_sales"} */

  
    
        create or replace table `dbt_learning`.`default`.`bronze_sales`
      
      
  using delta
      
      
      
      
      
      
      
      as
      -- block level config


SELECT 
    * 
FROM
    
    `dbt_learning`.`source`.`fact_sales`
  
[0m23:01:43.116658 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m23:01:44.207915 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f08ffe-59d7-144c-80d7-ed66e4178e6d) - Created
[0m23:01:48.010960 [debug] [Thread-3 (]: SQL status: OK in 4.890 seconds
[0m23:01:48.013160 [debug] [Thread-3 (]: Databricks adapter: Cursor(session-id=01f08ffe-59d7-144c-80d7-ed66e4178e6d, command-id=01f08ffe-5a01-183f-8adc-a4d837fc3f98) - Closing
[0m23:01:48.016030 [debug] [Thread-3 (]: Applying tags to relation None
[0m23:01:48.020306 [debug] [Thread-3 (]: On model.dbt_anirudh.bronze_sales: Close
[0m23:01:48.020951 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f08ffe-59d7-144c-80d7-ed66e4178e6d) - Closing
[0m23:01:48.314043 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'bef03264-1e67-421f-b8e3-b10726d9bcdf', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7732c8172420>]}
[0m23:01:48.316512 [info ] [Thread-3 (]: 5 of 6 OK created sql table model default.bronze_sales ......................... [[32mOK[0m in 5.22s]
[0m23:01:48.318366 [debug] [Thread-3 (]: Finished running node model.dbt_anirudh.bronze_sales
[0m23:01:48.319486 [debug] [Thread-3 (]: Began running node model.dbt_anirudh.bronze_store
[0m23:01:48.320885 [info ] [Thread-3 (]: 6 of 6 START sql view model default.bronze_store ............................... [RUN]
[0m23:01:48.322229 [debug] [Thread-3 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.dbt_anirudh.bronze_store) - Creating connection
[0m23:01:48.323113 [debug] [Thread-3 (]: Acquiring new databricks connection 'model.dbt_anirudh.bronze_store'
[0m23:01:48.324122 [debug] [Thread-3 (]: Began compiling node model.dbt_anirudh.bronze_store
[0m23:01:48.330339 [debug] [Thread-3 (]: Writing injected SQL for node "model.dbt_anirudh.bronze_store"
[0m23:01:48.331903 [debug] [Thread-3 (]: Began executing node model.dbt_anirudh.bronze_store
[0m23:01:48.337212 [debug] [Thread-3 (]: MATERIALIZING VIEW
[0m23:01:48.339769 [debug] [Thread-3 (]: Dropping relation `dbt_learning`.`default`.`bronze_store` because it is of type table
[0m23:01:48.345995 [debug] [Thread-3 (]: Applying DROP to: `dbt_learning`.`default`.`bronze_store`
[0m23:01:48.347902 [debug] [Thread-3 (]: Using databricks connection "model.dbt_anirudh.bronze_store"
[0m23:01:48.349118 [debug] [Thread-3 (]: On model.dbt_anirudh.bronze_store: /* {"app": "dbt", "dbt_version": "1.10.10", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_anirudh", "target_name": "dev", "node_id": "model.dbt_anirudh.bronze_store"} */
drop table if exists `dbt_learning`.`default`.`bronze_store`
[0m23:01:48.350262 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m23:01:49.434443 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f08ffe-5cf5-18cd-9e4e-242b5c0ab903) - Created
[0m23:01:50.376201 [debug] [Thread-3 (]: SQL status: OK in 2.030 seconds
[0m23:01:50.378686 [debug] [Thread-3 (]: Databricks adapter: Cursor(session-id=01f08ffe-5cf5-18cd-9e4e-242b5c0ab903, command-id=01f08ffe-5d1f-120e-a7da-0d2542b23d45) - Closing
[0m23:01:50.381934 [debug] [Thread-3 (]: Creating view `dbt_learning`.`default`.`bronze_store`
[0m23:01:50.384079 [debug] [Thread-3 (]: Writing runtime sql for node "model.dbt_anirudh.bronze_store"
[0m23:01:50.384999 [debug] [Thread-3 (]: Using databricks connection "model.dbt_anirudh.bronze_store"
[0m23:01:50.385787 [debug] [Thread-3 (]: On model.dbt_anirudh.bronze_store: /* {"app": "dbt", "dbt_version": "1.10.10", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_anirudh", "target_name": "dev", "node_id": "model.dbt_anirudh.bronze_store"} */

  
  
  create or replace view `dbt_learning`.`default`.`bronze_store`
  
  as (
    SELECT
    *
FROM
    `dbt_learning`.`source`.`dim_store`
  )

[0m23:01:51.310701 [debug] [Thread-3 (]: SQL status: OK in 0.920 seconds
[0m23:01:51.313163 [debug] [Thread-3 (]: Databricks adapter: Cursor(session-id=01f08ffe-5cf5-18cd-9e4e-242b5c0ab903, command-id=01f08ffe-5db0-15b9-ad20-129dd5ea79d6) - Closing
[0m23:01:51.315076 [debug] [Thread-3 (]: Applying tags to relation None
[0m23:01:51.316940 [debug] [Thread-3 (]: On model.dbt_anirudh.bronze_store: Close
[0m23:01:51.317922 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f08ffe-5cf5-18cd-9e4e-242b5c0ab903) - Closing
[0m23:01:51.607582 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'bef03264-1e67-421f-b8e3-b10726d9bcdf', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7732c8148dd0>]}
[0m23:01:51.609281 [info ] [Thread-3 (]: 6 of 6 OK created sql view model default.bronze_store .......................... [[32mOK[0m in 3.28s]
[0m23:01:51.610734 [debug] [Thread-3 (]: Finished running node model.dbt_anirudh.bronze_store
[0m23:01:51.613318 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=master) - Creating connection
[0m23:01:51.614226 [debug] [MainThread]: Acquiring new databricks connection 'master'
[0m23:01:51.615317 [info ] [MainThread]: 
[0m23:01:51.616259 [info ] [MainThread]: Finished running 4 table models, 2 view models in 0 hours 1 minutes and 44.06 seconds (104.06s).
[0m23:01:51.619370 [debug] [MainThread]: Command end result
[0m23:01:51.646346 [debug] [MainThread]: Wrote artifact WritableManifest to /home/aniruth/AI/DBT/DBT_Master/dbt_anirudh/target/manifest.json
[0m23:01:51.648021 [debug] [MainThread]: Wrote artifact SemanticManifest to /home/aniruth/AI/DBT/DBT_Master/dbt_anirudh/target/semantic_manifest.json
[0m23:01:51.652653 [debug] [MainThread]: Wrote artifact RunExecutionResult to /home/aniruth/AI/DBT/DBT_Master/dbt_anirudh/target/run_results.json
[0m23:01:51.652973 [info ] [MainThread]: 
[0m23:01:51.653255 [info ] [MainThread]: [32mCompleted successfully[0m
[0m23:01:51.653511 [info ] [MainThread]: 
[0m23:01:51.653762 [info ] [MainThread]: Done. PASS=6 WARN=0 ERROR=0 SKIP=0 NO-OP=0 TOTAL=6
[0m23:01:51.654691 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 105.7719, "process_in_blocks": "249528", "process_kernel_time": 0.256871, "process_mem_max_rss": "238632", "process_out_blocks": "3232", "process_user_time": 4.351827}
[0m23:01:51.655045 [debug] [MainThread]: Command `dbt run` succeeded at 23:01:51.654975 after 105.77 seconds
[0m23:01:51.655321 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7732f01d08f0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7732f06960f0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7732f0c9f050>]}
[0m23:01:51.655621 [debug] [MainThread]: Flushing usage events
[0m23:01:53.409374 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m23:05:12.596525 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7c2c687e1880>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7c2c6a3c5940>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7c2c68aed9d0>]}


============================== 23:05:12.599805 | 76233906-3960-4db1-9199-44e3b06743f1 ==============================
[0m23:05:12.599805 [info ] [MainThread]: Running with dbt=1.10.10
[0m23:05:12.600264 [debug] [MainThread]: running dbt with arguments {'quiet': 'False', 'static_parser': 'True', 'profiles_dir': '/home/aniruth/AI/DBT/DBT_Master/dbt_anirudh', 'log_cache_events': 'False', 'use_colors': 'True', 'empty': 'False', 'indirect_selection': 'eager', 'target_path': 'None', 'cache_selected_only': 'False', 'log_format': 'default', 'introspect': 'True', 'write_json': 'True', 'log_path': '/home/aniruth/AI/DBT/DBT_Master/dbt_anirudh/logs', 'version_check': 'True', 'use_experimental_parser': 'False', 'invocation_command': 'dbt run', 'no_print': 'None', 'printer_width': '80', 'warn_error': 'None', 'send_anonymous_usage_stats': 'True', 'fail_fast': 'False', 'partial_parse': 'True', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'debug': 'False'}
[0m23:05:13.240732 [debug] [MainThread]: Spark adapter: Setting pyhive.hive logging to ERROR
[0m23:05:13.241172 [debug] [MainThread]: Spark adapter: Setting thrift.transport logging to ERROR
[0m23:05:13.241574 [debug] [MainThread]: Spark adapter: Setting thrift.protocol logging to ERROR
[0m23:05:13.823953 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '76233906-3960-4db1-9199-44e3b06743f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7c2c43ec2150>]}
[0m23:05:13.869080 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '76233906-3960-4db1-9199-44e3b06743f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7c2c42f769c0>]}
[0m23:05:13.869606 [info ] [MainThread]: Registered adapter: databricks=1.10.9
[0m23:05:13.947717 [debug] [MainThread]: checksum: 502a0dc23e9052e1ae09f7c44ee219ef7a02dfea7e7d66580d54c304c14d553b, vars: {}, profile: , target: , version: 1.10.10
[0m23:05:14.019556 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m23:05:14.019886 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m23:05:14.045521 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '76233906-3960-4db1-9199-44e3b06743f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7c2c42b86180>]}
[0m23:05:14.099773 [debug] [MainThread]: Wrote artifact WritableManifest to /home/aniruth/AI/DBT/DBT_Master/dbt_anirudh/target/manifest.json
[0m23:05:14.101271 [debug] [MainThread]: Wrote artifact SemanticManifest to /home/aniruth/AI/DBT/DBT_Master/dbt_anirudh/target/semantic_manifest.json
[0m23:05:14.108287 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '76233906-3960-4db1-9199-44e3b06743f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7c2c42b87380>]}
[0m23:05:14.108686 [info ] [MainThread]: Found 6 models, 6 sources, 685 macros
[0m23:05:14.108981 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '76233906-3960-4db1-9199-44e3b06743f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7c2c4286bda0>]}
[0m23:05:14.110481 [info ] [MainThread]: 
[0m23:05:14.110808 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m23:05:14.111065 [info ] [MainThread]: 
[0m23:05:14.111477 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=master) - Creating connection
[0m23:05:14.111723 [debug] [MainThread]: Acquiring new databricks connection 'master'
[0m23:05:14.116809 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=list_dbt_learning) - Creating connection
[0m23:05:14.117265 [debug] [ThreadPool]: Acquiring new databricks connection 'list_dbt_learning'
[0m23:05:14.117568 [debug] [ThreadPool]: Using databricks connection "list_dbt_learning"
[0m23:05:14.117810 [debug] [ThreadPool]: On list_dbt_learning: GetSchemas(database=dbt_learning, schema=None)
[0m23:05:14.118036 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m23:05:15.452476 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f08ffe-d7b6-1fa6-934d-15154683c887) - Created
[0m23:05:15.909822 [debug] [ThreadPool]: SQL status: OK in 1.790 seconds
[0m23:05:15.912819 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01f08ffe-d7b6-1fa6-934d-15154683c887, command-id=01f08ffe-d7e8-1aad-bfee-0d7006334f72) - Closing
[0m23:05:15.913917 [debug] [ThreadPool]: On list_dbt_learning: Close
[0m23:05:15.914749 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f08ffe-d7b6-1fa6-934d-15154683c887) - Closing
[0m23:05:16.317407 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=list_dbt_learning_default) - Creating connection
[0m23:05:16.318823 [debug] [ThreadPool]: Acquiring new databricks connection 'list_dbt_learning_default'
[0m23:05:16.342142 [debug] [ThreadPool]: Using databricks connection "list_dbt_learning_default"
[0m23:05:16.342535 [debug] [ThreadPool]: On list_dbt_learning_default: /* {"app": "dbt", "dbt_version": "1.10.10", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_anirudh", "target_name": "dev", "connection_name": "list_dbt_learning_default"} */

    
SELECT
  table_name,
  if(table_type IN ('EXTERNAL', 'MANAGED', 'MANAGED_SHALLOW_CLONE', 'EXTERNAL_SHALLOW_CLONE'), 'table', lower(table_type)) AS table_type,
  lower(data_source_format) AS file_format,
  table_owner,
  if(
    table_type IN (
      'EXTERNAL',
      'MANAGED',
      'MANAGED_SHALLOW_CLONE',
      'EXTERNAL_SHALLOW_CLONE'
    ),
    lower(table_type),
    NULL
  ) AS databricks_table_type
FROM `system`.`information_schema`.`tables`
WHERE table_catalog = 'dbt_learning' 
  AND table_schema = 'default'

  
[0m23:05:16.342797 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m23:05:17.837435 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f08ffe-d91c-10b1-a9bb-3608d1ab96e9) - Created
[0m23:05:18.591692 [debug] [ThreadPool]: SQL status: OK in 2.250 seconds
[0m23:05:18.600950 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01f08ffe-d91c-10b1-a9bb-3608d1ab96e9, command-id=01f08ffe-d956-1697-a4b8-d67455edfb10) - Closing
[0m23:05:18.602581 [debug] [ThreadPool]: On list_dbt_learning_default: Close
[0m23:05:18.603545 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f08ffe-d91c-10b1-a9bb-3608d1ab96e9) - Closing
[0m23:05:19.013221 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '76233906-3960-4db1-9199-44e3b06743f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7c2c6a19c380>]}
[0m23:05:19.019100 [debug] [Thread-3 (]: Began running node model.dbt_anirudh.bronze_customer
[0m23:05:19.020507 [info ] [Thread-3 (]: 1 of 6 START sql table model default.bronze_customer ........................... [RUN]
[0m23:05:19.021909 [debug] [Thread-3 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.dbt_anirudh.bronze_customer) - Creating connection
[0m23:05:19.022879 [debug] [Thread-3 (]: Acquiring new databricks connection 'model.dbt_anirudh.bronze_customer'
[0m23:05:19.023746 [debug] [Thread-3 (]: Began compiling node model.dbt_anirudh.bronze_customer
[0m23:05:19.036648 [debug] [Thread-3 (]: Writing injected SQL for node "model.dbt_anirudh.bronze_customer"
[0m23:05:19.037263 [debug] [Thread-3 (]: Began executing node model.dbt_anirudh.bronze_customer
[0m23:05:19.051123 [debug] [Thread-3 (]: MATERIALIZING TABLE
[0m23:05:19.051778 [warn ] [Thread-3 (]: [[33mWARNING[0m]: Use revamped materializations based on separating create and insert.  This allows more performant column comments, as well as new column features.
You may opt into the new behavior sooner by setting `flags.use_materialization_v2` to `True` in `dbt_project.yml`.
Visit https://docs.getdbt.com/reference/global-configs/behavior-changes for more information.
[0m23:05:19.052181 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'BehaviorChangeEvent', 'label': '76233906-3960-4db1-9199-44e3b06743f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7c2c426583e0>]}
[0m23:05:19.086640 [debug] [Thread-3 (]: Writing runtime sql for node "model.dbt_anirudh.bronze_customer"
[0m23:05:19.087271 [debug] [Thread-3 (]: Using databricks connection "model.dbt_anirudh.bronze_customer"
[0m23:05:19.087655 [debug] [Thread-3 (]: On model.dbt_anirudh.bronze_customer: /* {"app": "dbt", "dbt_version": "1.10.10", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_anirudh", "target_name": "dev", "node_id": "model.dbt_anirudh.bronze_customer"} */

  
    
        create or replace table `dbt_learning`.`default`.`bronze_customer`
      
      
  using delta
      
      
      
      
      
      
      
      as
      SELECT 
    *
FROM
    `dbt_learning`.`source`.`dim_customer`
  
[0m23:05:19.087942 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m23:05:20.590881 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f08ffe-dabc-1445-ba07-37f06f6b7fcd) - Created
[0m23:05:22.915259 [debug] [Thread-3 (]: SQL status: OK in 3.830 seconds
[0m23:05:22.917708 [debug] [Thread-3 (]: Databricks adapter: Cursor(session-id=01f08ffe-dabc-1445-ba07-37f06f6b7fcd, command-id=01f08ffe-daf9-1a55-8a19-804b1c6e2651) - Closing
[0m23:05:22.930114 [debug] [Thread-3 (]: Applying tags to relation None
[0m23:05:22.942101 [debug] [Thread-3 (]: On model.dbt_anirudh.bronze_customer: Close
[0m23:05:22.942438 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f08ffe-dabc-1445-ba07-37f06f6b7fcd) - Closing
[0m23:05:23.358624 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '76233906-3960-4db1-9199-44e3b06743f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7c2c6a2c9d00>]}
[0m23:05:23.360329 [info ] [Thread-3 (]: 1 of 6 OK created sql table model default.bronze_customer ...................... [[32mOK[0m in 4.33s]
[0m23:05:23.361905 [debug] [Thread-3 (]: Finished running node model.dbt_anirudh.bronze_customer
[0m23:05:23.362979 [debug] [Thread-3 (]: Began running node model.dbt_anirudh.bronze_date
[0m23:05:23.364295 [info ] [Thread-3 (]: 2 of 6 START sql view model default.bronze_date ................................ [RUN]
[0m23:05:23.365743 [debug] [Thread-3 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.dbt_anirudh.bronze_date) - Creating connection
[0m23:05:23.366654 [debug] [Thread-3 (]: Acquiring new databricks connection 'model.dbt_anirudh.bronze_date'
[0m23:05:23.367883 [debug] [Thread-3 (]: Began compiling node model.dbt_anirudh.bronze_date
[0m23:05:23.374076 [debug] [Thread-3 (]: Writing injected SQL for node "model.dbt_anirudh.bronze_date"
[0m23:05:23.375037 [debug] [Thread-3 (]: Began executing node model.dbt_anirudh.bronze_date
[0m23:05:23.393986 [debug] [Thread-3 (]: MATERIALIZING VIEW
[0m23:05:23.403855 [debug] [Thread-3 (]: Creating view `dbt_learning`.`default`.`bronze_date`
[0m23:05:23.404804 [debug] [Thread-3 (]: Writing runtime sql for node "model.dbt_anirudh.bronze_date"
[0m23:05:23.405248 [debug] [Thread-3 (]: Using databricks connection "model.dbt_anirudh.bronze_date"
[0m23:05:23.405585 [debug] [Thread-3 (]: On model.dbt_anirudh.bronze_date: /* {"app": "dbt", "dbt_version": "1.10.10", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_anirudh", "target_name": "dev", "node_id": "model.dbt_anirudh.bronze_date"} */

  
  
  create or replace view `dbt_learning`.`default`.`bronze_date`
  
  as (
    SELECT  
    *
FROM
    `dbt_learning`.`source`.`dim_date`
  )

[0m23:05:23.405891 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m23:05:24.480201 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f08ffe-dd20-124c-b584-73e5589a308f) - Created
[0m23:05:25.310945 [debug] [Thread-3 (]: SQL status: OK in 1.900 seconds
[0m23:05:25.313293 [debug] [Thread-3 (]: Databricks adapter: Cursor(session-id=01f08ffe-dd20-124c-b584-73e5589a308f, command-id=01f08ffe-dd4c-11b9-8535-a69ad4cd4d03) - Closing
[0m23:05:25.315259 [debug] [Thread-3 (]: Applying tags to relation None
[0m23:05:25.317038 [debug] [Thread-3 (]: On model.dbt_anirudh.bronze_date: Close
[0m23:05:25.317979 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f08ffe-dd20-124c-b584-73e5589a308f) - Closing
[0m23:05:25.616919 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '76233906-3960-4db1-9199-44e3b06743f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7c2c426d1a60>]}
[0m23:05:25.617555 [info ] [Thread-3 (]: 2 of 6 OK created sql view model default.bronze_date ........................... [[32mOK[0m in 2.25s]
[0m23:05:25.618064 [debug] [Thread-3 (]: Finished running node model.dbt_anirudh.bronze_date
[0m23:05:25.618402 [debug] [Thread-3 (]: Began running node model.dbt_anirudh.bronze_product
[0m23:05:25.618827 [info ] [Thread-3 (]: 3 of 6 START sql table model default.bronze_product ............................ [RUN]
[0m23:05:25.619270 [debug] [Thread-3 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.dbt_anirudh.bronze_product) - Creating connection
[0m23:05:25.619554 [debug] [Thread-3 (]: Acquiring new databricks connection 'model.dbt_anirudh.bronze_product'
[0m23:05:25.619804 [debug] [Thread-3 (]: Began compiling node model.dbt_anirudh.bronze_product
[0m23:05:25.623308 [debug] [Thread-3 (]: Writing injected SQL for node "model.dbt_anirudh.bronze_product"
[0m23:05:25.624029 [debug] [Thread-3 (]: Began executing node model.dbt_anirudh.bronze_product
[0m23:05:25.626704 [debug] [Thread-3 (]: MATERIALIZING TABLE
[0m23:05:25.629593 [debug] [Thread-3 (]: Writing runtime sql for node "model.dbt_anirudh.bronze_product"
[0m23:05:25.630251 [debug] [Thread-3 (]: Using databricks connection "model.dbt_anirudh.bronze_product"
[0m23:05:25.630779 [debug] [Thread-3 (]: On model.dbt_anirudh.bronze_product: /* {"app": "dbt", "dbt_version": "1.10.10", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_anirudh", "target_name": "dev", "node_id": "model.dbt_anirudh.bronze_product"} */

  
    
        create or replace table `dbt_learning`.`default`.`bronze_product`
      
      
  using delta
      
      
      
      
      
      
      
      as
      SELECT
    *
FROM
    `dbt_learning`.`source`.`dim_product`
  
[0m23:05:25.631141 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m23:05:27.172054 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f08ffe-dead-12e4-a6eb-b3865d449bc7) - Created
[0m23:05:29.462399 [debug] [Thread-3 (]: SQL status: OK in 3.830 seconds
[0m23:05:29.464808 [debug] [Thread-3 (]: Databricks adapter: Cursor(session-id=01f08ffe-dead-12e4-a6eb-b3865d449bc7, command-id=01f08ffe-dee6-180c-b6bb-d3128835f14c) - Closing
[0m23:05:29.467189 [debug] [Thread-3 (]: Applying tags to relation None
[0m23:05:29.470582 [debug] [Thread-3 (]: On model.dbt_anirudh.bronze_product: Close
[0m23:05:29.471443 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f08ffe-dead-12e4-a6eb-b3865d449bc7) - Closing
[0m23:05:29.894614 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '76233906-3960-4db1-9199-44e3b06743f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7c2c427fef60>]}
[0m23:05:29.896135 [info ] [Thread-3 (]: 3 of 6 OK created sql table model default.bronze_product ....................... [[32mOK[0m in 4.27s]
[0m23:05:29.897601 [debug] [Thread-3 (]: Finished running node model.dbt_anirudh.bronze_product
[0m23:05:29.898567 [debug] [Thread-3 (]: Began running node model.dbt_anirudh.bronze_returns
[0m23:05:29.899798 [info ] [Thread-3 (]: 4 of 6 START sql table model default.bronze_returns ............................ [RUN]
[0m23:05:29.901045 [debug] [Thread-3 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.dbt_anirudh.bronze_returns) - Creating connection
[0m23:05:29.901928 [debug] [Thread-3 (]: Acquiring new databricks connection 'model.dbt_anirudh.bronze_returns'
[0m23:05:29.902807 [debug] [Thread-3 (]: Began compiling node model.dbt_anirudh.bronze_returns
[0m23:05:29.910245 [debug] [Thread-3 (]: Writing injected SQL for node "model.dbt_anirudh.bronze_returns"
[0m23:05:29.911068 [debug] [Thread-3 (]: Began executing node model.dbt_anirudh.bronze_returns
[0m23:05:29.913648 [debug] [Thread-3 (]: MATERIALIZING TABLE
[0m23:05:29.916372 [debug] [Thread-3 (]: Writing runtime sql for node "model.dbt_anirudh.bronze_returns"
[0m23:05:29.916934 [debug] [Thread-3 (]: Using databricks connection "model.dbt_anirudh.bronze_returns"
[0m23:05:29.917314 [debug] [Thread-3 (]: On model.dbt_anirudh.bronze_returns: /* {"app": "dbt", "dbt_version": "1.10.10", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_anirudh", "target_name": "dev", "node_id": "model.dbt_anirudh.bronze_returns"} */

  
    
        create or replace table `dbt_learning`.`default`.`bronze_returns`
      
      
  using delta
      
      
      
      
      
      
      
      as
      SELECT
    *
FROM
    `dbt_learning`.`source`.`fact_returns`
  
[0m23:05:29.917643 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m23:05:31.013468 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f08ffe-e105-1129-b168-a3934f452729) - Created
[0m23:05:32.888130 [debug] [Thread-3 (]: SQL status: OK in 2.970 seconds
[0m23:05:32.890495 [debug] [Thread-3 (]: Databricks adapter: Cursor(session-id=01f08ffe-e105-1129-b168-a3934f452729, command-id=01f08ffe-e12f-1d7c-a14f-d34fcb178885) - Closing
[0m23:05:32.893081 [debug] [Thread-3 (]: Applying tags to relation None
[0m23:05:32.896928 [debug] [Thread-3 (]: On model.dbt_anirudh.bronze_returns: Close
[0m23:05:32.897888 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f08ffe-e105-1129-b168-a3934f452729) - Closing
[0m23:05:33.198015 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '76233906-3960-4db1-9199-44e3b06743f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7c2c426f66c0>]}
[0m23:05:33.199907 [info ] [Thread-3 (]: 4 of 6 OK created sql table model default.bronze_returns ....................... [[32mOK[0m in 3.30s]
[0m23:05:33.201572 [debug] [Thread-3 (]: Finished running node model.dbt_anirudh.bronze_returns
[0m23:05:33.202653 [debug] [Thread-3 (]: Began running node model.dbt_anirudh.bronze_sales
[0m23:05:33.204014 [info ] [Thread-3 (]: 5 of 6 START sql vew model default.bronze_sales ................................ [RUN]
[0m23:05:33.205516 [debug] [Thread-3 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.dbt_anirudh.bronze_sales) - Creating connection
[0m23:05:33.206577 [debug] [Thread-3 (]: Acquiring new databricks connection 'model.dbt_anirudh.bronze_sales'
[0m23:05:33.207922 [debug] [Thread-3 (]: Began compiling node model.dbt_anirudh.bronze_sales
[0m23:05:33.214752 [debug] [Thread-3 (]: Writing injected SQL for node "model.dbt_anirudh.bronze_sales"
[0m23:05:33.215656 [debug] [Thread-3 (]: Began executing node model.dbt_anirudh.bronze_sales
[0m23:05:33.220067 [debug] [Thread-3 (]: Compilation Error in model bronze_sales (models/bronze/bronze_sales.sql)
  No materialization 'vew' was found for adapter databricks! (searched types 'default' and 'databricks')
[0m23:05:33.220732 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '76233906-3960-4db1-9199-44e3b06743f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7c2c4270fe00>]}
[0m23:05:33.221332 [error] [Thread-3 (]: 5 of 6 ERROR creating sql vew model default.bronze_sales ....................... [[31mERROR[0m in 0.02s]
[0m23:05:33.221886 [debug] [Thread-3 (]: Finished running node model.dbt_anirudh.bronze_sales
[0m23:05:33.222199 [debug] [Thread-3 (]: Began running node model.dbt_anirudh.bronze_store
[0m23:05:33.222569 [debug] [Thread-6 (]: Marking all children of 'model.dbt_anirudh.bronze_sales' to be skipped because of status 'error'.  Reason: Compilation Error in model bronze_sales (models/bronze/bronze_sales.sql)
  No materialization 'vew' was found for adapter databricks! (searched types 'default' and 'databricks').
[0m23:05:33.222966 [info ] [Thread-3 (]: 6 of 6 START sql view model default.bronze_store ............................... [RUN]
[0m23:05:33.223955 [debug] [Thread-3 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.dbt_anirudh.bronze_store) - Creating connection
[0m23:05:33.224238 [debug] [Thread-3 (]: Acquiring new databricks connection 'model.dbt_anirudh.bronze_store'
[0m23:05:33.224552 [debug] [Thread-3 (]: Began compiling node model.dbt_anirudh.bronze_store
[0m23:05:33.226651 [debug] [Thread-3 (]: Writing injected SQL for node "model.dbt_anirudh.bronze_store"
[0m23:05:33.227079 [debug] [Thread-3 (]: Began executing node model.dbt_anirudh.bronze_store
[0m23:05:33.232078 [debug] [Thread-3 (]: MATERIALIZING VIEW
[0m23:05:33.233132 [debug] [Thread-3 (]: Creating view `dbt_learning`.`default`.`bronze_store`
[0m23:05:33.233918 [debug] [Thread-3 (]: Writing runtime sql for node "model.dbt_anirudh.bronze_store"
[0m23:05:33.234305 [debug] [Thread-3 (]: Using databricks connection "model.dbt_anirudh.bronze_store"
[0m23:05:33.234631 [debug] [Thread-3 (]: On model.dbt_anirudh.bronze_store: /* {"app": "dbt", "dbt_version": "1.10.10", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_anirudh", "target_name": "dev", "node_id": "model.dbt_anirudh.bronze_store"} */

  
  
  create or replace view `dbt_learning`.`default`.`bronze_store`
  
  as (
    SELECT
    *
FROM
    `dbt_learning`.`source`.`dim_store`
  )

[0m23:05:33.234911 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m23:05:34.365394 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f08ffe-e302-1a81-817c-a5d3c8876596) - Created
[0m23:05:35.145314 [debug] [Thread-3 (]: SQL status: OK in 1.910 seconds
[0m23:05:35.147954 [debug] [Thread-3 (]: Databricks adapter: Cursor(session-id=01f08ffe-e302-1a81-817c-a5d3c8876596, command-id=01f08ffe-e32f-1624-93ec-68de389dcd37) - Closing
[0m23:05:35.149906 [debug] [Thread-3 (]: Applying tags to relation None
[0m23:05:35.151873 [debug] [Thread-3 (]: On model.dbt_anirudh.bronze_store: Close
[0m23:05:35.152971 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f08ffe-e302-1a81-817c-a5d3c8876596) - Closing
[0m23:05:35.462592 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '76233906-3960-4db1-9199-44e3b06743f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7c2c427275f0>]}
[0m23:05:35.464300 [info ] [Thread-3 (]: 6 of 6 OK created sql view model default.bronze_store .......................... [[32mOK[0m in 2.24s]
[0m23:05:35.465968 [debug] [Thread-3 (]: Finished running node model.dbt_anirudh.bronze_store
[0m23:05:35.468590 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=master) - Creating connection
[0m23:05:35.469515 [debug] [MainThread]: Acquiring new databricks connection 'master'
[0m23:05:35.470723 [info ] [MainThread]: 
[0m23:05:35.471676 [info ] [MainThread]: Finished running 3 table models, 1 vew model, 2 view models in 0 hours 0 minutes and 21.36 seconds (21.36s).
[0m23:05:35.476868 [debug] [MainThread]: Command end result
[0m23:05:35.581554 [debug] [MainThread]: Wrote artifact WritableManifest to /home/aniruth/AI/DBT/DBT_Master/dbt_anirudh/target/manifest.json
[0m23:05:35.582893 [debug] [MainThread]: Wrote artifact SemanticManifest to /home/aniruth/AI/DBT/DBT_Master/dbt_anirudh/target/semantic_manifest.json
[0m23:05:35.586991 [debug] [MainThread]: Wrote artifact RunExecutionResult to /home/aniruth/AI/DBT/DBT_Master/dbt_anirudh/target/run_results.json
[0m23:05:35.587271 [info ] [MainThread]: 
[0m23:05:35.587585 [info ] [MainThread]: [31mCompleted with 1 error, 0 partial successes, and 0 warnings:[0m
[0m23:05:35.587932 [info ] [MainThread]: 
[0m23:05:35.588273 [error] [MainThread]: [31mFailure in model bronze_sales (models/bronze/bronze_sales.sql)[0m
[0m23:05:35.588610 [error] [MainThread]:   Compilation Error in model bronze_sales (models/bronze/bronze_sales.sql)
  No materialization 'vew' was found for adapter databricks! (searched types 'default' and 'databricks')
[0m23:05:35.588850 [info ] [MainThread]: 
[0m23:05:35.589176 [info ] [MainThread]:   compiled code at target/compiled/dbt_anirudh/models/bronze/bronze_sales.sql
[0m23:05:35.589451 [info ] [MainThread]: 
[0m23:05:35.589751 [info ] [MainThread]: Done. PASS=5 WARN=0 ERROR=1 SKIP=0 NO-OP=0 TOTAL=6
[0m23:05:35.590555 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": false, "command_wall_clock_time": 23.038307, "process_in_blocks": "111984", "process_kernel_time": 0.229614, "process_mem_max_rss": "246312", "process_out_blocks": "3208", "process_user_time": 4.36768}
[0m23:05:35.590903 [debug] [MainThread]: Command `dbt run` failed at 23:05:35.590832 after 23.04 seconds
[0m23:05:35.591187 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7c2c67f85280>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7c2c6876f5c0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7c2c686552e0>]}
[0m23:05:35.591485 [debug] [MainThread]: Flushing usage events
[0m23:05:37.040167 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m23:06:08.041483 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x71cad4250c80>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x71cad60d5e50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x71cad3cdeae0>]}


============================== 23:06:08.043824 | 99b6bf5d-57b5-42b8-85bc-5908d493d86f ==============================
[0m23:06:08.043824 [info ] [MainThread]: Running with dbt=1.10.10
[0m23:06:08.044274 [debug] [MainThread]: running dbt with arguments {'quiet': 'False', 'indirect_selection': 'eager', 'debug': 'False', 'version_check': 'True', 'send_anonymous_usage_stats': 'True', 'log_format': 'default', 'empty': 'False', 'fail_fast': 'False', 'invocation_command': 'dbt run', 'static_parser': 'True', 'profiles_dir': '/home/aniruth/AI/DBT/DBT_Master/dbt_anirudh', 'use_colors': 'True', 'warn_error': 'None', 'introspect': 'True', 'write_json': 'True', 'log_cache_events': 'False', 'printer_width': '80', 'partial_parse': 'True', 'cache_selected_only': 'False', 'log_path': '/home/aniruth/AI/DBT/DBT_Master/dbt_anirudh/logs', 'no_print': 'None', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'use_experimental_parser': 'False', 'target_path': 'None'}
[0m23:06:08.616452 [debug] [MainThread]: Spark adapter: Setting pyhive.hive logging to ERROR
[0m23:06:08.616858 [debug] [MainThread]: Spark adapter: Setting thrift.transport logging to ERROR
[0m23:06:08.617125 [debug] [MainThread]: Spark adapter: Setting thrift.protocol logging to ERROR
[0m23:06:09.129485 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '99b6bf5d-57b5-42b8-85bc-5908d493d86f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x71caae863d70>]}
[0m23:06:09.175823 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '99b6bf5d-57b5-42b8-85bc-5908d493d86f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x71cad15d3620>]}
[0m23:06:09.176370 [info ] [MainThread]: Registered adapter: databricks=1.10.9
[0m23:06:09.256965 [debug] [MainThread]: checksum: 502a0dc23e9052e1ae09f7c44ee219ef7a02dfea7e7d66580d54c304c14d553b, vars: {}, profile: , target: , version: 1.10.10
[0m23:06:09.328120 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m23:06:09.328492 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m23:06:09.353569 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '99b6bf5d-57b5-42b8-85bc-5908d493d86f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x71caae766180>]}
[0m23:06:09.406006 [debug] [MainThread]: Wrote artifact WritableManifest to /home/aniruth/AI/DBT/DBT_Master/dbt_anirudh/target/manifest.json
[0m23:06:09.407290 [debug] [MainThread]: Wrote artifact SemanticManifest to /home/aniruth/AI/DBT/DBT_Master/dbt_anirudh/target/semantic_manifest.json
[0m23:06:09.412567 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '99b6bf5d-57b5-42b8-85bc-5908d493d86f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x71caae614e00>]}
[0m23:06:09.412905 [info ] [MainThread]: Found 6 models, 6 sources, 685 macros
[0m23:06:09.413185 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '99b6bf5d-57b5-42b8-85bc-5908d493d86f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x71caae75a5d0>]}
[0m23:06:09.414699 [info ] [MainThread]: 
[0m23:06:09.415015 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m23:06:09.415268 [info ] [MainThread]: 
[0m23:06:09.415690 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=master) - Creating connection
[0m23:06:09.415932 [debug] [MainThread]: Acquiring new databricks connection 'master'
[0m23:06:09.421260 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=list_dbt_learning) - Creating connection
[0m23:06:09.421672 [debug] [ThreadPool]: Acquiring new databricks connection 'list_dbt_learning'
[0m23:06:09.421949 [debug] [ThreadPool]: Using databricks connection "list_dbt_learning"
[0m23:06:09.422182 [debug] [ThreadPool]: On list_dbt_learning: GetSchemas(database=dbt_learning, schema=None)
[0m23:06:09.422413 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m23:06:10.550265 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f08ffe-f895-117f-b1b3-d8d8911574a6) - Created
[0m23:06:11.173414 [debug] [ThreadPool]: SQL status: OK in 1.750 seconds
[0m23:06:11.176315 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01f08ffe-f895-117f-b1b3-d8d8911574a6, command-id=01f08ffe-f8c7-1c2a-9c3d-ab48ac8dcc60) - Closing
[0m23:06:11.177082 [debug] [ThreadPool]: On list_dbt_learning: Close
[0m23:06:11.177663 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f08ffe-f895-117f-b1b3-d8d8911574a6) - Closing
[0m23:06:11.481329 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=list_dbt_learning_default) - Creating connection
[0m23:06:11.484124 [debug] [ThreadPool]: Acquiring new databricks connection 'list_dbt_learning_default'
[0m23:06:11.497847 [debug] [ThreadPool]: Using databricks connection "list_dbt_learning_default"
[0m23:06:11.498267 [debug] [ThreadPool]: On list_dbt_learning_default: /* {"app": "dbt", "dbt_version": "1.10.10", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_anirudh", "target_name": "dev", "connection_name": "list_dbt_learning_default"} */

    
SELECT
  table_name,
  if(table_type IN ('EXTERNAL', 'MANAGED', 'MANAGED_SHALLOW_CLONE', 'EXTERNAL_SHALLOW_CLONE'), 'table', lower(table_type)) AS table_type,
  lower(data_source_format) AS file_format,
  table_owner,
  if(
    table_type IN (
      'EXTERNAL',
      'MANAGED',
      'MANAGED_SHALLOW_CLONE',
      'EXTERNAL_SHALLOW_CLONE'
    ),
    lower(table_type),
    NULL
  ) AS databricks_table_type
FROM `system`.`information_schema`.`tables`
WHERE table_catalog = 'dbt_learning' 
  AND table_schema = 'default'

  
[0m23:06:11.498557 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m23:06:12.613538 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f08ffe-f9ce-19db-ae9b-30959b84ae09) - Created
[0m23:06:13.299099 [debug] [ThreadPool]: SQL status: OK in 1.800 seconds
[0m23:06:13.307244 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01f08ffe-f9ce-19db-ae9b-30959b84ae09, command-id=01f08ffe-f9fb-144c-bf9d-5fde277b02c5) - Closing
[0m23:06:13.308646 [debug] [ThreadPool]: On list_dbt_learning_default: Close
[0m23:06:13.309187 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f08ffe-f9ce-19db-ae9b-30959b84ae09) - Closing
[0m23:06:13.614143 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '99b6bf5d-57b5-42b8-85bc-5908d493d86f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x71cad4ab7f80>]}
[0m23:06:13.619003 [debug] [Thread-3 (]: Began running node model.dbt_anirudh.bronze_customer
[0m23:06:13.620364 [info ] [Thread-3 (]: 1 of 6 START sql table model default.bronze_customer ........................... [RUN]
[0m23:06:13.621737 [debug] [Thread-3 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.dbt_anirudh.bronze_customer) - Creating connection
[0m23:06:13.622652 [debug] [Thread-3 (]: Acquiring new databricks connection 'model.dbt_anirudh.bronze_customer'
[0m23:06:13.623548 [debug] [Thread-3 (]: Began compiling node model.dbt_anirudh.bronze_customer
[0m23:06:13.640346 [debug] [Thread-3 (]: Writing injected SQL for node "model.dbt_anirudh.bronze_customer"
[0m23:06:13.641218 [debug] [Thread-3 (]: Began executing node model.dbt_anirudh.bronze_customer
[0m23:06:13.655293 [debug] [Thread-3 (]: MATERIALIZING TABLE
[0m23:06:13.655881 [warn ] [Thread-3 (]: [[33mWARNING[0m]: Use revamped materializations based on separating create and insert.  This allows more performant column comments, as well as new column features.
You may opt into the new behavior sooner by setting `flags.use_materialization_v2` to `True` in `dbt_project.yml`.
Visit https://docs.getdbt.com/reference/global-configs/behavior-changes for more information.
[0m23:06:13.656285 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'BehaviorChangeEvent', 'label': '99b6bf5d-57b5-42b8-85bc-5908d493d86f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x71caae254380>]}
[0m23:06:13.693192 [debug] [Thread-3 (]: Writing runtime sql for node "model.dbt_anirudh.bronze_customer"
[0m23:06:13.693768 [debug] [Thread-3 (]: Using databricks connection "model.dbt_anirudh.bronze_customer"
[0m23:06:13.694109 [debug] [Thread-3 (]: On model.dbt_anirudh.bronze_customer: /* {"app": "dbt", "dbt_version": "1.10.10", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_anirudh", "target_name": "dev", "node_id": "model.dbt_anirudh.bronze_customer"} */

  
    
        create or replace table `dbt_learning`.`default`.`bronze_customer`
      
      
  using delta
      
      
      
      
      
      
      
      as
      SELECT 
    *
FROM
    `dbt_learning`.`source`.`dim_customer`
  
[0m23:06:13.694391 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m23:06:15.007131 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f08ffe-fb36-1dd8-8e37-cb09acc57646) - Created
[0m23:06:17.580716 [debug] [Thread-3 (]: SQL status: OK in 3.890 seconds
[0m23:06:17.583007 [debug] [Thread-3 (]: Databricks adapter: Cursor(session-id=01f08ffe-fb36-1dd8-8e37-cb09acc57646, command-id=01f08ffe-fb67-19ae-ab0d-704b3a908fe3) - Closing
[0m23:06:17.601129 [debug] [Thread-3 (]: Applying tags to relation None
[0m23:06:17.613160 [debug] [Thread-3 (]: On model.dbt_anirudh.bronze_customer: Close
[0m23:06:17.613476 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f08ffe-fb36-1dd8-8e37-cb09acc57646) - Closing
[0m23:06:17.961605 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '99b6bf5d-57b5-42b8-85bc-5908d493d86f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x71cad5ec5b80>]}
[0m23:06:17.963340 [info ] [Thread-3 (]: 1 of 6 OK created sql table model default.bronze_customer ...................... [[32mOK[0m in 4.34s]
[0m23:06:17.964842 [debug] [Thread-3 (]: Finished running node model.dbt_anirudh.bronze_customer
[0m23:06:17.965921 [debug] [Thread-3 (]: Began running node model.dbt_anirudh.bronze_date
[0m23:06:17.967218 [info ] [Thread-3 (]: 2 of 6 START sql view model default.bronze_date ................................ [RUN]
[0m23:06:17.968550 [debug] [Thread-3 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.dbt_anirudh.bronze_date) - Creating connection
[0m23:06:17.969472 [debug] [Thread-3 (]: Acquiring new databricks connection 'model.dbt_anirudh.bronze_date'
[0m23:06:17.970215 [debug] [Thread-3 (]: Began compiling node model.dbt_anirudh.bronze_date
[0m23:06:17.974574 [debug] [Thread-3 (]: Writing injected SQL for node "model.dbt_anirudh.bronze_date"
[0m23:06:17.975287 [debug] [Thread-3 (]: Began executing node model.dbt_anirudh.bronze_date
[0m23:06:17.992475 [debug] [Thread-3 (]: MATERIALIZING VIEW
[0m23:06:18.002898 [debug] [Thread-3 (]: Creating view `dbt_learning`.`default`.`bronze_date`
[0m23:06:18.003876 [debug] [Thread-3 (]: Writing runtime sql for node "model.dbt_anirudh.bronze_date"
[0m23:06:18.004331 [debug] [Thread-3 (]: Using databricks connection "model.dbt_anirudh.bronze_date"
[0m23:06:18.004664 [debug] [Thread-3 (]: On model.dbt_anirudh.bronze_date: /* {"app": "dbt", "dbt_version": "1.10.10", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_anirudh", "target_name": "dev", "node_id": "model.dbt_anirudh.bronze_date"} */

  
  
  create or replace view `dbt_learning`.`default`.`bronze_date`
  
  as (
    SELECT  
    *
FROM
    `dbt_learning`.`source`.`dim_date`
  )

[0m23:06:18.004927 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m23:06:19.126984 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f08ffe-fdaf-19a1-91b8-81e9ad8a77b3) - Created
[0m23:06:19.902245 [debug] [Thread-3 (]: SQL status: OK in 1.900 seconds
[0m23:06:19.904144 [debug] [Thread-3 (]: Databricks adapter: Cursor(session-id=01f08ffe-fdaf-19a1-91b8-81e9ad8a77b3, command-id=01f08ffe-fddc-1159-86fa-20c6120aaaa7) - Closing
[0m23:06:19.904803 [debug] [Thread-3 (]: Applying tags to relation None
[0m23:06:19.905434 [debug] [Thread-3 (]: On model.dbt_anirudh.bronze_date: Close
[0m23:06:19.905714 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f08ffe-fdaf-19a1-91b8-81e9ad8a77b3) - Closing
[0m23:06:20.201290 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '99b6bf5d-57b5-42b8-85bc-5908d493d86f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x71caae27cad0>]}
[0m23:06:20.202040 [info ] [Thread-3 (]: 2 of 6 OK created sql view model default.bronze_date ........................... [[32mOK[0m in 2.23s]
[0m23:06:20.202550 [debug] [Thread-3 (]: Finished running node model.dbt_anirudh.bronze_date
[0m23:06:20.202866 [debug] [Thread-3 (]: Began running node model.dbt_anirudh.bronze_product
[0m23:06:20.203256 [info ] [Thread-3 (]: 3 of 6 START sql table model default.bronze_product ............................ [RUN]
[0m23:06:20.203703 [debug] [Thread-3 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.dbt_anirudh.bronze_product) - Creating connection
[0m23:06:20.203982 [debug] [Thread-3 (]: Acquiring new databricks connection 'model.dbt_anirudh.bronze_product'
[0m23:06:20.204244 [debug] [Thread-3 (]: Began compiling node model.dbt_anirudh.bronze_product
[0m23:06:20.208353 [debug] [Thread-3 (]: Writing injected SQL for node "model.dbt_anirudh.bronze_product"
[0m23:06:20.209065 [debug] [Thread-3 (]: Began executing node model.dbt_anirudh.bronze_product
[0m23:06:20.210804 [debug] [Thread-3 (]: MATERIALIZING TABLE
[0m23:06:20.212597 [debug] [Thread-3 (]: Writing runtime sql for node "model.dbt_anirudh.bronze_product"
[0m23:06:20.213003 [debug] [Thread-3 (]: Using databricks connection "model.dbt_anirudh.bronze_product"
[0m23:06:20.213326 [debug] [Thread-3 (]: On model.dbt_anirudh.bronze_product: /* {"app": "dbt", "dbt_version": "1.10.10", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_anirudh", "target_name": "dev", "node_id": "model.dbt_anirudh.bronze_product"} */

  
    
        create or replace table `dbt_learning`.`default`.`bronze_product`
      
      
  using delta
      
      
      
      
      
      
      
      as
      SELECT
    *
FROM
    `dbt_learning`.`source`.`dim_product`
  
[0m23:06:20.213617 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m23:06:21.314451 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f08ffe-fefe-199e-b58b-0ed7e4e84cb2) - Created
[0m23:06:23.435919 [debug] [Thread-3 (]: SQL status: OK in 3.220 seconds
[0m23:06:23.438400 [debug] [Thread-3 (]: Databricks adapter: Cursor(session-id=01f08ffe-fefe-199e-b58b-0ed7e4e84cb2, command-id=01f08ffe-ff29-1710-814e-2f7aec3fb84f) - Closing
[0m23:06:23.440936 [debug] [Thread-3 (]: Applying tags to relation None
[0m23:06:23.444375 [debug] [Thread-3 (]: On model.dbt_anirudh.bronze_product: Close
[0m23:06:23.445355 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f08ffe-fefe-199e-b58b-0ed7e4e84cb2) - Closing
[0m23:06:23.744734 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '99b6bf5d-57b5-42b8-85bc-5908d493d86f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x71caae2f2fc0>]}
[0m23:06:23.746298 [info ] [Thread-3 (]: 3 of 6 OK created sql table model default.bronze_product ....................... [[32mOK[0m in 3.54s]
[0m23:06:23.747875 [debug] [Thread-3 (]: Finished running node model.dbt_anirudh.bronze_product
[0m23:06:23.748986 [debug] [Thread-3 (]: Began running node model.dbt_anirudh.bronze_returns
[0m23:06:23.750190 [info ] [Thread-3 (]: 4 of 6 START sql table model default.bronze_returns ............................ [RUN]
[0m23:06:23.751550 [debug] [Thread-3 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.dbt_anirudh.bronze_returns) - Creating connection
[0m23:06:23.752431 [debug] [Thread-3 (]: Acquiring new databricks connection 'model.dbt_anirudh.bronze_returns'
[0m23:06:23.753488 [debug] [Thread-3 (]: Began compiling node model.dbt_anirudh.bronze_returns
[0m23:06:23.761246 [debug] [Thread-3 (]: Writing injected SQL for node "model.dbt_anirudh.bronze_returns"
[0m23:06:23.761885 [debug] [Thread-3 (]: Began executing node model.dbt_anirudh.bronze_returns
[0m23:06:23.764326 [debug] [Thread-3 (]: MATERIALIZING TABLE
[0m23:06:23.766339 [debug] [Thread-3 (]: Writing runtime sql for node "model.dbt_anirudh.bronze_returns"
[0m23:06:23.767005 [debug] [Thread-3 (]: Using databricks connection "model.dbt_anirudh.bronze_returns"
[0m23:06:23.767344 [debug] [Thread-3 (]: On model.dbt_anirudh.bronze_returns: /* {"app": "dbt", "dbt_version": "1.10.10", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_anirudh", "target_name": "dev", "node_id": "model.dbt_anirudh.bronze_returns"} */

  
    
        create or replace table `dbt_learning`.`default`.`bronze_returns`
      
      
  using delta
      
      
      
      
      
      
      
      as
      SELECT
    *
FROM
    `dbt_learning`.`source`.`fact_returns`
  
[0m23:06:23.767662 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m23:06:24.862139 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f08fff-011c-14d3-b7e6-0881f58a6c14) - Created
[0m23:06:26.784523 [debug] [Thread-3 (]: SQL status: OK in 3.020 seconds
[0m23:06:26.786917 [debug] [Thread-3 (]: Databricks adapter: Cursor(session-id=01f08fff-011c-14d3-b7e6-0881f58a6c14, command-id=01f08fff-0147-14d3-9aac-639fe0344e75) - Closing
[0m23:06:26.789707 [debug] [Thread-3 (]: Applying tags to relation None
[0m23:06:26.794944 [debug] [Thread-3 (]: On model.dbt_anirudh.bronze_returns: Close
[0m23:06:26.795738 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f08fff-011c-14d3-b7e6-0881f58a6c14) - Closing
[0m23:06:27.098478 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '99b6bf5d-57b5-42b8-85bc-5908d493d86f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x71caae2f5d60>]}
[0m23:06:27.100148 [info ] [Thread-3 (]: 4 of 6 OK created sql table model default.bronze_returns ....................... [[32mOK[0m in 3.35s]
[0m23:06:27.102050 [debug] [Thread-3 (]: Finished running node model.dbt_anirudh.bronze_returns
[0m23:06:27.103131 [debug] [Thread-3 (]: Began running node model.dbt_anirudh.bronze_sales
[0m23:06:27.104432 [info ] [Thread-3 (]: 5 of 6 START sql view model default.bronze_sales ............................... [RUN]
[0m23:06:27.105698 [debug] [Thread-3 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.dbt_anirudh.bronze_sales) - Creating connection
[0m23:06:27.106476 [debug] [Thread-3 (]: Acquiring new databricks connection 'model.dbt_anirudh.bronze_sales'
[0m23:06:27.107338 [debug] [Thread-3 (]: Began compiling node model.dbt_anirudh.bronze_sales
[0m23:06:27.111530 [debug] [Thread-3 (]: Writing injected SQL for node "model.dbt_anirudh.bronze_sales"
[0m23:06:27.112131 [debug] [Thread-3 (]: Began executing node model.dbt_anirudh.bronze_sales
[0m23:06:27.114284 [debug] [Thread-3 (]: MATERIALIZING VIEW
[0m23:06:27.120781 [debug] [Thread-3 (]: Dropping relation `dbt_learning`.`default`.`bronze_sales` because it is of type table
[0m23:06:27.129464 [debug] [Thread-3 (]: Applying DROP to: `dbt_learning`.`default`.`bronze_sales`
[0m23:06:27.133609 [debug] [Thread-3 (]: Using databricks connection "model.dbt_anirudh.bronze_sales"
[0m23:06:27.133991 [debug] [Thread-3 (]: On model.dbt_anirudh.bronze_sales: /* {"app": "dbt", "dbt_version": "1.10.10", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_anirudh", "target_name": "dev", "node_id": "model.dbt_anirudh.bronze_sales"} */
drop table if exists `dbt_learning`.`default`.`bronze_sales`
[0m23:06:27.134346 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m23:06:28.674658 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f08fff-0352-1083-bea1-bbddc56d418f) - Created
[0m23:06:29.371137 [debug] [Thread-3 (]: SQL status: OK in 2.240 seconds
[0m23:06:29.373476 [debug] [Thread-3 (]: Databricks adapter: Cursor(session-id=01f08fff-0352-1083-bea1-bbddc56d418f, command-id=01f08fff-038d-189f-885e-e684af2519c7) - Closing
[0m23:06:29.376293 [debug] [Thread-3 (]: Creating view `dbt_learning`.`default`.`bronze_sales`
[0m23:06:29.379404 [debug] [Thread-3 (]: Writing runtime sql for node "model.dbt_anirudh.bronze_sales"
[0m23:06:29.380334 [debug] [Thread-3 (]: Using databricks connection "model.dbt_anirudh.bronze_sales"
[0m23:06:29.381155 [debug] [Thread-3 (]: On model.dbt_anirudh.bronze_sales: /* {"app": "dbt", "dbt_version": "1.10.10", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_anirudh", "target_name": "dev", "node_id": "model.dbt_anirudh.bronze_sales"} */

  
  
  create or replace view `dbt_learning`.`default`.`bronze_sales`
  
  as (
    -- block level config


SELECT 
    * 
FROM
    
    `dbt_learning`.`source`.`fact_sales`
  )

[0m23:06:30.109492 [debug] [Thread-3 (]: SQL status: OK in 0.730 seconds
[0m23:06:30.111780 [debug] [Thread-3 (]: Databricks adapter: Cursor(session-id=01f08fff-0352-1083-bea1-bbddc56d418f, command-id=01f08fff-03f8-1e26-9ce9-a83b1f74212c) - Closing
[0m23:06:30.113775 [debug] [Thread-3 (]: Applying tags to relation None
[0m23:06:30.115589 [debug] [Thread-3 (]: On model.dbt_anirudh.bronze_sales: Close
[0m23:06:30.116444 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f08fff-0352-1083-bea1-bbddc56d418f) - Closing
[0m23:06:30.543508 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '99b6bf5d-57b5-42b8-85bc-5908d493d86f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x71caae32a6c0>]}
[0m23:06:30.545187 [info ] [Thread-3 (]: 5 of 6 OK created sql view model default.bronze_sales .......................... [[32mOK[0m in 3.44s]
[0m23:06:30.546725 [debug] [Thread-3 (]: Finished running node model.dbt_anirudh.bronze_sales
[0m23:06:30.547757 [debug] [Thread-3 (]: Began running node model.dbt_anirudh.bronze_store
[0m23:06:30.549018 [info ] [Thread-3 (]: 6 of 6 START sql view model default.bronze_store ............................... [RUN]
[0m23:06:30.550442 [debug] [Thread-3 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.dbt_anirudh.bronze_store) - Creating connection
[0m23:06:30.551429 [debug] [Thread-3 (]: Acquiring new databricks connection 'model.dbt_anirudh.bronze_store'
[0m23:06:30.552725 [debug] [Thread-3 (]: Began compiling node model.dbt_anirudh.bronze_store
[0m23:06:30.557263 [debug] [Thread-3 (]: Writing injected SQL for node "model.dbt_anirudh.bronze_store"
[0m23:06:30.558170 [debug] [Thread-3 (]: Began executing node model.dbt_anirudh.bronze_store
[0m23:06:30.561392 [debug] [Thread-3 (]: MATERIALIZING VIEW
[0m23:06:30.563726 [debug] [Thread-3 (]: Creating view `dbt_learning`.`default`.`bronze_store`
[0m23:06:30.564971 [debug] [Thread-3 (]: Writing runtime sql for node "model.dbt_anirudh.bronze_store"
[0m23:06:30.565635 [debug] [Thread-3 (]: Using databricks connection "model.dbt_anirudh.bronze_store"
[0m23:06:30.566062 [debug] [Thread-3 (]: On model.dbt_anirudh.bronze_store: /* {"app": "dbt", "dbt_version": "1.10.10", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_anirudh", "target_name": "dev", "node_id": "model.dbt_anirudh.bronze_store"} */

  
  
  create or replace view `dbt_learning`.`default`.`bronze_store`
  
  as (
    SELECT
    *
FROM
    `dbt_learning`.`source`.`dim_store`
  )

[0m23:06:30.566442 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m23:06:31.657322 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f08fff-0528-1a5b-bf9a-b137be09fdf2) - Created
[0m23:06:32.458683 [debug] [Thread-3 (]: SQL status: OK in 1.890 seconds
[0m23:06:32.461109 [debug] [Thread-3 (]: Databricks adapter: Cursor(session-id=01f08fff-0528-1a5b-bf9a-b137be09fdf2, command-id=01f08fff-0554-1ac8-a230-9c1b4aaa5d1c) - Closing
[0m23:06:32.463506 [debug] [Thread-3 (]: Applying tags to relation None
[0m23:06:32.465547 [debug] [Thread-3 (]: On model.dbt_anirudh.bronze_store: Close
[0m23:06:32.466619 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f08fff-0528-1a5b-bf9a-b137be09fdf2) - Closing
[0m23:06:32.772496 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '99b6bf5d-57b5-42b8-85bc-5908d493d86f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x71caae2a7320>]}
[0m23:06:32.774312 [info ] [Thread-3 (]: 6 of 6 OK created sql view model default.bronze_store .......................... [[32mOK[0m in 2.22s]
[0m23:06:32.776166 [debug] [Thread-3 (]: Finished running node model.dbt_anirudh.bronze_store
[0m23:06:32.778733 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=master) - Creating connection
[0m23:06:32.779625 [debug] [MainThread]: Acquiring new databricks connection 'master'
[0m23:06:32.781199 [info ] [MainThread]: 
[0m23:06:32.782195 [info ] [MainThread]: Finished running 3 table models, 3 view models in 0 hours 0 minutes and 23.37 seconds (23.37s).
[0m23:06:32.784690 [debug] [MainThread]: Command end result
[0m23:06:32.899655 [debug] [MainThread]: Wrote artifact WritableManifest to /home/aniruth/AI/DBT/DBT_Master/dbt_anirudh/target/manifest.json
[0m23:06:32.901203 [debug] [MainThread]: Wrote artifact SemanticManifest to /home/aniruth/AI/DBT/DBT_Master/dbt_anirudh/target/semantic_manifest.json
[0m23:06:32.905829 [debug] [MainThread]: Wrote artifact RunExecutionResult to /home/aniruth/AI/DBT/DBT_Master/dbt_anirudh/target/run_results.json
[0m23:06:32.906139 [info ] [MainThread]: 
[0m23:06:32.906441 [info ] [MainThread]: [32mCompleted successfully[0m
[0m23:06:32.906686 [info ] [MainThread]: 
[0m23:06:32.906936 [info ] [MainThread]: Done. PASS=6 WARN=0 ERROR=0 SKIP=0 NO-OP=0 TOTAL=6
[0m23:06:32.907843 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 24.908188, "process_in_blocks": "32", "process_kernel_time": 0.185692, "process_mem_max_rss": "246368", "process_out_blocks": "3208", "process_user_time": 4.423683}
[0m23:06:32.908219 [debug] [MainThread]: Command `dbt run` succeeded at 23:06:32.908145 after 24.91 seconds
[0m23:06:32.908514 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x71cad451d7f0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x71cad5a30830>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x71caae300ce0>]}
[0m23:06:32.908790 [debug] [MainThread]: Flushing usage events
[0m23:06:34.174931 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m23:28:50.723492 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x72a2eb144470>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x72a2ec9c57f0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x72a2eaa2c950>]}


============================== 23:28:50.726518 | 81a015d2-e1fc-4506-bf7d-279018fbdc1c ==============================
[0m23:28:50.726518 [info ] [MainThread]: Running with dbt=1.10.10
[0m23:28:50.726937 [debug] [MainThread]: running dbt with arguments {'send_anonymous_usage_stats': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'cache_selected_only': 'False', 'debug': 'False', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'write_json': 'True', 'invocation_command': 'dbt run', 'version_check': 'True', 'target_path': 'None', 'printer_width': '80', 'introspect': 'True', 'log_format': 'default', 'profiles_dir': '/home/aniruth/AI/DBT/DBT_Master/dbt_anirudh', 'warn_error': 'None', 'partial_parse': 'True', 'quiet': 'False', 'use_colors': 'True', 'static_parser': 'True', 'empty': 'False', 'fail_fast': 'False', 'log_cache_events': 'False', 'indirect_selection': 'eager', 'log_path': '/home/aniruth/AI/DBT/DBT_Master/dbt_anirudh/logs'}
[0m23:28:51.376914 [debug] [MainThread]: Spark adapter: Setting pyhive.hive logging to ERROR
[0m23:28:51.377327 [debug] [MainThread]: Spark adapter: Setting thrift.transport logging to ERROR
[0m23:28:51.377652 [debug] [MainThread]: Spark adapter: Setting thrift.protocol logging to ERROR
[0m23:28:51.919308 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '81a015d2-e1fc-4506-bf7d-279018fbdc1c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x72a2c9d67e30>]}
[0m23:28:51.962950 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '81a015d2-e1fc-4506-bf7d-279018fbdc1c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x72a2c96bb5c0>]}
[0m23:28:51.963501 [info ] [MainThread]: Registered adapter: databricks=1.10.9
[0m23:28:52.045312 [debug] [MainThread]: checksum: 502a0dc23e9052e1ae09f7c44ee219ef7a02dfea7e7d66580d54c304c14d553b, vars: {}, profile: , target: , version: 1.10.10
[0m23:28:52.112708 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m23:28:52.113041 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m23:28:52.118151 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 2 unused configuration paths:
- models.dbt_anirudh.gold
- models.dbt_anirudh.silver
[0m23:28:52.139574 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '81a015d2-e1fc-4506-bf7d-279018fbdc1c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x72a2c92faf90>]}
[0m23:28:52.193857 [debug] [MainThread]: Wrote artifact WritableManifest to /home/aniruth/AI/DBT/DBT_Master/dbt_anirudh/target/manifest.json
[0m23:28:52.195137 [debug] [MainThread]: Wrote artifact SemanticManifest to /home/aniruth/AI/DBT/DBT_Master/dbt_anirudh/target/semantic_manifest.json
[0m23:28:52.202505 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '81a015d2-e1fc-4506-bf7d-279018fbdc1c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x72a2eb4e4cb0>]}
[0m23:28:52.202897 [info ] [MainThread]: Found 6 models, 6 sources, 686 macros
[0m23:28:52.203168 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '81a015d2-e1fc-4506-bf7d-279018fbdc1c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x72a2c92f8b90>]}
[0m23:28:52.204642 [info ] [MainThread]: 
[0m23:28:52.204987 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m23:28:52.205244 [info ] [MainThread]: 
[0m23:28:52.205651 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=master) - Creating connection
[0m23:28:52.205890 [debug] [MainThread]: Acquiring new databricks connection 'master'
[0m23:28:52.212908 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=list_dbt_learning) - Creating connection
[0m23:28:52.213302 [debug] [ThreadPool]: Acquiring new databricks connection 'list_dbt_learning'
[0m23:28:52.213578 [debug] [ThreadPool]: Using databricks connection "list_dbt_learning"
[0m23:28:52.213838 [debug] [ThreadPool]: On list_dbt_learning: GetSchemas(database=dbt_learning, schema=None)
[0m23:28:52.214049 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m23:28:53.629678 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f09002-2503-1619-a31d-63d2c9ed9f68) - Created
[0m23:29:55.187176 [debug] [ThreadPool]: SQL status: OK in 62.970 seconds
[0m23:29:55.190334 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01f09002-2503-1619-a31d-63d2c9ed9f68, command-id=01f09002-4932-127c-83ac-8320afdc2b1c) - Closing
[0m23:29:55.191547 [debug] [ThreadPool]: On list_dbt_learning: Close
[0m23:29:55.192684 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f09002-2503-1619-a31d-63d2c9ed9f68) - Closing
[0m23:29:55.500234 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=create_dbt_learning_bronze) - Creating connection
[0m23:29:55.501243 [debug] [ThreadPool]: Acquiring new databricks connection 'create_dbt_learning_bronze'
[0m23:29:55.502536 [debug] [ThreadPool]: Creating schema "database: "dbt_learning"
schema: "bronze"
"
[0m23:29:55.519644 [debug] [ThreadPool]: Using databricks connection "create_dbt_learning_bronze"
[0m23:29:55.519978 [debug] [ThreadPool]: On create_dbt_learning_bronze: /* {"app": "dbt", "dbt_version": "1.10.10", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_anirudh", "target_name": "dev", "connection_name": "create_dbt_learning_bronze"} */
create schema if not exists `dbt_learning`.`bronze`
  
[0m23:29:55.520228 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m23:29:56.648213 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f09002-4aa7-1013-97d6-a3335ca90eb9) - Created
[0m23:29:58.182708 [debug] [ThreadPool]: SQL status: OK in 2.660 seconds
[0m23:29:58.185033 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01f09002-4aa7-1013-97d6-a3335ca90eb9, command-id=01f09002-4ad4-1954-ae9a-71ea69c1718c) - Closing
[0m23:29:58.186116 [debug] [ThreadPool]: On create_dbt_learning_bronze: Close
[0m23:29:58.187025 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f09002-4aa7-1013-97d6-a3335ca90eb9) - Closing
[0m23:29:58.506512 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=list_dbt_learning_bronze) - Creating connection
[0m23:29:58.507590 [debug] [ThreadPool]: Acquiring new databricks connection 'list_dbt_learning_bronze'
[0m23:29:58.524104 [debug] [ThreadPool]: Using databricks connection "list_dbt_learning_bronze"
[0m23:29:58.524683 [debug] [ThreadPool]: On list_dbt_learning_bronze: /* {"app": "dbt", "dbt_version": "1.10.10", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_anirudh", "target_name": "dev", "connection_name": "list_dbt_learning_bronze"} */

    
SELECT
  table_name,
  if(table_type IN ('EXTERNAL', 'MANAGED', 'MANAGED_SHALLOW_CLONE', 'EXTERNAL_SHALLOW_CLONE'), 'table', lower(table_type)) AS table_type,
  lower(data_source_format) AS file_format,
  table_owner,
  if(
    table_type IN (
      'EXTERNAL',
      'MANAGED',
      'MANAGED_SHALLOW_CLONE',
      'EXTERNAL_SHALLOW_CLONE'
    ),
    lower(table_type),
    NULL
  ) AS databricks_table_type
FROM `system`.`information_schema`.`tables`
WHERE table_catalog = 'dbt_learning' 
  AND table_schema = 'bronze'

  
[0m23:29:58.525090 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m23:29:59.618015 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f09002-4c6f-101e-8fec-184a54e4945d) - Created
[0m23:30:01.620159 [debug] [ThreadPool]: SQL status: OK in 3.090 seconds
[0m23:30:01.628681 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01f09002-4c6f-101e-8fec-184a54e4945d, command-id=01f09002-4c99-1774-9248-e879a823f1f7) - Closing
[0m23:30:01.629682 [debug] [ThreadPool]: On list_dbt_learning_bronze: Close
[0m23:30:01.630437 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f09002-4c6f-101e-8fec-184a54e4945d) - Closing
[0m23:30:01.924450 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '81a015d2-e1fc-4506-bf7d-279018fbdc1c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x72a2eaa5b980>]}
[0m23:30:01.928651 [debug] [Thread-4 (]: Began running node model.dbt_anirudh.bronze_customer
[0m23:30:01.929717 [info ] [Thread-4 (]: 1 of 6 START sql table model bronze.bronze_customer ............................ [RUN]
[0m23:30:01.930775 [debug] [Thread-4 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.dbt_anirudh.bronze_customer) - Creating connection
[0m23:30:01.931467 [debug] [Thread-4 (]: Acquiring new databricks connection 'model.dbt_anirudh.bronze_customer'
[0m23:30:01.932039 [debug] [Thread-4 (]: Began compiling node model.dbt_anirudh.bronze_customer
[0m23:30:01.941626 [debug] [Thread-4 (]: Writing injected SQL for node "model.dbt_anirudh.bronze_customer"
[0m23:30:01.942550 [debug] [Thread-4 (]: Began executing node model.dbt_anirudh.bronze_customer
[0m23:30:01.964259 [debug] [Thread-4 (]: MATERIALIZING TABLE
[0m23:30:01.965106 [warn ] [Thread-4 (]: [[33mWARNING[0m]: Use revamped materializations based on separating create and insert.  This allows more performant column comments, as well as new column features.
You may opt into the new behavior sooner by setting `flags.use_materialization_v2` to `True` in `dbt_project.yml`.
Visit https://docs.getdbt.com/reference/global-configs/behavior-changes for more information.
[0m23:30:01.965726 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'BehaviorChangeEvent', 'label': '81a015d2-e1fc-4506-bf7d-279018fbdc1c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x72a2c8e28560>]}
[0m23:30:02.012441 [debug] [Thread-4 (]: Writing runtime sql for node "model.dbt_anirudh.bronze_customer"
[0m23:30:02.012973 [debug] [Thread-4 (]: Using databricks connection "model.dbt_anirudh.bronze_customer"
[0m23:30:02.013340 [debug] [Thread-4 (]: On model.dbt_anirudh.bronze_customer: /* {"app": "dbt", "dbt_version": "1.10.10", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_anirudh", "target_name": "dev", "node_id": "model.dbt_anirudh.bronze_customer"} */

  
    
        create or replace table `dbt_learning`.`bronze`.`bronze_customer`
      
      
  using delta
      
      
      
      
      
      
      
      as
      SELECT 
    *
FROM
    `dbt_learning`.`source`.`dim_customer`
  
[0m23:30:02.013666 [debug] [Thread-4 (]: Opening a new connection, currently in state init
[0m23:30:03.143256 [debug] [Thread-4 (]: Databricks adapter: Connection(session-id=01f09002-4e83-1c0c-a5c2-7e7155d7f3ef) - Created
[0m23:30:15.195884 [debug] [Thread-4 (]: SQL status: OK in 13.180 seconds
[0m23:30:15.198869 [debug] [Thread-4 (]: Databricks adapter: Cursor(session-id=01f09002-4e83-1c0c-a5c2-7e7155d7f3ef, command-id=01f09002-4eb3-11c1-982c-56b9a903e855) - Closing
[0m23:30:15.554506 [debug] [Thread-4 (]: Applying tags to relation None
[0m23:30:15.566952 [debug] [Thread-4 (]: On model.dbt_anirudh.bronze_customer: Close
[0m23:30:15.567287 [debug] [Thread-4 (]: Databricks adapter: Connection(session-id=01f09002-4e83-1c0c-a5c2-7e7155d7f3ef) - Closing
[0m23:30:15.872288 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '81a015d2-e1fc-4506-bf7d-279018fbdc1c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x72a2c8ddac60>]}
[0m23:30:15.873923 [info ] [Thread-4 (]: 1 of 6 OK created sql table model bronze.bronze_customer ....................... [[32mOK[0m in 13.94s]
[0m23:30:15.875397 [debug] [Thread-4 (]: Finished running node model.dbt_anirudh.bronze_customer
[0m23:30:15.876440 [debug] [Thread-4 (]: Began running node model.dbt_anirudh.bronze_date
[0m23:30:15.877508 [info ] [Thread-4 (]: 2 of 6 START sql view model bronze.bronze_date ................................. [RUN]
[0m23:30:15.878507 [debug] [Thread-4 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.dbt_anirudh.bronze_date) - Creating connection
[0m23:30:15.879190 [debug] [Thread-4 (]: Acquiring new databricks connection 'model.dbt_anirudh.bronze_date'
[0m23:30:15.879910 [debug] [Thread-4 (]: Began compiling node model.dbt_anirudh.bronze_date
[0m23:30:15.883530 [debug] [Thread-4 (]: Writing injected SQL for node "model.dbt_anirudh.bronze_date"
[0m23:30:15.884139 [debug] [Thread-4 (]: Began executing node model.dbt_anirudh.bronze_date
[0m23:30:15.901649 [debug] [Thread-4 (]: MATERIALIZING VIEW
[0m23:30:15.910699 [debug] [Thread-4 (]: Creating view `dbt_learning`.`bronze`.`bronze_date`
[0m23:30:15.911516 [debug] [Thread-4 (]: Writing runtime sql for node "model.dbt_anirudh.bronze_date"
[0m23:30:15.912022 [debug] [Thread-4 (]: Using databricks connection "model.dbt_anirudh.bronze_date"
[0m23:30:15.912350 [debug] [Thread-4 (]: On model.dbt_anirudh.bronze_date: /* {"app": "dbt", "dbt_version": "1.10.10", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_anirudh", "target_name": "dev", "node_id": "model.dbt_anirudh.bronze_date"} */

  
  
  create or replace view `dbt_learning`.`bronze`.`bronze_date`
  
  as (
    SELECT  
    *
FROM
    `dbt_learning`.`source`.`dim_date`
  )

[0m23:30:15.912642 [debug] [Thread-4 (]: Opening a new connection, currently in state init
[0m23:30:17.020782 [debug] [Thread-4 (]: Databricks adapter: Connection(session-id=01f09002-56c9-1f7c-932a-a1855b3bce57) - Created
[0m23:30:18.223398 [debug] [Thread-4 (]: SQL status: OK in 2.310 seconds
[0m23:30:18.225717 [debug] [Thread-4 (]: Databricks adapter: Cursor(session-id=01f09002-56c9-1f7c-932a-a1855b3bce57, command-id=01f09002-56f8-1fdb-affc-7858d6739d4b) - Closing
[0m23:30:18.226884 [debug] [Thread-4 (]: Applying tags to relation None
[0m23:30:18.228184 [debug] [Thread-4 (]: On model.dbt_anirudh.bronze_date: Close
[0m23:30:18.228821 [debug] [Thread-4 (]: Databricks adapter: Connection(session-id=01f09002-56c9-1f7c-932a-a1855b3bce57) - Closing
[0m23:30:18.526509 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '81a015d2-e1fc-4506-bf7d-279018fbdc1c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x72a2c849b350>]}
[0m23:30:18.528272 [info ] [Thread-4 (]: 2 of 6 OK created sql view model bronze.bronze_date ............................ [[32mOK[0m in 2.65s]
[0m23:30:18.529661 [debug] [Thread-4 (]: Finished running node model.dbt_anirudh.bronze_date
[0m23:30:18.530611 [debug] [Thread-4 (]: Began running node model.dbt_anirudh.bronze_product
[0m23:30:18.531928 [info ] [Thread-4 (]: 3 of 6 START sql table model bronze.bronze_product ............................. [RUN]
[0m23:30:18.533370 [debug] [Thread-4 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.dbt_anirudh.bronze_product) - Creating connection
[0m23:30:18.534267 [debug] [Thread-4 (]: Acquiring new databricks connection 'model.dbt_anirudh.bronze_product'
[0m23:30:18.535248 [debug] [Thread-4 (]: Began compiling node model.dbt_anirudh.bronze_product
[0m23:30:18.539729 [debug] [Thread-4 (]: Writing injected SQL for node "model.dbt_anirudh.bronze_product"
[0m23:30:18.540479 [debug] [Thread-4 (]: Began executing node model.dbt_anirudh.bronze_product
[0m23:30:18.542625 [debug] [Thread-4 (]: MATERIALIZING TABLE
[0m23:30:18.544126 [debug] [Thread-4 (]: Writing runtime sql for node "model.dbt_anirudh.bronze_product"
[0m23:30:18.544800 [debug] [Thread-4 (]: Using databricks connection "model.dbt_anirudh.bronze_product"
[0m23:30:18.545188 [debug] [Thread-4 (]: On model.dbt_anirudh.bronze_product: /* {"app": "dbt", "dbt_version": "1.10.10", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_anirudh", "target_name": "dev", "node_id": "model.dbt_anirudh.bronze_product"} */

  
    
        create or replace table `dbt_learning`.`bronze`.`bronze_product`
      
      
  using delta
      
      
      
      
      
      
      
      as
      SELECT
    *
FROM
    `dbt_learning`.`source`.`dim_product`
  
[0m23:30:18.545498 [debug] [Thread-4 (]: Opening a new connection, currently in state init
[0m23:30:19.613813 [debug] [Thread-4 (]: Databricks adapter: Connection(session-id=01f09002-585a-17e7-9ef4-91eb56fe2a32) - Created
[0m23:30:23.456575 [debug] [Thread-4 (]: SQL status: OK in 4.910 seconds
[0m23:30:23.458964 [debug] [Thread-4 (]: Databricks adapter: Cursor(session-id=01f09002-585a-17e7-9ef4-91eb56fe2a32, command-id=01f09002-5884-14de-8335-7f1a387f1042) - Closing
[0m23:30:23.460645 [debug] [Thread-4 (]: Applying tags to relation None
[0m23:30:23.463129 [debug] [Thread-4 (]: On model.dbt_anirudh.bronze_product: Close
[0m23:30:23.464073 [debug] [Thread-4 (]: Databricks adapter: Connection(session-id=01f09002-585a-17e7-9ef4-91eb56fe2a32) - Closing
[0m23:30:23.768556 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '81a015d2-e1fc-4506-bf7d-279018fbdc1c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x72a2c8dea990>]}
[0m23:30:23.770193 [info ] [Thread-4 (]: 3 of 6 OK created sql table model bronze.bronze_product ........................ [[32mOK[0m in 5.23s]
[0m23:30:23.771820 [debug] [Thread-4 (]: Finished running node model.dbt_anirudh.bronze_product
[0m23:30:23.772813 [debug] [Thread-4 (]: Began running node model.dbt_anirudh.bronze_returns
[0m23:30:23.774126 [info ] [Thread-4 (]: 4 of 6 START sql table model bronze.bronze_returns ............................. [RUN]
[0m23:30:23.775642 [debug] [Thread-4 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.dbt_anirudh.bronze_returns) - Creating connection
[0m23:30:23.776620 [debug] [Thread-4 (]: Acquiring new databricks connection 'model.dbt_anirudh.bronze_returns'
[0m23:30:23.777667 [debug] [Thread-4 (]: Began compiling node model.dbt_anirudh.bronze_returns
[0m23:30:23.784898 [debug] [Thread-4 (]: Writing injected SQL for node "model.dbt_anirudh.bronze_returns"
[0m23:30:23.785662 [debug] [Thread-4 (]: Began executing node model.dbt_anirudh.bronze_returns
[0m23:30:23.787542 [debug] [Thread-4 (]: MATERIALIZING TABLE
[0m23:30:23.789076 [debug] [Thread-4 (]: Writing runtime sql for node "model.dbt_anirudh.bronze_returns"
[0m23:30:23.789558 [debug] [Thread-4 (]: Using databricks connection "model.dbt_anirudh.bronze_returns"
[0m23:30:23.789898 [debug] [Thread-4 (]: On model.dbt_anirudh.bronze_returns: /* {"app": "dbt", "dbt_version": "1.10.10", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_anirudh", "target_name": "dev", "node_id": "model.dbt_anirudh.bronze_returns"} */

  
    
        create or replace table `dbt_learning`.`bronze`.`bronze_returns`
      
      
  using delta
      
      
      
      
      
      
      
      as
      SELECT
    *
FROM
    `dbt_learning`.`source`.`fact_returns`
  
[0m23:30:23.790204 [debug] [Thread-4 (]: Opening a new connection, currently in state init
[0m23:30:24.923576 [debug] [Thread-4 (]: Databricks adapter: Connection(session-id=01f09002-5b82-1a52-b70c-65080cd8e770) - Created
[0m23:30:28.399077 [debug] [Thread-4 (]: SQL status: OK in 4.610 seconds
[0m23:30:28.401359 [debug] [Thread-4 (]: Databricks adapter: Cursor(session-id=01f09002-5b82-1a52-b70c-65080cd8e770, command-id=01f09002-5bae-1e73-9a09-dc9b48268434) - Closing
[0m23:30:28.402810 [debug] [Thread-4 (]: Applying tags to relation None
[0m23:30:28.405165 [debug] [Thread-4 (]: On model.dbt_anirudh.bronze_returns: Close
[0m23:30:28.406121 [debug] [Thread-4 (]: Databricks adapter: Connection(session-id=01f09002-5b82-1a52-b70c-65080cd8e770) - Closing
[0m23:30:28.713307 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '81a015d2-e1fc-4506-bf7d-279018fbdc1c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x72a2c8def7a0>]}
[0m23:30:28.715037 [info ] [Thread-4 (]: 4 of 6 OK created sql table model bronze.bronze_returns ........................ [[32mOK[0m in 4.94s]
[0m23:30:28.716593 [debug] [Thread-4 (]: Finished running node model.dbt_anirudh.bronze_returns
[0m23:30:28.717562 [debug] [Thread-4 (]: Began running node model.dbt_anirudh.bronze_sales
[0m23:30:28.718602 [info ] [Thread-4 (]: 5 of 6 START sql view model bronze.bronze_sales ................................ [RUN]
[0m23:30:28.719905 [debug] [Thread-4 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.dbt_anirudh.bronze_sales) - Creating connection
[0m23:30:28.720793 [debug] [Thread-4 (]: Acquiring new databricks connection 'model.dbt_anirudh.bronze_sales'
[0m23:30:28.721800 [debug] [Thread-4 (]: Began compiling node model.dbt_anirudh.bronze_sales
[0m23:30:28.729599 [debug] [Thread-4 (]: Writing injected SQL for node "model.dbt_anirudh.bronze_sales"
[0m23:30:28.730422 [debug] [Thread-4 (]: Began executing node model.dbt_anirudh.bronze_sales
[0m23:30:28.732513 [debug] [Thread-4 (]: MATERIALIZING VIEW
[0m23:30:28.733510 [debug] [Thread-4 (]: Creating view `dbt_learning`.`bronze`.`bronze_sales`
[0m23:30:28.734112 [debug] [Thread-4 (]: Writing runtime sql for node "model.dbt_anirudh.bronze_sales"
[0m23:30:28.734741 [debug] [Thread-4 (]: Using databricks connection "model.dbt_anirudh.bronze_sales"
[0m23:30:28.735059 [debug] [Thread-4 (]: On model.dbt_anirudh.bronze_sales: /* {"app": "dbt", "dbt_version": "1.10.10", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_anirudh", "target_name": "dev", "node_id": "model.dbt_anirudh.bronze_sales"} */

  
  
  create or replace view `dbt_learning`.`bronze`.`bronze_sales`
  
  as (
    -- block level config


SELECT 
    * 
FROM
    
    `dbt_learning`.`source`.`fact_sales`
  )

[0m23:30:28.735335 [debug] [Thread-4 (]: Opening a new connection, currently in state init
[0m23:30:29.845641 [debug] [Thread-4 (]: Databricks adapter: Connection(session-id=01f09002-5e72-18ca-8b73-632021e1b54d) - Created
[0m23:30:30.960423 [debug] [Thread-4 (]: SQL status: OK in 2.220 seconds
[0m23:30:30.962952 [debug] [Thread-4 (]: Databricks adapter: Cursor(session-id=01f09002-5e72-18ca-8b73-632021e1b54d, command-id=01f09002-5e9e-156a-8df3-8a969a6a122e) - Closing
[0m23:30:30.964691 [debug] [Thread-4 (]: Applying tags to relation None
[0m23:30:30.966492 [debug] [Thread-4 (]: On model.dbt_anirudh.bronze_sales: Close
[0m23:30:30.967349 [debug] [Thread-4 (]: Databricks adapter: Connection(session-id=01f09002-5e72-18ca-8b73-632021e1b54d) - Closing
[0m23:30:31.277275 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '81a015d2-e1fc-4506-bf7d-279018fbdc1c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x72a2c8dbbe90>]}
[0m23:30:31.279116 [info ] [Thread-4 (]: 5 of 6 OK created sql view model bronze.bronze_sales ........................... [[32mOK[0m in 2.56s]
[0m23:30:31.280564 [debug] [Thread-4 (]: Finished running node model.dbt_anirudh.bronze_sales
[0m23:30:31.281582 [debug] [Thread-4 (]: Began running node model.dbt_anirudh.bronze_store
[0m23:30:31.282694 [info ] [Thread-4 (]: 6 of 6 START sql view model bronze.bronze_store ................................ [RUN]
[0m23:30:31.284327 [debug] [Thread-4 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.dbt_anirudh.bronze_store) - Creating connection
[0m23:30:31.285473 [debug] [Thread-4 (]: Acquiring new databricks connection 'model.dbt_anirudh.bronze_store'
[0m23:30:31.286905 [debug] [Thread-4 (]: Began compiling node model.dbt_anirudh.bronze_store
[0m23:30:31.301129 [debug] [Thread-4 (]: Writing injected SQL for node "model.dbt_anirudh.bronze_store"
[0m23:30:31.301709 [debug] [Thread-4 (]: Began executing node model.dbt_anirudh.bronze_store
[0m23:30:31.303458 [debug] [Thread-4 (]: MATERIALIZING VIEW
[0m23:30:31.304262 [debug] [Thread-4 (]: Creating view `dbt_learning`.`bronze`.`bronze_store`
[0m23:30:31.304798 [debug] [Thread-4 (]: Writing runtime sql for node "model.dbt_anirudh.bronze_store"
[0m23:30:31.305184 [debug] [Thread-4 (]: Using databricks connection "model.dbt_anirudh.bronze_store"
[0m23:30:31.305519 [debug] [Thread-4 (]: On model.dbt_anirudh.bronze_store: /* {"app": "dbt", "dbt_version": "1.10.10", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_anirudh", "target_name": "dev", "node_id": "model.dbt_anirudh.bronze_store"} */

  
  
  create or replace view `dbt_learning`.`bronze`.`bronze_store`
  
  as (
    SELECT
    *
FROM
    `dbt_learning`.`source`.`dim_store`
  )

[0m23:30:31.305784 [debug] [Thread-4 (]: Opening a new connection, currently in state init
[0m23:30:32.432870 [debug] [Thread-4 (]: Databricks adapter: Connection(session-id=01f09002-5ffa-1aa4-b6fc-7ae3b3cc6d86) - Created
[0m23:30:33.463405 [debug] [Thread-4 (]: SQL status: OK in 2.160 seconds
[0m23:30:33.465870 [debug] [Thread-4 (]: Databricks adapter: Cursor(session-id=01f09002-5ffa-1aa4-b6fc-7ae3b3cc6d86, command-id=01f09002-6028-1c0a-86df-0d3156fce8a6) - Closing
[0m23:30:33.467579 [debug] [Thread-4 (]: Applying tags to relation None
[0m23:30:33.469485 [debug] [Thread-4 (]: On model.dbt_anirudh.bronze_store: Close
[0m23:30:33.470470 [debug] [Thread-4 (]: Databricks adapter: Connection(session-id=01f09002-5ffa-1aa4-b6fc-7ae3b3cc6d86) - Closing
[0m23:30:33.774058 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '81a015d2-e1fc-4506-bf7d-279018fbdc1c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x72a2c84c6e70>]}
[0m23:30:33.775726 [info ] [Thread-4 (]: 6 of 6 OK created sql view model bronze.bronze_store ........................... [[32mOK[0m in 2.49s]
[0m23:30:33.777213 [debug] [Thread-4 (]: Finished running node model.dbt_anirudh.bronze_store
[0m23:30:33.779912 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=master) - Creating connection
[0m23:30:33.780827 [debug] [MainThread]: Acquiring new databricks connection 'master'
[0m23:30:33.782008 [info ] [MainThread]: 
[0m23:30:33.783309 [info ] [MainThread]: Finished running 3 table models, 3 view models in 0 hours 1 minutes and 41.58 seconds (101.58s).
[0m23:30:33.786425 [debug] [MainThread]: Command end result
[0m23:30:33.814981 [debug] [MainThread]: Wrote artifact WritableManifest to /home/aniruth/AI/DBT/DBT_Master/dbt_anirudh/target/manifest.json
[0m23:30:33.817045 [debug] [MainThread]: Wrote artifact SemanticManifest to /home/aniruth/AI/DBT/DBT_Master/dbt_anirudh/target/semantic_manifest.json
[0m23:30:33.821888 [debug] [MainThread]: Wrote artifact RunExecutionResult to /home/aniruth/AI/DBT/DBT_Master/dbt_anirudh/target/run_results.json
[0m23:30:33.822200 [info ] [MainThread]: 
[0m23:30:33.822497 [info ] [MainThread]: [32mCompleted successfully[0m
[0m23:30:33.822749 [info ] [MainThread]: 
[0m23:30:33.823003 [info ] [MainThread]: Done. PASS=6 WARN=0 ERROR=0 SKIP=0 NO-OP=0 TOTAL=6
[0m23:30:33.823640 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 103.140114, "process_in_blocks": "90000", "process_kernel_time": 0.228159, "process_mem_max_rss": "245324", "process_out_blocks": "3232", "process_user_time": 4.461121}
[0m23:30:33.823999 [debug] [MainThread]: Command `dbt run` succeeded at 23:30:33.823930 after 103.14 seconds
[0m23:30:33.824286 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x72a2ee3b3a70>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x72a2c8d73fb0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x72a2ecada4e0>]}
[0m23:30:33.824596 [debug] [MainThread]: Flushing usage events
[0m23:30:35.110920 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m23:32:44.020691 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7b6f17cfd970>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7b6f17e832c0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7b6f17fdd820>]}


============================== 23:32:44.023822 | 416d2052-a487-4865-a589-732241c362cc ==============================
[0m23:32:44.023822 [info ] [MainThread]: Running with dbt=1.10.10
[0m23:32:44.024229 [debug] [MainThread]: running dbt with arguments {'fail_fast': 'False', 'profiles_dir': '/home/aniruth/AI/DBT/DBT_Master/dbt_anirudh', 'version_check': 'True', 'indirect_selection': 'eager', 'warn_error': 'None', 'log_path': '/home/aniruth/AI/DBT/DBT_Master/dbt_anirudh/logs', 'quiet': 'False', 'use_colors': 'True', 'log_cache_events': 'False', 'write_json': 'True', 'target_path': 'None', 'send_anonymous_usage_stats': 'True', 'log_format': 'default', 'static_parser': 'True', 'cache_selected_only': 'False', 'partial_parse': 'True', 'use_experimental_parser': 'False', 'debug': 'False', 'empty': 'False', 'printer_width': '80', 'no_print': 'None', 'invocation_command': 'dbt run --select bronze_date', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'introspect': 'True'}
[0m23:32:44.653740 [debug] [MainThread]: Spark adapter: Setting pyhive.hive logging to ERROR
[0m23:32:44.654145 [debug] [MainThread]: Spark adapter: Setting thrift.transport logging to ERROR
[0m23:32:44.654473 [debug] [MainThread]: Spark adapter: Setting thrift.protocol logging to ERROR
[0m23:32:45.178595 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '416d2052-a487-4865-a589-732241c362cc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7b6ef2277bf0>]}
[0m23:32:45.228321 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '416d2052-a487-4865-a589-732241c362cc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7b6f17388b90>]}
[0m23:32:45.228893 [info ] [MainThread]: Registered adapter: databricks=1.10.9
[0m23:32:45.312428 [debug] [MainThread]: checksum: 502a0dc23e9052e1ae09f7c44ee219ef7a02dfea7e7d66580d54c304c14d553b, vars: {}, profile: , target: , version: 1.10.10
[0m23:32:45.389127 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m23:32:45.389481 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m23:32:45.395367 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 2 unused configuration paths:
- models.dbt_anirudh.gold
- models.dbt_anirudh.silver
[0m23:32:45.419035 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '416d2052-a487-4865-a589-732241c362cc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7b6ef1e90a70>]}
[0m23:32:45.477332 [debug] [MainThread]: Wrote artifact WritableManifest to /home/aniruth/AI/DBT/DBT_Master/dbt_anirudh/target/manifest.json
[0m23:32:45.478955 [debug] [MainThread]: Wrote artifact SemanticManifest to /home/aniruth/AI/DBT/DBT_Master/dbt_anirudh/target/semantic_manifest.json
[0m23:32:45.484649 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '416d2052-a487-4865-a589-732241c362cc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7b6ef1e20740>]}
[0m23:32:45.485030 [info ] [MainThread]: Found 6 models, 6 sources, 686 macros
[0m23:32:45.485335 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '416d2052-a487-4865-a589-732241c362cc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7b6f162ea450>]}
[0m23:32:45.486470 [info ] [MainThread]: 
[0m23:32:45.486788 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m23:32:45.487070 [info ] [MainThread]: 
[0m23:32:45.487508 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=master) - Creating connection
[0m23:32:45.487776 [debug] [MainThread]: Acquiring new databricks connection 'master'
[0m23:32:45.488613 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=list_dbt_learning) - Creating connection
[0m23:32:45.488937 [debug] [ThreadPool]: Acquiring new databricks connection 'list_dbt_learning'
[0m23:32:45.489200 [debug] [ThreadPool]: Using databricks connection "list_dbt_learning"
[0m23:32:45.489446 [debug] [ThreadPool]: On list_dbt_learning: GetSchemas(database=dbt_learning, schema=None)
[0m23:32:45.489670 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m23:32:46.639155 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f09002-affb-14a9-a518-4864f3a4649a) - Created
[0m23:32:47.054498 [debug] [ThreadPool]: SQL status: OK in 1.560 seconds
[0m23:32:47.057358 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01f09002-affb-14a9-a518-4864f3a4649a, command-id=01f09002-b026-1c57-9d61-1b155f12821f) - Closing
[0m23:32:47.058653 [debug] [ThreadPool]: On list_dbt_learning: Close
[0m23:32:47.059432 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f09002-affb-14a9-a518-4864f3a4649a) - Closing
[0m23:32:47.428931 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=list_dbt_learning_bronze) - Creating connection
[0m23:32:47.429668 [debug] [ThreadPool]: Acquiring new databricks connection 'list_dbt_learning_bronze'
[0m23:32:47.451329 [debug] [ThreadPool]: Using databricks connection "list_dbt_learning_bronze"
[0m23:32:47.451716 [debug] [ThreadPool]: On list_dbt_learning_bronze: /* {"app": "dbt", "dbt_version": "1.10.10", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_anirudh", "target_name": "dev", "connection_name": "list_dbt_learning_bronze"} */

    
SELECT
  table_name,
  if(table_type IN ('EXTERNAL', 'MANAGED', 'MANAGED_SHALLOW_CLONE', 'EXTERNAL_SHALLOW_CLONE'), 'table', lower(table_type)) AS table_type,
  lower(data_source_format) AS file_format,
  table_owner,
  if(
    table_type IN (
      'EXTERNAL',
      'MANAGED',
      'MANAGED_SHALLOW_CLONE',
      'EXTERNAL_SHALLOW_CLONE'
    ),
    lower(table_type),
    NULL
  ) AS databricks_table_type
FROM `system`.`information_schema`.`tables`
WHERE table_catalog = 'dbt_learning' 
  AND table_schema = 'bronze'

  
[0m23:32:47.451980 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m23:32:48.626545 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f09002-b128-1811-a03d-4f8637af3653) - Created
[0m23:32:49.693322 [debug] [ThreadPool]: SQL status: OK in 2.240 seconds
[0m23:32:49.702437 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01f09002-b128-1811-a03d-4f8637af3653, command-id=01f09002-b163-1036-b9cf-e7ec110fe712) - Closing
[0m23:32:49.704064 [debug] [ThreadPool]: On list_dbt_learning_bronze: Close
[0m23:32:49.704683 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f09002-b128-1811-a03d-4f8637af3653) - Closing
[0m23:32:50.037822 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '416d2052-a487-4865-a589-732241c362cc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7b6ef21246e0>]}
[0m23:32:50.043356 [debug] [Thread-3 (]: Began running node model.dbt_anirudh.bronze_date
[0m23:32:50.044713 [info ] [Thread-3 (]: 1 of 1 START sql view model bronze.bronze_date ................................. [RUN]
[0m23:32:50.046061 [debug] [Thread-3 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.dbt_anirudh.bronze_date) - Creating connection
[0m23:32:50.046980 [debug] [Thread-3 (]: Acquiring new databricks connection 'model.dbt_anirudh.bronze_date'
[0m23:32:50.047825 [debug] [Thread-3 (]: Began compiling node model.dbt_anirudh.bronze_date
[0m23:32:50.061817 [debug] [Thread-3 (]: Writing injected SQL for node "model.dbt_anirudh.bronze_date"
[0m23:32:50.062606 [debug] [Thread-3 (]: Began executing node model.dbt_anirudh.bronze_date
[0m23:32:50.074995 [debug] [Thread-3 (]: MATERIALIZING VIEW
[0m23:32:50.076919 [warn ] [Thread-3 (]: [[33mWARNING[0m]: Use revamped materializations based on separating create and insert.  This allows more performant column comments, as well as new column features.
You may opt into the new behavior sooner by setting `flags.use_materialization_v2` to `True` in `dbt_project.yml`.
Visit https://docs.getdbt.com/reference/global-configs/behavior-changes for more information.
[0m23:32:50.077338 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'BehaviorChangeEvent', 'label': '416d2052-a487-4865-a589-732241c362cc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7b6ef1bcbbf0>]}
[0m23:32:50.087930 [debug] [Thread-3 (]: Creating view `dbt_learning`.`bronze`.`bronze_date`
[0m23:32:50.096131 [debug] [Thread-3 (]: Writing runtime sql for node "model.dbt_anirudh.bronze_date"
[0m23:32:50.096734 [debug] [Thread-3 (]: Using databricks connection "model.dbt_anirudh.bronze_date"
[0m23:32:50.097124 [debug] [Thread-3 (]: On model.dbt_anirudh.bronze_date: /* {"app": "dbt", "dbt_version": "1.10.10", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_anirudh", "target_name": "dev", "node_id": "model.dbt_anirudh.bronze_date"} */

  
  
  create or replace view `dbt_learning`.`bronze`.`bronze_date`
  
  as (
    SELECT  
    *
FROM
    `dbt_learning`.`source`.`dim_date`
  )

[0m23:32:50.097448 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m23:32:51.200250 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f09002-b2b2-151c-8d51-d3cefa4b42c2) - Created
[0m23:32:52.129352 [debug] [Thread-3 (]: SQL status: OK in 2.030 seconds
[0m23:32:52.131888 [debug] [Thread-3 (]: Databricks adapter: Cursor(session-id=01f09002-b2b2-151c-8d51-d3cefa4b42c2, command-id=01f09002-b2df-1315-b719-fab8d55464a0) - Closing
[0m23:32:52.149439 [debug] [Thread-3 (]: Applying tags to relation None
[0m23:32:52.150835 [debug] [Thread-3 (]: On model.dbt_anirudh.bronze_date: Close
[0m23:32:52.151157 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f09002-b2b2-151c-8d51-d3cefa4b42c2) - Closing
[0m23:32:52.447688 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '416d2052-a487-4865-a589-732241c362cc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7b6ef1b99dc0>]}
[0m23:32:52.449260 [info ] [Thread-3 (]: 1 of 1 OK created sql view model bronze.bronze_date ............................ [[32mOK[0m in 2.40s]
[0m23:32:52.450712 [debug] [Thread-3 (]: Finished running node model.dbt_anirudh.bronze_date
[0m23:32:52.453286 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=master) - Creating connection
[0m23:32:52.454149 [debug] [MainThread]: Acquiring new databricks connection 'master'
[0m23:32:52.455004 [info ] [MainThread]: 
[0m23:32:52.455715 [info ] [MainThread]: Finished running 1 view model in 0 hours 0 minutes and 6.97 seconds (6.97s).
[0m23:32:52.457103 [debug] [MainThread]: Command end result
[0m23:32:52.485456 [debug] [MainThread]: Wrote artifact WritableManifest to /home/aniruth/AI/DBT/DBT_Master/dbt_anirudh/target/manifest.json
[0m23:32:52.486903 [debug] [MainThread]: Wrote artifact SemanticManifest to /home/aniruth/AI/DBT/DBT_Master/dbt_anirudh/target/semantic_manifest.json
[0m23:32:52.491057 [debug] [MainThread]: Wrote artifact RunExecutionResult to /home/aniruth/AI/DBT/DBT_Master/dbt_anirudh/target/run_results.json
[0m23:32:52.491319 [info ] [MainThread]: 
[0m23:32:52.491631 [info ] [MainThread]: [32mCompleted successfully[0m
[0m23:32:52.491864 [info ] [MainThread]: 
[0m23:32:52.492107 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 NO-OP=0 TOTAL=1
[0m23:32:52.492806 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 8.515235, "process_in_blocks": "61008", "process_kernel_time": 0.188802, "process_mem_max_rss": "245700", "process_out_blocks": "3096", "process_user_time": 3.812018}
[0m23:32:52.493312 [debug] [MainThread]: Command `dbt run` succeeded at 23:32:52.493205 after 8.52 seconds
[0m23:32:52.493655 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7b6f17fa6a20>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7b6f17e34c20>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7b6f17e34dd0>]}
[0m23:32:52.493978 [debug] [MainThread]: Flushing usage events
[0m23:32:53.474037 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m23:34:15.318085 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x715ee2977950>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x715ee2059e80>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x715ee2917d70>]}


============================== 23:34:15.320887 | 75e0ca8e-e70b-4c84-a90f-08fd053ab753 ==============================
[0m23:34:15.320887 [info ] [MainThread]: Running with dbt=1.10.10
[0m23:34:15.321308 [debug] [MainThread]: running dbt with arguments {'static_parser': 'True', 'version_check': 'True', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'write_json': 'True', 'profiles_dir': '/home/aniruth/AI/DBT/DBT_Master/dbt_anirudh', 'quiet': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'log_cache_events': 'False', 'printer_width': '80', 'empty': 'False', 'invocation_command': 'dbt run --select bronze_store bronze_customer', 'debug': 'False', 'warn_error': 'None', 'log_format': 'default', 'fail_fast': 'False', 'send_anonymous_usage_stats': 'True', 'target_path': 'None', 'use_colors': 'True', 'use_experimental_parser': 'False', 'log_path': '/home/aniruth/AI/DBT/DBT_Master/dbt_anirudh/logs', 'no_print': 'None', 'indirect_selection': 'eager', 'introspect': 'True'}
[0m23:34:15.920764 [debug] [MainThread]: Spark adapter: Setting pyhive.hive logging to ERROR
[0m23:34:15.921164 [debug] [MainThread]: Spark adapter: Setting thrift.transport logging to ERROR
[0m23:34:15.921478 [debug] [MainThread]: Spark adapter: Setting thrift.protocol logging to ERROR
[0m23:34:16.428648 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '75e0ca8e-e70b-4c84-a90f-08fd053ab753', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x715ec0cc7fb0>]}
[0m23:34:16.476938 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '75e0ca8e-e70b-4c84-a90f-08fd053ab753', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x715ec2a76d20>]}
[0m23:34:16.477501 [info ] [MainThread]: Registered adapter: databricks=1.10.9
[0m23:34:16.559857 [debug] [MainThread]: checksum: 502a0dc23e9052e1ae09f7c44ee219ef7a02dfea7e7d66580d54c304c14d553b, vars: {}, profile: , target: , version: 1.10.10
[0m23:34:16.633708 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m23:34:16.634056 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m23:34:16.639830 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 2 unused configuration paths:
- models.dbt_anirudh.gold
- models.dbt_anirudh.silver
[0m23:34:16.664844 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '75e0ca8e-e70b-4c84-a90f-08fd053ab753', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x715edf7cee10>]}
[0m23:34:16.721679 [debug] [MainThread]: Wrote artifact WritableManifest to /home/aniruth/AI/DBT/DBT_Master/dbt_anirudh/target/manifest.json
[0m23:34:16.723070 [debug] [MainThread]: Wrote artifact SemanticManifest to /home/aniruth/AI/DBT/DBT_Master/dbt_anirudh/target/semantic_manifest.json
[0m23:34:16.728563 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '75e0ca8e-e70b-4c84-a90f-08fd053ab753', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x715ec08890d0>]}
[0m23:34:16.728940 [info ] [MainThread]: Found 6 models, 6 sources, 686 macros
[0m23:34:16.729219 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '75e0ca8e-e70b-4c84-a90f-08fd053ab753', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x715ec05bf3e0>]}
[0m23:34:16.730387 [info ] [MainThread]: 
[0m23:34:16.730702 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m23:34:16.730946 [info ] [MainThread]: 
[0m23:34:16.731340 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=master) - Creating connection
[0m23:34:16.731585 [debug] [MainThread]: Acquiring new databricks connection 'master'
[0m23:34:16.737567 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=list_dbt_learning) - Creating connection
[0m23:34:16.738038 [debug] [ThreadPool]: Acquiring new databricks connection 'list_dbt_learning'
[0m23:34:16.738327 [debug] [ThreadPool]: Using databricks connection "list_dbt_learning"
[0m23:34:16.738590 [debug] [ThreadPool]: On list_dbt_learning: GetSchemas(database=dbt_learning, schema=None)
[0m23:34:16.738837 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m23:34:17.897035 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f09002-e65f-1c6f-8e01-f4fe44060c09) - Created
[0m23:34:18.490858 [debug] [ThreadPool]: SQL status: OK in 1.750 seconds
[0m23:34:18.491899 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01f09002-e65f-1c6f-8e01-f4fe44060c09, command-id=01f09002-e68c-1a9e-9fca-e869a659b965) - Closing
[0m23:34:18.492267 [debug] [ThreadPool]: On list_dbt_learning: Close
[0m23:34:18.492556 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f09002-e65f-1c6f-8e01-f4fe44060c09) - Closing
[0m23:34:18.808198 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=list_dbt_learning_bronze) - Creating connection
[0m23:34:18.809333 [debug] [ThreadPool]: Acquiring new databricks connection 'list_dbt_learning_bronze'
[0m23:34:18.831310 [debug] [ThreadPool]: Using databricks connection "list_dbt_learning_bronze"
[0m23:34:18.831684 [debug] [ThreadPool]: On list_dbt_learning_bronze: /* {"app": "dbt", "dbt_version": "1.10.10", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_anirudh", "target_name": "dev", "connection_name": "list_dbt_learning_bronze"} */

    
SELECT
  table_name,
  if(table_type IN ('EXTERNAL', 'MANAGED', 'MANAGED_SHALLOW_CLONE', 'EXTERNAL_SHALLOW_CLONE'), 'table', lower(table_type)) AS table_type,
  lower(data_source_format) AS file_format,
  table_owner,
  if(
    table_type IN (
      'EXTERNAL',
      'MANAGED',
      'MANAGED_SHALLOW_CLONE',
      'EXTERNAL_SHALLOW_CLONE'
    ),
    lower(table_type),
    NULL
  ) AS databricks_table_type
FROM `system`.`information_schema`.`tables`
WHERE table_catalog = 'dbt_learning' 
  AND table_schema = 'bronze'

  
[0m23:34:18.831924 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m23:34:20.018499 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f09002-e799-178f-aab8-7302b4f8b93b) - Created
[0m23:34:20.632758 [debug] [ThreadPool]: SQL status: OK in 1.800 seconds
[0m23:34:20.642678 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01f09002-e799-178f-aab8-7302b4f8b93b, command-id=01f09002-e7cf-1d6c-8766-d7b7be147ed1) - Closing
[0m23:34:20.644474 [debug] [ThreadPool]: On list_dbt_learning_bronze: Close
[0m23:34:20.645774 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f09002-e799-178f-aab8-7302b4f8b93b) - Closing
[0m23:34:20.966372 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '75e0ca8e-e70b-4c84-a90f-08fd053ab753', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x715ee41e02c0>]}
[0m23:34:20.971266 [debug] [Thread-3 (]: Began running node model.dbt_anirudh.bronze_customer
[0m23:34:20.972762 [info ] [Thread-3 (]: 1 of 2 START sql table model bronze.bronze_customer ............................ [RUN]
[0m23:34:20.974021 [debug] [Thread-3 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.dbt_anirudh.bronze_customer) - Creating connection
[0m23:34:20.974871 [debug] [Thread-3 (]: Acquiring new databricks connection 'model.dbt_anirudh.bronze_customer'
[0m23:34:20.975716 [debug] [Thread-3 (]: Began compiling node model.dbt_anirudh.bronze_customer
[0m23:34:20.991162 [debug] [Thread-3 (]: Writing injected SQL for node "model.dbt_anirudh.bronze_customer"
[0m23:34:20.992033 [debug] [Thread-3 (]: Began executing node model.dbt_anirudh.bronze_customer
[0m23:34:21.006471 [debug] [Thread-3 (]: MATERIALIZING TABLE
[0m23:34:21.007024 [warn ] [Thread-3 (]: [[33mWARNING[0m]: Use revamped materializations based on separating create and insert.  This allows more performant column comments, as well as new column features.
You may opt into the new behavior sooner by setting `flags.use_materialization_v2` to `True` in `dbt_project.yml`.
Visit https://docs.getdbt.com/reference/global-configs/behavior-changes for more information.
[0m23:34:21.007423 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'BehaviorChangeEvent', 'label': '75e0ca8e-e70b-4c84-a90f-08fd053ab753', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x715ec06602c0>]}
[0m23:34:21.044320 [debug] [Thread-3 (]: Writing runtime sql for node "model.dbt_anirudh.bronze_customer"
[0m23:34:21.044917 [debug] [Thread-3 (]: Using databricks connection "model.dbt_anirudh.bronze_customer"
[0m23:34:21.045284 [debug] [Thread-3 (]: On model.dbt_anirudh.bronze_customer: /* {"app": "dbt", "dbt_version": "1.10.10", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_anirudh", "target_name": "dev", "node_id": "model.dbt_anirudh.bronze_customer"} */

  
    
        create or replace table `dbt_learning`.`bronze`.`bronze_customer`
      
      
  using delta
      
      
      
      
      
      
      
      as
      SELECT 
    *
FROM
    `dbt_learning`.`source`.`dim_customer`
  
[0m23:34:21.045622 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m23:34:22.167761 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f09002-e8eb-1fea-b5a3-9822e936b404) - Created
[0m23:34:24.872179 [debug] [Thread-3 (]: SQL status: OK in 3.830 seconds
[0m23:34:24.874649 [debug] [Thread-3 (]: Databricks adapter: Cursor(session-id=01f09002-e8eb-1fea-b5a3-9822e936b404, command-id=01f09002-e918-1431-8ef3-db7c7a10e44c) - Closing
[0m23:34:24.892701 [debug] [Thread-3 (]: Applying tags to relation None
[0m23:34:24.904671 [debug] [Thread-3 (]: On model.dbt_anirudh.bronze_customer: Close
[0m23:34:24.905015 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f09002-e8eb-1fea-b5a3-9822e936b404) - Closing
[0m23:34:25.222511 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '75e0ca8e-e70b-4c84-a90f-08fd053ab753', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x715ee4111af0>]}
[0m23:34:25.224209 [info ] [Thread-3 (]: 1 of 2 OK created sql table model bronze.bronze_customer ....................... [[32mOK[0m in 4.25s]
[0m23:34:25.225717 [debug] [Thread-3 (]: Finished running node model.dbt_anirudh.bronze_customer
[0m23:34:25.226708 [debug] [Thread-3 (]: Began running node model.dbt_anirudh.bronze_store
[0m23:34:25.227853 [info ] [Thread-3 (]: 2 of 2 START sql view model bronze.bronze_store ................................ [RUN]
[0m23:34:25.229340 [debug] [Thread-3 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.dbt_anirudh.bronze_store) - Creating connection
[0m23:34:25.230337 [debug] [Thread-3 (]: Acquiring new databricks connection 'model.dbt_anirudh.bronze_store'
[0m23:34:25.231070 [debug] [Thread-3 (]: Began compiling node model.dbt_anirudh.bronze_store
[0m23:34:25.235426 [debug] [Thread-3 (]: Writing injected SQL for node "model.dbt_anirudh.bronze_store"
[0m23:34:25.236211 [debug] [Thread-3 (]: Began executing node model.dbt_anirudh.bronze_store
[0m23:34:25.249654 [debug] [Thread-3 (]: MATERIALIZING VIEW
[0m23:34:25.264503 [debug] [Thread-3 (]: Creating view `dbt_learning`.`bronze`.`bronze_store`
[0m23:34:25.265241 [debug] [Thread-3 (]: Writing runtime sql for node "model.dbt_anirudh.bronze_store"
[0m23:34:25.265684 [debug] [Thread-3 (]: Using databricks connection "model.dbt_anirudh.bronze_store"
[0m23:34:25.266003 [debug] [Thread-3 (]: On model.dbt_anirudh.bronze_store: /* {"app": "dbt", "dbt_version": "1.10.10", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_anirudh", "target_name": "dev", "node_id": "model.dbt_anirudh.bronze_store"} */

  
  
  create or replace view `dbt_learning`.`bronze`.`bronze_store`
  
  as (
    SELECT
    *
FROM
    `dbt_learning`.`source`.`dim_store`
  )

[0m23:34:25.266286 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m23:34:26.395503 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f09002-eb70-1b13-925d-8d8c4cb08a6b) - Created
[0m23:34:27.213692 [debug] [Thread-3 (]: SQL status: OK in 1.950 seconds
[0m23:34:27.216107 [debug] [Thread-3 (]: Databricks adapter: Cursor(session-id=01f09002-eb70-1b13-925d-8d8c4cb08a6b, command-id=01f09002-eb9d-1ee5-b6b4-9c5f6d8d3069) - Closing
[0m23:34:27.217700 [debug] [Thread-3 (]: Applying tags to relation None
[0m23:34:27.219606 [debug] [Thread-3 (]: On model.dbt_anirudh.bronze_store: Close
[0m23:34:27.220599 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f09002-eb70-1b13-925d-8d8c4cb08a6b) - Closing
[0m23:34:27.537040 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '75e0ca8e-e70b-4c84-a90f-08fd053ab753', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x715ec04c79b0>]}
[0m23:34:27.538718 [info ] [Thread-3 (]: 2 of 2 OK created sql view model bronze.bronze_store ........................... [[32mOK[0m in 2.31s]
[0m23:34:27.540203 [debug] [Thread-3 (]: Finished running node model.dbt_anirudh.bronze_store
[0m23:34:27.542958 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=master) - Creating connection
[0m23:34:27.543862 [debug] [MainThread]: Acquiring new databricks connection 'master'
[0m23:34:27.544871 [info ] [MainThread]: 
[0m23:34:27.545726 [info ] [MainThread]: Finished running 1 table model, 1 view model in 0 hours 0 minutes and 10.81 seconds (10.81s).
[0m23:34:27.547783 [debug] [MainThread]: Command end result
[0m23:34:27.578207 [debug] [MainThread]: Wrote artifact WritableManifest to /home/aniruth/AI/DBT/DBT_Master/dbt_anirudh/target/manifest.json
[0m23:34:27.580326 [debug] [MainThread]: Wrote artifact SemanticManifest to /home/aniruth/AI/DBT/DBT_Master/dbt_anirudh/target/semantic_manifest.json
[0m23:34:27.584719 [debug] [MainThread]: Wrote artifact RunExecutionResult to /home/aniruth/AI/DBT/DBT_Master/dbt_anirudh/target/run_results.json
[0m23:34:27.585016 [info ] [MainThread]: 
[0m23:34:27.585343 [info ] [MainThread]: [32mCompleted successfully[0m
[0m23:34:27.585601 [info ] [MainThread]: 
[0m23:34:27.585853 [info ] [MainThread]: Done. PASS=2 WARN=0 ERROR=0 SKIP=0 NO-OP=0 TOTAL=2
[0m23:34:27.586497 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 12.310643, "process_in_blocks": "0", "process_kernel_time": 0.189685, "process_mem_max_rss": "246280", "process_out_blocks": "3120", "process_user_time": 3.971408}
[0m23:34:27.586879 [debug] [MainThread]: Command `dbt run` succeeded at 23:34:27.586805 after 12.31 seconds
[0m23:34:27.587169 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x715ee21b71d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x715ec05f4800>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x715ec091c350>]}
[0m23:34:27.587471 [debug] [MainThread]: Flushing usage events
[0m23:34:28.825528 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m23:35:31.113373 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x76a4e2d48440>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x76a4e3ff2f60>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x76a4e2946570>]}


============================== 23:35:31.115694 | 1cd226ad-8f51-4547-8644-b900e59727e5 ==============================
[0m23:35:31.115694 [info ] [MainThread]: Running with dbt=1.10.10
[0m23:35:31.116170 [debug] [MainThread]: running dbt with arguments {'log_format': 'default', 'warn_error': 'None', 'empty': 'False', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'target_path': 'None', 'write_json': 'True', 'indirect_selection': 'eager', 'version_check': 'True', 'use_experimental_parser': 'False', 'send_anonymous_usage_stats': 'True', 'cache_selected_only': 'False', 'invocation_command': 'dbt run --select models/bronze', 'partial_parse': 'True', 'fail_fast': 'False', 'profiles_dir': '/home/aniruth/AI/DBT/DBT_Master/dbt_anirudh', 'log_cache_events': 'False', 'static_parser': 'True', 'no_print': 'None', 'quiet': 'False', 'introspect': 'True', 'log_path': '/home/aniruth/AI/DBT/DBT_Master/dbt_anirudh/logs', 'printer_width': '80', 'debug': 'False', 'use_colors': 'True'}
[0m23:35:31.692337 [debug] [MainThread]: Spark adapter: Setting pyhive.hive logging to ERROR
[0m23:35:31.692780 [debug] [MainThread]: Spark adapter: Setting thrift.transport logging to ERROR
[0m23:35:31.693050 [debug] [MainThread]: Spark adapter: Setting thrift.protocol logging to ERROR
[0m23:35:32.178408 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '1cd226ad-8f51-4547-8644-b900e59727e5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x76a4c0f59d90>]}
[0m23:35:32.224851 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '1cd226ad-8f51-4547-8644-b900e59727e5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x76a4dfbd3560>]}
[0m23:35:32.225379 [info ] [MainThread]: Registered adapter: databricks=1.10.9
[0m23:35:32.302580 [debug] [MainThread]: checksum: 502a0dc23e9052e1ae09f7c44ee219ef7a02dfea7e7d66580d54c304c14d553b, vars: {}, profile: , target: , version: 1.10.10
[0m23:35:32.371165 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m23:35:32.371492 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m23:35:32.376923 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 2 unused configuration paths:
- models.dbt_anirudh.silver
- models.dbt_anirudh.gold
[0m23:35:32.397760 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '1cd226ad-8f51-4547-8644-b900e59727e5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x76a4c0d70a70>]}
[0m23:35:32.450445 [debug] [MainThread]: Wrote artifact WritableManifest to /home/aniruth/AI/DBT/DBT_Master/dbt_anirudh/target/manifest.json
[0m23:35:32.451810 [debug] [MainThread]: Wrote artifact SemanticManifest to /home/aniruth/AI/DBT/DBT_Master/dbt_anirudh/target/semantic_manifest.json
[0m23:35:32.456964 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '1cd226ad-8f51-4547-8644-b900e59727e5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x76a4c0c28440>]}
[0m23:35:32.457320 [info ] [MainThread]: Found 6 models, 6 sources, 686 macros
[0m23:35:32.457610 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '1cd226ad-8f51-4547-8644-b900e59727e5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x76a4c0d55e20>]}
[0m23:35:32.459286 [info ] [MainThread]: 
[0m23:35:32.459599 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m23:35:32.459833 [info ] [MainThread]: 
[0m23:35:32.460219 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=master) - Creating connection
[0m23:35:32.460476 [debug] [MainThread]: Acquiring new databricks connection 'master'
[0m23:35:32.465284 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=list_dbt_learning) - Creating connection
[0m23:35:32.465674 [debug] [ThreadPool]: Acquiring new databricks connection 'list_dbt_learning'
[0m23:35:32.465993 [debug] [ThreadPool]: Using databricks connection "list_dbt_learning"
[0m23:35:32.466256 [debug] [ThreadPool]: On list_dbt_learning: GetSchemas(database=dbt_learning, schema=None)
[0m23:35:32.466508 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m23:35:33.617830 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f09003-1380-10ed-b22f-840ed6e16298) - Created
[0m23:35:34.164078 [debug] [ThreadPool]: SQL status: OK in 1.700 seconds
[0m23:35:34.165237 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01f09003-1380-10ed-b22f-840ed6e16298, command-id=01f09003-13b3-1b22-bddc-a3f3c6e73681) - Closing
[0m23:35:34.165604 [debug] [ThreadPool]: On list_dbt_learning: Close
[0m23:35:34.165869 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f09003-1380-10ed-b22f-840ed6e16298) - Closing
[0m23:35:34.470249 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=list_dbt_learning_bronze) - Creating connection
[0m23:35:34.471416 [debug] [ThreadPool]: Acquiring new databricks connection 'list_dbt_learning_bronze'
[0m23:35:34.508081 [debug] [ThreadPool]: Using databricks connection "list_dbt_learning_bronze"
[0m23:35:34.508806 [debug] [ThreadPool]: On list_dbt_learning_bronze: /* {"app": "dbt", "dbt_version": "1.10.10", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_anirudh", "target_name": "dev", "connection_name": "list_dbt_learning_bronze"} */

    
SELECT
  table_name,
  if(table_type IN ('EXTERNAL', 'MANAGED', 'MANAGED_SHALLOW_CLONE', 'EXTERNAL_SHALLOW_CLONE'), 'table', lower(table_type)) AS table_type,
  lower(data_source_format) AS file_format,
  table_owner,
  if(
    table_type IN (
      'EXTERNAL',
      'MANAGED',
      'MANAGED_SHALLOW_CLONE',
      'EXTERNAL_SHALLOW_CLONE'
    ),
    lower(table_type),
    NULL
  ) AS databricks_table_type
FROM `system`.`information_schema`.`tables`
WHERE table_catalog = 'dbt_learning' 
  AND table_schema = 'bronze'

  
[0m23:35:34.509335 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m23:35:35.682085 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f09003-14bc-12db-913c-0c0377e1735a) - Created
[0m23:35:36.317873 [debug] [ThreadPool]: SQL status: OK in 1.810 seconds
[0m23:35:36.324820 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01f09003-14bc-12db-913c-0c0377e1735a, command-id=01f09003-14ea-11b5-8d88-06e0c316eca0) - Closing
[0m23:35:36.326136 [debug] [ThreadPool]: On list_dbt_learning_bronze: Close
[0m23:35:36.326757 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f09003-14bc-12db-913c-0c0377e1735a) - Closing
[0m23:35:36.643564 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '1cd226ad-8f51-4547-8644-b900e59727e5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x76a4c0d563f0>]}
[0m23:35:36.649560 [debug] [Thread-3 (]: Began running node model.dbt_anirudh.bronze_customer
[0m23:35:36.650954 [info ] [Thread-3 (]: 1 of 6 START sql table model bronze.bronze_customer ............................ [RUN]
[0m23:35:36.652413 [debug] [Thread-3 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.dbt_anirudh.bronze_customer) - Creating connection
[0m23:35:36.653301 [debug] [Thread-3 (]: Acquiring new databricks connection 'model.dbt_anirudh.bronze_customer'
[0m23:35:36.654159 [debug] [Thread-3 (]: Began compiling node model.dbt_anirudh.bronze_customer
[0m23:35:36.666034 [debug] [Thread-3 (]: Writing injected SQL for node "model.dbt_anirudh.bronze_customer"
[0m23:35:36.667050 [debug] [Thread-3 (]: Began executing node model.dbt_anirudh.bronze_customer
[0m23:35:36.680641 [debug] [Thread-3 (]: MATERIALIZING TABLE
[0m23:35:36.681198 [warn ] [Thread-3 (]: [[33mWARNING[0m]: Use revamped materializations based on separating create and insert.  This allows more performant column comments, as well as new column features.
You may opt into the new behavior sooner by setting `flags.use_materialization_v2` to `True` in `dbt_project.yml`.
Visit https://docs.getdbt.com/reference/global-configs/behavior-changes for more information.
[0m23:35:36.681620 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'BehaviorChangeEvent', 'label': '1cd226ad-8f51-4547-8644-b900e59727e5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x76a4c0a07da0>]}
[0m23:35:36.715621 [debug] [Thread-3 (]: Writing runtime sql for node "model.dbt_anirudh.bronze_customer"
[0m23:35:36.716358 [debug] [Thread-3 (]: Using databricks connection "model.dbt_anirudh.bronze_customer"
[0m23:35:36.716764 [debug] [Thread-3 (]: On model.dbt_anirudh.bronze_customer: /* {"app": "dbt", "dbt_version": "1.10.10", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_anirudh", "target_name": "dev", "node_id": "model.dbt_anirudh.bronze_customer"} */

  
    
        create or replace table `dbt_learning`.`bronze`.`bronze_customer`
      
      
  using delta
      
      
      
      
      
      
      
      as
      SELECT 
    *
FROM
    `dbt_learning`.`source`.`dim_customer`
  
[0m23:35:36.717051 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m23:35:37.823757 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f09003-1605-1960-81b1-8f9c8cf7b642) - Created
[0m23:35:40.311473 [debug] [Thread-3 (]: SQL status: OK in 3.590 seconds
[0m23:35:40.313915 [debug] [Thread-3 (]: Databricks adapter: Cursor(session-id=01f09003-1605-1960-81b1-8f9c8cf7b642, command-id=01f09003-1630-145c-8609-e9649e85184f) - Closing
[0m23:35:40.331643 [debug] [Thread-3 (]: Applying tags to relation None
[0m23:35:40.345145 [debug] [Thread-3 (]: On model.dbt_anirudh.bronze_customer: Close
[0m23:35:40.345553 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f09003-1605-1960-81b1-8f9c8cf7b642) - Closing
[0m23:35:40.665098 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1cd226ad-8f51-4547-8644-b900e59727e5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x76a4e44c9c70>]}
[0m23:35:40.666834 [info ] [Thread-3 (]: 1 of 6 OK created sql table model bronze.bronze_customer ....................... [[32mOK[0m in 4.01s]
[0m23:35:40.668646 [debug] [Thread-3 (]: Finished running node model.dbt_anirudh.bronze_customer
[0m23:35:40.669632 [debug] [Thread-3 (]: Began running node model.dbt_anirudh.bronze_date
[0m23:35:40.670777 [info ] [Thread-3 (]: 2 of 6 START sql view model bronze.bronze_date ................................. [RUN]
[0m23:35:40.672053 [debug] [Thread-3 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.dbt_anirudh.bronze_date) - Creating connection
[0m23:35:40.672857 [debug] [Thread-3 (]: Acquiring new databricks connection 'model.dbt_anirudh.bronze_date'
[0m23:35:40.673527 [debug] [Thread-3 (]: Began compiling node model.dbt_anirudh.bronze_date
[0m23:35:40.677142 [debug] [Thread-3 (]: Writing injected SQL for node "model.dbt_anirudh.bronze_date"
[0m23:35:40.677810 [debug] [Thread-3 (]: Began executing node model.dbt_anirudh.bronze_date
[0m23:35:40.690498 [debug] [Thread-3 (]: MATERIALIZING VIEW
[0m23:35:40.704290 [debug] [Thread-3 (]: Creating view `dbt_learning`.`bronze`.`bronze_date`
[0m23:35:40.704933 [debug] [Thread-3 (]: Writing runtime sql for node "model.dbt_anirudh.bronze_date"
[0m23:35:40.705337 [debug] [Thread-3 (]: Using databricks connection "model.dbt_anirudh.bronze_date"
[0m23:35:40.705705 [debug] [Thread-3 (]: On model.dbt_anirudh.bronze_date: /* {"app": "dbt", "dbt_version": "1.10.10", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_anirudh", "target_name": "dev", "node_id": "model.dbt_anirudh.bronze_date"} */

  
  
  create or replace view `dbt_learning`.`bronze`.`bronze_date`
  
  as (
    SELECT  
    *
FROM
    `dbt_learning`.`source`.`dim_date`
  )

[0m23:35:40.705968 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m23:35:41.817236 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f09003-1864-1e81-993f-ab845ee51f8c) - Created
[0m23:35:42.624734 [debug] [Thread-3 (]: SQL status: OK in 1.920 seconds
[0m23:35:42.625620 [debug] [Thread-3 (]: Databricks adapter: Cursor(session-id=01f09003-1864-1e81-993f-ab845ee51f8c, command-id=01f09003-1891-1862-820f-bbbeb095f8ca) - Closing
[0m23:35:42.626160 [debug] [Thread-3 (]: Applying tags to relation None
[0m23:35:42.626814 [debug] [Thread-3 (]: On model.dbt_anirudh.bronze_date: Close
[0m23:35:42.627093 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f09003-1864-1e81-993f-ab845ee51f8c) - Closing
[0m23:35:42.940103 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1cd226ad-8f51-4547-8644-b900e59727e5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x76a4c007cec0>]}
[0m23:35:42.941867 [info ] [Thread-3 (]: 2 of 6 OK created sql view model bronze.bronze_date ............................ [[32mOK[0m in 2.27s]
[0m23:35:42.943295 [debug] [Thread-3 (]: Finished running node model.dbt_anirudh.bronze_date
[0m23:35:42.944267 [debug] [Thread-3 (]: Began running node model.dbt_anirudh.bronze_product
[0m23:35:42.945364 [info ] [Thread-3 (]: 3 of 6 START sql table model bronze.bronze_product ............................. [RUN]
[0m23:35:42.946820 [debug] [Thread-3 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.dbt_anirudh.bronze_product) - Creating connection
[0m23:35:42.947508 [debug] [Thread-3 (]: Acquiring new databricks connection 'model.dbt_anirudh.bronze_product'
[0m23:35:42.948164 [debug] [Thread-3 (]: Began compiling node model.dbt_anirudh.bronze_product
[0m23:35:42.954937 [debug] [Thread-3 (]: Writing injected SQL for node "model.dbt_anirudh.bronze_product"
[0m23:35:42.955576 [debug] [Thread-3 (]: Began executing node model.dbt_anirudh.bronze_product
[0m23:35:42.957259 [debug] [Thread-3 (]: MATERIALIZING TABLE
[0m23:35:42.958466 [debug] [Thread-3 (]: Writing runtime sql for node "model.dbt_anirudh.bronze_product"
[0m23:35:42.958866 [debug] [Thread-3 (]: Using databricks connection "model.dbt_anirudh.bronze_product"
[0m23:35:42.959173 [debug] [Thread-3 (]: On model.dbt_anirudh.bronze_product: /* {"app": "dbt", "dbt_version": "1.10.10", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_anirudh", "target_name": "dev", "node_id": "model.dbt_anirudh.bronze_product"} */

  
    
        create or replace table `dbt_learning`.`bronze`.`bronze_product`
      
      
  using delta
      
      
      
      
      
      
      
      as
      SELECT
    *
FROM
    `dbt_learning`.`source`.`dim_product`
  
[0m23:35:42.959462 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m23:35:44.050846 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f09003-19ba-1c8b-ba77-cd2ffc173643) - Created
[0m23:35:46.190942 [debug] [Thread-3 (]: SQL status: OK in 3.230 seconds
[0m23:35:46.192825 [debug] [Thread-3 (]: Databricks adapter: Cursor(session-id=01f09003-19ba-1c8b-ba77-cd2ffc173643, command-id=01f09003-19e5-16e1-a063-25d855b0f3df) - Closing
[0m23:35:46.194027 [debug] [Thread-3 (]: Applying tags to relation None
[0m23:35:46.195512 [debug] [Thread-3 (]: On model.dbt_anirudh.bronze_product: Close
[0m23:35:46.196112 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f09003-19ba-1c8b-ba77-cd2ffc173643) - Closing
[0m23:35:46.504142 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1cd226ad-8f51-4547-8644-b900e59727e5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x76a4c09e55e0>]}
[0m23:35:46.505328 [info ] [Thread-3 (]: 3 of 6 OK created sql table model bronze.bronze_product ........................ [[32mOK[0m in 3.56s]
[0m23:35:46.506015 [debug] [Thread-3 (]: Finished running node model.dbt_anirudh.bronze_product
[0m23:35:46.506621 [debug] [Thread-3 (]: Began running node model.dbt_anirudh.bronze_returns
[0m23:35:46.507041 [info ] [Thread-3 (]: 4 of 6 START sql table model bronze.bronze_returns ............................. [RUN]
[0m23:35:46.507487 [debug] [Thread-3 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.dbt_anirudh.bronze_returns) - Creating connection
[0m23:35:46.507778 [debug] [Thread-3 (]: Acquiring new databricks connection 'model.dbt_anirudh.bronze_returns'
[0m23:35:46.508042 [debug] [Thread-3 (]: Began compiling node model.dbt_anirudh.bronze_returns
[0m23:35:46.511691 [debug] [Thread-3 (]: Writing injected SQL for node "model.dbt_anirudh.bronze_returns"
[0m23:35:46.512173 [debug] [Thread-3 (]: Began executing node model.dbt_anirudh.bronze_returns
[0m23:35:46.513754 [debug] [Thread-3 (]: MATERIALIZING TABLE
[0m23:35:46.514810 [debug] [Thread-3 (]: Writing runtime sql for node "model.dbt_anirudh.bronze_returns"
[0m23:35:46.515220 [debug] [Thread-3 (]: Using databricks connection "model.dbt_anirudh.bronze_returns"
[0m23:35:46.515568 [debug] [Thread-3 (]: On model.dbt_anirudh.bronze_returns: /* {"app": "dbt", "dbt_version": "1.10.10", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_anirudh", "target_name": "dev", "node_id": "model.dbt_anirudh.bronze_returns"} */

  
    
        create or replace table `dbt_learning`.`bronze`.`bronze_returns`
      
      
  using delta
      
      
      
      
      
      
      
      as
      SELECT
    *
FROM
    `dbt_learning`.`source`.`fact_returns`
  
[0m23:35:46.515855 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m23:35:47.645852 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f09003-1bde-1a70-8598-5afc79c59093) - Created
[0m23:35:49.590941 [debug] [Thread-3 (]: SQL status: OK in 3.070 seconds
[0m23:35:49.593207 [debug] [Thread-3 (]: Databricks adapter: Cursor(session-id=01f09003-1bde-1a70-8598-5afc79c59093, command-id=01f09003-1c0c-1850-9cf9-08f92d1a8d90) - Closing
[0m23:35:49.595071 [debug] [Thread-3 (]: Applying tags to relation None
[0m23:35:49.597239 [debug] [Thread-3 (]: On model.dbt_anirudh.bronze_returns: Close
[0m23:35:49.597945 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f09003-1bde-1a70-8598-5afc79c59093) - Closing
[0m23:35:49.907812 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1cd226ad-8f51-4547-8644-b900e59727e5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x76a4c09becc0>]}
[0m23:35:49.909457 [info ] [Thread-3 (]: 4 of 6 OK created sql table model bronze.bronze_returns ........................ [[32mOK[0m in 3.40s]
[0m23:35:49.910808 [debug] [Thread-3 (]: Finished running node model.dbt_anirudh.bronze_returns
[0m23:35:49.911765 [debug] [Thread-3 (]: Began running node model.dbt_anirudh.bronze_sales
[0m23:35:49.913613 [info ] [Thread-3 (]: 5 of 6 START sql view model bronze.bronze_sales ................................ [RUN]
[0m23:35:49.915693 [debug] [Thread-3 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.dbt_anirudh.bronze_sales) - Creating connection
[0m23:35:49.916833 [debug] [Thread-3 (]: Acquiring new databricks connection 'model.dbt_anirudh.bronze_sales'
[0m23:35:49.917750 [debug] [Thread-3 (]: Began compiling node model.dbt_anirudh.bronze_sales
[0m23:35:49.922104 [debug] [Thread-3 (]: Writing injected SQL for node "model.dbt_anirudh.bronze_sales"
[0m23:35:49.922729 [debug] [Thread-3 (]: Began executing node model.dbt_anirudh.bronze_sales
[0m23:35:49.925163 [debug] [Thread-3 (]: MATERIALIZING VIEW
[0m23:35:49.926377 [debug] [Thread-3 (]: Creating view `dbt_learning`.`bronze`.`bronze_sales`
[0m23:35:49.927138 [debug] [Thread-3 (]: Writing runtime sql for node "model.dbt_anirudh.bronze_sales"
[0m23:35:49.927671 [debug] [Thread-3 (]: Using databricks connection "model.dbt_anirudh.bronze_sales"
[0m23:35:49.927991 [debug] [Thread-3 (]: On model.dbt_anirudh.bronze_sales: /* {"app": "dbt", "dbt_version": "1.10.10", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_anirudh", "target_name": "dev", "node_id": "model.dbt_anirudh.bronze_sales"} */

  
  
  create or replace view `dbt_learning`.`bronze`.`bronze_sales`
  
  as (
    -- block level config


SELECT 
    * 
FROM
    
    `dbt_learning`.`source`.`fact_sales`
  )

[0m23:35:49.928256 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m23:35:51.069424 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f09003-1de8-18de-9a84-909b53d22f98) - Created
[0m23:35:51.902187 [debug] [Thread-3 (]: SQL status: OK in 1.970 seconds
[0m23:35:51.904214 [debug] [Thread-3 (]: Databricks adapter: Cursor(session-id=01f09003-1de8-18de-9a84-909b53d22f98, command-id=01f09003-1e15-1778-8c54-936088f6bcf0) - Closing
[0m23:35:51.905581 [debug] [Thread-3 (]: Applying tags to relation None
[0m23:35:51.907354 [debug] [Thread-3 (]: On model.dbt_anirudh.bronze_sales: Close
[0m23:35:51.908396 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f09003-1de8-18de-9a84-909b53d22f98) - Closing
[0m23:35:52.228491 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1cd226ad-8f51-4547-8644-b900e59727e5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x76a4c00c6150>]}
[0m23:35:52.229957 [info ] [Thread-3 (]: 5 of 6 OK created sql view model bronze.bronze_sales ........................... [[32mOK[0m in 2.31s]
[0m23:35:52.231005 [debug] [Thread-3 (]: Finished running node model.dbt_anirudh.bronze_sales
[0m23:35:52.231795 [debug] [Thread-3 (]: Began running node model.dbt_anirudh.bronze_store
[0m23:35:52.232667 [info ] [Thread-3 (]: 6 of 6 START sql view model bronze.bronze_store ................................ [RUN]
[0m23:35:52.233346 [debug] [Thread-3 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.dbt_anirudh.bronze_store) - Creating connection
[0m23:35:52.233792 [debug] [Thread-3 (]: Acquiring new databricks connection 'model.dbt_anirudh.bronze_store'
[0m23:35:52.234193 [debug] [Thread-3 (]: Began compiling node model.dbt_anirudh.bronze_store
[0m23:35:52.239514 [debug] [Thread-3 (]: Writing injected SQL for node "model.dbt_anirudh.bronze_store"
[0m23:35:52.240260 [debug] [Thread-3 (]: Began executing node model.dbt_anirudh.bronze_store
[0m23:35:52.244575 [debug] [Thread-3 (]: MATERIALIZING VIEW
[0m23:35:52.245302 [debug] [Thread-3 (]: Creating view `dbt_learning`.`bronze`.`bronze_store`
[0m23:35:52.245917 [debug] [Thread-3 (]: Writing runtime sql for node "model.dbt_anirudh.bronze_store"
[0m23:35:52.246302 [debug] [Thread-3 (]: Using databricks connection "model.dbt_anirudh.bronze_store"
[0m23:35:52.246601 [debug] [Thread-3 (]: On model.dbt_anirudh.bronze_store: /* {"app": "dbt", "dbt_version": "1.10.10", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_anirudh", "target_name": "dev", "node_id": "model.dbt_anirudh.bronze_store"} */

  
  
  create or replace view `dbt_learning`.`bronze`.`bronze_store`
  
  as (
    SELECT
    *
FROM
    `dbt_learning`.`source`.`dim_store`
  )

[0m23:35:52.246876 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m23:35:53.369248 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f09003-1f48-1fc3-af60-6784449c8b10) - Created
[0m23:35:54.149488 [debug] [Thread-3 (]: SQL status: OK in 1.900 seconds
[0m23:35:54.150822 [debug] [Thread-3 (]: Databricks adapter: Cursor(session-id=01f09003-1f48-1fc3-af60-6784449c8b10, command-id=01f09003-1f75-1161-a299-6147da42df84) - Closing
[0m23:35:54.151666 [debug] [Thread-3 (]: Applying tags to relation None
[0m23:35:54.152567 [debug] [Thread-3 (]: On model.dbt_anirudh.bronze_store: Close
[0m23:35:54.152913 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f09003-1f48-1fc3-af60-6784449c8b10) - Closing
[0m23:35:54.467154 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1cd226ad-8f51-4547-8644-b900e59727e5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x76a4c00cda30>]}
[0m23:35:54.468777 [info ] [Thread-3 (]: 6 of 6 OK created sql view model bronze.bronze_store ........................... [[32mOK[0m in 2.23s]
[0m23:35:54.470213 [debug] [Thread-3 (]: Finished running node model.dbt_anirudh.bronze_store
[0m23:35:54.472745 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=master) - Creating connection
[0m23:35:54.473636 [debug] [MainThread]: Acquiring new databricks connection 'master'
[0m23:35:54.474527 [info ] [MainThread]: 
[0m23:35:54.475179 [info ] [MainThread]: Finished running 3 table models, 3 view models in 0 hours 0 minutes and 22.01 seconds (22.01s).
[0m23:35:54.477968 [debug] [MainThread]: Command end result
[0m23:35:54.503091 [debug] [MainThread]: Wrote artifact WritableManifest to /home/aniruth/AI/DBT/DBT_Master/dbt_anirudh/target/manifest.json
[0m23:35:54.504816 [debug] [MainThread]: Wrote artifact SemanticManifest to /home/aniruth/AI/DBT/DBT_Master/dbt_anirudh/target/semantic_manifest.json
[0m23:35:54.509174 [debug] [MainThread]: Wrote artifact RunExecutionResult to /home/aniruth/AI/DBT/DBT_Master/dbt_anirudh/target/run_results.json
[0m23:35:54.509486 [info ] [MainThread]: 
[0m23:35:54.509800 [info ] [MainThread]: [32mCompleted successfully[0m
[0m23:35:54.510061 [info ] [MainThread]: 
[0m23:35:54.510332 [info ] [MainThread]: Done. PASS=6 WARN=0 ERROR=0 SKIP=0 NO-OP=0 TOTAL=6
[0m23:35:54.510986 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 23.4424, "process_in_blocks": "0", "process_kernel_time": 0.16677, "process_mem_max_rss": "246904", "process_out_blocks": "3216", "process_user_time": 4.329054}
[0m23:35:54.511333 [debug] [MainThread]: Command `dbt run` succeeded at 23:35:54.511265 after 23.44 seconds
[0m23:35:54.511636 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x76a4e3ff2f60>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x76a4c13100e0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x76a4e262c740>]}
[0m23:35:54.511913 [debug] [MainThread]: Flushing usage events
[0m23:35:55.727553 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m10:40:45.328420 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7feaaa1498e0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7feaac7d6270>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7feaaa14bbc0>]}


============================== 10:40:45.331970 | fd93623c-dedf-4402-a80b-c22b08dc12ae ==============================
[0m10:40:45.331970 [info ] [MainThread]: Running with dbt=1.10.10
[0m10:40:45.332425 [debug] [MainThread]: running dbt with arguments {'log_format': 'default', 'introspect': 'True', 'write_json': 'True', 'debug': 'False', 'use_experimental_parser': 'False', 'use_colors': 'True', 'partial_parse': 'True', 'static_parser': 'True', 'printer_width': '80', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'empty': 'None', 'send_anonymous_usage_stats': 'True', 'profiles_dir': '/home/aniruth/AI/DBT/DBT_Master/dbt_anirudh', 'warn_error': 'None', 'invocation_command': 'dbt clean', 'cache_selected_only': 'False', 'version_check': 'True', 'log_cache_events': 'False', 'quiet': 'False', 'no_print': 'None', 'target_path': 'None', 'indirect_selection': 'eager', 'fail_fast': 'False', 'log_path': '/home/aniruth/AI/DBT/DBT_Master/dbt_anirudh/logs'}
[0m10:40:45.425534 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'fd93623c-dedf-4402-a80b-c22b08dc12ae', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7feaa9ed6f30>]}
[0m10:40:45.439369 [debug] [MainThread]: Resource report: {"command_name": "clean", "command_success": true, "command_wall_clock_time": 0.15376876, "process_in_blocks": "71656", "process_kernel_time": 0.118363, "process_mem_max_rss": "99636", "process_out_blocks": "8", "process_user_time": 1.061255}
[0m10:40:45.439735 [debug] [MainThread]: Command `dbt clean` succeeded at 10:40:45.439666 after 0.15 seconds
[0m10:40:45.440001 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7feaaa2303e0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7feaa9ed74d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7feaac58aea0>]}
[0m10:40:45.440284 [debug] [MainThread]: Flushing usage events
[0m10:40:46.453182 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m10:44:21.126779 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7461854df560>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x746185e2bdd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x746185e2bd70>]}


============================== 10:44:21.129847 | 4f080d1b-0fbe-4908-a959-5ca3c0965be7 ==============================
[0m10:44:21.129847 [info ] [MainThread]: Running with dbt=1.10.10
[0m10:44:21.130293 [debug] [MainThread]: running dbt with arguments {'use_experimental_parser': 'False', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'warn_error': 'None', 'debug': 'False', 'introspect': 'True', 'empty': 'False', 'indirect_selection': 'eager', 'target_path': 'None', 'static_parser': 'True', 'write_json': 'True', 'version_check': 'True', 'log_cache_events': 'False', 'use_colors': 'True', 'invocation_command': 'dbt run --select models/bronze', 'cache_selected_only': 'False', 'quiet': 'False', 'no_print': 'None', 'partial_parse': 'True', 'log_path': '/home/aniruth/AI/DBT/DBT_Master/dbt_anirudh/logs', 'printer_width': '80', 'profiles_dir': '/home/aniruth/AI/DBT/DBT_Master/dbt_anirudh', 'log_format': 'default', 'send_anonymous_usage_stats': 'True', 'fail_fast': 'False'}
[0m10:44:21.743391 [debug] [MainThread]: Spark adapter: Setting pyhive.hive logging to ERROR
[0m10:44:21.743806 [debug] [MainThread]: Spark adapter: Setting thrift.transport logging to ERROR
[0m10:44:21.744078 [debug] [MainThread]: Spark adapter: Setting thrift.protocol logging to ERROR
[0m10:44:22.451573 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '4f080d1b-0fbe-4908-a959-5ca3c0965be7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x74616424bb90>]}
[0m10:44:22.496363 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '4f080d1b-0fbe-4908-a959-5ca3c0965be7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x74616b826e10>]}
[0m10:44:22.496905 [info ] [MainThread]: Registered adapter: databricks=1.10.9
[0m10:44:22.578819 [debug] [MainThread]: checksum: 502a0dc23e9052e1ae09f7c44ee219ef7a02dfea7e7d66580d54c304c14d553b, vars: {}, profile: , target: , version: 1.10.10
[0m10:44:22.579300 [info ] [MainThread]: Unable to do partial parsing because saved manifest not found. Starting full parse.
[0m10:44:22.579610 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': '4f080d1b-0fbe-4908-a959-5ca3c0965be7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x746182e18f50>]}
[0m10:44:23.922737 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 2 unused configuration paths:
- models.dbt_anirudh.silver
- models.dbt_anirudh.gold
[0m10:44:23.930641 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '4f080d1b-0fbe-4908-a959-5ca3c0965be7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x74615e87c3e0>]}
[0m10:44:23.986658 [debug] [MainThread]: Wrote artifact WritableManifest to /home/aniruth/AI/DBT/DBT_Master/dbt_anirudh/target/manifest.json
[0m10:44:23.988911 [debug] [MainThread]: Wrote artifact SemanticManifest to /home/aniruth/AI/DBT/DBT_Master/dbt_anirudh/target/semantic_manifest.json
[0m10:44:23.996248 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '4f080d1b-0fbe-4908-a959-5ca3c0965be7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x74615fa31a90>]}
[0m10:44:23.996633 [info ] [MainThread]: Found 6 models, 6 sources, 686 macros
[0m10:44:23.996926 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '4f080d1b-0fbe-4908-a959-5ca3c0965be7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x74615e854920>]}
[0m10:44:23.998698 [info ] [MainThread]: 
[0m10:44:23.999077 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m10:44:23.999513 [info ] [MainThread]: 
[0m10:44:24.000130 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=master) - Creating connection
[0m10:44:24.000385 [debug] [MainThread]: Acquiring new databricks connection 'master'
[0m10:44:24.005970 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=list_dbt_learning) - Creating connection
[0m10:44:24.006380 [debug] [ThreadPool]: Acquiring new databricks connection 'list_dbt_learning'
[0m10:44:24.006747 [debug] [ThreadPool]: Using databricks connection "list_dbt_learning"
[0m10:44:24.007071 [debug] [ThreadPool]: On list_dbt_learning: GetSchemas(database=dbt_learning, schema=None)
[0m10:44:24.007437 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m10:44:25.594524 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f09129-ae54-1216-b455-56a96a93522e) - Created
[0m10:45:27.794943 [debug] [ThreadPool]: SQL status: OK in 63.790 seconds
[0m10:45:27.797965 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01f09129-ae54-1216-b455-56a96a93522e, command-id=01f09129-d296-1695-90e5-e5fd5b451c2a) - Closing
[0m10:45:27.799053 [debug] [ThreadPool]: On list_dbt_learning: Close
[0m10:45:27.799890 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f09129-ae54-1216-b455-56a96a93522e) - Closing
[0m10:45:28.130714 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=list_dbt_learning_bronze) - Creating connection
[0m10:45:28.131115 [debug] [ThreadPool]: Acquiring new databricks connection 'list_dbt_learning_bronze'
[0m10:45:28.139381 [debug] [ThreadPool]: Using databricks connection "list_dbt_learning_bronze"
[0m10:45:28.139752 [debug] [ThreadPool]: On list_dbt_learning_bronze: /* {"app": "dbt", "dbt_version": "1.10.10", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_anirudh", "target_name": "dev", "connection_name": "list_dbt_learning_bronze"} */

    
SELECT
  table_name,
  if(table_type IN ('EXTERNAL', 'MANAGED', 'MANAGED_SHALLOW_CLONE', 'EXTERNAL_SHALLOW_CLONE'), 'table', lower(table_type)) AS table_type,
  lower(data_source_format) AS file_format,
  table_owner,
  if(
    table_type IN (
      'EXTERNAL',
      'MANAGED',
      'MANAGED_SHALLOW_CLONE',
      'EXTERNAL_SHALLOW_CLONE'
    ),
    lower(table_type),
    NULL
  ) AS databricks_table_type
FROM `system`.`information_schema`.`tables`
WHERE table_catalog = 'dbt_learning' 
  AND table_schema = 'bronze'

  
[0m10:45:28.139984 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m10:45:29.261815 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f09129-d460-1c51-8962-f46e672a51fd) - Created
[0m10:45:32.501212 [debug] [ThreadPool]: SQL status: OK in 4.360 seconds
[0m10:45:32.511042 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01f09129-d460-1c51-8962-f46e672a51fd, command-id=01f09129-d498-1112-879a-b5a35883ee01) - Closing
[0m10:45:32.512518 [debug] [ThreadPool]: On list_dbt_learning_bronze: Close
[0m10:45:32.513337 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f09129-d460-1c51-8962-f46e672a51fd) - Closing
[0m10:45:32.838818 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '4f080d1b-0fbe-4908-a959-5ca3c0965be7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x74615e87c980>]}
[0m10:45:32.844342 [debug] [Thread-3 (]: Began running node model.dbt_anirudh.bronze_customer
[0m10:45:32.845989 [info ] [Thread-3 (]: 1 of 6 START sql table model bronze.bronze_customer ............................ [RUN]
[0m10:45:32.847474 [debug] [Thread-3 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.dbt_anirudh.bronze_customer) - Creating connection
[0m10:45:32.848382 [debug] [Thread-3 (]: Acquiring new databricks connection 'model.dbt_anirudh.bronze_customer'
[0m10:45:32.849253 [debug] [Thread-3 (]: Began compiling node model.dbt_anirudh.bronze_customer
[0m10:45:32.861629 [debug] [Thread-3 (]: Writing injected SQL for node "model.dbt_anirudh.bronze_customer"
[0m10:45:32.862618 [debug] [Thread-3 (]: Began executing node model.dbt_anirudh.bronze_customer
[0m10:45:32.884494 [debug] [Thread-3 (]: MATERIALIZING TABLE
[0m10:45:32.885515 [warn ] [Thread-3 (]: [[33mWARNING[0m]: Use revamped materializations based on separating create and insert.  This allows more performant column comments, as well as new column features.
You may opt into the new behavior sooner by setting `flags.use_materialization_v2` to `True` in `dbt_project.yml`.
Visit https://docs.getdbt.com/reference/global-configs/behavior-changes for more information.
[0m10:45:32.886272 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'BehaviorChangeEvent', 'label': '4f080d1b-0fbe-4908-a959-5ca3c0965be7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x74615e86e8a0>]}
[0m10:45:32.931591 [debug] [Thread-3 (]: Writing runtime sql for node "model.dbt_anirudh.bronze_customer"
[0m10:45:32.932169 [debug] [Thread-3 (]: Using databricks connection "model.dbt_anirudh.bronze_customer"
[0m10:45:32.932528 [debug] [Thread-3 (]: On model.dbt_anirudh.bronze_customer: /* {"app": "dbt", "dbt_version": "1.10.10", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_anirudh", "target_name": "dev", "node_id": "model.dbt_anirudh.bronze_customer"} */

  
    
        create or replace table `dbt_learning`.`bronze`.`bronze_customer`
      
      
  using delta
      
      
      
      
      
      
      
      as
      SELECT 
    *
FROM
    `dbt_learning`.`source`.`dim_customer`
  
[0m10:45:32.932818 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m10:45:34.041246 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f09129-d73a-1739-bd21-976580bff0f8) - Created
[0m10:45:44.424622 [debug] [Thread-3 (]: SQL status: OK in 11.490 seconds
[0m10:45:44.427024 [debug] [Thread-3 (]: Databricks adapter: Cursor(session-id=01f09129-d73a-1739-bd21-976580bff0f8, command-id=01f09129-d766-1207-8420-f297427aba62) - Closing
[0m10:45:44.766818 [debug] [Thread-3 (]: Applying tags to relation None
[0m10:45:44.778721 [debug] [Thread-3 (]: On model.dbt_anirudh.bronze_customer: Close
[0m10:45:44.779060 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f09129-d73a-1739-bd21-976580bff0f8) - Closing
[0m10:45:45.096232 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '4f080d1b-0fbe-4908-a959-5ca3c0965be7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x74618750e060>]}
[0m10:45:45.097898 [info ] [Thread-3 (]: 1 of 6 OK created sql table model bronze.bronze_customer ....................... [[32mOK[0m in 12.25s]
[0m10:45:45.099507 [debug] [Thread-3 (]: Finished running node model.dbt_anirudh.bronze_customer
[0m10:45:45.100562 [debug] [Thread-3 (]: Began running node model.dbt_anirudh.bronze_date
[0m10:45:45.101876 [info ] [Thread-3 (]: 2 of 6 START sql view model bronze.bronze_date ................................. [RUN]
[0m10:45:45.103198 [debug] [Thread-3 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.dbt_anirudh.bronze_date) - Creating connection
[0m10:45:45.104085 [debug] [Thread-3 (]: Acquiring new databricks connection 'model.dbt_anirudh.bronze_date'
[0m10:45:45.105015 [debug] [Thread-3 (]: Began compiling node model.dbt_anirudh.bronze_date
[0m10:45:45.109403 [debug] [Thread-3 (]: Writing injected SQL for node "model.dbt_anirudh.bronze_date"
[0m10:45:45.110148 [debug] [Thread-3 (]: Began executing node model.dbt_anirudh.bronze_date
[0m10:45:45.122699 [debug] [Thread-3 (]: MATERIALIZING VIEW
[0m10:45:45.132018 [debug] [Thread-3 (]: Creating view `dbt_learning`.`bronze`.`bronze_date`
[0m10:45:45.132673 [debug] [Thread-3 (]: Writing runtime sql for node "model.dbt_anirudh.bronze_date"
[0m10:45:45.133099 [debug] [Thread-3 (]: Using databricks connection "model.dbt_anirudh.bronze_date"
[0m10:45:45.133420 [debug] [Thread-3 (]: On model.dbt_anirudh.bronze_date: /* {"app": "dbt", "dbt_version": "1.10.10", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_anirudh", "target_name": "dev", "node_id": "model.dbt_anirudh.bronze_date"} */

  
  
  create or replace view `dbt_learning`.`bronze`.`bronze_date`
  
  as (
    SELECT  
    *
FROM
    `dbt_learning`.`source`.`dim_date`
  )

[0m10:45:45.133727 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m10:45:46.196839 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f09129-de7a-1433-b2bc-4f45a8dd848f) - Created
[0m10:45:47.508387 [debug] [Thread-3 (]: SQL status: OK in 2.370 seconds
[0m10:45:47.511077 [debug] [Thread-3 (]: Databricks adapter: Cursor(session-id=01f09129-de7a-1433-b2bc-4f45a8dd848f, command-id=01f09129-dea4-110d-9b9a-8ae25854ae1b) - Closing
[0m10:45:47.512644 [debug] [Thread-3 (]: Applying tags to relation None
[0m10:45:47.514694 [debug] [Thread-3 (]: On model.dbt_anirudh.bronze_date: Close
[0m10:45:47.515777 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f09129-de7a-1433-b2bc-4f45a8dd848f) - Closing
[0m10:45:47.809385 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '4f080d1b-0fbe-4908-a959-5ca3c0965be7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x74615e8d0680>]}
[0m10:45:47.811141 [info ] [Thread-3 (]: 2 of 6 OK created sql view model bronze.bronze_date ............................ [[32mOK[0m in 2.71s]
[0m10:45:47.812708 [debug] [Thread-3 (]: Finished running node model.dbt_anirudh.bronze_date
[0m10:45:47.813764 [debug] [Thread-3 (]: Began running node model.dbt_anirudh.bronze_product
[0m10:45:47.814936 [info ] [Thread-3 (]: 3 of 6 START sql table model bronze.bronze_product ............................. [RUN]
[0m10:45:47.816495 [debug] [Thread-3 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.dbt_anirudh.bronze_product) - Creating connection
[0m10:45:47.817469 [debug] [Thread-3 (]: Acquiring new databricks connection 'model.dbt_anirudh.bronze_product'
[0m10:45:47.818727 [debug] [Thread-3 (]: Began compiling node model.dbt_anirudh.bronze_product
[0m10:45:47.832816 [debug] [Thread-3 (]: Writing injected SQL for node "model.dbt_anirudh.bronze_product"
[0m10:45:47.833365 [debug] [Thread-3 (]: Began executing node model.dbt_anirudh.bronze_product
[0m10:45:47.835161 [debug] [Thread-3 (]: MATERIALIZING TABLE
[0m10:45:47.836795 [debug] [Thread-3 (]: Writing runtime sql for node "model.dbt_anirudh.bronze_product"
[0m10:45:47.837265 [debug] [Thread-3 (]: Using databricks connection "model.dbt_anirudh.bronze_product"
[0m10:45:47.837660 [debug] [Thread-3 (]: On model.dbt_anirudh.bronze_product: /* {"app": "dbt", "dbt_version": "1.10.10", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_anirudh", "target_name": "dev", "node_id": "model.dbt_anirudh.bronze_product"} */

  
    
        create or replace table `dbt_learning`.`bronze`.`bronze_product`
      
      
  using delta
      
      
      
      
      
      
      
      as
      SELECT
    *
FROM
    `dbt_learning`.`source`.`dim_product`
  
[0m10:45:47.837952 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m10:45:48.897546 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f09129-e015-1b79-a8c6-b53e80622297) - Created
[0m10:45:53.302449 [debug] [Thread-3 (]: SQL status: OK in 5.460 seconds
[0m10:45:53.305053 [debug] [Thread-3 (]: Databricks adapter: Cursor(session-id=01f09129-e015-1b79-a8c6-b53e80622297, command-id=01f09129-e03f-1d96-943d-c8321435db47) - Closing
[0m10:45:53.306900 [debug] [Thread-3 (]: Applying tags to relation None
[0m10:45:53.309428 [debug] [Thread-3 (]: On model.dbt_anirudh.bronze_product: Close
[0m10:45:53.310359 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f09129-e015-1b79-a8c6-b53e80622297) - Closing
[0m10:45:53.611358 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '4f080d1b-0fbe-4908-a959-5ca3c0965be7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x746184e57740>]}
[0m10:45:53.613118 [info ] [Thread-3 (]: 3 of 6 OK created sql table model bronze.bronze_product ........................ [[32mOK[0m in 5.79s]
[0m10:45:53.614733 [debug] [Thread-3 (]: Finished running node model.dbt_anirudh.bronze_product
[0m10:45:53.615742 [debug] [Thread-3 (]: Began running node model.dbt_anirudh.bronze_returns
[0m10:45:53.616831 [info ] [Thread-3 (]: 4 of 6 START sql table model bronze.bronze_returns ............................. [RUN]
[0m10:45:53.618331 [debug] [Thread-3 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.dbt_anirudh.bronze_returns) - Creating connection
[0m10:45:53.619507 [debug] [Thread-3 (]: Acquiring new databricks connection 'model.dbt_anirudh.bronze_returns'
[0m10:45:53.620625 [debug] [Thread-3 (]: Began compiling node model.dbt_anirudh.bronze_returns
[0m10:45:53.628574 [debug] [Thread-3 (]: Writing injected SQL for node "model.dbt_anirudh.bronze_returns"
[0m10:45:53.629508 [debug] [Thread-3 (]: Began executing node model.dbt_anirudh.bronze_returns
[0m10:45:53.631720 [debug] [Thread-3 (]: MATERIALIZING TABLE
[0m10:45:53.633000 [debug] [Thread-3 (]: Writing runtime sql for node "model.dbt_anirudh.bronze_returns"
[0m10:45:53.633510 [debug] [Thread-3 (]: Using databricks connection "model.dbt_anirudh.bronze_returns"
[0m10:45:53.633951 [debug] [Thread-3 (]: On model.dbt_anirudh.bronze_returns: /* {"app": "dbt", "dbt_version": "1.10.10", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_anirudh", "target_name": "dev", "node_id": "model.dbt_anirudh.bronze_returns"} */

  
    
        create or replace table `dbt_learning`.`bronze`.`bronze_returns`
      
      
  using delta
      
      
      
      
      
      
      
      as
      SELECT
    *
FROM
    `dbt_learning`.`source`.`fact_returns`
  
[0m10:45:53.634242 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m10:45:54.745294 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f09129-e38e-1f02-9993-f4dd1e205c85) - Created
[0m10:45:58.285254 [debug] [Thread-3 (]: SQL status: OK in 4.650 seconds
[0m10:45:58.287700 [debug] [Thread-3 (]: Databricks adapter: Cursor(session-id=01f09129-e38e-1f02-9993-f4dd1e205c85, command-id=01f09129-e3bc-1d1d-a598-50bdd519c7f1) - Closing
[0m10:45:58.289377 [debug] [Thread-3 (]: Applying tags to relation None
[0m10:45:58.292076 [debug] [Thread-3 (]: On model.dbt_anirudh.bronze_returns: Close
[0m10:45:58.293075 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f09129-e38e-1f02-9993-f4dd1e205c85) - Closing
[0m10:45:58.588362 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '4f080d1b-0fbe-4908-a959-5ca3c0965be7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x74615fef9f40>]}
[0m10:45:58.590039 [info ] [Thread-3 (]: 4 of 6 OK created sql table model bronze.bronze_returns ........................ [[32mOK[0m in 4.97s]
[0m10:45:58.591556 [debug] [Thread-3 (]: Finished running node model.dbt_anirudh.bronze_returns
[0m10:45:58.592628 [debug] [Thread-3 (]: Began running node model.dbt_anirudh.bronze_sales
[0m10:45:58.593832 [info ] [Thread-3 (]: 5 of 6 START sql view model bronze.bronze_sales ................................ [RUN]
[0m10:45:58.595295 [debug] [Thread-3 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.dbt_anirudh.bronze_sales) - Creating connection
[0m10:45:58.596340 [debug] [Thread-3 (]: Acquiring new databricks connection 'model.dbt_anirudh.bronze_sales'
[0m10:45:58.597292 [debug] [Thread-3 (]: Began compiling node model.dbt_anirudh.bronze_sales
[0m10:45:58.604007 [debug] [Thread-3 (]: Writing injected SQL for node "model.dbt_anirudh.bronze_sales"
[0m10:45:58.604746 [debug] [Thread-3 (]: Began executing node model.dbt_anirudh.bronze_sales
[0m10:45:58.607687 [debug] [Thread-3 (]: MATERIALIZING VIEW
[0m10:45:58.608643 [debug] [Thread-3 (]: Creating view `dbt_learning`.`bronze`.`bronze_sales`
[0m10:45:58.609200 [debug] [Thread-3 (]: Writing runtime sql for node "model.dbt_anirudh.bronze_sales"
[0m10:45:58.609587 [debug] [Thread-3 (]: Using databricks connection "model.dbt_anirudh.bronze_sales"
[0m10:45:58.609887 [debug] [Thread-3 (]: On model.dbt_anirudh.bronze_sales: /* {"app": "dbt", "dbt_version": "1.10.10", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_anirudh", "target_name": "dev", "node_id": "model.dbt_anirudh.bronze_sales"} */

  
  
  create or replace view `dbt_learning`.`bronze`.`bronze_sales`
  
  as (
    -- block level config


SELECT 
    * 
FROM
    
    `dbt_learning`.`source`.`fact_sales`
  )

[0m10:45:58.610158 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m10:45:59.711519 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f09129-e684-1151-9b58-2a8dc16ff1b5) - Created
[0m10:46:00.885373 [debug] [Thread-3 (]: SQL status: OK in 2.270 seconds
[0m10:46:00.887858 [debug] [Thread-3 (]: Databricks adapter: Cursor(session-id=01f09129-e684-1151-9b58-2a8dc16ff1b5, command-id=01f09129-e6b1-1c4e-ad94-6ddc78e59ec9) - Closing
[0m10:46:00.889504 [debug] [Thread-3 (]: Applying tags to relation None
[0m10:46:00.891322 [debug] [Thread-3 (]: On model.dbt_anirudh.bronze_sales: Close
[0m10:46:00.892255 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f09129-e684-1151-9b58-2a8dc16ff1b5) - Closing
[0m10:46:01.199769 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '4f080d1b-0fbe-4908-a959-5ca3c0965be7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x74615e78ec00>]}
[0m10:46:01.201477 [info ] [Thread-3 (]: 5 of 6 OK created sql view model bronze.bronze_sales ........................... [[32mOK[0m in 2.60s]
[0m10:46:01.202862 [debug] [Thread-3 (]: Finished running node model.dbt_anirudh.bronze_sales
[0m10:46:01.203860 [debug] [Thread-3 (]: Began running node model.dbt_anirudh.bronze_store
[0m10:46:01.204862 [info ] [Thread-3 (]: 6 of 6 START sql view model bronze.bronze_store ................................ [RUN]
[0m10:46:01.205934 [debug] [Thread-3 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.dbt_anirudh.bronze_store) - Creating connection
[0m10:46:01.206723 [debug] [Thread-3 (]: Acquiring new databricks connection 'model.dbt_anirudh.bronze_store'
[0m10:46:01.207379 [debug] [Thread-3 (]: Began compiling node model.dbt_anirudh.bronze_store
[0m10:46:01.213459 [debug] [Thread-3 (]: Writing injected SQL for node "model.dbt_anirudh.bronze_store"
[0m10:46:01.214216 [debug] [Thread-3 (]: Began executing node model.dbt_anirudh.bronze_store
[0m10:46:01.216058 [debug] [Thread-3 (]: MATERIALIZING VIEW
[0m10:46:01.219664 [debug] [Thread-3 (]: Creating view `dbt_learning`.`bronze`.`bronze_store`
[0m10:46:01.220257 [debug] [Thread-3 (]: Writing runtime sql for node "model.dbt_anirudh.bronze_store"
[0m10:46:01.220679 [debug] [Thread-3 (]: Using databricks connection "model.dbt_anirudh.bronze_store"
[0m10:46:01.220985 [debug] [Thread-3 (]: On model.dbt_anirudh.bronze_store: /* {"app": "dbt", "dbt_version": "1.10.10", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_anirudh", "target_name": "dev", "node_id": "model.dbt_anirudh.bronze_store"} */

  
  
  create or replace view `dbt_learning`.`bronze`.`bronze_store`
  
  as (
    SELECT
    *
FROM
    `dbt_learning`.`source`.`dim_store`
  )

[0m10:46:01.221250 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m10:46:02.329518 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f09129-e817-1f55-adae-84c596987019) - Created
[0m10:46:03.536648 [debug] [Thread-3 (]: SQL status: OK in 2.320 seconds
[0m10:46:03.539285 [debug] [Thread-3 (]: Databricks adapter: Cursor(session-id=01f09129-e817-1f55-adae-84c596987019, command-id=01f09129-e842-1ca7-a69f-557216380e60) - Closing
[0m10:46:03.540795 [debug] [Thread-3 (]: Applying tags to relation None
[0m10:46:03.542609 [debug] [Thread-3 (]: On model.dbt_anirudh.bronze_store: Close
[0m10:46:03.543607 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f09129-e817-1f55-adae-84c596987019) - Closing
[0m10:46:03.849576 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '4f080d1b-0fbe-4908-a959-5ca3c0965be7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x74615e7ce3f0>]}
[0m10:46:03.851273 [info ] [Thread-3 (]: 6 of 6 OK created sql view model bronze.bronze_store ........................... [[32mOK[0m in 2.64s]
[0m10:46:03.852776 [debug] [Thread-3 (]: Finished running node model.dbt_anirudh.bronze_store
[0m10:46:03.855082 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=master) - Creating connection
[0m10:46:03.855956 [debug] [MainThread]: Acquiring new databricks connection 'master'
[0m10:46:03.857071 [info ] [MainThread]: 
[0m10:46:03.857976 [info ] [MainThread]: Finished running 3 table models, 3 view models in 0 hours 1 minutes and 39.86 seconds (99.86s).
[0m10:46:03.862555 [debug] [MainThread]: Command end result
[0m10:46:03.891105 [debug] [MainThread]: Wrote artifact WritableManifest to /home/aniruth/AI/DBT/DBT_Master/dbt_anirudh/target/manifest.json
[0m10:46:03.892463 [debug] [MainThread]: Wrote artifact SemanticManifest to /home/aniruth/AI/DBT/DBT_Master/dbt_anirudh/target/semantic_manifest.json
[0m10:46:03.896556 [debug] [MainThread]: Wrote artifact RunExecutionResult to /home/aniruth/AI/DBT/DBT_Master/dbt_anirudh/target/run_results.json
[0m10:46:03.896816 [info ] [MainThread]: 
[0m10:46:03.897116 [info ] [MainThread]: [32mCompleted successfully[0m
[0m10:46:03.897365 [info ] [MainThread]: 
[0m10:46:03.897633 [info ] [MainThread]: Done. PASS=6 WARN=0 ERROR=0 SKIP=0 NO-OP=0 TOTAL=6
[0m10:46:03.898380 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 102.81144, "process_in_blocks": "245720", "process_kernel_time": 0.252482, "process_mem_max_rss": "251856", "process_out_blocks": "4736", "process_user_time": 5.590675}
[0m10:46:03.898772 [debug] [MainThread]: Command `dbt run` succeeded at 10:46:03.898700 after 102.81 seconds
[0m10:46:03.899083 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x746185ce2840>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x74618742bf20>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7461854bdbb0>]}
[0m10:46:03.899367 [debug] [MainThread]: Flushing usage events
[0m10:46:05.121566 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m12:27:14.166104 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7c6d109de6c0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7c6d10b0b800>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7c6d10195520>]}


============================== 12:27:14.169425 | 81a676da-6571-4bbc-ba5f-0034f3456d73 ==============================
[0m12:27:14.169425 [info ] [MainThread]: Running with dbt=1.10.10
[0m12:27:14.169906 [debug] [MainThread]: running dbt with arguments {'send_anonymous_usage_stats': 'True', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'write_json': 'True', 'empty': 'False', 'indirect_selection': 'eager', 'warn_error': 'None', 'log_format': 'default', 'version_check': 'True', 'target_path': 'None', 'log_cache_events': 'False', 'invocation_command': 'dbt run --select models/bronze/bronze_sales', 'log_path': '/home/aniruth/AI/DBT/DBT_Master/dbt_anirudh/logs', 'introspect': 'True', 'debug': 'False', 'use_experimental_parser': 'False', 'no_print': 'None', 'profiles_dir': '/home/aniruth/AI/DBT/DBT_Master/dbt_anirudh', 'cache_selected_only': 'False', 'fail_fast': 'False', 'printer_width': '80', 'static_parser': 'True', 'quiet': 'False', 'use_colors': 'True', 'partial_parse': 'True'}
[0m12:27:14.811579 [debug] [MainThread]: Spark adapter: Setting pyhive.hive logging to ERROR
[0m12:27:14.812167 [debug] [MainThread]: Spark adapter: Setting thrift.transport logging to ERROR
[0m12:27:14.812474 [debug] [MainThread]: Spark adapter: Setting thrift.protocol logging to ERROR
[0m12:27:15.409591 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '81a676da-6571-4bbc-ba5f-0034f3456d73', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7c6ceb11f500>]}
[0m12:27:15.454073 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '81a676da-6571-4bbc-ba5f-0034f3456d73', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7c6cf030c9b0>]}
[0m12:27:15.454583 [info ] [MainThread]: Registered adapter: databricks=1.10.9
[0m12:27:15.533177 [debug] [MainThread]: checksum: 502a0dc23e9052e1ae09f7c44ee219ef7a02dfea7e7d66580d54c304c14d553b, vars: {}, profile: , target: , version: 1.10.10
[0m12:27:15.602016 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m12:27:15.602326 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m12:27:15.607581 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 2 unused configuration paths:
- models.dbt_anirudh.gold
- models.dbt_anirudh.silver
[0m12:27:15.628255 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '81a676da-6571-4bbc-ba5f-0034f3456d73', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7c6ceac73350>]}
[0m12:27:15.684070 [debug] [MainThread]: Wrote artifact WritableManifest to /home/aniruth/AI/DBT/DBT_Master/dbt_anirudh/target/manifest.json
[0m12:27:15.687544 [debug] [MainThread]: Wrote artifact SemanticManifest to /home/aniruth/AI/DBT/DBT_Master/dbt_anirudh/target/semantic_manifest.json
[0m12:27:15.694365 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '81a676da-6571-4bbc-ba5f-0034f3456d73', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7c6cea9f8da0>]}
[0m12:27:15.694744 [info ] [MainThread]: Found 6 models, 6 sources, 686 macros
[0m12:27:15.695045 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '81a676da-6571-4bbc-ba5f-0034f3456d73', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7c6ceacb8f80>]}
[0m12:27:15.695936 [warn ] [MainThread]: The selection criterion 'models/bronze/bronze_sales' does not match any enabled nodes
[0m12:27:15.696751 [warn ] [MainThread]: Nothing to do. Try checking your model configs and model specification args
[0m12:27:15.698091 [debug] [MainThread]: Command end result
[0m12:27:15.717493 [debug] [MainThread]: Wrote artifact WritableManifest to /home/aniruth/AI/DBT/DBT_Master/dbt_anirudh/target/manifest.json
[0m12:27:15.718865 [debug] [MainThread]: Wrote artifact SemanticManifest to /home/aniruth/AI/DBT/DBT_Master/dbt_anirudh/target/semantic_manifest.json
[0m12:27:15.721151 [debug] [MainThread]: Wrote artifact RunExecutionResult to /home/aniruth/AI/DBT/DBT_Master/dbt_anirudh/target/run_results.json
[0m12:27:15.721818 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 1.5958571, "process_in_blocks": "94520", "process_kernel_time": 0.192071, "process_mem_max_rss": "234836", "process_out_blocks": "3064", "process_user_time": 3.339861}
[0m12:27:15.722291 [debug] [MainThread]: Command `dbt run` succeeded at 12:27:15.722213 after 1.60 seconds
[0m12:27:15.722624 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7c6d13db3aa0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7c6d0da73bf0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7c6d10be6d20>]}
[0m12:27:15.722917 [debug] [MainThread]: Flushing usage events
[0m12:27:16.715243 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m12:27:28.608821 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x705c2d74d970>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x705c2d9a6960>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x705c2dcbed80>]}


============================== 12:27:28.611160 | a91cb154-dea0-442e-8738-725251f2ed59 ==============================
[0m12:27:28.611160 [info ] [MainThread]: Running with dbt=1.10.10
[0m12:27:28.611571 [debug] [MainThread]: running dbt with arguments {'quiet': 'False', 'log_path': '/home/aniruth/AI/DBT/DBT_Master/dbt_anirudh/logs', 'log_format': 'default', 'empty': 'False', 'introspect': 'True', 'target_path': 'None', 'version_check': 'True', 'indirect_selection': 'eager', 'no_print': 'None', 'invocation_command': 'dbt run --select models/bronze', 'write_json': 'True', 'log_cache_events': 'False', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'warn_error': 'None', 'fail_fast': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/home/aniruth/AI/DBT/DBT_Master/dbt_anirudh', 'printer_width': '80', 'static_parser': 'True', 'use_colors': 'True', 'send_anonymous_usage_stats': 'True', 'use_experimental_parser': 'False', 'debug': 'False'}
[0m12:27:29.210567 [debug] [MainThread]: Spark adapter: Setting pyhive.hive logging to ERROR
[0m12:27:29.210989 [debug] [MainThread]: Spark adapter: Setting thrift.transport logging to ERROR
[0m12:27:29.211299 [debug] [MainThread]: Spark adapter: Setting thrift.protocol logging to ERROR
[0m12:27:29.723616 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'a91cb154-dea0-442e-8738-725251f2ed59', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x705c0c4fcb00>]}
[0m12:27:29.771380 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'a91cb154-dea0-442e-8738-725251f2ed59', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x705c0c65d790>]}
[0m12:27:29.771955 [info ] [MainThread]: Registered adapter: databricks=1.10.9
[0m12:27:29.855291 [debug] [MainThread]: checksum: 502a0dc23e9052e1ae09f7c44ee219ef7a02dfea7e7d66580d54c304c14d553b, vars: {}, profile: , target: , version: 1.10.10
[0m12:27:29.929669 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m12:27:29.930023 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m12:27:29.935823 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 2 unused configuration paths:
- models.dbt_anirudh.silver
- models.dbt_anirudh.gold
[0m12:27:29.958755 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'a91cb154-dea0-442e-8738-725251f2ed59', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x705c0c32d640>]}
[0m12:27:30.017429 [debug] [MainThread]: Wrote artifact WritableManifest to /home/aniruth/AI/DBT/DBT_Master/dbt_anirudh/target/manifest.json
[0m12:27:30.019090 [debug] [MainThread]: Wrote artifact SemanticManifest to /home/aniruth/AI/DBT/DBT_Master/dbt_anirudh/target/semantic_manifest.json
[0m12:27:30.024914 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'a91cb154-dea0-442e-8738-725251f2ed59', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x705c0c2987a0>]}
[0m12:27:30.025303 [info ] [MainThread]: Found 6 models, 6 sources, 686 macros
[0m12:27:30.025597 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'a91cb154-dea0-442e-8738-725251f2ed59', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x705c0c89d2e0>]}
[0m12:27:30.027388 [info ] [MainThread]: 
[0m12:27:30.027752 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m12:27:30.027986 [info ] [MainThread]: 
[0m12:27:30.028367 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=master) - Creating connection
[0m12:27:30.028614 [debug] [MainThread]: Acquiring new databricks connection 'master'
[0m12:27:30.033775 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=list_dbt_learning) - Creating connection
[0m12:27:30.034166 [debug] [ThreadPool]: Acquiring new databricks connection 'list_dbt_learning'
[0m12:27:30.034452 [debug] [ThreadPool]: Using databricks connection "list_dbt_learning"
[0m12:27:30.034730 [debug] [ThreadPool]: On list_dbt_learning: GetSchemas(database=dbt_learning, schema=None)
[0m12:27:30.034950 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m12:27:31.427750 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f09138-155d-1bda-8baa-7ef2c545e700) - Created
[0m12:28:32.985192 [debug] [ThreadPool]: SQL status: OK in 62.950 seconds
[0m12:28:32.988521 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01f09138-155d-1bda-8baa-7ef2c545e700, command-id=01f09138-399a-13ac-8191-1d9ce6fb1f77) - Closing
[0m12:28:32.989668 [debug] [ThreadPool]: On list_dbt_learning: Close
[0m12:28:32.990520 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f09138-155d-1bda-8baa-7ef2c545e700) - Closing
[0m12:28:33.297168 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=list_dbt_learning) - Creating connection
[0m12:28:33.297935 [debug] [ThreadPool]: Acquiring new databricks connection 'list_dbt_learning'
[0m12:28:33.298537 [debug] [ThreadPool]: Using databricks connection "list_dbt_learning"
[0m12:28:33.299077 [debug] [ThreadPool]: On list_dbt_learning: GetSchemas(database=dbt_learning, schema=None)
[0m12:28:33.299607 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m12:28:34.415534 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f09138-3b01-1bc8-bdbf-eeb2000ce725) - Created
[0m12:28:34.888121 [debug] [ThreadPool]: SQL status: OK in 1.590 seconds
[0m12:28:34.890933 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01f09138-3b01-1bc8-bdbf-eeb2000ce725, command-id=01f09138-3b2e-1c8a-a314-7f2d8a35d04b) - Closing
[0m12:28:34.891875 [debug] [ThreadPool]: On list_dbt_learning: Close
[0m12:28:34.892719 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f09138-3b01-1bc8-bdbf-eeb2000ce725) - Closing
[0m12:28:35.197255 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=create_dbt_learning_gold) - Creating connection
[0m12:28:35.198363 [debug] [ThreadPool]: Acquiring new databricks connection 'create_dbt_learning_gold'
[0m12:28:35.199676 [debug] [ThreadPool]: Creating schema "database: "dbt_learning"
schema: "gold"
"
[0m12:28:35.219474 [debug] [ThreadPool]: Using databricks connection "create_dbt_learning_gold"
[0m12:28:35.219837 [debug] [ThreadPool]: On create_dbt_learning_gold: /* {"app": "dbt", "dbt_version": "1.10.10", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_anirudh", "target_name": "dev", "connection_name": "create_dbt_learning_gold"} */
create schema if not exists `dbt_learning`.`gold`
  
[0m12:28:35.220089 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m12:28:36.344127 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f09138-3c29-1f64-b96f-e06d48831e2b) - Created
[0m12:28:37.637708 [debug] [ThreadPool]: SQL status: OK in 2.420 seconds
[0m12:28:37.639944 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01f09138-3c29-1f64-b96f-e06d48831e2b, command-id=01f09138-3c55-1c70-8d68-e49fcb418728) - Closing
[0m12:28:37.640999 [debug] [ThreadPool]: On create_dbt_learning_gold: Close
[0m12:28:37.641923 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f09138-3c29-1f64-b96f-e06d48831e2b) - Closing
[0m12:28:37.941340 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=list_dbt_learning_bronze) - Creating connection
[0m12:28:37.942470 [debug] [ThreadPool]: Acquiring new databricks connection 'list_dbt_learning_bronze'
[0m12:28:37.959733 [debug] [ThreadPool]: Using databricks connection "list_dbt_learning_bronze"
[0m12:28:37.960318 [debug] [ThreadPool]: On list_dbt_learning_bronze: /* {"app": "dbt", "dbt_version": "1.10.10", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_anirudh", "target_name": "dev", "connection_name": "list_dbt_learning_bronze"} */

    
SELECT
  table_name,
  if(table_type IN ('EXTERNAL', 'MANAGED', 'MANAGED_SHALLOW_CLONE', 'EXTERNAL_SHALLOW_CLONE'), 'table', lower(table_type)) AS table_type,
  lower(data_source_format) AS file_format,
  table_owner,
  if(
    table_type IN (
      'EXTERNAL',
      'MANAGED',
      'MANAGED_SHALLOW_CLONE',
      'EXTERNAL_SHALLOW_CLONE'
    ),
    lower(table_type),
    NULL
  ) AS databricks_table_type
FROM `system`.`information_schema`.`tables`
WHERE table_catalog = 'dbt_learning' 
  AND table_schema = 'bronze'

  
[0m12:28:37.960664 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m12:28:39.114139 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f09138-3dcc-1428-b3c1-000a506b601f) - Created
[0m12:28:42.350555 [debug] [ThreadPool]: SQL status: OK in 4.390 seconds
[0m12:28:42.360422 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01f09138-3dcc-1428-b3c1-000a506b601f, command-id=01f09138-3e00-1488-b734-8e532bf8eb0b) - Closing
[0m12:28:42.362469 [debug] [ThreadPool]: On list_dbt_learning_bronze: Close
[0m12:28:42.363439 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f09138-3dcc-1428-b3c1-000a506b601f) - Closing
[0m12:28:42.682004 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=list_dbt_learning_gold) - Creating connection
[0m12:28:42.685358 [debug] [ThreadPool]: Acquiring new databricks connection 'list_dbt_learning_gold'
[0m12:28:42.693691 [debug] [ThreadPool]: Using databricks connection "list_dbt_learning_gold"
[0m12:28:42.694625 [debug] [ThreadPool]: On list_dbt_learning_gold: /* {"app": "dbt", "dbt_version": "1.10.10", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_anirudh", "target_name": "dev", "connection_name": "list_dbt_learning_gold"} */

    
SELECT
  table_name,
  if(table_type IN ('EXTERNAL', 'MANAGED', 'MANAGED_SHALLOW_CLONE', 'EXTERNAL_SHALLOW_CLONE'), 'table', lower(table_type)) AS table_type,
  lower(data_source_format) AS file_format,
  table_owner,
  if(
    table_type IN (
      'EXTERNAL',
      'MANAGED',
      'MANAGED_SHALLOW_CLONE',
      'EXTERNAL_SHALLOW_CLONE'
    ),
    lower(table_type),
    NULL
  ) AS databricks_table_type
FROM `system`.`information_schema`.`tables`
WHERE table_catalog = 'dbt_learning' 
  AND table_schema = 'gold'

  
[0m12:28:42.695469 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m12:28:43.849225 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f09138-409e-1a4c-b44a-270714bbdb69) - Created
[0m12:28:44.733677 [debug] [ThreadPool]: SQL status: OK in 2.040 seconds
[0m12:28:44.735124 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01f09138-409e-1a4c-b44a-270714bbdb69, command-id=01f09138-40ce-1839-94c8-3a5e81effa04) - Closing
[0m12:28:44.735563 [debug] [ThreadPool]: On list_dbt_learning_gold: Close
[0m12:28:44.735820 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f09138-409e-1a4c-b44a-270714bbdb69) - Closing
[0m12:28:45.051573 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'a91cb154-dea0-442e-8738-725251f2ed59', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x705c07f245f0>]}
[0m12:28:45.057342 [debug] [Thread-6 (]: Began running node model.dbt_anirudh.bronze_customer
[0m12:28:45.058641 [info ] [Thread-6 (]: 1 of 6 START sql table model bronze.bronze_customer ............................ [RUN]
[0m12:28:45.059977 [debug] [Thread-6 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.dbt_anirudh.bronze_customer) - Creating connection
[0m12:28:45.061015 [debug] [Thread-6 (]: Acquiring new databricks connection 'model.dbt_anirudh.bronze_customer'
[0m12:28:45.061869 [debug] [Thread-6 (]: Began compiling node model.dbt_anirudh.bronze_customer
[0m12:28:45.077924 [debug] [Thread-6 (]: Writing injected SQL for node "model.dbt_anirudh.bronze_customer"
[0m12:28:45.078659 [debug] [Thread-6 (]: Began executing node model.dbt_anirudh.bronze_customer
[0m12:28:45.092723 [debug] [Thread-6 (]: MATERIALIZING TABLE
[0m12:28:45.093276 [warn ] [Thread-6 (]: [[33mWARNING[0m]: Use revamped materializations based on separating create and insert.  This allows more performant column comments, as well as new column features.
You may opt into the new behavior sooner by setting `flags.use_materialization_v2` to `True` in `dbt_project.yml`.
Visit https://docs.getdbt.com/reference/global-configs/behavior-changes for more information.
[0m12:28:45.093692 [debug] [Thread-6 (]: Sending event: {'category': 'dbt', 'action': 'BehaviorChangeEvent', 'label': 'a91cb154-dea0-442e-8738-725251f2ed59', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x705c07fec650>]}
[0m12:28:45.128293 [debug] [Thread-6 (]: Writing runtime sql for node "model.dbt_anirudh.bronze_customer"
[0m12:28:45.129077 [debug] [Thread-6 (]: Using databricks connection "model.dbt_anirudh.bronze_customer"
[0m12:28:45.129521 [debug] [Thread-6 (]: On model.dbt_anirudh.bronze_customer: /* {"app": "dbt", "dbt_version": "1.10.10", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_anirudh", "target_name": "dev", "node_id": "model.dbt_anirudh.bronze_customer"} */

  
    
        create or replace table `dbt_learning`.`bronze`.`bronze_customer`
      
      
  using delta
      
      
      
      
      
      
      
      as
      SELECT 
    *
FROM
    `dbt_learning`.`source`.`dim_customer`
  
[0m12:28:45.129853 [debug] [Thread-6 (]: Opening a new connection, currently in state init
[0m12:28:46.272976 [debug] [Thread-6 (]: Databricks adapter: Connection(session-id=01f09138-4211-1f46-a62a-8941207f7a07) - Created
[0m12:28:54.400947 [debug] [Thread-6 (]: SQL status: OK in 9.270 seconds
[0m12:28:54.403270 [debug] [Thread-6 (]: Databricks adapter: Cursor(session-id=01f09138-4211-1f46-a62a-8941207f7a07, command-id=01f09138-4241-115e-a4c5-8d565f5c3c5d) - Closing
[0m12:28:54.767052 [debug] [Thread-6 (]: Applying tags to relation None
[0m12:28:54.778546 [debug] [Thread-6 (]: On model.dbt_anirudh.bronze_customer: Close
[0m12:28:54.778850 [debug] [Thread-6 (]: Databricks adapter: Connection(session-id=01f09138-4211-1f46-a62a-8941207f7a07) - Closing
[0m12:28:55.094276 [debug] [Thread-6 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a91cb154-dea0-442e-8738-725251f2ed59', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x705c07fc3d70>]}
[0m12:28:55.095813 [info ] [Thread-6 (]: 1 of 6 OK created sql table model bronze.bronze_customer ....................... [[32mOK[0m in 10.03s]
[0m12:28:55.096963 [debug] [Thread-6 (]: Finished running node model.dbt_anirudh.bronze_customer
[0m12:28:55.097735 [debug] [Thread-6 (]: Began running node model.dbt_anirudh.bronze_date
[0m12:28:55.098712 [info ] [Thread-6 (]: 2 of 6 START sql view model bronze.bronze_date ................................. [RUN]
[0m12:28:55.099543 [debug] [Thread-6 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.dbt_anirudh.bronze_date) - Creating connection
[0m12:28:55.100088 [debug] [Thread-6 (]: Acquiring new databricks connection 'model.dbt_anirudh.bronze_date'
[0m12:28:55.100583 [debug] [Thread-6 (]: Began compiling node model.dbt_anirudh.bronze_date
[0m12:28:55.107754 [debug] [Thread-6 (]: Writing injected SQL for node "model.dbt_anirudh.bronze_date"
[0m12:28:55.108371 [debug] [Thread-6 (]: Began executing node model.dbt_anirudh.bronze_date
[0m12:28:55.120582 [debug] [Thread-6 (]: MATERIALIZING VIEW
[0m12:28:55.130188 [debug] [Thread-6 (]: Creating view `dbt_learning`.`bronze`.`bronze_date`
[0m12:28:55.130949 [debug] [Thread-6 (]: Writing runtime sql for node "model.dbt_anirudh.bronze_date"
[0m12:28:55.131473 [debug] [Thread-6 (]: Using databricks connection "model.dbt_anirudh.bronze_date"
[0m12:28:55.131821 [debug] [Thread-6 (]: On model.dbt_anirudh.bronze_date: /* {"app": "dbt", "dbt_version": "1.10.10", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_anirudh", "target_name": "dev", "node_id": "model.dbt_anirudh.bronze_date"} */

  
  
  create or replace view `dbt_learning`.`bronze`.`bronze_date`
  
  as (
    SELECT  
    *
FROM
    `dbt_learning`.`source`.`dim_date`
  )

[0m12:28:55.132095 [debug] [Thread-6 (]: Opening a new connection, currently in state init
[0m12:28:56.261338 [debug] [Thread-6 (]: Databricks adapter: Connection(session-id=01f09138-4809-1370-b5ca-a770d93e9bdc) - Created
[0m12:28:57.684728 [debug] [Thread-6 (]: SQL status: OK in 2.550 seconds
[0m12:28:57.687346 [debug] [Thread-6 (]: Databricks adapter: Cursor(session-id=01f09138-4809-1370-b5ca-a770d93e9bdc, command-id=01f09138-4834-1c31-bfa6-85f7ba62b17b) - Closing
[0m12:28:57.688930 [debug] [Thread-6 (]: Applying tags to relation None
[0m12:28:57.690916 [debug] [Thread-6 (]: On model.dbt_anirudh.bronze_date: Close
[0m12:28:57.691919 [debug] [Thread-6 (]: Databricks adapter: Connection(session-id=01f09138-4809-1370-b5ca-a770d93e9bdc) - Closing
[0m12:28:57.995636 [debug] [Thread-6 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a91cb154-dea0-442e-8738-725251f2ed59', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x705c0c0c6f30>]}
[0m12:28:57.997405 [info ] [Thread-6 (]: 2 of 6 OK created sql view model bronze.bronze_date ............................ [[32mOK[0m in 2.90s]
[0m12:28:57.998899 [debug] [Thread-6 (]: Finished running node model.dbt_anirudh.bronze_date
[0m12:28:57.999977 [debug] [Thread-6 (]: Began running node model.dbt_anirudh.bronze_product
[0m12:28:58.001445 [info ] [Thread-6 (]: 3 of 6 START sql table model bronze.bronze_product ............................. [RUN]
[0m12:28:58.002806 [debug] [Thread-6 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.dbt_anirudh.bronze_product) - Creating connection
[0m12:28:58.003687 [debug] [Thread-6 (]: Acquiring new databricks connection 'model.dbt_anirudh.bronze_product'
[0m12:28:58.004626 [debug] [Thread-6 (]: Began compiling node model.dbt_anirudh.bronze_product
[0m12:28:58.011810 [debug] [Thread-6 (]: Writing injected SQL for node "model.dbt_anirudh.bronze_product"
[0m12:28:58.012673 [debug] [Thread-6 (]: Began executing node model.dbt_anirudh.bronze_product
[0m12:28:58.015134 [debug] [Thread-6 (]: MATERIALIZING TABLE
[0m12:28:58.016754 [debug] [Thread-6 (]: Writing runtime sql for node "model.dbt_anirudh.bronze_product"
[0m12:28:58.017210 [debug] [Thread-6 (]: Using databricks connection "model.dbt_anirudh.bronze_product"
[0m12:28:58.017574 [debug] [Thread-6 (]: On model.dbt_anirudh.bronze_product: /* {"app": "dbt", "dbt_version": "1.10.10", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_anirudh", "target_name": "dev", "node_id": "model.dbt_anirudh.bronze_product"} */

  
    
        create or replace table `dbt_learning`.`bronze`.`bronze_product`
      
      
  using delta
      
      
      
      
      
      
      
      as
      SELECT
    *
FROM
    `dbt_learning`.`source`.`dim_product`
  
[0m12:28:58.017882 [debug] [Thread-6 (]: Opening a new connection, currently in state init
[0m12:28:59.139526 [debug] [Thread-6 (]: Databricks adapter: Connection(session-id=01f09138-49bf-1dea-aaab-db907adb6ff7) - Created
[0m12:29:02.745713 [debug] [Thread-6 (]: SQL status: OK in 4.730 seconds
[0m12:29:02.748143 [debug] [Thread-6 (]: Databricks adapter: Cursor(session-id=01f09138-49bf-1dea-aaab-db907adb6ff7, command-id=01f09138-49eb-114c-bd1f-548da1f02618) - Closing
[0m12:29:02.749827 [debug] [Thread-6 (]: Applying tags to relation None
[0m12:29:02.752391 [debug] [Thread-6 (]: On model.dbt_anirudh.bronze_product: Close
[0m12:29:02.753288 [debug] [Thread-6 (]: Databricks adapter: Connection(session-id=01f09138-49bf-1dea-aaab-db907adb6ff7) - Closing
[0m12:29:03.056903 [debug] [Thread-6 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a91cb154-dea0-442e-8738-725251f2ed59', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x705c07fe47d0>]}
[0m12:29:03.058748 [info ] [Thread-6 (]: 3 of 6 OK created sql table model bronze.bronze_product ........................ [[32mOK[0m in 5.05s]
[0m12:29:03.060236 [debug] [Thread-6 (]: Finished running node model.dbt_anirudh.bronze_product
[0m12:29:03.061331 [debug] [Thread-6 (]: Began running node model.dbt_anirudh.bronze_returns
[0m12:29:03.062522 [info ] [Thread-6 (]: 4 of 6 START sql table model bronze.bronze_returns ............................. [RUN]
[0m12:29:03.064026 [debug] [Thread-6 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.dbt_anirudh.bronze_returns) - Creating connection
[0m12:29:03.064972 [debug] [Thread-6 (]: Acquiring new databricks connection 'model.dbt_anirudh.bronze_returns'
[0m12:29:03.065929 [debug] [Thread-6 (]: Began compiling node model.dbt_anirudh.bronze_returns
[0m12:29:03.073670 [debug] [Thread-6 (]: Writing injected SQL for node "model.dbt_anirudh.bronze_returns"
[0m12:29:03.074500 [debug] [Thread-6 (]: Began executing node model.dbt_anirudh.bronze_returns
[0m12:29:03.077043 [debug] [Thread-6 (]: MATERIALIZING TABLE
[0m12:29:03.078490 [debug] [Thread-6 (]: Writing runtime sql for node "model.dbt_anirudh.bronze_returns"
[0m12:29:03.078984 [debug] [Thread-6 (]: Using databricks connection "model.dbt_anirudh.bronze_returns"
[0m12:29:03.079313 [debug] [Thread-6 (]: On model.dbt_anirudh.bronze_returns: /* {"app": "dbt", "dbt_version": "1.10.10", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_anirudh", "target_name": "dev", "node_id": "model.dbt_anirudh.bronze_returns"} */

  
    
        create or replace table `dbt_learning`.`bronze`.`bronze_returns`
      
      
  using delta
      
      
      
      
      
      
      
      as
      SELECT
    *
FROM
    `dbt_learning`.`source`.`fact_returns`
  
[0m12:29:03.079609 [debug] [Thread-6 (]: Opening a new connection, currently in state init
[0m12:29:04.199235 [debug] [Thread-6 (]: Databricks adapter: Connection(session-id=01f09138-4cc3-1593-9cf9-9af3459b5255) - Created
[0m12:29:07.261758 [debug] [Thread-6 (]: SQL status: OK in 4.180 seconds
[0m12:29:07.264175 [debug] [Thread-6 (]: Databricks adapter: Cursor(session-id=01f09138-4cc3-1593-9cf9-9af3459b5255, command-id=01f09138-4cee-1c3c-a942-ac603e952177) - Closing
[0m12:29:07.265893 [debug] [Thread-6 (]: Applying tags to relation None
[0m12:29:07.268235 [debug] [Thread-6 (]: On model.dbt_anirudh.bronze_returns: Close
[0m12:29:07.269144 [debug] [Thread-6 (]: Databricks adapter: Connection(session-id=01f09138-4cc3-1593-9cf9-9af3459b5255) - Closing
[0m12:29:07.577966 [debug] [Thread-6 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a91cb154-dea0-442e-8738-725251f2ed59', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x705c04653290>]}
[0m12:29:07.579548 [info ] [Thread-6 (]: 4 of 6 OK created sql table model bronze.bronze_returns ........................ [[32mOK[0m in 4.51s]
[0m12:29:07.581048 [debug] [Thread-6 (]: Finished running node model.dbt_anirudh.bronze_returns
[0m12:29:07.582132 [debug] [Thread-6 (]: Began running node model.dbt_anirudh.bronze_sales
[0m12:29:07.583346 [info ] [Thread-6 (]: 5 of 6 START sql view model gold.bronze_sales .................................. [RUN]
[0m12:29:07.584817 [debug] [Thread-6 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.dbt_anirudh.bronze_sales) - Creating connection
[0m12:29:07.585952 [debug] [Thread-6 (]: Acquiring new databricks connection 'model.dbt_anirudh.bronze_sales'
[0m12:29:07.586982 [debug] [Thread-6 (]: Began compiling node model.dbt_anirudh.bronze_sales
[0m12:29:07.592614 [debug] [Thread-6 (]: Writing injected SQL for node "model.dbt_anirudh.bronze_sales"
[0m12:29:07.593619 [debug] [Thread-6 (]: Began executing node model.dbt_anirudh.bronze_sales
[0m12:29:07.598871 [debug] [Thread-6 (]: MATERIALIZING VIEW
[0m12:29:07.599616 [debug] [Thread-6 (]: Creating view `dbt_learning`.`gold`.`bronze_sales`
[0m12:29:07.600199 [debug] [Thread-6 (]: Writing runtime sql for node "model.dbt_anirudh.bronze_sales"
[0m12:29:07.600655 [debug] [Thread-6 (]: Using databricks connection "model.dbt_anirudh.bronze_sales"
[0m12:29:07.601015 [debug] [Thread-6 (]: On model.dbt_anirudh.bronze_sales: /* {"app": "dbt", "dbt_version": "1.10.10", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_anirudh", "target_name": "dev", "node_id": "model.dbt_anirudh.bronze_sales"} */

  
  
  create or replace view `dbt_learning`.`gold`.`bronze_sales`
  
  as (
    -- block level config


SELECT 
    * 
FROM
    
    `dbt_learning`.`source`.`fact_sales`
  )

[0m12:29:07.601321 [debug] [Thread-6 (]: Opening a new connection, currently in state init
[0m12:29:08.696049 [debug] [Thread-6 (]: Databricks adapter: Connection(session-id=01f09138-4f72-1969-b054-f9b315e342cd) - Created
[0m12:29:09.945615 [debug] [Thread-6 (]: SQL status: OK in 2.340 seconds
[0m12:29:09.948099 [debug] [Thread-6 (]: Databricks adapter: Cursor(session-id=01f09138-4f72-1969-b054-f9b315e342cd, command-id=01f09138-4f9d-13f0-8b4e-1c4d8a7f8676) - Closing
[0m12:29:09.949657 [debug] [Thread-6 (]: Applying tags to relation None
[0m12:29:09.951616 [debug] [Thread-6 (]: On model.dbt_anirudh.bronze_sales: Close
[0m12:29:09.952536 [debug] [Thread-6 (]: Databricks adapter: Connection(session-id=01f09138-4f72-1969-b054-f9b315e342cd) - Closing
[0m12:29:10.262939 [debug] [Thread-6 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a91cb154-dea0-442e-8738-725251f2ed59', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x705c04660ec0>]}
[0m12:29:10.264637 [info ] [Thread-6 (]: 5 of 6 OK created sql view model gold.bronze_sales ............................. [[32mOK[0m in 2.68s]
[0m12:29:10.266210 [debug] [Thread-6 (]: Finished running node model.dbt_anirudh.bronze_sales
[0m12:29:10.267316 [debug] [Thread-6 (]: Began running node model.dbt_anirudh.bronze_store
[0m12:29:10.268503 [info ] [Thread-6 (]: 6 of 6 START sql view model bronze.bronze_store ................................ [RUN]
[0m12:29:10.269978 [debug] [Thread-6 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.dbt_anirudh.bronze_store) - Creating connection
[0m12:29:10.271141 [debug] [Thread-6 (]: Acquiring new databricks connection 'model.dbt_anirudh.bronze_store'
[0m12:29:10.272109 [debug] [Thread-6 (]: Began compiling node model.dbt_anirudh.bronze_store
[0m12:29:10.279306 [debug] [Thread-6 (]: Writing injected SQL for node "model.dbt_anirudh.bronze_store"
[0m12:29:10.280217 [debug] [Thread-6 (]: Began executing node model.dbt_anirudh.bronze_store
[0m12:29:10.282246 [debug] [Thread-6 (]: MATERIALIZING VIEW
[0m12:29:10.283180 [debug] [Thread-6 (]: Creating view `dbt_learning`.`bronze`.`bronze_store`
[0m12:29:10.283784 [debug] [Thread-6 (]: Writing runtime sql for node "model.dbt_anirudh.bronze_store"
[0m12:29:10.284213 [debug] [Thread-6 (]: Using databricks connection "model.dbt_anirudh.bronze_store"
[0m12:29:10.284566 [debug] [Thread-6 (]: On model.dbt_anirudh.bronze_store: /* {"app": "dbt", "dbt_version": "1.10.10", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_anirudh", "target_name": "dev", "node_id": "model.dbt_anirudh.bronze_store"} */

  
  
  create or replace view `dbt_learning`.`bronze`.`bronze_store`
  
  as (
    SELECT
    *
FROM
    `dbt_learning`.`source`.`dim_store`
  )

[0m12:29:10.284872 [debug] [Thread-6 (]: Opening a new connection, currently in state init
[0m12:29:11.386311 [debug] [Thread-6 (]: Databricks adapter: Connection(session-id=01f09138-510c-1417-8f36-55fe1c41718e) - Created
[0m12:29:12.351852 [debug] [Thread-6 (]: SQL status: OK in 2.070 seconds
[0m12:29:12.354061 [debug] [Thread-6 (]: Databricks adapter: Cursor(session-id=01f09138-510c-1417-8f36-55fe1c41718e, command-id=01f09138-5137-1a7b-8dd1-714d2a38363e) - Closing
[0m12:29:12.355511 [debug] [Thread-6 (]: Applying tags to relation None
[0m12:29:12.357247 [debug] [Thread-6 (]: On model.dbt_anirudh.bronze_store: Close
[0m12:29:12.358133 [debug] [Thread-6 (]: Databricks adapter: Connection(session-id=01f09138-510c-1417-8f36-55fe1c41718e) - Closing
[0m12:29:12.661772 [debug] [Thread-6 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a91cb154-dea0-442e-8738-725251f2ed59', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x705c07f9e870>]}
[0m12:29:12.662933 [info ] [Thread-6 (]: 6 of 6 OK created sql view model bronze.bronze_store ........................... [[32mOK[0m in 2.39s]
[0m12:29:12.663931 [debug] [Thread-6 (]: Finished running node model.dbt_anirudh.bronze_store
[0m12:29:12.665266 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=master) - Creating connection
[0m12:29:12.665731 [debug] [MainThread]: Acquiring new databricks connection 'master'
[0m12:29:12.666359 [info ] [MainThread]: 
[0m12:29:12.666742 [info ] [MainThread]: Finished running 3 table models, 3 view models in 0 hours 1 minutes and 42.64 seconds (102.64s).
[0m12:29:12.667756 [debug] [MainThread]: Command end result
[0m12:29:12.690449 [debug] [MainThread]: Wrote artifact WritableManifest to /home/aniruth/AI/DBT/DBT_Master/dbt_anirudh/target/manifest.json
[0m12:29:12.691855 [debug] [MainThread]: Wrote artifact SemanticManifest to /home/aniruth/AI/DBT/DBT_Master/dbt_anirudh/target/semantic_manifest.json
[0m12:29:12.696209 [debug] [MainThread]: Wrote artifact RunExecutionResult to /home/aniruth/AI/DBT/DBT_Master/dbt_anirudh/target/run_results.json
[0m12:29:12.696488 [info ] [MainThread]: 
[0m12:29:12.696784 [info ] [MainThread]: [32mCompleted successfully[0m
[0m12:29:12.697025 [info ] [MainThread]: 
[0m12:29:12.697278 [info ] [MainThread]: Done. PASS=6 WARN=0 ERROR=0 SKIP=0 NO-OP=0 TOTAL=6
[0m12:29:12.697922 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 104.13169, "process_in_blocks": "768", "process_kernel_time": 0.192374, "process_mem_max_rss": "245128", "process_out_blocks": "3224", "process_user_time": 4.680772}
[0m12:29:12.698264 [debug] [MainThread]: Command `dbt run` succeeded at 12:29:12.698198 after 104.13 seconds
[0m12:29:12.698566 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x705c315b3aa0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x705c2e1c7020>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x705c0c4c7e00>]}
[0m12:29:12.698847 [debug] [MainThread]: Flushing usage events
[0m12:29:13.910856 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m15:38:03.986482 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x70d9b63321e0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x70d9b673aa80>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x70d9b6167ef0>]}


============================== 15:38:03.990446 | 914f15fc-2e6f-4a94-a107-15a1cc18b689 ==============================
[0m15:38:03.990446 [info ] [MainThread]: Running with dbt=1.10.10
[0m15:38:03.990959 [debug] [MainThread]: running dbt with arguments {'indirect_selection': 'eager', 'cache_selected_only': 'False', 'no_print': 'None', 'log_path': '/home/aniruth/AI/DBT/DBT_Master/dbt_anirudh/logs', 'write_json': 'True', 'use_colors': 'True', 'send_anonymous_usage_stats': 'True', 'partial_parse': 'True', 'version_check': 'True', 'quiet': 'False', 'invocation_command': 'dbt ', 'warn_error': 'None', 'use_experimental_parser': 'False', 'introspect': 'True', 'fail_fast': 'False', 'target_path': 'None', 'empty': 'None', 'debug': 'False', 'static_parser': 'True', 'log_cache_events': 'False', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'printer_width': '80', 'log_format': 'default', 'profiles_dir': '/home/aniruth/AI/DBT/DBT_Master/dbt_anirudh'}
[0m15:38:04.086331 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '914f15fc-2e6f-4a94-a107-15a1cc18b689', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x70d9b5896870>]}
[0m15:38:04.099308 [info ] [MainThread]: Warning: No packages were found in packages.yml
[0m15:38:04.099961 [info ] [MainThread]: Warning: No packages were found in packages.yml
[0m15:38:04.100879 [debug] [MainThread]: Resource report: {"command_name": "deps", "command_success": true, "command_wall_clock_time": 0.16340066, "process_in_blocks": "35832", "process_kernel_time": 0.138246, "process_mem_max_rss": "99960", "process_out_blocks": "16", "process_user_time": 1.428552}
[0m15:38:04.101367 [debug] [MainThread]: Command `cli deps` succeeded at 15:38:04.101252 after 0.16 seconds
[0m15:38:04.101804 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x70d9b621f890>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x70d9b5a56fc0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x70d9b83599a0>]}
[0m15:38:04.102246 [debug] [MainThread]: Flushing usage events
[0m15:38:05.079266 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m15:40:12.219767 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x72527f98d610>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x725281718920>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x72527fcc13a0>]}


============================== 15:40:12.222975 | c43e9b5c-f1c9-4d96-872d-9b0b47235274 ==============================
[0m15:40:12.222975 [info ] [MainThread]: Running with dbt=1.10.10
[0m15:40:12.223414 [debug] [MainThread]: running dbt with arguments {'partial_parse': 'True', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'no_print': 'None', 'debug': 'False', 'log_format': 'default', 'printer_width': '80', 'use_colors': 'True', 'introspect': 'True', 'invocation_command': 'dbt test', 'indirect_selection': 'eager', 'cache_selected_only': 'False', 'version_check': 'True', 'quiet': 'False', 'empty': 'None', 'static_parser': 'True', 'profiles_dir': '/home/aniruth/AI/DBT/DBT_Master/dbt_anirudh', 'warn_error': 'None', 'use_experimental_parser': 'False', 'log_cache_events': 'False', 'target_path': 'None', 'send_anonymous_usage_stats': 'True', 'write_json': 'True', 'log_path': '/home/aniruth/AI/DBT/DBT_Master/dbt_anirudh/logs', 'fail_fast': 'False'}
[0m15:40:12.821205 [debug] [MainThread]: Spark adapter: Setting pyhive.hive logging to ERROR
[0m15:40:12.821578 [debug] [MainThread]: Spark adapter: Setting thrift.transport logging to ERROR
[0m15:40:12.821861 [debug] [MainThread]: Spark adapter: Setting thrift.protocol logging to ERROR
[0m15:40:13.349668 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'c43e9b5c-f1c9-4d96-872d-9b0b47235274', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x72526641b0b0>]}
[0m15:40:13.394609 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'c43e9b5c-f1c9-4d96-872d-9b0b47235274', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x72525abfbf50>]}
[0m15:40:13.395176 [info ] [MainThread]: Registered adapter: databricks=1.10.9
[0m15:40:13.475925 [debug] [MainThread]: checksum: 502a0dc23e9052e1ae09f7c44ee219ef7a02dfea7e7d66580d54c304c14d553b, vars: {}, profile: , target: , version: 1.10.10
[0m15:40:13.558893 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m15:40:13.559248 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m15:40:13.564945 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 2 unused configuration paths:
- models.dbt_anirudh.gold
- models.dbt_anirudh.silver
[0m15:40:13.595783 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'c43e9b5c-f1c9-4d96-872d-9b0b47235274', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x72525aaf4140>]}
[0m15:40:13.658172 [debug] [MainThread]: Wrote artifact WritableManifest to /home/aniruth/AI/DBT/DBT_Master/dbt_anirudh/target/manifest.json
[0m15:40:13.659540 [debug] [MainThread]: Wrote artifact SemanticManifest to /home/aniruth/AI/DBT/DBT_Master/dbt_anirudh/target/semantic_manifest.json
[0m15:40:13.758441 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'c43e9b5c-f1c9-4d96-872d-9b0b47235274', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x72525a8be9c0>]}
[0m15:40:13.758852 [info ] [MainThread]: Found 6 models, 3 data tests, 6 sources, 686 macros
[0m15:40:13.759172 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'c43e9b5c-f1c9-4d96-872d-9b0b47235274', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x72525ab3a180>]}
[0m15:40:13.760514 [info ] [MainThread]: 
[0m15:40:13.760822 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m15:40:13.761100 [info ] [MainThread]: 
[0m15:40:13.761549 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=master) - Creating connection
[0m15:40:13.761806 [debug] [MainThread]: Acquiring new databricks connection 'master'
[0m15:40:13.767054 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=list_dbt_learning_bronze) - Creating connection
[0m15:40:13.767421 [debug] [ThreadPool]: Acquiring new databricks connection 'list_dbt_learning_bronze'
[0m15:40:13.779447 [debug] [ThreadPool]: Using databricks connection "list_dbt_learning_bronze"
[0m15:40:13.779868 [debug] [ThreadPool]: On list_dbt_learning_bronze: /* {"app": "dbt", "dbt_version": "1.10.10", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_anirudh", "target_name": "dev", "connection_name": "list_dbt_learning_bronze"} */

    
SELECT
  table_name,
  if(table_type IN ('EXTERNAL', 'MANAGED', 'MANAGED_SHALLOW_CLONE', 'EXTERNAL_SHALLOW_CLONE'), 'table', lower(table_type)) AS table_type,
  lower(data_source_format) AS file_format,
  table_owner,
  if(
    table_type IN (
      'EXTERNAL',
      'MANAGED',
      'MANAGED_SHALLOW_CLONE',
      'EXTERNAL_SHALLOW_CLONE'
    ),
    lower(table_type),
    NULL
  ) AS databricks_table_type
FROM `system`.`information_schema`.`tables`
WHERE table_catalog = 'dbt_learning' 
  AND table_schema = 'bronze'

  
[0m15:40:13.780148 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m15:40:14.939553 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f09153-022e-1e0a-b020-135acaa240b4) - Created
[0m15:40:16.210458 [debug] [ThreadPool]: SQL status: OK in 2.430 seconds
[0m15:40:16.221527 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01f09153-022e-1e0a-b020-135acaa240b4, command-id=01f09153-025c-17c9-8f5d-87fb6a9164f9) - Closing
[0m15:40:16.223600 [debug] [ThreadPool]: On list_dbt_learning_bronze: Close
[0m15:40:16.224490 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f09153-022e-1e0a-b020-135acaa240b4) - Closing
[0m15:40:16.533986 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'c43e9b5c-f1c9-4d96-872d-9b0b47235274', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x72525ab94ef0>]}
[0m15:40:16.540305 [debug] [Thread-2 (]: Began running node test.dbt_anirudh.accepted_values_bronze_store_store_name__MegaMart_Manhattan__MegaMart_Brooklyn__MegaMart_Austin__MegaMart_San_Jose__MegaMart_Toronto.557ba83159
[0m15:40:16.541515 [info ] [Thread-2 (]: 1 of 3 START test accepted_values_bronze_store_store_name__MegaMart_Manhattan__MegaMart_Brooklyn__MegaMart_Austin__MegaMart_San_Jose__MegaMart_Toronto  [RUN]
[0m15:40:16.542998 [debug] [Thread-2 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=test.dbt_anirudh.accepted_values_bronze_store_store_name__MegaMart_Manhattan__MegaMart_Brooklyn__MegaMart_Austin__MegaMart_San_Jose__MegaMart_Toronto.557ba83159) - Creating connection
[0m15:40:16.544081 [debug] [Thread-2 (]: Acquiring new databricks connection 'test.dbt_anirudh.accepted_values_bronze_store_store_name__MegaMart_Manhattan__MegaMart_Brooklyn__MegaMart_Austin__MegaMart_San_Jose__MegaMart_Toronto.557ba83159'
[0m15:40:16.545040 [debug] [Thread-2 (]: Began compiling node test.dbt_anirudh.accepted_values_bronze_store_store_name__MegaMart_Manhattan__MegaMart_Brooklyn__MegaMart_Austin__MegaMart_San_Jose__MegaMart_Toronto.557ba83159
[0m15:40:16.567850 [debug] [Thread-2 (]: Writing injected SQL for node "test.dbt_anirudh.accepted_values_bronze_store_store_name__MegaMart_Manhattan__MegaMart_Brooklyn__MegaMart_Austin__MegaMart_San_Jose__MegaMart_Toronto.557ba83159"
[0m15:40:16.568471 [debug] [Thread-2 (]: Began executing node test.dbt_anirudh.accepted_values_bronze_store_store_name__MegaMart_Manhattan__MegaMart_Brooklyn__MegaMart_Austin__MegaMart_San_Jose__MegaMart_Toronto.557ba83159
[0m15:40:16.582060 [debug] [Thread-2 (]: Writing runtime sql for node "test.dbt_anirudh.accepted_values_bronze_store_store_name__MegaMart_Manhattan__MegaMart_Brooklyn__MegaMart_Austin__MegaMart_San_Jose__MegaMart_Toronto.557ba83159"
[0m15:40:16.582587 [debug] [Thread-2 (]: Using databricks connection "test.dbt_anirudh.accepted_values_bronze_store_store_name__MegaMart_Manhattan__MegaMart_Brooklyn__MegaMart_Austin__MegaMart_San_Jose__MegaMart_Toronto.557ba83159"
[0m15:40:16.582952 [debug] [Thread-2 (]: On test.dbt_anirudh.accepted_values_bronze_store_store_name__MegaMart_Manhattan__MegaMart_Brooklyn__MegaMart_Austin__MegaMart_San_Jose__MegaMart_Toronto.557ba83159: /* {"app": "dbt", "dbt_version": "1.10.10", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_anirudh", "target_name": "dev", "node_id": "test.dbt_anirudh.accepted_values_bronze_store_store_name__MegaMart_Manhattan__MegaMart_Brooklyn__MegaMart_Austin__MegaMart_San_Jose__MegaMart_Toronto.557ba83159"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    

with all_values as (

    select
        store_name as value_field,
        count(*) as n_records

    from `dbt_learning`.`bronze`.`bronze_store`
    group by store_name

)

select *
from all_values
where value_field not in (
    'MegaMart Manhattan','MegaMart Brooklyn','MegaMart Austin','MegaMart San Jose','MegaMart Toronto'
)



  
  
      
    ) dbt_internal_test
[0m15:40:16.583311 [debug] [Thread-2 (]: Opening a new connection, currently in state init
[0m15:40:17.686848 [debug] [Thread-2 (]: Databricks adapter: Connection(session-id=01f09153-03d3-1b56-8195-fb134558e50a) - Created
[0m15:40:19.078325 [debug] [Thread-2 (]: SQL status: OK in 2.490 seconds
[0m15:40:19.084526 [debug] [Thread-2 (]: Databricks adapter: Cursor(session-id=01f09153-03d3-1b56-8195-fb134558e50a, command-id=01f09153-03fe-13e2-bcae-4d3eb9ace5be) - Closing
[0m15:40:19.091440 [debug] [Thread-2 (]: On test.dbt_anirudh.accepted_values_bronze_store_store_name__MegaMart_Manhattan__MegaMart_Brooklyn__MegaMart_Austin__MegaMart_San_Jose__MegaMart_Toronto.557ba83159: Close
[0m15:40:19.092057 [debug] [Thread-2 (]: Databricks adapter: Connection(session-id=01f09153-03d3-1b56-8195-fb134558e50a) - Closing
[0m15:40:19.398535 [info ] [Thread-2 (]: 1 of 3 PASS accepted_values_bronze_store_store_name__MegaMart_Manhattan__MegaMart_Brooklyn__MegaMart_Austin__MegaMart_San_Jose__MegaMart_Toronto  [[32mPASS[0m in 2.86s]
[0m15:40:19.400153 [debug] [Thread-2 (]: Finished running node test.dbt_anirudh.accepted_values_bronze_store_store_name__MegaMart_Manhattan__MegaMart_Brooklyn__MegaMart_Austin__MegaMart_San_Jose__MegaMart_Toronto.557ba83159
[0m15:40:19.401164 [debug] [Thread-2 (]: Began running node test.dbt_anirudh.not_null_bronze_sales_sales_id.e4b1b997fb
[0m15:40:19.402222 [info ] [Thread-2 (]: 2 of 3 START test not_null_bronze_sales_sales_id ............................... [RUN]
[0m15:40:19.403585 [debug] [Thread-2 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=test.dbt_anirudh.not_null_bronze_sales_sales_id.e4b1b997fb) - Creating connection
[0m15:40:19.404477 [debug] [Thread-2 (]: Acquiring new databricks connection 'test.dbt_anirudh.not_null_bronze_sales_sales_id.e4b1b997fb'
[0m15:40:19.405303 [debug] [Thread-2 (]: Began compiling node test.dbt_anirudh.not_null_bronze_sales_sales_id.e4b1b997fb
[0m15:40:19.422480 [debug] [Thread-2 (]: Writing injected SQL for node "test.dbt_anirudh.not_null_bronze_sales_sales_id.e4b1b997fb"
[0m15:40:19.423255 [debug] [Thread-2 (]: Began executing node test.dbt_anirudh.not_null_bronze_sales_sales_id.e4b1b997fb
[0m15:40:19.425331 [debug] [Thread-2 (]: Writing runtime sql for node "test.dbt_anirudh.not_null_bronze_sales_sales_id.e4b1b997fb"
[0m15:40:19.425827 [debug] [Thread-2 (]: Using databricks connection "test.dbt_anirudh.not_null_bronze_sales_sales_id.e4b1b997fb"
[0m15:40:19.426263 [debug] [Thread-2 (]: On test.dbt_anirudh.not_null_bronze_sales_sales_id.e4b1b997fb: /* {"app": "dbt", "dbt_version": "1.10.10", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_anirudh", "target_name": "dev", "node_id": "test.dbt_anirudh.not_null_bronze_sales_sales_id.e4b1b997fb"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select sales_id
from `dbt_learning`.`bronze`.`bronze_sales`
where sales_id is null



  
  
      
    ) dbt_internal_test
[0m15:40:19.426547 [debug] [Thread-2 (]: Opening a new connection, currently in state init
[0m15:40:20.536621 [debug] [Thread-2 (]: Databricks adapter: Connection(session-id=01f09153-0587-1169-9f79-c6dd1e321e86) - Created
[0m15:40:21.876169 [debug] [Thread-2 (]: SQL status: OK in 2.450 seconds
[0m15:40:21.880359 [debug] [Thread-2 (]: Databricks adapter: Cursor(session-id=01f09153-0587-1169-9f79-c6dd1e321e86, command-id=01f09153-05b2-11e9-bbc4-4be762646a48) - Closing
[0m15:40:21.881860 [debug] [Thread-2 (]: On test.dbt_anirudh.not_null_bronze_sales_sales_id.e4b1b997fb: Close
[0m15:40:21.882842 [debug] [Thread-2 (]: Databricks adapter: Connection(session-id=01f09153-0587-1169-9f79-c6dd1e321e86) - Closing
[0m15:40:22.184217 [info ] [Thread-2 (]: 2 of 3 PASS not_null_bronze_sales_sales_id ..................................... [[32mPASS[0m in 2.78s]
[0m15:40:22.185839 [debug] [Thread-2 (]: Finished running node test.dbt_anirudh.not_null_bronze_sales_sales_id.e4b1b997fb
[0m15:40:22.186907 [debug] [Thread-2 (]: Began running node test.dbt_anirudh.unique_bronze_sales_sales_id.3c35aa753d
[0m15:40:22.188036 [info ] [Thread-2 (]: 3 of 3 START test unique_bronze_sales_sales_id ................................. [RUN]
[0m15:40:22.189405 [debug] [Thread-2 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=test.dbt_anirudh.unique_bronze_sales_sales_id.3c35aa753d) - Creating connection
[0m15:40:22.190332 [debug] [Thread-2 (]: Acquiring new databricks connection 'test.dbt_anirudh.unique_bronze_sales_sales_id.3c35aa753d'
[0m15:40:22.191237 [debug] [Thread-2 (]: Began compiling node test.dbt_anirudh.unique_bronze_sales_sales_id.3c35aa753d
[0m15:40:22.204002 [debug] [Thread-2 (]: Writing injected SQL for node "test.dbt_anirudh.unique_bronze_sales_sales_id.3c35aa753d"
[0m15:40:22.204717 [debug] [Thread-2 (]: Began executing node test.dbt_anirudh.unique_bronze_sales_sales_id.3c35aa753d
[0m15:40:22.206792 [debug] [Thread-2 (]: Writing runtime sql for node "test.dbt_anirudh.unique_bronze_sales_sales_id.3c35aa753d"
[0m15:40:22.207326 [debug] [Thread-2 (]: Using databricks connection "test.dbt_anirudh.unique_bronze_sales_sales_id.3c35aa753d"
[0m15:40:22.207668 [debug] [Thread-2 (]: On test.dbt_anirudh.unique_bronze_sales_sales_id.3c35aa753d: /* {"app": "dbt", "dbt_version": "1.10.10", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_anirudh", "target_name": "dev", "node_id": "test.dbt_anirudh.unique_bronze_sales_sales_id.3c35aa753d"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    

select
    sales_id as unique_field,
    count(*) as n_records

from `dbt_learning`.`bronze`.`bronze_sales`
where sales_id is not null
group by sales_id
having count(*) > 1



  
  
      
    ) dbt_internal_test
[0m15:40:22.207970 [debug] [Thread-2 (]: Opening a new connection, currently in state init
[0m15:40:23.310802 [debug] [Thread-2 (]: Databricks adapter: Connection(session-id=01f09153-072e-1b73-ab17-9dfb0cf0cb09) - Created
[0m15:40:24.267803 [debug] [Thread-2 (]: SQL status: OK in 2.060 seconds
[0m15:40:24.272084 [debug] [Thread-2 (]: Databricks adapter: Cursor(session-id=01f09153-072e-1b73-ab17-9dfb0cf0cb09, command-id=01f09153-0759-1d32-97b2-aaeaaf431624) - Closing
[0m15:40:24.273541 [debug] [Thread-2 (]: On test.dbt_anirudh.unique_bronze_sales_sales_id.3c35aa753d: Close
[0m15:40:24.274494 [debug] [Thread-2 (]: Databricks adapter: Connection(session-id=01f09153-072e-1b73-ab17-9dfb0cf0cb09) - Closing
[0m15:40:24.582420 [info ] [Thread-2 (]: 3 of 3 PASS unique_bronze_sales_sales_id ....................................... [[32mPASS[0m in 2.39s]
[0m15:40:24.584392 [debug] [Thread-2 (]: Finished running node test.dbt_anirudh.unique_bronze_sales_sales_id.3c35aa753d
[0m15:40:24.586995 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=master) - Creating connection
[0m15:40:24.588007 [debug] [MainThread]: Acquiring new databricks connection 'master'
[0m15:40:24.589333 [info ] [MainThread]: 
[0m15:40:24.590596 [info ] [MainThread]: Finished running 3 data tests in 0 hours 0 minutes and 10.83 seconds (10.83s).
[0m15:40:24.593351 [debug] [MainThread]: Command end result
[0m15:40:24.620773 [debug] [MainThread]: Wrote artifact WritableManifest to /home/aniruth/AI/DBT/DBT_Master/dbt_anirudh/target/manifest.json
[0m15:40:24.622253 [debug] [MainThread]: Wrote artifact SemanticManifest to /home/aniruth/AI/DBT/DBT_Master/dbt_anirudh/target/semantic_manifest.json
[0m15:40:24.627863 [debug] [MainThread]: Wrote artifact RunExecutionResult to /home/aniruth/AI/DBT/DBT_Master/dbt_anirudh/target/run_results.json
[0m15:40:24.628216 [info ] [MainThread]: 
[0m15:40:24.628577 [info ] [MainThread]: [32mCompleted successfully[0m
[0m15:40:24.628912 [info ] [MainThread]: 
[0m15:40:24.629231 [info ] [MainThread]: Done. PASS=3 WARN=0 ERROR=0 SKIP=0 NO-OP=0 TOTAL=3
[0m15:40:24.630073 [debug] [MainThread]: Resource report: {"command_name": "test", "command_success": true, "command_wall_clock_time": 12.450273, "process_in_blocks": "90696", "process_kernel_time": 0.201645, "process_mem_max_rss": "271072", "process_out_blocks": "4304", "process_user_time": 3.945633}
[0m15:40:24.630517 [debug] [MainThread]: Command `dbt test` succeeded at 15:40:24.630441 after 12.45 seconds
[0m15:40:24.630853 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x72527ff99970>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7252801addf0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7252801acc20>]}
[0m15:40:24.631158 [debug] [MainThread]: Flushing usage events
[0m15:40:25.622232 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m15:40:41.810224 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7d9761d4c1d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7d97636da480>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7d9762ed9fa0>]}


============================== 15:40:41.812898 | 479e284e-c209-47f1-82bb-4cfcdf18850b ==============================
[0m15:40:41.812898 [info ] [MainThread]: Running with dbt=1.10.10
[0m15:40:41.813399 [debug] [MainThread]: running dbt with arguments {'fail_fast': 'False', 'introspect': 'True', 'write_json': 'True', 'send_anonymous_usage_stats': 'True', 'use_experimental_parser': 'False', 'log_format': 'default', 'quiet': 'False', 'debug': 'False', 'empty': 'None', 'no_print': 'None', 'profiles_dir': '/home/aniruth/AI/DBT/DBT_Master/dbt_anirudh', 'use_colors': 'True', 'warn_error': 'None', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'version_check': 'True', 'partial_parse': 'True', 'log_cache_events': 'False', 'invocation_command': 'dbt test', 'target_path': 'None', 'log_path': '/home/aniruth/AI/DBT/DBT_Master/dbt_anirudh/logs', 'cache_selected_only': 'False', 'static_parser': 'True', 'printer_width': '80', 'indirect_selection': 'eager'}
[0m15:40:42.398605 [debug] [MainThread]: Spark adapter: Setting pyhive.hive logging to ERROR
[0m15:40:42.399044 [debug] [MainThread]: Spark adapter: Setting thrift.transport logging to ERROR
[0m15:40:42.399340 [debug] [MainThread]: Spark adapter: Setting thrift.protocol logging to ERROR
[0m15:40:42.902472 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '479e284e-c209-47f1-82bb-4cfcdf18850b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7d9761185d00>]}
[0m15:40:42.951544 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '479e284e-c209-47f1-82bb-4cfcdf18850b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7d9740a6cf20>]}
[0m15:40:42.952088 [info ] [MainThread]: Registered adapter: databricks=1.10.9
[0m15:40:43.035713 [debug] [MainThread]: checksum: 502a0dc23e9052e1ae09f7c44ee219ef7a02dfea7e7d66580d54c304c14d553b, vars: {}, profile: , target: , version: 1.10.10
[0m15:40:43.126941 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m15:40:43.127351 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m15:40:43.133765 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 2 unused configuration paths:
- models.dbt_anirudh.silver
- models.dbt_anirudh.gold
[0m15:40:43.167093 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '479e284e-c209-47f1-82bb-4cfcdf18850b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7d97403a0bf0>]}
[0m15:40:43.235171 [debug] [MainThread]: Wrote artifact WritableManifest to /home/aniruth/AI/DBT/DBT_Master/dbt_anirudh/target/manifest.json
[0m15:40:43.236546 [debug] [MainThread]: Wrote artifact SemanticManifest to /home/aniruth/AI/DBT/DBT_Master/dbt_anirudh/target/semantic_manifest.json
[0m15:40:43.248875 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '479e284e-c209-47f1-82bb-4cfcdf18850b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7d973b819b80>]}
[0m15:40:43.249284 [info ] [MainThread]: Found 6 models, 3 data tests, 6 sources, 686 macros
[0m15:40:43.249564 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '479e284e-c209-47f1-82bb-4cfcdf18850b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7d973bf0b2f0>]}
[0m15:40:43.250903 [info ] [MainThread]: 
[0m15:40:43.251211 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m15:40:43.251472 [info ] [MainThread]: 
[0m15:40:43.251867 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=master) - Creating connection
[0m15:40:43.252139 [debug] [MainThread]: Acquiring new databricks connection 'master'
[0m15:40:43.257513 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=list_dbt_learning_bronze) - Creating connection
[0m15:40:43.257885 [debug] [ThreadPool]: Acquiring new databricks connection 'list_dbt_learning_bronze'
[0m15:40:43.270004 [debug] [ThreadPool]: Using databricks connection "list_dbt_learning_bronze"
[0m15:40:43.270461 [debug] [ThreadPool]: On list_dbt_learning_bronze: /* {"app": "dbt", "dbt_version": "1.10.10", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_anirudh", "target_name": "dev", "connection_name": "list_dbt_learning_bronze"} */

    
SELECT
  table_name,
  if(table_type IN ('EXTERNAL', 'MANAGED', 'MANAGED_SHALLOW_CLONE', 'EXTERNAL_SHALLOW_CLONE'), 'table', lower(table_type)) AS table_type,
  lower(data_source_format) AS file_format,
  table_owner,
  if(
    table_type IN (
      'EXTERNAL',
      'MANAGED',
      'MANAGED_SHALLOW_CLONE',
      'EXTERNAL_SHALLOW_CLONE'
    ),
    lower(table_type),
    NULL
  ) AS databricks_table_type
FROM `system`.`information_schema`.`tables`
WHERE table_catalog = 'dbt_learning' 
  AND table_schema = 'bronze'

  
[0m15:40:43.270735 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m15:40:44.363000 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f09153-13ba-117b-85ac-c276811d9759) - Created
[0m15:40:44.959385 [debug] [ThreadPool]: SQL status: OK in 1.690 seconds
[0m15:40:44.967855 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01f09153-13ba-117b-85ac-c276811d9759, command-id=01f09153-13e4-157d-8d6c-b879e1ac6710) - Closing
[0m15:40:44.969114 [debug] [ThreadPool]: On list_dbt_learning_bronze: Close
[0m15:40:44.969667 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f09153-13ba-117b-85ac-c276811d9759) - Closing
[0m15:40:45.274794 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '479e284e-c209-47f1-82bb-4cfcdf18850b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7d973be419a0>]}
[0m15:40:45.280383 [debug] [Thread-2 (]: Began running node test.dbt_anirudh.accepted_values_bronze_store_store_name__MegaMar_Manhattan__MegaMart_Brooklyn__MegaMart_Austin__MegaMart_San_Jose__MegaMart_Toronto.b983752665
[0m15:40:45.281541 [info ] [Thread-2 (]: 1 of 3 START test accepted_values_bronze_store_store_name__MegaMar_Manhattan__MegaMart_Brooklyn__MegaMart_Austin__MegaMart_San_Jose__MegaMart_Toronto  [RUN]
[0m15:40:45.282813 [debug] [Thread-2 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=test.dbt_anirudh.accepted_values_bronze_store_store_name__MegaMar_Manhattan__MegaMart_Brooklyn__MegaMart_Austin__MegaMart_San_Jose__MegaMart_Toronto.b983752665) - Creating connection
[0m15:40:45.283489 [debug] [Thread-2 (]: Acquiring new databricks connection 'test.dbt_anirudh.accepted_values_bronze_store_store_name__MegaMar_Manhattan__MegaMart_Brooklyn__MegaMart_Austin__MegaMart_San_Jose__MegaMart_Toronto.b983752665'
[0m15:40:45.284115 [debug] [Thread-2 (]: Began compiling node test.dbt_anirudh.accepted_values_bronze_store_store_name__MegaMar_Manhattan__MegaMart_Brooklyn__MegaMart_Austin__MegaMart_San_Jose__MegaMart_Toronto.b983752665
[0m15:40:45.302350 [debug] [Thread-2 (]: Writing injected SQL for node "test.dbt_anirudh.accepted_values_bronze_store_store_name__MegaMar_Manhattan__MegaMart_Brooklyn__MegaMart_Austin__MegaMart_San_Jose__MegaMart_Toronto.b983752665"
[0m15:40:45.302890 [debug] [Thread-2 (]: Began executing node test.dbt_anirudh.accepted_values_bronze_store_store_name__MegaMar_Manhattan__MegaMart_Brooklyn__MegaMart_Austin__MegaMart_San_Jose__MegaMart_Toronto.b983752665
[0m15:40:45.319723 [debug] [Thread-2 (]: Writing runtime sql for node "test.dbt_anirudh.accepted_values_bronze_store_store_name__MegaMar_Manhattan__MegaMart_Brooklyn__MegaMart_Austin__MegaMart_San_Jose__MegaMart_Toronto.b983752665"
[0m15:40:45.320265 [debug] [Thread-2 (]: Using databricks connection "test.dbt_anirudh.accepted_values_bronze_store_store_name__MegaMar_Manhattan__MegaMart_Brooklyn__MegaMart_Austin__MegaMart_San_Jose__MegaMart_Toronto.b983752665"
[0m15:40:45.320598 [debug] [Thread-2 (]: On test.dbt_anirudh.accepted_values_bronze_store_store_name__MegaMar_Manhattan__MegaMart_Brooklyn__MegaMart_Austin__MegaMart_San_Jose__MegaMart_Toronto.b983752665: /* {"app": "dbt", "dbt_version": "1.10.10", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_anirudh", "target_name": "dev", "node_id": "test.dbt_anirudh.accepted_values_bronze_store_store_name__MegaMar_Manhattan__MegaMart_Brooklyn__MegaMart_Austin__MegaMart_San_Jose__MegaMart_Toronto.b983752665"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    

with all_values as (

    select
        store_name as value_field,
        count(*) as n_records

    from `dbt_learning`.`bronze`.`bronze_store`
    group by store_name

)

select *
from all_values
where value_field not in (
    'MegaMar Manhattan','MegaMart Brooklyn','MegaMart Austin','MegaMart San Jose','MegaMart Toronto'
)



  
  
      
    ) dbt_internal_test
[0m15:40:45.320889 [debug] [Thread-2 (]: Opening a new connection, currently in state init
[0m15:40:46.451892 [debug] [Thread-2 (]: Databricks adapter: Connection(session-id=01f09153-14f8-15eb-b971-630874a05cc0) - Created
[0m15:40:47.554979 [debug] [Thread-2 (]: SQL status: OK in 2.230 seconds
[0m15:40:47.559859 [debug] [Thread-2 (]: Databricks adapter: Cursor(session-id=01f09153-14f8-15eb-b971-630874a05cc0, command-id=01f09153-1524-16ff-a63e-5b6954c4eb35) - Closing
[0m15:40:47.565696 [debug] [Thread-2 (]: On test.dbt_anirudh.accepted_values_bronze_store_store_name__MegaMar_Manhattan__MegaMart_Brooklyn__MegaMart_Austin__MegaMart_San_Jose__MegaMart_Toronto.b983752665: Close
[0m15:40:47.566339 [debug] [Thread-2 (]: Databricks adapter: Connection(session-id=01f09153-14f8-15eb-b971-630874a05cc0) - Closing
[0m15:40:47.886334 [error] [Thread-2 (]: 1 of 3 FAIL 1 accepted_values_bronze_store_store_name__MegaMar_Manhattan__MegaMart_Brooklyn__MegaMart_Austin__MegaMart_San_Jose__MegaMart_Toronto  [[31mFAIL 1[0m in 2.60s]
[0m15:40:47.888793 [debug] [Thread-2 (]: Finished running node test.dbt_anirudh.accepted_values_bronze_store_store_name__MegaMar_Manhattan__MegaMart_Brooklyn__MegaMart_Austin__MegaMart_San_Jose__MegaMart_Toronto.b983752665
[0m15:40:47.890098 [debug] [Thread-2 (]: Began running node test.dbt_anirudh.not_null_bronze_sales_sales_id.e4b1b997fb
[0m15:40:47.891474 [info ] [Thread-2 (]: 2 of 3 START test not_null_bronze_sales_sales_id ............................... [RUN]
[0m15:40:47.892834 [debug] [Thread-2 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=test.dbt_anirudh.not_null_bronze_sales_sales_id.e4b1b997fb) - Creating connection
[0m15:40:47.893830 [debug] [Thread-2 (]: Acquiring new databricks connection 'test.dbt_anirudh.not_null_bronze_sales_sales_id.e4b1b997fb'
[0m15:40:47.894795 [debug] [Thread-2 (]: Began compiling node test.dbt_anirudh.not_null_bronze_sales_sales_id.e4b1b997fb
[0m15:40:47.906114 [debug] [Thread-2 (]: Writing injected SQL for node "test.dbt_anirudh.not_null_bronze_sales_sales_id.e4b1b997fb"
[0m15:40:47.906797 [debug] [Thread-2 (]: Began executing node test.dbt_anirudh.not_null_bronze_sales_sales_id.e4b1b997fb
[0m15:40:47.908861 [debug] [Thread-2 (]: Writing runtime sql for node "test.dbt_anirudh.not_null_bronze_sales_sales_id.e4b1b997fb"
[0m15:40:47.909266 [debug] [Thread-2 (]: Using databricks connection "test.dbt_anirudh.not_null_bronze_sales_sales_id.e4b1b997fb"
[0m15:40:47.909647 [debug] [Thread-2 (]: On test.dbt_anirudh.not_null_bronze_sales_sales_id.e4b1b997fb: /* {"app": "dbt", "dbt_version": "1.10.10", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_anirudh", "target_name": "dev", "node_id": "test.dbt_anirudh.not_null_bronze_sales_sales_id.e4b1b997fb"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select sales_id
from `dbt_learning`.`bronze`.`bronze_sales`
where sales_id is null



  
  
      
    ) dbt_internal_test
[0m15:40:47.909937 [debug] [Thread-2 (]: Opening a new connection, currently in state init
[0m15:40:49.025110 [debug] [Thread-2 (]: Databricks adapter: Connection(session-id=01f09153-1681-17e7-a0d6-625a2ccc09ec) - Created
[0m15:40:49.545631 [debug] [Thread-2 (]: SQL status: OK in 1.640 seconds
[0m15:40:49.550086 [debug] [Thread-2 (]: Databricks adapter: Cursor(session-id=01f09153-1681-17e7-a0d6-625a2ccc09ec, command-id=01f09153-16ad-14d0-9e6e-4ae53bad449d) - Closing
[0m15:40:49.551765 [debug] [Thread-2 (]: On test.dbt_anirudh.not_null_bronze_sales_sales_id.e4b1b997fb: Close
[0m15:40:49.552647 [debug] [Thread-2 (]: Databricks adapter: Connection(session-id=01f09153-1681-17e7-a0d6-625a2ccc09ec) - Closing
[0m15:40:49.865872 [info ] [Thread-2 (]: 2 of 3 PASS not_null_bronze_sales_sales_id ..................................... [[32mPASS[0m in 1.97s]
[0m15:40:49.867511 [debug] [Thread-2 (]: Finished running node test.dbt_anirudh.not_null_bronze_sales_sales_id.e4b1b997fb
[0m15:40:49.868630 [debug] [Thread-2 (]: Began running node test.dbt_anirudh.unique_bronze_sales_sales_id.3c35aa753d
[0m15:40:49.869635 [info ] [Thread-2 (]: 3 of 3 START test unique_bronze_sales_sales_id ................................. [RUN]
[0m15:40:49.870965 [debug] [Thread-2 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=test.dbt_anirudh.unique_bronze_sales_sales_id.3c35aa753d) - Creating connection
[0m15:40:49.871931 [debug] [Thread-2 (]: Acquiring new databricks connection 'test.dbt_anirudh.unique_bronze_sales_sales_id.3c35aa753d'
[0m15:40:49.872882 [debug] [Thread-2 (]: Began compiling node test.dbt_anirudh.unique_bronze_sales_sales_id.3c35aa753d
[0m15:40:49.884663 [debug] [Thread-2 (]: Writing injected SQL for node "test.dbt_anirudh.unique_bronze_sales_sales_id.3c35aa753d"
[0m15:40:49.885376 [debug] [Thread-2 (]: Began executing node test.dbt_anirudh.unique_bronze_sales_sales_id.3c35aa753d
[0m15:40:49.887351 [debug] [Thread-2 (]: Writing runtime sql for node "test.dbt_anirudh.unique_bronze_sales_sales_id.3c35aa753d"
[0m15:40:49.887811 [debug] [Thread-2 (]: Using databricks connection "test.dbt_anirudh.unique_bronze_sales_sales_id.3c35aa753d"
[0m15:40:49.888174 [debug] [Thread-2 (]: On test.dbt_anirudh.unique_bronze_sales_sales_id.3c35aa753d: /* {"app": "dbt", "dbt_version": "1.10.10", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_anirudh", "target_name": "dev", "node_id": "test.dbt_anirudh.unique_bronze_sales_sales_id.3c35aa753d"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    

select
    sales_id as unique_field,
    count(*) as n_records

from `dbt_learning`.`bronze`.`bronze_sales`
where sales_id is not null
group by sales_id
having count(*) > 1



  
  
      
    ) dbt_internal_test
[0m15:40:49.888443 [debug] [Thread-2 (]: Opening a new connection, currently in state init
[0m15:40:51.060066 [debug] [Thread-2 (]: Databricks adapter: Connection(session-id=01f09153-17b3-112a-b244-281b7aa27788) - Created
[0m15:40:51.568669 [debug] [Thread-2 (]: SQL status: OK in 1.680 seconds
[0m15:40:51.571068 [debug] [Thread-2 (]: Databricks adapter: Cursor(session-id=01f09153-17b3-112a-b244-281b7aa27788, command-id=01f09153-17e3-1df5-9506-992d7d1fb7bf) - Closing
[0m15:40:51.571835 [debug] [Thread-2 (]: On test.dbt_anirudh.unique_bronze_sales_sales_id.3c35aa753d: Close
[0m15:40:51.572269 [debug] [Thread-2 (]: Databricks adapter: Connection(session-id=01f09153-17b3-112a-b244-281b7aa27788) - Closing
[0m15:40:51.879446 [info ] [Thread-2 (]: 3 of 3 PASS unique_bronze_sales_sales_id ....................................... [[32mPASS[0m in 2.01s]
[0m15:40:51.880984 [debug] [Thread-2 (]: Finished running node test.dbt_anirudh.unique_bronze_sales_sales_id.3c35aa753d
[0m15:40:51.883633 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=master) - Creating connection
[0m15:40:51.884513 [debug] [MainThread]: Acquiring new databricks connection 'master'
[0m15:40:51.885545 [info ] [MainThread]: 
[0m15:40:51.886498 [info ] [MainThread]: Finished running 3 data tests in 0 hours 0 minutes and 8.63 seconds (8.63s).
[0m15:40:51.888946 [debug] [MainThread]: Command end result
[0m15:40:51.917940 [debug] [MainThread]: Wrote artifact WritableManifest to /home/aniruth/AI/DBT/DBT_Master/dbt_anirudh/target/manifest.json
[0m15:40:51.919737 [debug] [MainThread]: Wrote artifact SemanticManifest to /home/aniruth/AI/DBT/DBT_Master/dbt_anirudh/target/semantic_manifest.json
[0m15:40:51.925074 [debug] [MainThread]: Wrote artifact RunExecutionResult to /home/aniruth/AI/DBT/DBT_Master/dbt_anirudh/target/run_results.json
[0m15:40:51.925384 [info ] [MainThread]: 
[0m15:40:51.925670 [info ] [MainThread]: [31mCompleted with 1 error, 0 partial successes, and 0 warnings:[0m
[0m15:40:51.925952 [info ] [MainThread]: 
[0m15:40:51.926276 [error] [MainThread]: [31mFailure in test accepted_values_bronze_store_store_name__MegaMar_Manhattan__MegaMart_Brooklyn__MegaMart_Austin__MegaMart_San_Jose__MegaMart_Toronto (models/bronze/properties.yml)[0m
[0m15:40:51.926581 [error] [MainThread]:   Got 1 result, configured to fail if != 0
[0m15:40:51.926817 [info ] [MainThread]: 
[0m15:40:51.927115 [info ] [MainThread]:   compiled code at target/compiled/dbt_anirudh/models/bronze/properties.yml/accepted_values_bronze_store_8308937ffa06d226d8f7cff5d272d129.sql
[0m15:40:51.927371 [info ] [MainThread]: 
[0m15:40:51.927646 [info ] [MainThread]: Done. PASS=2 WARN=0 ERROR=1 SKIP=0 NO-OP=0 TOTAL=3
[0m15:40:51.928313 [debug] [MainThread]: Resource report: {"command_name": "test", "command_success": false, "command_wall_clock_time": 10.162033, "process_in_blocks": "0", "process_kernel_time": 0.184489, "process_mem_max_rss": "245404", "process_out_blocks": "3184", "process_user_time": 3.910184}
[0m15:40:51.928655 [debug] [MainThread]: Command `dbt test` failed at 15:40:51.928587 after 10.16 seconds
[0m15:40:51.928935 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7d9761541580>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7d9761b212b0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7d9761b46210>]}
[0m15:40:51.929239 [debug] [MainThread]: Flushing usage events
[0m15:40:52.926340 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m15:46:48.720033 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2c0f137b30>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2c0efd66c0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2c0f015f40>]}


============================== 15:46:48.723053 | 0cbdf61a-2c90-4047-ade5-e41f2c1bc96b ==============================
[0m15:46:48.723053 [info ] [MainThread]: Running with dbt=1.10.10
[0m15:46:48.723523 [debug] [MainThread]: running dbt with arguments {'cache_selected_only': 'False', 'send_anonymous_usage_stats': 'True', 'no_print': 'None', 'write_json': 'True', 'empty': 'None', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'introspect': 'True', 'invocation_command': 'dbt test', 'version_check': 'True', 'static_parser': 'True', 'partial_parse': 'True', 'warn_error': 'None', 'profiles_dir': '/home/aniruth/AI/DBT/DBT_Master/dbt_anirudh', 'use_experimental_parser': 'False', 'log_cache_events': 'False', 'log_format': 'default', 'printer_width': '80', 'target_path': 'None', 'quiet': 'False', 'use_colors': 'True', 'indirect_selection': 'eager', 'log_path': '/home/aniruth/AI/DBT/DBT_Master/dbt_anirudh/logs', 'debug': 'False', 'fail_fast': 'False'}
[0m15:46:49.322562 [debug] [MainThread]: Spark adapter: Setting pyhive.hive logging to ERROR
[0m15:46:49.323118 [debug] [MainThread]: Spark adapter: Setting thrift.transport logging to ERROR
[0m15:46:49.323428 [debug] [MainThread]: Spark adapter: Setting thrift.protocol logging to ERROR
[0m15:46:49.891301 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '0cbdf61a-2c90-4047-ade5-e41f2c1bc96b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2c1085e900>]}
[0m15:46:49.942747 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '0cbdf61a-2c90-4047-ade5-e41f2c1bc96b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2c0958f8c0>]}
[0m15:46:49.943351 [info ] [MainThread]: Registered adapter: databricks=1.10.9
[0m15:46:50.029875 [debug] [MainThread]: checksum: 502a0dc23e9052e1ae09f7c44ee219ef7a02dfea7e7d66580d54c304c14d553b, vars: {}, profile: , target: , version: 1.10.10
[0m15:46:50.115347 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m15:46:50.115706 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m15:46:50.121052 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 2 unused configuration paths:
- models.dbt_anirudh.silver
- models.dbt_anirudh.gold
[0m15:46:50.156142 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '0cbdf61a-2c90-4047-ade5-e41f2c1bc96b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2bed04a240>]}
[0m15:46:50.218641 [debug] [MainThread]: Wrote artifact WritableManifest to /home/aniruth/AI/DBT/DBT_Master/dbt_anirudh/target/manifest.json
[0m15:46:50.220029 [debug] [MainThread]: Wrote artifact SemanticManifest to /home/aniruth/AI/DBT/DBT_Master/dbt_anirudh/target/semantic_manifest.json
[0m15:46:50.234623 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '0cbdf61a-2c90-4047-ade5-e41f2c1bc96b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2becb4a060>]}
[0m15:46:50.234988 [info ] [MainThread]: Found 6 models, 3 data tests, 6 sources, 686 macros
[0m15:46:50.235273 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '0cbdf61a-2c90-4047-ade5-e41f2c1bc96b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2bed04b830>]}
[0m15:46:50.236586 [info ] [MainThread]: 
[0m15:46:50.236877 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m15:46:50.237107 [info ] [MainThread]: 
[0m15:46:50.237494 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=master) - Creating connection
[0m15:46:50.237743 [debug] [MainThread]: Acquiring new databricks connection 'master'
[0m15:46:50.243064 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=list_dbt_learning_bronze) - Creating connection
[0m15:46:50.243442 [debug] [ThreadPool]: Acquiring new databricks connection 'list_dbt_learning_bronze'
[0m15:46:50.255134 [debug] [ThreadPool]: Using databricks connection "list_dbt_learning_bronze"
[0m15:46:50.255551 [debug] [ThreadPool]: On list_dbt_learning_bronze: /* {"app": "dbt", "dbt_version": "1.10.10", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_anirudh", "target_name": "dev", "connection_name": "list_dbt_learning_bronze"} */

    
SELECT
  table_name,
  if(table_type IN ('EXTERNAL', 'MANAGED', 'MANAGED_SHALLOW_CLONE', 'EXTERNAL_SHALLOW_CLONE'), 'table', lower(table_type)) AS table_type,
  lower(data_source_format) AS file_format,
  table_owner,
  if(
    table_type IN (
      'EXTERNAL',
      'MANAGED',
      'MANAGED_SHALLOW_CLONE',
      'EXTERNAL_SHALLOW_CLONE'
    ),
    lower(table_type),
    NULL
  ) AS databricks_table_type
FROM `system`.`information_schema`.`tables`
WHERE table_catalog = 'dbt_learning' 
  AND table_schema = 'bronze'

  
[0m15:46:50.255871 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m15:46:51.422268 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f09153-ee2d-143f-af8c-7c72d9300bda) - Created
[0m15:46:52.119803 [debug] [ThreadPool]: SQL status: OK in 1.860 seconds
[0m15:46:52.129179 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01f09153-ee2d-143f-af8c-7c72d9300bda, command-id=01f09153-ee59-126c-b899-6347fac2d127) - Closing
[0m15:46:52.130421 [debug] [ThreadPool]: On list_dbt_learning_bronze: Close
[0m15:46:52.131047 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f09153-ee2d-143f-af8c-7c72d9300bda) - Closing
[0m15:46:52.443225 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '0cbdf61a-2c90-4047-ade5-e41f2c1bc96b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2bed13dc10>]}
[0m15:46:52.447709 [debug] [Thread-2 (]: Began running node test.dbt_anirudh.accepted_values_bronze_store_store_name__MegaMar_Manhattan__MegaMart_Brooklyn__MegaMart_Austin__MegaMart_San_Jose__MegaMart_Toronto.b983752665
[0m15:46:52.448795 [info ] [Thread-2 (]: 1 of 3 START test accepted_values_bronze_store_store_name__MegaMar_Manhattan__MegaMart_Brooklyn__MegaMart_Austin__MegaMart_San_Jose__MegaMart_Toronto  [RUN]
[0m15:46:52.450309 [debug] [Thread-2 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=test.dbt_anirudh.accepted_values_bronze_store_store_name__MegaMar_Manhattan__MegaMart_Brooklyn__MegaMart_Austin__MegaMart_San_Jose__MegaMart_Toronto.b983752665) - Creating connection
[0m15:46:52.451232 [debug] [Thread-2 (]: Acquiring new databricks connection 'test.dbt_anirudh.accepted_values_bronze_store_store_name__MegaMar_Manhattan__MegaMart_Brooklyn__MegaMart_Austin__MegaMart_San_Jose__MegaMart_Toronto.b983752665'
[0m15:46:52.452096 [debug] [Thread-2 (]: Began compiling node test.dbt_anirudh.accepted_values_bronze_store_store_name__MegaMar_Manhattan__MegaMart_Brooklyn__MegaMart_Austin__MegaMart_San_Jose__MegaMart_Toronto.b983752665
[0m15:46:52.478067 [debug] [Thread-2 (]: Writing injected SQL for node "test.dbt_anirudh.accepted_values_bronze_store_store_name__MegaMar_Manhattan__MegaMart_Brooklyn__MegaMart_Austin__MegaMart_San_Jose__MegaMart_Toronto.b983752665"
[0m15:46:52.478687 [debug] [Thread-2 (]: Began executing node test.dbt_anirudh.accepted_values_bronze_store_store_name__MegaMar_Manhattan__MegaMart_Brooklyn__MegaMart_Austin__MegaMart_San_Jose__MegaMart_Toronto.b983752665
[0m15:46:52.495033 [debug] [Thread-2 (]: Writing runtime sql for node "test.dbt_anirudh.accepted_values_bronze_store_store_name__MegaMar_Manhattan__MegaMart_Brooklyn__MegaMart_Austin__MegaMart_San_Jose__MegaMart_Toronto.b983752665"
[0m15:46:52.495550 [debug] [Thread-2 (]: Using databricks connection "test.dbt_anirudh.accepted_values_bronze_store_store_name__MegaMar_Manhattan__MegaMart_Brooklyn__MegaMart_Austin__MegaMart_San_Jose__MegaMart_Toronto.b983752665"
[0m15:46:52.495897 [debug] [Thread-2 (]: On test.dbt_anirudh.accepted_values_bronze_store_store_name__MegaMar_Manhattan__MegaMart_Brooklyn__MegaMart_Austin__MegaMart_San_Jose__MegaMart_Toronto.b983752665: /* {"app": "dbt", "dbt_version": "1.10.10", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_anirudh", "target_name": "dev", "node_id": "test.dbt_anirudh.accepted_values_bronze_store_store_name__MegaMar_Manhattan__MegaMart_Brooklyn__MegaMart_Austin__MegaMart_San_Jose__MegaMart_Toronto.b983752665"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    

with all_values as (

    select
        store_name as value_field,
        count(*) as n_records

    from `dbt_learning`.`bronze`.`bronze_store`
    group by store_name

)

select *
from all_values
where value_field not in (
    'MegaMar Manhattan','MegaMart Brooklyn','MegaMart Austin','MegaMart San Jose','MegaMart Toronto'
)



  
  
      
    ) dbt_internal_test
[0m15:46:52.496205 [debug] [Thread-2 (]: Opening a new connection, currently in state init
[0m15:46:53.610393 [debug] [Thread-2 (]: Databricks adapter: Connection(session-id=01f09153-ef7b-17dc-9e6d-a3110cd52c6f) - Created
[0m15:46:54.295919 [debug] [Thread-2 (]: SQL status: OK in 1.800 seconds
[0m15:46:54.301439 [debug] [Thread-2 (]: Databricks adapter: Cursor(session-id=01f09153-ef7b-17dc-9e6d-a3110cd52c6f, command-id=01f09153-efb1-14af-a73d-8b85801b83b2) - Closing
[0m15:46:54.308655 [debug] [Thread-2 (]: On test.dbt_anirudh.accepted_values_bronze_store_store_name__MegaMar_Manhattan__MegaMart_Brooklyn__MegaMart_Austin__MegaMart_San_Jose__MegaMart_Toronto.b983752665: Close
[0m15:46:54.309728 [debug] [Thread-2 (]: Databricks adapter: Connection(session-id=01f09153-ef7b-17dc-9e6d-a3110cd52c6f) - Closing
[0m15:46:54.601162 [warn ] [Thread-2 (]: 1 of 3 WARN 1 accepted_values_bronze_store_store_name__MegaMar_Manhattan__MegaMart_Brooklyn__MegaMart_Austin__MegaMart_San_Jose__MegaMart_Toronto  [[33mWARN 1[0m in 2.15s]
[0m15:46:54.602834 [debug] [Thread-2 (]: Finished running node test.dbt_anirudh.accepted_values_bronze_store_store_name__MegaMar_Manhattan__MegaMart_Brooklyn__MegaMart_Austin__MegaMart_San_Jose__MegaMart_Toronto.b983752665
[0m15:46:54.603877 [debug] [Thread-2 (]: Began running node test.dbt_anirudh.not_null_bronze_sales_sales_id.e4b1b997fb
[0m15:46:54.604805 [info ] [Thread-2 (]: 2 of 3 START test not_null_bronze_sales_sales_id ............................... [RUN]
[0m15:46:54.606467 [debug] [Thread-2 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=test.dbt_anirudh.not_null_bronze_sales_sales_id.e4b1b997fb) - Creating connection
[0m15:46:54.607574 [debug] [Thread-2 (]: Acquiring new databricks connection 'test.dbt_anirudh.not_null_bronze_sales_sales_id.e4b1b997fb'
[0m15:46:54.608967 [debug] [Thread-2 (]: Began compiling node test.dbt_anirudh.not_null_bronze_sales_sales_id.e4b1b997fb
[0m15:46:54.625011 [debug] [Thread-2 (]: Writing injected SQL for node "test.dbt_anirudh.not_null_bronze_sales_sales_id.e4b1b997fb"
[0m15:46:54.625658 [debug] [Thread-2 (]: Began executing node test.dbt_anirudh.not_null_bronze_sales_sales_id.e4b1b997fb
[0m15:46:54.627944 [debug] [Thread-2 (]: Writing runtime sql for node "test.dbt_anirudh.not_null_bronze_sales_sales_id.e4b1b997fb"
[0m15:46:54.628471 [debug] [Thread-2 (]: Using databricks connection "test.dbt_anirudh.not_null_bronze_sales_sales_id.e4b1b997fb"
[0m15:46:54.628906 [debug] [Thread-2 (]: On test.dbt_anirudh.not_null_bronze_sales_sales_id.e4b1b997fb: /* {"app": "dbt", "dbt_version": "1.10.10", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_anirudh", "target_name": "dev", "node_id": "test.dbt_anirudh.not_null_bronze_sales_sales_id.e4b1b997fb"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select sales_id
from `dbt_learning`.`bronze`.`bronze_sales`
where sales_id is null



  
  
      
    ) dbt_internal_test
[0m15:46:54.629240 [debug] [Thread-2 (]: Opening a new connection, currently in state init
[0m15:46:55.765209 [debug] [Thread-2 (]: Databricks adapter: Connection(session-id=01f09153-f0c1-1f40-b29a-d29923e44aa6) - Created
[0m15:46:56.244865 [debug] [Thread-2 (]: SQL status: OK in 1.620 seconds
[0m15:46:56.249949 [debug] [Thread-2 (]: Databricks adapter: Cursor(session-id=01f09153-f0c1-1f40-b29a-d29923e44aa6, command-id=01f09153-f0ee-1f49-883e-6218b4456e31) - Closing
[0m15:46:56.251430 [debug] [Thread-2 (]: On test.dbt_anirudh.not_null_bronze_sales_sales_id.e4b1b997fb: Close
[0m15:46:56.252246 [debug] [Thread-2 (]: Databricks adapter: Connection(session-id=01f09153-f0c1-1f40-b29a-d29923e44aa6) - Closing
[0m15:46:56.537165 [info ] [Thread-2 (]: 2 of 3 PASS not_null_bronze_sales_sales_id ..................................... [[32mPASS[0m in 1.93s]
[0m15:46:56.538767 [debug] [Thread-2 (]: Finished running node test.dbt_anirudh.not_null_bronze_sales_sales_id.e4b1b997fb
[0m15:46:56.539784 [debug] [Thread-2 (]: Began running node test.dbt_anirudh.unique_bronze_sales_sales_id.3c35aa753d
[0m15:46:56.540716 [info ] [Thread-2 (]: 3 of 3 START test unique_bronze_sales_sales_id ................................. [RUN]
[0m15:46:56.542161 [debug] [Thread-2 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=test.dbt_anirudh.unique_bronze_sales_sales_id.3c35aa753d) - Creating connection
[0m15:46:56.543253 [debug] [Thread-2 (]: Acquiring new databricks connection 'test.dbt_anirudh.unique_bronze_sales_sales_id.3c35aa753d'
[0m15:46:56.544161 [debug] [Thread-2 (]: Began compiling node test.dbt_anirudh.unique_bronze_sales_sales_id.3c35aa753d
[0m15:46:56.556996 [debug] [Thread-2 (]: Writing injected SQL for node "test.dbt_anirudh.unique_bronze_sales_sales_id.3c35aa753d"
[0m15:46:56.557770 [debug] [Thread-2 (]: Began executing node test.dbt_anirudh.unique_bronze_sales_sales_id.3c35aa753d
[0m15:46:56.559896 [debug] [Thread-2 (]: Writing runtime sql for node "test.dbt_anirudh.unique_bronze_sales_sales_id.3c35aa753d"
[0m15:46:56.560319 [debug] [Thread-2 (]: Using databricks connection "test.dbt_anirudh.unique_bronze_sales_sales_id.3c35aa753d"
[0m15:46:56.560676 [debug] [Thread-2 (]: On test.dbt_anirudh.unique_bronze_sales_sales_id.3c35aa753d: /* {"app": "dbt", "dbt_version": "1.10.10", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_anirudh", "target_name": "dev", "node_id": "test.dbt_anirudh.unique_bronze_sales_sales_id.3c35aa753d"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    

select
    sales_id as unique_field,
    count(*) as n_records

from `dbt_learning`.`bronze`.`bronze_sales`
where sales_id is not null
group by sales_id
having count(*) > 1



  
  
      
    ) dbt_internal_test
[0m15:46:56.560952 [debug] [Thread-2 (]: Opening a new connection, currently in state init
[0m15:46:57.635366 [debug] [Thread-2 (]: Databricks adapter: Connection(session-id=01f09153-f1e1-1db7-beeb-004aa198167b) - Created
[0m15:46:58.292393 [debug] [Thread-2 (]: SQL status: OK in 1.730 seconds
[0m15:46:58.296818 [debug] [Thread-2 (]: Databricks adapter: Cursor(session-id=01f09153-f1e1-1db7-beeb-004aa198167b, command-id=01f09153-f20c-1425-8cc6-c9f0ad8ca8de) - Closing
[0m15:46:58.298226 [debug] [Thread-2 (]: On test.dbt_anirudh.unique_bronze_sales_sales_id.3c35aa753d: Close
[0m15:46:58.299168 [debug] [Thread-2 (]: Databricks adapter: Connection(session-id=01f09153-f1e1-1db7-beeb-004aa198167b) - Closing
[0m15:46:58.592351 [info ] [Thread-2 (]: 3 of 3 PASS unique_bronze_sales_sales_id ....................................... [[32mPASS[0m in 2.05s]
[0m15:46:58.593867 [debug] [Thread-2 (]: Finished running node test.dbt_anirudh.unique_bronze_sales_sales_id.3c35aa753d
[0m15:46:58.596221 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=master) - Creating connection
[0m15:46:58.597061 [debug] [MainThread]: Acquiring new databricks connection 'master'
[0m15:46:58.598070 [info ] [MainThread]: 
[0m15:46:58.598909 [info ] [MainThread]: Finished running 3 data tests in 0 hours 0 minutes and 8.36 seconds (8.36s).
[0m15:46:58.602243 [debug] [MainThread]: Command end result
[0m15:46:58.637731 [debug] [MainThread]: Wrote artifact WritableManifest to /home/aniruth/AI/DBT/DBT_Master/dbt_anirudh/target/manifest.json
[0m15:46:58.639179 [debug] [MainThread]: Wrote artifact SemanticManifest to /home/aniruth/AI/DBT/DBT_Master/dbt_anirudh/target/semantic_manifest.json
[0m15:46:58.644009 [debug] [MainThread]: Wrote artifact RunExecutionResult to /home/aniruth/AI/DBT/DBT_Master/dbt_anirudh/target/run_results.json
[0m15:46:58.644312 [info ] [MainThread]: 
[0m15:46:58.644739 [info ] [MainThread]: [33mCompleted with 1 warning:[0m
[0m15:46:58.645052 [info ] [MainThread]: 
[0m15:46:58.645345 [warn ] [MainThread]: [33mWarning in test accepted_values_bronze_store_store_name__MegaMar_Manhattan__MegaMart_Brooklyn__MegaMart_Austin__MegaMart_San_Jose__MegaMart_Toronto (models/bronze/properties.yml)[0m
[0m15:46:58.645628 [warn ] [MainThread]: Got 1 result, configured to warn if != 0
[0m15:46:58.645839 [info ] [MainThread]: 
[0m15:46:58.646097 [info ] [MainThread]:   compiled code at target/compiled/dbt_anirudh/models/bronze/properties.yml/accepted_values_bronze_store_8308937ffa06d226d8f7cff5d272d129.sql
[0m15:46:58.646318 [info ] [MainThread]: 
[0m15:46:58.646621 [info ] [MainThread]: Done. PASS=2 WARN=1 ERROR=0 SKIP=0 NO-OP=0 TOTAL=3
[0m15:46:58.647489 [debug] [MainThread]: Resource report: {"command_name": "test", "command_success": true, "command_wall_clock_time": 9.96936, "process_in_blocks": "81784", "process_kernel_time": 0.213837, "process_mem_max_rss": "245448", "process_out_blocks": "3192", "process_user_time": 3.930012}
[0m15:46:58.647861 [debug] [MainThread]: Command `dbt test` succeeded at 15:46:58.647790 after 9.97 seconds
[0m15:46:58.648145 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2c0e1e2b70>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2c0e1e2f90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2c0e1e3890>]}
[0m15:46:58.648425 [debug] [MainThread]: Flushing usage events
[0m15:46:59.633126 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m16:14:30.631625 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7286610fc8f0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x728661bcb0b0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7286614c9820>]}


============================== 16:14:30.633990 | e126b45c-a319-4fec-a5f4-9b31ca9f8a52 ==============================
[0m16:14:30.633990 [info ] [MainThread]: Running with dbt=1.10.10
[0m16:14:30.634468 [debug] [MainThread]: running dbt with arguments {'debug': 'False', 'static_parser': 'True', 'use_colors': 'True', 'version_check': 'True', 'indirect_selection': 'eager', 'empty': 'None', 'log_path': '/home/aniruth/AI/DBT/DBT_Master/dbt_anirudh/logs', 'log_format': 'default', 'log_cache_events': 'False', 'use_experimental_parser': 'False', 'quiet': 'False', 'invocation_command': 'dbt test', 'partial_parse': 'True', 'write_json': 'True', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'introspect': 'True', 'target_path': 'None', 'printer_width': '80', 'send_anonymous_usage_stats': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'fail_fast': 'False', 'profiles_dir': '/home/aniruth/AI/DBT/DBT_Master/dbt_anirudh', 'no_print': 'None'}
[0m16:14:31.268260 [debug] [MainThread]: Spark adapter: Setting pyhive.hive logging to ERROR
[0m16:14:31.268683 [debug] [MainThread]: Spark adapter: Setting thrift.transport logging to ERROR
[0m16:14:31.268985 [debug] [MainThread]: Spark adapter: Setting thrift.protocol logging to ERROR
[0m16:14:31.815372 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'e126b45c-a319-4fec-a5f4-9b31ca9f8a52', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7286402d5d00>]}
[0m16:14:31.862604 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'e126b45c-a319-4fec-a5f4-9b31ca9f8a52', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x728661a2b5f0>]}
[0m16:14:31.863172 [info ] [MainThread]: Registered adapter: databricks=1.10.9
[0m16:14:31.946870 [debug] [MainThread]: checksum: 502a0dc23e9052e1ae09f7c44ee219ef7a02dfea7e7d66580d54c304c14d553b, vars: {}, profile: , target: , version: 1.10.10
[0m16:14:32.039240 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m16:14:32.039591 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m16:14:32.045142 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 2 unused configuration paths:
- models.dbt_anirudh.silver
- models.dbt_anirudh.gold
[0m16:14:32.095807 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'e126b45c-a319-4fec-a5f4-9b31ca9f8a52', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x72863bd12540>]}
[0m16:14:32.181464 [debug] [MainThread]: Wrote artifact WritableManifest to /home/aniruth/AI/DBT/DBT_Master/dbt_anirudh/target/manifest.json
[0m16:14:32.182927 [debug] [MainThread]: Wrote artifact SemanticManifest to /home/aniruth/AI/DBT/DBT_Master/dbt_anirudh/target/semantic_manifest.json
[0m16:14:32.197230 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'e126b45c-a319-4fec-a5f4-9b31ca9f8a52', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x72863b86c380>]}
[0m16:14:32.197634 [info ] [MainThread]: Found 6 models, 5 data tests, 6 sources, 686 macros
[0m16:14:32.197947 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'e126b45c-a319-4fec-a5f4-9b31ca9f8a52', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x72863b9dfc20>]}
[0m16:14:32.199318 [info ] [MainThread]: 
[0m16:14:32.199628 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m16:14:32.199973 [info ] [MainThread]: 
[0m16:14:32.200411 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=master) - Creating connection
[0m16:14:32.200659 [debug] [MainThread]: Acquiring new databricks connection 'master'
[0m16:14:32.206087 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=list_dbt_learning_bronze) - Creating connection
[0m16:14:32.206542 [debug] [ThreadPool]: Acquiring new databricks connection 'list_dbt_learning_bronze'
[0m16:14:32.217544 [debug] [ThreadPool]: Using databricks connection "list_dbt_learning_bronze"
[0m16:14:32.217955 [debug] [ThreadPool]: On list_dbt_learning_bronze: /* {"app": "dbt", "dbt_version": "1.10.10", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_anirudh", "target_name": "dev", "connection_name": "list_dbt_learning_bronze"} */

    
SELECT
  table_name,
  if(table_type IN ('EXTERNAL', 'MANAGED', 'MANAGED_SHALLOW_CLONE', 'EXTERNAL_SHALLOW_CLONE'), 'table', lower(table_type)) AS table_type,
  lower(data_source_format) AS file_format,
  table_owner,
  if(
    table_type IN (
      'EXTERNAL',
      'MANAGED',
      'MANAGED_SHALLOW_CLONE',
      'EXTERNAL_SHALLOW_CLONE'
    ),
    lower(table_type),
    NULL
  ) AS databricks_table_type
FROM `system`.`information_schema`.`tables`
WHERE table_catalog = 'dbt_learning' 
  AND table_schema = 'bronze'

  
[0m16:14:32.218222 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m16:14:33.389408 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f09157-ccc8-1257-b288-ad578df4aa41) - Created
[0m16:14:35.533852 [debug] [ThreadPool]: SQL status: OK in 3.320 seconds
[0m16:14:35.540238 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01f09157-ccc8-1257-b288-ad578df4aa41, command-id=01f09157-ccf6-1a00-ab7b-7327defa4c13) - Closing
[0m16:14:35.541126 [debug] [ThreadPool]: On list_dbt_learning_bronze: Close
[0m16:14:35.541548 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f09157-ccc8-1257-b288-ad578df4aa41) - Closing
[0m16:14:35.847960 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'e126b45c-a319-4fec-a5f4-9b31ca9f8a52', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x72863bf5bce0>]}
[0m16:14:35.853675 [debug] [Thread-2 (]: Began running node test.dbt_anirudh.accepted_values_bronze_store_store_name__MegaMar_Manhattan__MegaMart_Brooklyn__MegaMart_Austin__MegaMart_San_Jose__MegaMart_Toronto.b983752665
[0m16:14:35.854815 [info ] [Thread-2 (]: 1 of 5 START test accepted_values_bronze_store_store_name__MegaMar_Manhattan__MegaMart_Brooklyn__MegaMart_Austin__MegaMart_San_Jose__MegaMart_Toronto  [RUN]
[0m16:14:35.856253 [debug] [Thread-2 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=test.dbt_anirudh.accepted_values_bronze_store_store_name__MegaMar_Manhattan__MegaMart_Brooklyn__MegaMart_Austin__MegaMart_San_Jose__MegaMart_Toronto.b983752665) - Creating connection
[0m16:14:35.857402 [debug] [Thread-2 (]: Acquiring new databricks connection 'test.dbt_anirudh.accepted_values_bronze_store_store_name__MegaMar_Manhattan__MegaMart_Brooklyn__MegaMart_Austin__MegaMart_San_Jose__MegaMart_Toronto.b983752665'
[0m16:14:35.858424 [debug] [Thread-2 (]: Began compiling node test.dbt_anirudh.accepted_values_bronze_store_store_name__MegaMar_Manhattan__MegaMart_Brooklyn__MegaMart_Austin__MegaMart_San_Jose__MegaMart_Toronto.b983752665
[0m16:14:35.885027 [debug] [Thread-2 (]: Writing injected SQL for node "test.dbt_anirudh.accepted_values_bronze_store_store_name__MegaMar_Manhattan__MegaMart_Brooklyn__MegaMart_Austin__MegaMart_San_Jose__MegaMart_Toronto.b983752665"
[0m16:14:35.885887 [debug] [Thread-2 (]: Began executing node test.dbt_anirudh.accepted_values_bronze_store_store_name__MegaMar_Manhattan__MegaMart_Brooklyn__MegaMart_Austin__MegaMart_San_Jose__MegaMart_Toronto.b983752665
[0m16:14:35.900000 [debug] [Thread-2 (]: Writing runtime sql for node "test.dbt_anirudh.accepted_values_bronze_store_store_name__MegaMar_Manhattan__MegaMart_Brooklyn__MegaMart_Austin__MegaMart_San_Jose__MegaMart_Toronto.b983752665"
[0m16:14:35.900543 [debug] [Thread-2 (]: Using databricks connection "test.dbt_anirudh.accepted_values_bronze_store_store_name__MegaMar_Manhattan__MegaMart_Brooklyn__MegaMart_Austin__MegaMart_San_Jose__MegaMart_Toronto.b983752665"
[0m16:14:35.900927 [debug] [Thread-2 (]: On test.dbt_anirudh.accepted_values_bronze_store_store_name__MegaMar_Manhattan__MegaMart_Brooklyn__MegaMart_Austin__MegaMart_San_Jose__MegaMart_Toronto.b983752665: /* {"app": "dbt", "dbt_version": "1.10.10", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_anirudh", "target_name": "dev", "node_id": "test.dbt_anirudh.accepted_values_bronze_store_store_name__MegaMar_Manhattan__MegaMart_Brooklyn__MegaMart_Austin__MegaMart_San_Jose__MegaMart_Toronto.b983752665"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    

with all_values as (

    select
        store_name as value_field,
        count(*) as n_records

    from `dbt_learning`.`bronze`.`bronze_store`
    group by store_name

)

select *
from all_values
where value_field not in (
    'MegaMar Manhattan','MegaMart Brooklyn','MegaMart Austin','MegaMart San Jose','MegaMart Toronto'
)



  
  
      
    ) dbt_internal_test
[0m16:14:35.901236 [debug] [Thread-2 (]: Opening a new connection, currently in state init
[0m16:14:37.015121 [debug] [Thread-2 (]: Databricks adapter: Connection(session-id=01f09157-cef3-15d7-a9e1-dbfb36553779) - Created
[0m16:14:38.538374 [debug] [Thread-2 (]: SQL status: OK in 2.640 seconds
[0m16:14:38.540237 [debug] [Thread-2 (]: Databricks adapter: Cursor(session-id=01f09157-cef3-15d7-a9e1-dbfb36553779, command-id=01f09157-cf28-1d13-9e68-556a8150dd13) - Closing
[0m16:14:38.542775 [debug] [Thread-2 (]: On test.dbt_anirudh.accepted_values_bronze_store_store_name__MegaMar_Manhattan__MegaMart_Brooklyn__MegaMart_Austin__MegaMart_San_Jose__MegaMart_Toronto.b983752665: Close
[0m16:14:38.543231 [debug] [Thread-2 (]: Databricks adapter: Connection(session-id=01f09157-cef3-15d7-a9e1-dbfb36553779) - Closing
[0m16:14:38.844797 [warn ] [Thread-2 (]: 1 of 5 WARN 1 accepted_values_bronze_store_store_name__MegaMar_Manhattan__MegaMart_Brooklyn__MegaMart_Austin__MegaMart_San_Jose__MegaMart_Toronto  [[33mWARN 1[0m in 2.99s]
[0m16:14:38.846443 [debug] [Thread-2 (]: Finished running node test.dbt_anirudh.accepted_values_bronze_store_store_name__MegaMar_Manhattan__MegaMart_Brooklyn__MegaMart_Austin__MegaMart_San_Jose__MegaMart_Toronto.b983752665
[0m16:14:38.847471 [debug] [Thread-2 (]: Began running node test.dbt_anirudh.non_negartive
[0m16:14:38.848663 [info ] [Thread-2 (]: 2 of 5 START test non_negartive ................................................ [RUN]
[0m16:14:38.850137 [debug] [Thread-2 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=test.dbt_anirudh.non_negartive) - Creating connection
[0m16:14:38.851196 [debug] [Thread-2 (]: Acquiring new databricks connection 'test.dbt_anirudh.non_negartive'
[0m16:14:38.852204 [debug] [Thread-2 (]: Began compiling node test.dbt_anirudh.non_negartive
[0m16:14:38.860874 [debug] [Thread-2 (]: Writing injected SQL for node "test.dbt_anirudh.non_negartive"
[0m16:14:38.861755 [debug] [Thread-2 (]: Began executing node test.dbt_anirudh.non_negartive
[0m16:14:38.864629 [debug] [Thread-2 (]: Writing runtime sql for node "test.dbt_anirudh.non_negartive"
[0m16:14:38.865180 [debug] [Thread-2 (]: Using databricks connection "test.dbt_anirudh.non_negartive"
[0m16:14:38.865579 [debug] [Thread-2 (]: On test.dbt_anirudh.non_negartive: /* {"app": "dbt", "dbt_version": "1.10.10", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_anirudh", "target_name": "dev", "node_id": "test.dbt_anirudh.non_negartive"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  SELECT
    *
FROM
    `dbt_learning`.`bronze`.`bronze_sales`
WHERE
    gross_amount < 0 AND net_amount < 0
  
  
      
    ) dbt_internal_test
[0m16:14:38.865955 [debug] [Thread-2 (]: Opening a new connection, currently in state init
[0m16:14:39.998671 [debug] [Thread-2 (]: Databricks adapter: Connection(session-id=01f09157-d0b8-1bf6-bb87-055b7a6fe803) - Created
[0m16:14:41.072616 [debug] [Thread-2 (]: SQL status: OK in 2.210 seconds
[0m16:14:41.077432 [debug] [Thread-2 (]: Databricks adapter: Cursor(session-id=01f09157-d0b8-1bf6-bb87-055b7a6fe803, command-id=01f09157-d0e6-1ac1-9bd7-5f46d4cf3067) - Closing
[0m16:14:41.078981 [debug] [Thread-2 (]: On test.dbt_anirudh.non_negartive: Close
[0m16:14:41.079966 [debug] [Thread-2 (]: Databricks adapter: Connection(session-id=01f09157-d0b8-1bf6-bb87-055b7a6fe803) - Closing
[0m16:14:41.390840 [info ] [Thread-2 (]: 2 of 5 PASS non_negartive ...................................................... [[32mPASS[0m in 2.54s]
[0m16:14:41.391472 [debug] [Thread-2 (]: Finished running node test.dbt_anirudh.non_negartive
[0m16:14:41.391888 [debug] [Thread-2 (]: Began running node test.dbt_anirudh.non_negative
[0m16:14:41.392287 [info ] [Thread-2 (]: 3 of 5 START test non_negative ................................................. [RUN]
[0m16:14:41.392794 [debug] [Thread-2 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=test.dbt_anirudh.non_negative) - Creating connection
[0m16:14:41.393101 [debug] [Thread-2 (]: Acquiring new databricks connection 'test.dbt_anirudh.non_negative'
[0m16:14:41.393378 [debug] [Thread-2 (]: Began compiling node test.dbt_anirudh.non_negative
[0m16:14:41.397322 [debug] [Thread-2 (]: Writing injected SQL for node "test.dbt_anirudh.non_negative"
[0m16:14:41.397951 [debug] [Thread-2 (]: Began executing node test.dbt_anirudh.non_negative
[0m16:14:41.400182 [debug] [Thread-2 (]: Writing runtime sql for node "test.dbt_anirudh.non_negative"
[0m16:14:41.400645 [debug] [Thread-2 (]: Using databricks connection "test.dbt_anirudh.non_negative"
[0m16:14:41.400995 [debug] [Thread-2 (]: On test.dbt_anirudh.non_negative: /* {"app": "dbt", "dbt_version": "1.10.10", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_anirudh", "target_name": "dev", "node_id": "test.dbt_anirudh.non_negative"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  SELECT
    *
FROM
    `dbt_learning`.`bronze`.`bronze_sales`
  
  
      
    ) dbt_internal_test
[0m16:14:41.401288 [debug] [Thread-2 (]: Opening a new connection, currently in state init
[0m16:14:42.532583 [debug] [Thread-2 (]: Databricks adapter: Connection(session-id=01f09157-d23b-158e-ad0f-13e221bbaf14) - Created
[0m16:14:43.696160 [debug] [Thread-2 (]: SQL status: OK in 2.290 seconds
[0m16:14:43.700179 [debug] [Thread-2 (]: Databricks adapter: Cursor(session-id=01f09157-d23b-158e-ad0f-13e221bbaf14, command-id=01f09157-d269-1e86-b837-9c16f6dd2bd5) - Closing
[0m16:14:43.701410 [debug] [Thread-2 (]: On test.dbt_anirudh.non_negative: Close
[0m16:14:43.702074 [debug] [Thread-2 (]: Databricks adapter: Connection(session-id=01f09157-d23b-158e-ad0f-13e221bbaf14) - Closing
[0m16:14:44.006021 [error] [Thread-2 (]: 3 of 5 FAIL 7173 non_negative .................................................. [[31mFAIL 7173[0m in 2.61s]
[0m16:14:44.007860 [debug] [Thread-2 (]: Finished running node test.dbt_anirudh.non_negative
[0m16:14:44.008955 [debug] [Thread-2 (]: Began running node test.dbt_anirudh.not_null_bronze_sales_sales_id.e4b1b997fb
[0m16:14:44.010183 [info ] [Thread-2 (]: 4 of 5 START test not_null_bronze_sales_sales_id ............................... [RUN]
[0m16:14:44.011793 [debug] [Thread-2 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=test.dbt_anirudh.not_null_bronze_sales_sales_id.e4b1b997fb) - Creating connection
[0m16:14:44.012939 [debug] [Thread-2 (]: Acquiring new databricks connection 'test.dbt_anirudh.not_null_bronze_sales_sales_id.e4b1b997fb'
[0m16:14:44.014332 [debug] [Thread-2 (]: Began compiling node test.dbt_anirudh.not_null_bronze_sales_sales_id.e4b1b997fb
[0m16:14:44.029852 [debug] [Thread-2 (]: Writing injected SQL for node "test.dbt_anirudh.not_null_bronze_sales_sales_id.e4b1b997fb"
[0m16:14:44.030816 [debug] [Thread-2 (]: Began executing node test.dbt_anirudh.not_null_bronze_sales_sales_id.e4b1b997fb
[0m16:14:44.033578 [debug] [Thread-2 (]: Writing runtime sql for node "test.dbt_anirudh.not_null_bronze_sales_sales_id.e4b1b997fb"
[0m16:14:44.034064 [debug] [Thread-2 (]: Using databricks connection "test.dbt_anirudh.not_null_bronze_sales_sales_id.e4b1b997fb"
[0m16:14:44.034397 [debug] [Thread-2 (]: On test.dbt_anirudh.not_null_bronze_sales_sales_id.e4b1b997fb: /* {"app": "dbt", "dbt_version": "1.10.10", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_anirudh", "target_name": "dev", "node_id": "test.dbt_anirudh.not_null_bronze_sales_sales_id.e4b1b997fb"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select sales_id
from `dbt_learning`.`bronze`.`bronze_sales`
where sales_id is null



  
  
      
    ) dbt_internal_test
[0m16:14:44.034688 [debug] [Thread-2 (]: Opening a new connection, currently in state init
[0m16:14:45.181076 [debug] [Thread-2 (]: Databricks adapter: Connection(session-id=01f09157-d3cf-1eca-ae6d-488bba226e37) - Created
[0m16:14:46.074260 [debug] [Thread-2 (]: SQL status: OK in 2.040 seconds
[0m16:14:46.079023 [debug] [Thread-2 (]: Databricks adapter: Cursor(session-id=01f09157-d3cf-1eca-ae6d-488bba226e37, command-id=01f09157-d3fc-191d-a77a-51c7a7f24a25) - Closing
[0m16:14:46.080759 [debug] [Thread-2 (]: On test.dbt_anirudh.not_null_bronze_sales_sales_id.e4b1b997fb: Close
[0m16:14:46.081831 [debug] [Thread-2 (]: Databricks adapter: Connection(session-id=01f09157-d3cf-1eca-ae6d-488bba226e37) - Closing
[0m16:14:46.386754 [info ] [Thread-2 (]: 4 of 5 PASS not_null_bronze_sales_sales_id ..................................... [[32mPASS[0m in 2.37s]
[0m16:14:46.388437 [debug] [Thread-2 (]: Finished running node test.dbt_anirudh.not_null_bronze_sales_sales_id.e4b1b997fb
[0m16:14:46.389501 [debug] [Thread-2 (]: Began running node test.dbt_anirudh.unique_bronze_sales_sales_id.3c35aa753d
[0m16:14:46.390618 [info ] [Thread-2 (]: 5 of 5 START test unique_bronze_sales_sales_id ................................. [RUN]
[0m16:14:46.391923 [debug] [Thread-2 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=test.dbt_anirudh.unique_bronze_sales_sales_id.3c35aa753d) - Creating connection
[0m16:14:46.392906 [debug] [Thread-2 (]: Acquiring new databricks connection 'test.dbt_anirudh.unique_bronze_sales_sales_id.3c35aa753d'
[0m16:14:46.393815 [debug] [Thread-2 (]: Began compiling node test.dbt_anirudh.unique_bronze_sales_sales_id.3c35aa753d
[0m16:14:46.406678 [debug] [Thread-2 (]: Writing injected SQL for node "test.dbt_anirudh.unique_bronze_sales_sales_id.3c35aa753d"
[0m16:14:46.407396 [debug] [Thread-2 (]: Began executing node test.dbt_anirudh.unique_bronze_sales_sales_id.3c35aa753d
[0m16:14:46.409563 [debug] [Thread-2 (]: Writing runtime sql for node "test.dbt_anirudh.unique_bronze_sales_sales_id.3c35aa753d"
[0m16:14:46.410016 [debug] [Thread-2 (]: Using databricks connection "test.dbt_anirudh.unique_bronze_sales_sales_id.3c35aa753d"
[0m16:14:46.410329 [debug] [Thread-2 (]: On test.dbt_anirudh.unique_bronze_sales_sales_id.3c35aa753d: /* {"app": "dbt", "dbt_version": "1.10.10", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_anirudh", "target_name": "dev", "node_id": "test.dbt_anirudh.unique_bronze_sales_sales_id.3c35aa753d"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    

select
    sales_id as unique_field,
    count(*) as n_records

from `dbt_learning`.`bronze`.`bronze_sales`
where sales_id is not null
group by sales_id
having count(*) > 1



  
  
      
    ) dbt_internal_test
[0m16:14:46.410625 [debug] [Thread-2 (]: Opening a new connection, currently in state init
[0m16:14:47.522396 [debug] [Thread-2 (]: Databricks adapter: Connection(session-id=01f09157-d537-1a4d-86fa-36c2b5f6828f) - Created
[0m16:14:48.347878 [debug] [Thread-2 (]: SQL status: OK in 1.940 seconds
[0m16:14:48.352422 [debug] [Thread-2 (]: Databricks adapter: Cursor(session-id=01f09157-d537-1a4d-86fa-36c2b5f6828f, command-id=01f09157-d563-1cbe-9483-686d4c7bf99d) - Closing
[0m16:14:48.353712 [debug] [Thread-2 (]: On test.dbt_anirudh.unique_bronze_sales_sales_id.3c35aa753d: Close
[0m16:14:48.354269 [debug] [Thread-2 (]: Databricks adapter: Connection(session-id=01f09157-d537-1a4d-86fa-36c2b5f6828f) - Closing
[0m16:14:48.661950 [info ] [Thread-2 (]: 5 of 5 PASS unique_bronze_sales_sales_id ....................................... [[32mPASS[0m in 2.27s]
[0m16:14:48.662567 [debug] [Thread-2 (]: Finished running node test.dbt_anirudh.unique_bronze_sales_sales_id.3c35aa753d
[0m16:14:48.663681 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=master) - Creating connection
[0m16:14:48.664145 [debug] [MainThread]: Acquiring new databricks connection 'master'
[0m16:14:48.664687 [info ] [MainThread]: 
[0m16:14:48.665098 [info ] [MainThread]: Finished running 5 data tests in 0 hours 0 minutes and 16.46 seconds (16.46s).
[0m16:14:48.666277 [debug] [MainThread]: Command end result
[0m16:14:48.785387 [debug] [MainThread]: Wrote artifact WritableManifest to /home/aniruth/AI/DBT/DBT_Master/dbt_anirudh/target/manifest.json
[0m16:14:48.786990 [debug] [MainThread]: Wrote artifact SemanticManifest to /home/aniruth/AI/DBT/DBT_Master/dbt_anirudh/target/semantic_manifest.json
[0m16:14:48.793374 [debug] [MainThread]: Wrote artifact RunExecutionResult to /home/aniruth/AI/DBT/DBT_Master/dbt_anirudh/target/run_results.json
[0m16:14:48.793749 [info ] [MainThread]: 
[0m16:14:48.794068 [info ] [MainThread]: [31mCompleted with 1 error, 0 partial successes, and 1 warning:[0m
[0m16:14:48.794343 [info ] [MainThread]: 
[0m16:14:48.794676 [error] [MainThread]: [31mFailure in test non_negative (tests/non_negative.sql)[0m
[0m16:14:48.794992 [error] [MainThread]:   Got 7173 results, configured to fail if != 0
[0m16:14:48.795235 [info ] [MainThread]: 
[0m16:14:48.795600 [info ] [MainThread]:   compiled code at target/compiled/dbt_anirudh/tests/non_negative.sql
[0m16:14:48.795867 [info ] [MainThread]: 
[0m16:14:48.796185 [warn ] [MainThread]: [33mWarning in test accepted_values_bronze_store_store_name__MegaMar_Manhattan__MegaMart_Brooklyn__MegaMart_Austin__MegaMart_San_Jose__MegaMart_Toronto (models/bronze/properties.yml)[0m
[0m16:14:48.796483 [warn ] [MainThread]: Got 1 result, configured to warn if != 0
[0m16:14:48.796738 [info ] [MainThread]: 
[0m16:14:48.797059 [info ] [MainThread]:   compiled code at target/compiled/dbt_anirudh/models/bronze/properties.yml/accepted_values_bronze_store_8308937ffa06d226d8f7cff5d272d129.sql
[0m16:14:48.797304 [info ] [MainThread]: 
[0m16:14:48.797595 [info ] [MainThread]: Done. PASS=3 WARN=1 ERROR=1 SKIP=0 NO-OP=0 TOTAL=5
[0m16:14:48.798329 [debug] [MainThread]: Resource report: {"command_name": "test", "command_success": false, "command_wall_clock_time": 18.21198, "process_in_blocks": "1952", "process_kernel_time": 0.185437, "process_mem_max_rss": "245524", "process_out_blocks": "3240", "process_user_time": 4.268047}
[0m16:14:48.798777 [debug] [MainThread]: Command `dbt test` failed at 16:14:48.798696 after 18.21 seconds
[0m16:14:48.799170 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7286614a7920>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7286611b5820>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x728638732600>]}
[0m16:14:48.799521 [debug] [MainThread]: Flushing usage events
[0m16:14:49.820877 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m16:19:29.732791 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7b3938ea6b70>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7b393938eb40>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7b39397ea2a0>]}


============================== 16:19:29.735250 | bee41140-5edb-43f5-9761-e6e10c3f1ace ==============================
[0m16:19:29.735250 [info ] [MainThread]: Running with dbt=1.10.10
[0m16:19:29.735720 [debug] [MainThread]: running dbt with arguments {'use_colors': 'True', 'no_print': 'None', 'target_path': 'None', 'introspect': 'True', 'log_cache_events': 'False', 'write_json': 'True', 'invocation_command': 'dbt test', 'send_anonymous_usage_stats': 'True', 'profiles_dir': '/home/aniruth/AI/DBT/DBT_Master/dbt_anirudh', 'indirect_selection': 'eager', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'debug': 'False', 'use_experimental_parser': 'False', 'printer_width': '80', 'warn_error': 'None', 'fail_fast': 'False', 'empty': 'None', 'log_format': 'default', 'log_path': '/home/aniruth/AI/DBT/DBT_Master/dbt_anirudh/logs', 'version_check': 'True', 'quiet': 'False', 'static_parser': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False'}
[0m16:19:30.364229 [debug] [MainThread]: Spark adapter: Setting pyhive.hive logging to ERROR
[0m16:19:30.364687 [debug] [MainThread]: Spark adapter: Setting thrift.transport logging to ERROR
[0m16:19:30.364971 [debug] [MainThread]: Spark adapter: Setting thrift.protocol logging to ERROR
[0m16:19:30.883973 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'bee41140-5edb-43f5-9761-e6e10c3f1ace', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7b3913c72180>]}
[0m16:19:30.933996 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'bee41140-5edb-43f5-9761-e6e10c3f1ace', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7b3913d38470>]}
[0m16:19:30.934574 [info ] [MainThread]: Registered adapter: databricks=1.10.9
[0m16:19:31.017317 [debug] [MainThread]: checksum: 502a0dc23e9052e1ae09f7c44ee219ef7a02dfea7e7d66580d54c304c14d553b, vars: {}, profile: , target: , version: 1.10.10
[0m16:19:31.113022 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m16:19:31.113394 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m16:19:31.119381 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 2 unused configuration paths:
- models.dbt_anirudh.silver
- models.dbt_anirudh.gold
[0m16:19:31.161179 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'bee41140-5edb-43f5-9761-e6e10c3f1ace', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7b3913bf1580>]}
[0m16:19:31.244787 [debug] [MainThread]: Wrote artifact WritableManifest to /home/aniruth/AI/DBT/DBT_Master/dbt_anirudh/target/manifest.json
[0m16:19:31.246253 [debug] [MainThread]: Wrote artifact SemanticManifest to /home/aniruth/AI/DBT/DBT_Master/dbt_anirudh/target/semantic_manifest.json
[0m16:19:31.259673 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'bee41140-5edb-43f5-9761-e6e10c3f1ace', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7b3913544650>]}
[0m16:19:31.260198 [info ] [MainThread]: Found 6 models, 5 data tests, 6 sources, 686 macros
[0m16:19:31.260574 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'bee41140-5edb-43f5-9761-e6e10c3f1ace', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7b3913626660>]}
[0m16:19:31.262148 [info ] [MainThread]: 
[0m16:19:31.262474 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m16:19:31.262744 [info ] [MainThread]: 
[0m16:19:31.263161 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=master) - Creating connection
[0m16:19:31.263403 [debug] [MainThread]: Acquiring new databricks connection 'master'
[0m16:19:31.268871 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=list_dbt_learning_bronze) - Creating connection
[0m16:19:31.269292 [debug] [ThreadPool]: Acquiring new databricks connection 'list_dbt_learning_bronze'
[0m16:19:31.282422 [debug] [ThreadPool]: Using databricks connection "list_dbt_learning_bronze"
[0m16:19:31.282849 [debug] [ThreadPool]: On list_dbt_learning_bronze: /* {"app": "dbt", "dbt_version": "1.10.10", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_anirudh", "target_name": "dev", "connection_name": "list_dbt_learning_bronze"} */

    
SELECT
  table_name,
  if(table_type IN ('EXTERNAL', 'MANAGED', 'MANAGED_SHALLOW_CLONE', 'EXTERNAL_SHALLOW_CLONE'), 'table', lower(table_type)) AS table_type,
  lower(data_source_format) AS file_format,
  table_owner,
  if(
    table_type IN (
      'EXTERNAL',
      'MANAGED',
      'MANAGED_SHALLOW_CLONE',
      'EXTERNAL_SHALLOW_CLONE'
    ),
    lower(table_type),
    NULL
  ) AS databricks_table_type
FROM `system`.`information_schema`.`tables`
WHERE table_catalog = 'dbt_learning' 
  AND table_schema = 'bronze'

  
[0m16:19:31.283127 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m16:19:32.422015 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f09158-7f05-1eae-9b13-a48005150dfe) - Created
[0m16:19:33.132832 [debug] [ThreadPool]: SQL status: OK in 1.850 seconds
[0m16:19:33.141172 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01f09158-7f05-1eae-9b13-a48005150dfe, command-id=01f09158-7f39-1a66-9e97-b0322bdad3e7) - Closing
[0m16:19:33.142277 [debug] [ThreadPool]: On list_dbt_learning_bronze: Close
[0m16:19:33.142877 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f09158-7f05-1eae-9b13-a48005150dfe) - Closing
[0m16:19:33.444088 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'bee41140-5edb-43f5-9761-e6e10c3f1ace', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7b391368b9e0>]}
[0m16:19:33.448948 [debug] [Thread-2 (]: Began running node test.dbt_anirudh.accepted_values_bronze_store_store_name__MegaMar_Manhattan__MegaMart_Brooklyn__MegaMart_Austin__MegaMart_San_Jose__MegaMart_Toronto.b983752665
[0m16:19:33.449891 [info ] [Thread-2 (]: 1 of 5 START test accepted_values_bronze_store_store_name__MegaMar_Manhattan__MegaMart_Brooklyn__MegaMart_Austin__MegaMart_San_Jose__MegaMart_Toronto  [RUN]
[0m16:19:33.451184 [debug] [Thread-2 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=test.dbt_anirudh.accepted_values_bronze_store_store_name__MegaMar_Manhattan__MegaMart_Brooklyn__MegaMart_Austin__MegaMart_San_Jose__MegaMart_Toronto.b983752665) - Creating connection
[0m16:19:33.452046 [debug] [Thread-2 (]: Acquiring new databricks connection 'test.dbt_anirudh.accepted_values_bronze_store_store_name__MegaMar_Manhattan__MegaMart_Brooklyn__MegaMart_Austin__MegaMart_San_Jose__MegaMart_Toronto.b983752665'
[0m16:19:33.452821 [debug] [Thread-2 (]: Began compiling node test.dbt_anirudh.accepted_values_bronze_store_store_name__MegaMar_Manhattan__MegaMart_Brooklyn__MegaMart_Austin__MegaMart_San_Jose__MegaMart_Toronto.b983752665
[0m16:19:33.478652 [debug] [Thread-2 (]: Writing injected SQL for node "test.dbt_anirudh.accepted_values_bronze_store_store_name__MegaMar_Manhattan__MegaMart_Brooklyn__MegaMart_Austin__MegaMart_San_Jose__MegaMart_Toronto.b983752665"
[0m16:19:33.479436 [debug] [Thread-2 (]: Began executing node test.dbt_anirudh.accepted_values_bronze_store_store_name__MegaMar_Manhattan__MegaMart_Brooklyn__MegaMart_Austin__MegaMart_San_Jose__MegaMart_Toronto.b983752665
[0m16:19:33.494183 [debug] [Thread-2 (]: Writing runtime sql for node "test.dbt_anirudh.accepted_values_bronze_store_store_name__MegaMar_Manhattan__MegaMart_Brooklyn__MegaMart_Austin__MegaMart_San_Jose__MegaMart_Toronto.b983752665"
[0m16:19:33.494745 [debug] [Thread-2 (]: Using databricks connection "test.dbt_anirudh.accepted_values_bronze_store_store_name__MegaMar_Manhattan__MegaMart_Brooklyn__MegaMart_Austin__MegaMart_San_Jose__MegaMart_Toronto.b983752665"
[0m16:19:33.495116 [debug] [Thread-2 (]: On test.dbt_anirudh.accepted_values_bronze_store_store_name__MegaMar_Manhattan__MegaMart_Brooklyn__MegaMart_Austin__MegaMart_San_Jose__MegaMart_Toronto.b983752665: /* {"app": "dbt", "dbt_version": "1.10.10", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_anirudh", "target_name": "dev", "node_id": "test.dbt_anirudh.accepted_values_bronze_store_store_name__MegaMar_Manhattan__MegaMart_Brooklyn__MegaMart_Austin__MegaMart_San_Jose__MegaMart_Toronto.b983752665"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    

with all_values as (

    select
        store_name as value_field,
        count(*) as n_records

    from `dbt_learning`.`bronze`.`bronze_store`
    group by store_name

)

select *
from all_values
where value_field not in (
    'MegaMar Manhattan','MegaMart Brooklyn','MegaMart Austin','MegaMart San Jose','MegaMart Toronto'
)



  
  
      
    ) dbt_internal_test
[0m16:19:33.495404 [debug] [Thread-2 (]: Opening a new connection, currently in state init
[0m16:19:34.559645 [debug] [Thread-2 (]: Databricks adapter: Connection(session-id=01f09158-804e-1785-9972-19ea6bbb268e) - Created
[0m16:19:35.125752 [debug] [Thread-2 (]: SQL status: OK in 1.630 seconds
[0m16:19:35.130385 [debug] [Thread-2 (]: Databricks adapter: Cursor(session-id=01f09158-804e-1785-9972-19ea6bbb268e, command-id=01f09158-8078-1a94-a3b9-330fe0cdfdd3) - Closing
[0m16:19:35.134838 [debug] [Thread-2 (]: On test.dbt_anirudh.accepted_values_bronze_store_store_name__MegaMar_Manhattan__MegaMart_Brooklyn__MegaMart_Austin__MegaMart_San_Jose__MegaMart_Toronto.b983752665: Close
[0m16:19:35.135249 [debug] [Thread-2 (]: Databricks adapter: Connection(session-id=01f09158-804e-1785-9972-19ea6bbb268e) - Closing
[0m16:19:35.425614 [warn ] [Thread-2 (]: 1 of 5 WARN 1 accepted_values_bronze_store_store_name__MegaMar_Manhattan__MegaMart_Brooklyn__MegaMart_Austin__MegaMart_San_Jose__MegaMart_Toronto  [[33mWARN 1[0m in 1.97s]
[0m16:19:35.427157 [debug] [Thread-2 (]: Finished running node test.dbt_anirudh.accepted_values_bronze_store_store_name__MegaMar_Manhattan__MegaMart_Brooklyn__MegaMart_Austin__MegaMart_San_Jose__MegaMart_Toronto.b983752665
[0m16:19:35.428193 [debug] [Thread-2 (]: Began running node test.dbt_anirudh.non_negartive
[0m16:19:35.429078 [info ] [Thread-2 (]: 2 of 5 START test non_negartive ................................................ [RUN]
[0m16:19:35.430706 [debug] [Thread-2 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=test.dbt_anirudh.non_negartive) - Creating connection
[0m16:19:35.431682 [debug] [Thread-2 (]: Acquiring new databricks connection 'test.dbt_anirudh.non_negartive'
[0m16:19:35.432495 [debug] [Thread-2 (]: Began compiling node test.dbt_anirudh.non_negartive
[0m16:19:35.439026 [debug] [Thread-2 (]: Writing injected SQL for node "test.dbt_anirudh.non_negartive"
[0m16:19:35.439684 [debug] [Thread-2 (]: Began executing node test.dbt_anirudh.non_negartive
[0m16:19:35.441856 [debug] [Thread-2 (]: Writing runtime sql for node "test.dbt_anirudh.non_negartive"
[0m16:19:35.442459 [debug] [Thread-2 (]: Using databricks connection "test.dbt_anirudh.non_negartive"
[0m16:19:35.442853 [debug] [Thread-2 (]: On test.dbt_anirudh.non_negartive: /* {"app": "dbt", "dbt_version": "1.10.10", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_anirudh", "target_name": "dev", "node_id": "test.dbt_anirudh.non_negartive"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  SELECT
    *
FROM
    `dbt_learning`.`bronze`.`bronze_sales`
WHERE
    gross_amount < 0 AND net_amount < 0
  
  
      
    ) dbt_internal_test
[0m16:19:35.443131 [debug] [Thread-2 (]: Opening a new connection, currently in state init
[0m16:19:36.558258 [debug] [Thread-2 (]: Databricks adapter: Connection(session-id=01f09158-817f-1238-9e3b-f9b56d3f5cc8) - Created
[0m16:19:37.066518 [debug] [Thread-2 (]: SQL status: OK in 1.620 seconds
[0m16:19:37.071152 [debug] [Thread-2 (]: Databricks adapter: Cursor(session-id=01f09158-817f-1238-9e3b-f9b56d3f5cc8, command-id=01f09158-81aa-15ca-9b00-3912fef3e4ca) - Closing
[0m16:19:37.073818 [debug] [Thread-2 (]: On test.dbt_anirudh.non_negartive: Close
[0m16:19:37.075095 [debug] [Thread-2 (]: Databricks adapter: Connection(session-id=01f09158-817f-1238-9e3b-f9b56d3f5cc8) - Closing
[0m16:19:37.376418 [info ] [Thread-2 (]: 2 of 5 PASS non_negartive ...................................................... [[32mPASS[0m in 1.95s]
[0m16:19:37.377945 [debug] [Thread-2 (]: Finished running node test.dbt_anirudh.non_negartive
[0m16:19:37.379448 [debug] [Thread-2 (]: Began running node test.dbt_anirudh.non_negative
[0m16:19:37.381293 [info ] [Thread-2 (]: 3 of 5 START test non_negative ................................................. [RUN]
[0m16:19:37.382510 [debug] [Thread-2 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=test.dbt_anirudh.non_negative) - Creating connection
[0m16:19:37.383497 [debug] [Thread-2 (]: Acquiring new databricks connection 'test.dbt_anirudh.non_negative'
[0m16:19:37.384205 [debug] [Thread-2 (]: Began compiling node test.dbt_anirudh.non_negative
[0m16:19:37.389127 [debug] [Thread-2 (]: Writing injected SQL for node "test.dbt_anirudh.non_negative"
[0m16:19:37.389901 [debug] [Thread-2 (]: Began executing node test.dbt_anirudh.non_negative
[0m16:19:37.392069 [debug] [Thread-2 (]: Writing runtime sql for node "test.dbt_anirudh.non_negative"
[0m16:19:37.392571 [debug] [Thread-2 (]: Using databricks connection "test.dbt_anirudh.non_negative"
[0m16:19:37.392926 [debug] [Thread-2 (]: On test.dbt_anirudh.non_negative: /* {"app": "dbt", "dbt_version": "1.10.10", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_anirudh", "target_name": "dev", "node_id": "test.dbt_anirudh.non_negative"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  SELECT
    *
FROM
    `dbt_learning`.`bronze`.`bronze_sales`
  
  
      
    ) dbt_internal_test
[0m16:19:37.393224 [debug] [Thread-2 (]: Opening a new connection, currently in state init
[0m16:19:38.517850 [debug] [Thread-2 (]: Databricks adapter: Connection(session-id=01f09158-82a9-11de-87f0-6d3fa5d922ce) - Created
[0m16:19:39.150796 [debug] [Thread-2 (]: SQL status: OK in 1.760 seconds
[0m16:19:39.154095 [debug] [Thread-2 (]: Databricks adapter: Cursor(session-id=01f09158-82a9-11de-87f0-6d3fa5d922ce, command-id=01f09158-82d5-174a-8495-81c5272f496b) - Closing
[0m16:19:39.155285 [debug] [Thread-2 (]: On test.dbt_anirudh.non_negative: Close
[0m16:19:39.155955 [debug] [Thread-2 (]: Databricks adapter: Connection(session-id=01f09158-82a9-11de-87f0-6d3fa5d922ce) - Closing
[0m16:19:39.459277 [error] [Thread-2 (]: 3 of 5 FAIL 7173 non_negative .................................................. [[31mFAIL 7173[0m in 2.08s]
[0m16:19:39.461051 [debug] [Thread-2 (]: Finished running node test.dbt_anirudh.non_negative
[0m16:19:39.462073 [debug] [Thread-2 (]: Began running node test.dbt_anirudh.not_null_bronze_sales_sales_id.e4b1b997fb
[0m16:19:39.463069 [info ] [Thread-2 (]: 4 of 5 START test not_null_bronze_sales_sales_id ............................... [RUN]
[0m16:19:39.464253 [debug] [Thread-2 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=test.dbt_anirudh.not_null_bronze_sales_sales_id.e4b1b997fb) - Creating connection
[0m16:19:39.465006 [debug] [Thread-2 (]: Acquiring new databricks connection 'test.dbt_anirudh.not_null_bronze_sales_sales_id.e4b1b997fb'
[0m16:19:39.465774 [debug] [Thread-2 (]: Began compiling node test.dbt_anirudh.not_null_bronze_sales_sales_id.e4b1b997fb
[0m16:19:39.475801 [debug] [Thread-2 (]: Writing injected SQL for node "test.dbt_anirudh.not_null_bronze_sales_sales_id.e4b1b997fb"
[0m16:19:39.476376 [debug] [Thread-2 (]: Began executing node test.dbt_anirudh.not_null_bronze_sales_sales_id.e4b1b997fb
[0m16:19:39.478412 [debug] [Thread-2 (]: Writing runtime sql for node "test.dbt_anirudh.not_null_bronze_sales_sales_id.e4b1b997fb"
[0m16:19:39.478914 [debug] [Thread-2 (]: Using databricks connection "test.dbt_anirudh.not_null_bronze_sales_sales_id.e4b1b997fb"
[0m16:19:39.479245 [debug] [Thread-2 (]: On test.dbt_anirudh.not_null_bronze_sales_sales_id.e4b1b997fb: /* {"app": "dbt", "dbt_version": "1.10.10", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_anirudh", "target_name": "dev", "node_id": "test.dbt_anirudh.not_null_bronze_sales_sales_id.e4b1b997fb"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select sales_id
from `dbt_learning`.`bronze`.`bronze_sales`
where sales_id is null



  
  
      
    ) dbt_internal_test
[0m16:19:39.479519 [debug] [Thread-2 (]: Opening a new connection, currently in state init
[0m16:19:40.558789 [debug] [Thread-2 (]: Databricks adapter: Connection(session-id=01f09158-83e1-166d-8c05-5b6ba1adab6a) - Created
[0m16:19:41.073978 [debug] [Thread-2 (]: SQL status: OK in 1.590 seconds
[0m16:19:41.078313 [debug] [Thread-2 (]: Databricks adapter: Cursor(session-id=01f09158-83e1-166d-8c05-5b6ba1adab6a, command-id=01f09158-840b-17b5-9453-dd3d5eba5a7a) - Closing
[0m16:19:41.079811 [debug] [Thread-2 (]: On test.dbt_anirudh.not_null_bronze_sales_sales_id.e4b1b997fb: Close
[0m16:19:41.080770 [debug] [Thread-2 (]: Databricks adapter: Connection(session-id=01f09158-83e1-166d-8c05-5b6ba1adab6a) - Closing
[0m16:19:41.387398 [info ] [Thread-2 (]: 4 of 5 PASS not_null_bronze_sales_sales_id ..................................... [[32mPASS[0m in 1.92s]
[0m16:19:41.389386 [debug] [Thread-2 (]: Finished running node test.dbt_anirudh.not_null_bronze_sales_sales_id.e4b1b997fb
[0m16:19:41.390406 [debug] [Thread-2 (]: Began running node test.dbt_anirudh.unique_bronze_sales_sales_id.3c35aa753d
[0m16:19:41.391330 [info ] [Thread-2 (]: 5 of 5 START test unique_bronze_sales_sales_id ................................. [RUN]
[0m16:19:41.392562 [debug] [Thread-2 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=test.dbt_anirudh.unique_bronze_sales_sales_id.3c35aa753d) - Creating connection
[0m16:19:41.393237 [debug] [Thread-2 (]: Acquiring new databricks connection 'test.dbt_anirudh.unique_bronze_sales_sales_id.3c35aa753d'
[0m16:19:41.394096 [debug] [Thread-2 (]: Began compiling node test.dbt_anirudh.unique_bronze_sales_sales_id.3c35aa753d
[0m16:19:41.415034 [debug] [Thread-2 (]: Writing injected SQL for node "test.dbt_anirudh.unique_bronze_sales_sales_id.3c35aa753d"
[0m16:19:41.416406 [debug] [Thread-2 (]: Began executing node test.dbt_anirudh.unique_bronze_sales_sales_id.3c35aa753d
[0m16:19:41.420140 [debug] [Thread-2 (]: Writing runtime sql for node "test.dbt_anirudh.unique_bronze_sales_sales_id.3c35aa753d"
[0m16:19:41.420967 [debug] [Thread-2 (]: Using databricks connection "test.dbt_anirudh.unique_bronze_sales_sales_id.3c35aa753d"
[0m16:19:41.421627 [debug] [Thread-2 (]: On test.dbt_anirudh.unique_bronze_sales_sales_id.3c35aa753d: /* {"app": "dbt", "dbt_version": "1.10.10", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_anirudh", "target_name": "dev", "node_id": "test.dbt_anirudh.unique_bronze_sales_sales_id.3c35aa753d"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    

select
    sales_id as unique_field,
    count(*) as n_records

from `dbt_learning`.`bronze`.`bronze_sales`
where sales_id is not null
group by sales_id
having count(*) > 1



  
  
      
    ) dbt_internal_test
[0m16:19:41.422210 [debug] [Thread-2 (]: Opening a new connection, currently in state init
[0m16:19:42.544694 [debug] [Thread-2 (]: Databricks adapter: Connection(session-id=01f09158-8510-13cf-99a2-047ce20c5bd1) - Created
[0m16:19:43.068807 [debug] [Thread-2 (]: SQL status: OK in 1.650 seconds
[0m16:19:43.072988 [debug] [Thread-2 (]: Databricks adapter: Cursor(session-id=01f09158-8510-13cf-99a2-047ce20c5bd1, command-id=01f09158-853d-15ee-a4ec-47b0e8e92ed1) - Closing
[0m16:19:43.074189 [debug] [Thread-2 (]: On test.dbt_anirudh.unique_bronze_sales_sales_id.3c35aa753d: Close
[0m16:19:43.074763 [debug] [Thread-2 (]: Databricks adapter: Connection(session-id=01f09158-8510-13cf-99a2-047ce20c5bd1) - Closing
[0m16:19:43.386250 [info ] [Thread-2 (]: 5 of 5 PASS unique_bronze_sales_sales_id ....................................... [[32mPASS[0m in 1.99s]
[0m16:19:43.387928 [debug] [Thread-2 (]: Finished running node test.dbt_anirudh.unique_bronze_sales_sales_id.3c35aa753d
[0m16:19:43.390433 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=master) - Creating connection
[0m16:19:43.391476 [debug] [MainThread]: Acquiring new databricks connection 'master'
[0m16:19:43.392439 [info ] [MainThread]: 
[0m16:19:43.393242 [info ] [MainThread]: Finished running 5 data tests in 0 hours 0 minutes and 12.13 seconds (12.13s).
[0m16:19:43.395410 [debug] [MainThread]: Command end result
[0m16:19:43.502357 [debug] [MainThread]: Wrote artifact WritableManifest to /home/aniruth/AI/DBT/DBT_Master/dbt_anirudh/target/manifest.json
[0m16:19:43.503723 [debug] [MainThread]: Wrote artifact SemanticManifest to /home/aniruth/AI/DBT/DBT_Master/dbt_anirudh/target/semantic_manifest.json
[0m16:19:43.508375 [debug] [MainThread]: Wrote artifact RunExecutionResult to /home/aniruth/AI/DBT/DBT_Master/dbt_anirudh/target/run_results.json
[0m16:19:43.508681 [info ] [MainThread]: 
[0m16:19:43.508960 [info ] [MainThread]: [31mCompleted with 1 error, 0 partial successes, and 1 warning:[0m
[0m16:19:43.509195 [info ] [MainThread]: 
[0m16:19:43.509475 [error] [MainThread]: [31mFailure in test non_negative (tests/non_negative.sql)[0m
[0m16:19:43.509754 [error] [MainThread]:   Got 7173 results, configured to fail if != 0
[0m16:19:43.509970 [info ] [MainThread]: 
[0m16:19:43.510221 [info ] [MainThread]:   compiled code at target/compiled/dbt_anirudh/tests/non_negative.sql
[0m16:19:43.510441 [info ] [MainThread]: 
[0m16:19:43.510725 [warn ] [MainThread]: [33mWarning in test accepted_values_bronze_store_store_name__MegaMar_Manhattan__MegaMart_Brooklyn__MegaMart_Austin__MegaMart_San_Jose__MegaMart_Toronto (models/bronze/properties.yml)[0m
[0m16:19:43.510984 [warn ] [MainThread]: Got 1 result, configured to warn if != 0
[0m16:19:43.511190 [info ] [MainThread]: 
[0m16:19:43.511436 [info ] [MainThread]:   compiled code at target/compiled/dbt_anirudh/models/bronze/properties.yml/accepted_values_bronze_store_8308937ffa06d226d8f7cff5d272d129.sql
[0m16:19:43.511698 [info ] [MainThread]: 
[0m16:19:43.511942 [info ] [MainThread]: Done. PASS=3 WARN=1 ERROR=1 SKIP=0 NO-OP=0 TOTAL=5
[0m16:19:43.512587 [debug] [MainThread]: Resource report: {"command_name": "test", "command_success": false, "command_wall_clock_time": 13.826956, "process_in_blocks": "0", "process_kernel_time": 0.203441, "process_mem_max_rss": "245476", "process_out_blocks": "3240", "process_user_time": 4.366018}
[0m16:19:43.512957 [debug] [MainThread]: Command `dbt test` failed at 16:19:43.512888 after 13.83 seconds
[0m16:19:43.513266 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7b393cbb3a70>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7b39397ea2a0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7b393982fd70>]}
[0m16:19:43.513598 [debug] [MainThread]: Flushing usage events
[0m16:19:44.498284 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m16:27:11.297481 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x735de67178f0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x735de5b4b5f0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x735de5c1f110>]}


============================== 16:27:11.299962 | a7bab3de-c2ca-49fa-9866-29056723cc00 ==============================
[0m16:27:11.299962 [info ] [MainThread]: Running with dbt=1.10.10
[0m16:27:11.300421 [debug] [MainThread]: running dbt with arguments {'log_cache_events': 'False', 'introspect': 'True', 'cache_selected_only': 'False', 'printer_width': '80', 'quiet': 'False', 'use_experimental_parser': 'False', 'send_anonymous_usage_stats': 'True', 'no_print': 'None', 'fail_fast': 'False', 'profiles_dir': '/home/aniruth/AI/DBT/DBT_Master/dbt_anirudh', 'partial_parse': 'True', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'debug': 'False', 'invocation_command': 'dbt debug', 'version_check': 'True', 'use_colors': 'True', 'indirect_selection': 'eager', 'target_path': 'None', 'log_path': '/home/aniruth/AI/DBT/DBT_Master/dbt_anirudh/logs', 'empty': 'None', 'static_parser': 'True', 'warn_error': 'None', 'write_json': 'True', 'log_format': 'default'}
[0m16:27:11.307812 [info ] [MainThread]: dbt version: 1.10.10
[0m16:27:11.308183 [info ] [MainThread]: python version: 3.12.3
[0m16:27:11.308457 [info ] [MainThread]: python path: /home/aniruth/AI/DBT/.venv/bin/python3
[0m16:27:11.308708 [info ] [MainThread]: os info: Linux-6.14.0-28-generic-x86_64-with-glibc2.39
[0m16:27:11.904823 [debug] [MainThread]: Spark adapter: Setting pyhive.hive logging to ERROR
[0m16:27:11.905260 [debug] [MainThread]: Spark adapter: Setting thrift.transport logging to ERROR
[0m16:27:11.905539 [debug] [MainThread]: Spark adapter: Setting thrift.protocol logging to ERROR
[0m16:27:12.313775 [info ] [MainThread]: Using profiles dir at /home/aniruth/AI/DBT/DBT_Master/dbt_anirudh
[0m16:27:12.314204 [info ] [MainThread]: Using profiles.yml file at /home/aniruth/AI/DBT/DBT_Master/dbt_anirudh/profiles.yml
[0m16:27:12.314541 [info ] [MainThread]: Using dbt_project.yml file at /home/aniruth/AI/DBT/DBT_Master/dbt_anirudh/dbt_project.yml
[0m16:27:12.314850 [info ] [MainThread]: adapter type: databricks
[0m16:27:12.315137 [info ] [MainThread]: adapter version: 1.10.9
[0m16:27:12.394874 [info ] [MainThread]: Configuration:
[0m16:27:12.395290 [info ] [MainThread]:   profiles.yml file [[32mOK found and valid[0m]
[0m16:27:12.395680 [info ] [MainThread]:   dbt_project.yml file [[32mOK found and valid[0m]
[0m16:27:12.395977 [info ] [MainThread]: Required dependencies:
[0m16:27:12.396274 [debug] [MainThread]: Executing "git --help"
[0m16:27:12.397814 [debug] [MainThread]: STDOUT: "b"usage: git [-v | --version] [-h | --help] [-C <path>] [-c <name>=<value>]\n           [--exec-path[=<path>]] [--html-path] [--man-path] [--info-path]\n           [-p | --paginate | -P | --no-pager] [--no-replace-objects] [--bare]\n           [--git-dir=<path>] [--work-tree=<path>] [--namespace=<name>]\n           [--config-env=<name>=<envvar>] <command> [<args>]\n\nThese are common Git commands used in various situations:\n\nstart a working area (see also: git help tutorial)\n   clone     Clone a repository into a new directory\n   init      Create an empty Git repository or reinitialize an existing one\n\nwork on the current change (see also: git help everyday)\n   add       Add file contents to the index\n   mv        Move or rename a file, a directory, or a symlink\n   restore   Restore working tree files\n   rm        Remove files from the working tree and from the index\n\nexamine the history and state (see also: git help revisions)\n   bisect    Use binary search to find the commit that introduced a bug\n   diff      Show changes between commits, commit and working tree, etc\n   grep      Print lines matching a pattern\n   log       Show commit logs\n   show      Show various types of objects\n   status    Show the working tree status\n\ngrow, mark and tweak your common history\n   branch    List, create, or delete branches\n   commit    Record changes to the repository\n   merge     Join two or more development histories together\n   rebase    Reapply commits on top of another base tip\n   reset     Reset current HEAD to the specified state\n   switch    Switch branches\n   tag       Create, list, delete or verify a tag object signed with GPG\n\ncollaborate (see also: git help workflows)\n   fetch     Download objects and refs from another repository\n   pull      Fetch from and integrate with another repository or a local branch\n   push      Update remote refs along with associated objects\n\n'git help -a' and 'git help -g' list available subcommands and some\nconcept guides. See 'git help <command>' or 'git help <concept>'\nto read about a specific subcommand or concept.\nSee 'git help git' for an overview of the system.\n""
[0m16:27:12.398129 [debug] [MainThread]: STDERR: "b''"
[0m16:27:12.398356 [info ] [MainThread]:  - git [[32mOK found[0m]

[0m16:27:12.398631 [info ] [MainThread]: Connection:
[0m16:27:12.398919 [info ] [MainThread]:   host: dbc-da390f9a-8fc8.cloud.databricks.com
[0m16:27:12.399177 [info ] [MainThread]:   http_path: /sql/1.0/warehouses/cd9c3d27e6f79760
[0m16:27:12.399428 [info ] [MainThread]:   catalog: dbt_learning
[0m16:27:12.399713 [info ] [MainThread]:   schema: default
[0m16:27:12.400141 [info ] [MainThread]: Registered adapter: databricks=1.10.9
[0m16:27:12.469598 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=debug) - Creating connection
[0m16:27:12.469933 [debug] [MainThread]: Acquiring new databricks connection 'debug'
[0m16:27:12.470174 [debug] [MainThread]: Using databricks connection "debug"
[0m16:27:12.470417 [debug] [MainThread]: On debug: select 1 as id
[0m16:27:12.470652 [debug] [MainThread]: Opening a new connection, currently in state init
[0m16:27:13.681856 [debug] [MainThread]: Databricks adapter: Connection(session-id=01f09159-91f5-15fd-b179-c41d911e64af) - Created
[0m16:27:14.217538 [debug] [MainThread]: SQL status: OK in 1.750 seconds
[0m16:27:14.219956 [debug] [MainThread]: Databricks adapter: Cursor(session-id=01f09159-91f5-15fd-b179-c41d911e64af, command-id=01f09159-922a-1e8e-9fa5-da2d992eb08f) - Closing
[0m16:27:14.221018 [debug] [MainThread]: On debug: Close
[0m16:27:14.221875 [debug] [MainThread]: Databricks adapter: Connection(session-id=01f09159-91f5-15fd-b179-c41d911e64af) - Closing
[0m16:27:14.528917 [info ] [MainThread]:   Connection test: [[32mOK connection ok[0m]

[0m16:27:14.529921 [info ] [MainThread]: [32mAll checks passed![0m
[0m16:27:14.531883 [debug] [MainThread]: Resource report: {"command_name": "debug", "command_success": true, "command_wall_clock_time": 3.2790978, "process_in_blocks": "440", "process_kernel_time": 0.172595, "process_mem_max_rss": "233064", "process_out_blocks": "24", "process_user_time": 3.215469}
[0m16:27:14.533064 [debug] [MainThread]: Command `dbt debug` succeeded at 16:27:14.532823 after 3.28 seconds
[0m16:27:14.533953 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x735de74293a0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x735de3428710>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x735de48a8b90>]}
[0m16:27:14.534977 [debug] [MainThread]: Flushing usage events
[0m16:27:15.591778 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m16:28:04.451823 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x72d7e7433ef0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x72d7e7c03290>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x72d7e73b3890>]}


============================== 16:28:04.454130 | 80246f70-ab9b-4ca5-ad80-15cbf50cccbf ==============================
[0m16:28:04.454130 [info ] [MainThread]: Running with dbt=1.10.10
[0m16:28:04.454560 [debug] [MainThread]: running dbt with arguments {'write_json': 'True', 'profiles_dir': '/home/aniruth/AI/DBT/DBT_Master/dbt_anirudh', 'use_colors': 'True', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'fail_fast': 'False', 'log_path': '/home/aniruth/AI/DBT/DBT_Master/dbt_anirudh/logs', 'empty': 'None', 'invocation_command': 'dbt test', 'static_parser': 'True', 'use_experimental_parser': 'False', 'debug': 'False', 'warn_error': 'None', 'introspect': 'True', 'log_format': 'default', 'send_anonymous_usage_stats': 'True', 'version_check': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'printer_width': '80', 'no_print': 'None', 'quiet': 'False', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])'}
[0m16:28:05.018271 [debug] [MainThread]: Spark adapter: Setting pyhive.hive logging to ERROR
[0m16:28:05.018722 [debug] [MainThread]: Spark adapter: Setting thrift.transport logging to ERROR
[0m16:28:05.019043 [debug] [MainThread]: Spark adapter: Setting thrift.protocol logging to ERROR
[0m16:28:05.506171 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '80246f70-ab9b-4ca5-ad80-15cbf50cccbf', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x72d7e230ffb0>]}
[0m16:28:05.550843 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '80246f70-ab9b-4ca5-ad80-15cbf50cccbf', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x72d7c38c0ce0>]}
[0m16:28:05.551386 [info ] [MainThread]: Registered adapter: databricks=1.10.9
[0m16:28:05.623978 [debug] [MainThread]: checksum: 502a0dc23e9052e1ae09f7c44ee219ef7a02dfea7e7d66580d54c304c14d553b, vars: {}, profile: , target: , version: 1.10.10
[0m16:28:05.711425 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m16:28:05.711742 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m16:28:05.717212 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 2 unused configuration paths:
- models.dbt_anirudh.silver
- models.dbt_anirudh.gold
[0m16:28:05.751295 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '80246f70-ab9b-4ca5-ad80-15cbf50cccbf', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x72d7c207e3f0>]}
[0m16:28:05.823566 [debug] [MainThread]: Wrote artifact WritableManifest to /home/aniruth/AI/DBT/DBT_Master/dbt_anirudh/target/manifest.json
[0m16:28:05.825005 [debug] [MainThread]: Wrote artifact SemanticManifest to /home/aniruth/AI/DBT/DBT_Master/dbt_anirudh/target/semantic_manifest.json
[0m16:28:05.837003 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '80246f70-ab9b-4ca5-ad80-15cbf50cccbf', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x72d7c1bc83b0>]}
[0m16:28:05.837404 [info ] [MainThread]: Found 6 models, 5 data tests, 6 sources, 686 macros
[0m16:28:05.837723 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '80246f70-ab9b-4ca5-ad80-15cbf50cccbf', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x72d7c2582cc0>]}
[0m16:28:05.839119 [info ] [MainThread]: 
[0m16:28:05.839429 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m16:28:05.839734 [info ] [MainThread]: 
[0m16:28:05.840183 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=master) - Creating connection
[0m16:28:05.840441 [debug] [MainThread]: Acquiring new databricks connection 'master'
[0m16:28:05.845687 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=list_dbt_learning_bronze) - Creating connection
[0m16:28:05.846066 [debug] [ThreadPool]: Acquiring new databricks connection 'list_dbt_learning_bronze'
[0m16:28:05.857809 [debug] [ThreadPool]: Using databricks connection "list_dbt_learning_bronze"
[0m16:28:05.858216 [debug] [ThreadPool]: On list_dbt_learning_bronze: /* {"app": "dbt", "dbt_version": "1.10.10", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_anirudh", "target_name": "dev", "connection_name": "list_dbt_learning_bronze"} */

    
SELECT
  table_name,
  if(table_type IN ('EXTERNAL', 'MANAGED', 'MANAGED_SHALLOW_CLONE', 'EXTERNAL_SHALLOW_CLONE'), 'table', lower(table_type)) AS table_type,
  lower(data_source_format) AS file_format,
  table_owner,
  if(
    table_type IN (
      'EXTERNAL',
      'MANAGED',
      'MANAGED_SHALLOW_CLONE',
      'EXTERNAL_SHALLOW_CLONE'
    ),
    lower(table_type),
    NULL
  ) AS databricks_table_type
FROM `system`.`information_schema`.`tables`
WHERE table_catalog = 'dbt_learning' 
  AND table_schema = 'bronze'

  
[0m16:28:05.858519 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m16:28:06.975883 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f09159-b1ba-12ae-b1e2-3a0ebd15fb29) - Created
[0m16:28:07.786362 [debug] [ThreadPool]: SQL status: OK in 1.930 seconds
[0m16:28:07.794860 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01f09159-b1ba-12ae-b1e2-3a0ebd15fb29, command-id=01f09159-b1e5-13c1-a868-9a1d140449fb) - Closing
[0m16:28:07.796509 [debug] [ThreadPool]: On list_dbt_learning_bronze: Close
[0m16:28:07.797377 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f09159-b1ba-12ae-b1e2-3a0ebd15fb29) - Closing
[0m16:28:08.118396 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '80246f70-ab9b-4ca5-ad80-15cbf50cccbf', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x72d7c2177290>]}
[0m16:28:08.123260 [debug] [Thread-2 (]: Began running node test.dbt_anirudh.accepted_values_bronze_store_store_name__MegaMar_Manhattan__MegaMart_Brooklyn__MegaMart_Austin__MegaMart_San_Jose__MegaMart_Toronto.b983752665
[0m16:28:08.124375 [info ] [Thread-2 (]: 1 of 5 START test accepted_values_bronze_store_store_name__MegaMar_Manhattan__MegaMart_Brooklyn__MegaMart_Austin__MegaMart_San_Jose__MegaMart_Toronto  [RUN]
[0m16:28:08.125863 [debug] [Thread-2 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=test.dbt_anirudh.accepted_values_bronze_store_store_name__MegaMar_Manhattan__MegaMart_Brooklyn__MegaMart_Austin__MegaMart_San_Jose__MegaMart_Toronto.b983752665) - Creating connection
[0m16:28:08.126909 [debug] [Thread-2 (]: Acquiring new databricks connection 'test.dbt_anirudh.accepted_values_bronze_store_store_name__MegaMar_Manhattan__MegaMart_Brooklyn__MegaMart_Austin__MegaMart_San_Jose__MegaMart_Toronto.b983752665'
[0m16:28:08.127787 [debug] [Thread-2 (]: Began compiling node test.dbt_anirudh.accepted_values_bronze_store_store_name__MegaMar_Manhattan__MegaMart_Brooklyn__MegaMart_Austin__MegaMart_San_Jose__MegaMart_Toronto.b983752665
[0m16:28:08.154375 [debug] [Thread-2 (]: Writing injected SQL for node "test.dbt_anirudh.accepted_values_bronze_store_store_name__MegaMar_Manhattan__MegaMart_Brooklyn__MegaMart_Austin__MegaMart_San_Jose__MegaMart_Toronto.b983752665"
[0m16:28:08.154954 [debug] [Thread-2 (]: Began executing node test.dbt_anirudh.accepted_values_bronze_store_store_name__MegaMar_Manhattan__MegaMart_Brooklyn__MegaMart_Austin__MegaMart_San_Jose__MegaMart_Toronto.b983752665
[0m16:28:08.168980 [debug] [Thread-2 (]: Writing runtime sql for node "test.dbt_anirudh.accepted_values_bronze_store_store_name__MegaMar_Manhattan__MegaMart_Brooklyn__MegaMart_Austin__MegaMart_San_Jose__MegaMart_Toronto.b983752665"
[0m16:28:08.169629 [debug] [Thread-2 (]: Using databricks connection "test.dbt_anirudh.accepted_values_bronze_store_store_name__MegaMar_Manhattan__MegaMart_Brooklyn__MegaMart_Austin__MegaMart_San_Jose__MegaMart_Toronto.b983752665"
[0m16:28:08.170018 [debug] [Thread-2 (]: On test.dbt_anirudh.accepted_values_bronze_store_store_name__MegaMar_Manhattan__MegaMart_Brooklyn__MegaMart_Austin__MegaMart_San_Jose__MegaMart_Toronto.b983752665: /* {"app": "dbt", "dbt_version": "1.10.10", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_anirudh", "target_name": "dev", "node_id": "test.dbt_anirudh.accepted_values_bronze_store_store_name__MegaMar_Manhattan__MegaMart_Brooklyn__MegaMart_Austin__MegaMart_San_Jose__MegaMart_Toronto.b983752665"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    

with all_values as (

    select
        store_name as value_field,
        count(*) as n_records

    from `dbt_learning`.`bronze`.`bronze_store`
    group by store_name

)

select *
from all_values
where value_field not in (
    'MegaMar Manhattan','MegaMart Brooklyn','MegaMart Austin','MegaMart San Jose','MegaMart Toronto'
)



  
  
      
    ) dbt_internal_test
[0m16:28:08.170315 [debug] [Thread-2 (]: Opening a new connection, currently in state init
[0m16:28:09.306061 [debug] [Thread-2 (]: Databricks adapter: Connection(session-id=01f09159-b31d-1cf4-ae0f-959f73544edd) - Created
[0m16:28:09.878369 [debug] [Thread-2 (]: SQL status: OK in 1.710 seconds
[0m16:28:09.883383 [debug] [Thread-2 (]: Databricks adapter: Cursor(session-id=01f09159-b31d-1cf4-ae0f-959f73544edd, command-id=01f09159-b349-1f1a-bedc-fc49e04ba715) - Closing
[0m16:28:09.888128 [debug] [Thread-2 (]: On test.dbt_anirudh.accepted_values_bronze_store_store_name__MegaMar_Manhattan__MegaMart_Brooklyn__MegaMart_Austin__MegaMart_San_Jose__MegaMart_Toronto.b983752665: Close
[0m16:28:09.888587 [debug] [Thread-2 (]: Databricks adapter: Connection(session-id=01f09159-b31d-1cf4-ae0f-959f73544edd) - Closing
[0m16:28:10.188187 [warn ] [Thread-2 (]: 1 of 5 WARN 1 accepted_values_bronze_store_store_name__MegaMar_Manhattan__MegaMart_Brooklyn__MegaMart_Austin__MegaMart_San_Jose__MegaMart_Toronto  [[33mWARN 1[0m in 2.06s]
[0m16:28:10.189938 [debug] [Thread-2 (]: Finished running node test.dbt_anirudh.accepted_values_bronze_store_store_name__MegaMar_Manhattan__MegaMart_Brooklyn__MegaMart_Austin__MegaMart_San_Jose__MegaMart_Toronto.b983752665
[0m16:28:10.191047 [debug] [Thread-2 (]: Began running node test.dbt_anirudh.non_negartive
[0m16:28:10.192289 [info ] [Thread-2 (]: 2 of 5 START test non_negartive ................................................ [RUN]
[0m16:28:10.193699 [debug] [Thread-2 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=test.dbt_anirudh.non_negartive) - Creating connection
[0m16:28:10.194588 [debug] [Thread-2 (]: Acquiring new databricks connection 'test.dbt_anirudh.non_negartive'
[0m16:28:10.195563 [debug] [Thread-2 (]: Began compiling node test.dbt_anirudh.non_negartive
[0m16:28:10.203756 [debug] [Thread-2 (]: Writing injected SQL for node "test.dbt_anirudh.non_negartive"
[0m16:28:10.204499 [debug] [Thread-2 (]: Began executing node test.dbt_anirudh.non_negartive
[0m16:28:10.207442 [debug] [Thread-2 (]: Writing runtime sql for node "test.dbt_anirudh.non_negartive"
[0m16:28:10.208102 [debug] [Thread-2 (]: Using databricks connection "test.dbt_anirudh.non_negartive"
[0m16:28:10.208496 [debug] [Thread-2 (]: On test.dbt_anirudh.non_negartive: /* {"app": "dbt", "dbt_version": "1.10.10", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_anirudh", "target_name": "dev", "node_id": "test.dbt_anirudh.non_negartive"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  SELECT
    *
FROM
    `dbt_learning`.`bronze`.`bronze_sales`
WHERE
    gross_amount < 0 AND net_amount < 0
  
  
      
    ) dbt_internal_test
[0m16:28:10.208791 [debug] [Thread-2 (]: Opening a new connection, currently in state init
[0m16:28:11.334200 [debug] [Thread-2 (]: Databricks adapter: Connection(session-id=01f09159-b452-1e08-a9f1-9bdf1c7c00b7) - Created
[0m16:28:11.845329 [debug] [Thread-2 (]: SQL status: OK in 1.640 seconds
[0m16:28:11.849720 [debug] [Thread-2 (]: Databricks adapter: Cursor(session-id=01f09159-b452-1e08-a9f1-9bdf1c7c00b7, command-id=01f09159-b47f-1030-8e32-954a2c3eac79) - Closing
[0m16:28:11.851310 [debug] [Thread-2 (]: On test.dbt_anirudh.non_negartive: Close
[0m16:28:11.852352 [debug] [Thread-2 (]: Databricks adapter: Connection(session-id=01f09159-b452-1e08-a9f1-9bdf1c7c00b7) - Closing
[0m16:28:12.164324 [info ] [Thread-2 (]: 2 of 5 PASS non_negartive ...................................................... [[32mPASS[0m in 1.97s]
[0m16:28:12.164927 [debug] [Thread-2 (]: Finished running node test.dbt_anirudh.non_negartive
[0m16:28:12.165274 [debug] [Thread-2 (]: Began running node test.dbt_anirudh.non_negative
[0m16:28:12.165671 [info ] [Thread-2 (]: 3 of 5 START test non_negative ................................................. [RUN]
[0m16:28:12.166109 [debug] [Thread-2 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=test.dbt_anirudh.non_negative) - Creating connection
[0m16:28:12.166415 [debug] [Thread-2 (]: Acquiring new databricks connection 'test.dbt_anirudh.non_negative'
[0m16:28:12.166700 [debug] [Thread-2 (]: Began compiling node test.dbt_anirudh.non_negative
[0m16:28:12.170263 [debug] [Thread-2 (]: Writing injected SQL for node "test.dbt_anirudh.non_negative"
[0m16:28:12.170985 [debug] [Thread-2 (]: Began executing node test.dbt_anirudh.non_negative
[0m16:28:12.173988 [debug] [Thread-2 (]: Writing runtime sql for node "test.dbt_anirudh.non_negative"
[0m16:28:12.174784 [debug] [Thread-2 (]: Using databricks connection "test.dbt_anirudh.non_negative"
[0m16:28:12.175305 [debug] [Thread-2 (]: On test.dbt_anirudh.non_negative: /* {"app": "dbt", "dbt_version": "1.10.10", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_anirudh", "target_name": "dev", "node_id": "test.dbt_anirudh.non_negative"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  SELECT
    *
FROM
    `dbt_learning`.`bronze`.`bronze_sales`
  
  
      
    ) dbt_internal_test
[0m16:28:12.175819 [debug] [Thread-2 (]: Opening a new connection, currently in state init
[0m16:28:13.267756 [debug] [Thread-2 (]: Databricks adapter: Connection(session-id=01f09159-b57a-1a42-b4d1-827504c7509f) - Created
[0m16:28:13.754186 [debug] [Thread-2 (]: SQL status: OK in 1.580 seconds
[0m16:28:13.758276 [debug] [Thread-2 (]: Databricks adapter: Cursor(session-id=01f09159-b57a-1a42-b4d1-827504c7509f, command-id=01f09159-b5a5-1da9-8f58-4f8650a6cdfc) - Closing
[0m16:28:13.759736 [debug] [Thread-2 (]: On test.dbt_anirudh.non_negative: Close
[0m16:28:13.760669 [debug] [Thread-2 (]: Databricks adapter: Connection(session-id=01f09159-b57a-1a42-b4d1-827504c7509f) - Closing
[0m16:28:14.065005 [error] [Thread-2 (]: 3 of 5 FAIL 7173 non_negative .................................................. [[31mFAIL 7173[0m in 1.90s]
[0m16:28:14.066654 [debug] [Thread-2 (]: Finished running node test.dbt_anirudh.non_negative
[0m16:28:14.067781 [debug] [Thread-2 (]: Began running node test.dbt_anirudh.not_null_bronze_sales_sales_id.e4b1b997fb
[0m16:28:14.068724 [info ] [Thread-2 (]: 4 of 5 START test not_null_bronze_sales_sales_id ............................... [RUN]
[0m16:28:14.070174 [debug] [Thread-2 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=test.dbt_anirudh.not_null_bronze_sales_sales_id.e4b1b997fb) - Creating connection
[0m16:28:14.071188 [debug] [Thread-2 (]: Acquiring new databricks connection 'test.dbt_anirudh.not_null_bronze_sales_sales_id.e4b1b997fb'
[0m16:28:14.072139 [debug] [Thread-2 (]: Began compiling node test.dbt_anirudh.not_null_bronze_sales_sales_id.e4b1b997fb
[0m16:28:14.085563 [debug] [Thread-2 (]: Writing injected SQL for node "test.dbt_anirudh.not_null_bronze_sales_sales_id.e4b1b997fb"
[0m16:28:14.086123 [debug] [Thread-2 (]: Began executing node test.dbt_anirudh.not_null_bronze_sales_sales_id.e4b1b997fb
[0m16:28:14.088260 [debug] [Thread-2 (]: Writing runtime sql for node "test.dbt_anirudh.not_null_bronze_sales_sales_id.e4b1b997fb"
[0m16:28:14.088749 [debug] [Thread-2 (]: Using databricks connection "test.dbt_anirudh.not_null_bronze_sales_sales_id.e4b1b997fb"
[0m16:28:14.089092 [debug] [Thread-2 (]: On test.dbt_anirudh.not_null_bronze_sales_sales_id.e4b1b997fb: /* {"app": "dbt", "dbt_version": "1.10.10", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_anirudh", "target_name": "dev", "node_id": "test.dbt_anirudh.not_null_bronze_sales_sales_id.e4b1b997fb"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select sales_id
from `dbt_learning`.`bronze`.`bronze_sales`
where sales_id is null



  
  
      
    ) dbt_internal_test
[0m16:28:14.089374 [debug] [Thread-2 (]: Opening a new connection, currently in state init
[0m16:28:15.212728 [debug] [Thread-2 (]: Databricks adapter: Connection(session-id=01f09159-b6a1-18cd-9c4e-2b0e9b954973) - Created
[0m16:28:15.745610 [debug] [Thread-2 (]: SQL status: OK in 1.660 seconds
[0m16:28:15.750451 [debug] [Thread-2 (]: Databricks adapter: Cursor(session-id=01f09159-b6a1-18cd-9c4e-2b0e9b954973, command-id=01f09159-b6cd-1ad1-be9a-a69e5a308ca8) - Closing
[0m16:28:15.751953 [debug] [Thread-2 (]: On test.dbt_anirudh.not_null_bronze_sales_sales_id.e4b1b997fb: Close
[0m16:28:15.752903 [debug] [Thread-2 (]: Databricks adapter: Connection(session-id=01f09159-b6a1-18cd-9c4e-2b0e9b954973) - Closing
[0m16:28:16.056542 [info ] [Thread-2 (]: 4 of 5 PASS not_null_bronze_sales_sales_id ..................................... [[32mPASS[0m in 1.99s]
[0m16:28:16.058120 [debug] [Thread-2 (]: Finished running node test.dbt_anirudh.not_null_bronze_sales_sales_id.e4b1b997fb
[0m16:28:16.059221 [debug] [Thread-2 (]: Began running node test.dbt_anirudh.unique_bronze_sales_sales_id.3c35aa753d
[0m16:28:16.060157 [info ] [Thread-2 (]: 5 of 5 START test unique_bronze_sales_sales_id ................................. [RUN]
[0m16:28:16.061389 [debug] [Thread-2 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=test.dbt_anirudh.unique_bronze_sales_sales_id.3c35aa753d) - Creating connection
[0m16:28:16.062497 [debug] [Thread-2 (]: Acquiring new databricks connection 'test.dbt_anirudh.unique_bronze_sales_sales_id.3c35aa753d'
[0m16:28:16.063369 [debug] [Thread-2 (]: Began compiling node test.dbt_anirudh.unique_bronze_sales_sales_id.3c35aa753d
[0m16:28:16.075558 [debug] [Thread-2 (]: Writing injected SQL for node "test.dbt_anirudh.unique_bronze_sales_sales_id.3c35aa753d"
[0m16:28:16.076280 [debug] [Thread-2 (]: Began executing node test.dbt_anirudh.unique_bronze_sales_sales_id.3c35aa753d
[0m16:28:16.078353 [debug] [Thread-2 (]: Writing runtime sql for node "test.dbt_anirudh.unique_bronze_sales_sales_id.3c35aa753d"
[0m16:28:16.078871 [debug] [Thread-2 (]: Using databricks connection "test.dbt_anirudh.unique_bronze_sales_sales_id.3c35aa753d"
[0m16:28:16.079206 [debug] [Thread-2 (]: On test.dbt_anirudh.unique_bronze_sales_sales_id.3c35aa753d: /* {"app": "dbt", "dbt_version": "1.10.10", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_anirudh", "target_name": "dev", "node_id": "test.dbt_anirudh.unique_bronze_sales_sales_id.3c35aa753d"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    

select
    sales_id as unique_field,
    count(*) as n_records

from `dbt_learning`.`bronze`.`bronze_sales`
where sales_id is not null
group by sales_id
having count(*) > 1



  
  
      
    ) dbt_internal_test
[0m16:28:16.079475 [debug] [Thread-2 (]: Opening a new connection, currently in state init
[0m16:28:17.211926 [debug] [Thread-2 (]: Databricks adapter: Connection(session-id=01f09159-b7d3-145f-bdbc-4cbfc134d91e) - Created
[0m16:28:17.709335 [debug] [Thread-2 (]: SQL status: OK in 1.630 seconds
[0m16:28:17.713770 [debug] [Thread-2 (]: Databricks adapter: Cursor(session-id=01f09159-b7d3-145f-bdbc-4cbfc134d91e, command-id=01f09159-b7ff-1e2e-98d5-c94b5d575c65) - Closing
[0m16:28:17.715266 [debug] [Thread-2 (]: On test.dbt_anirudh.unique_bronze_sales_sales_id.3c35aa753d: Close
[0m16:28:17.716139 [debug] [Thread-2 (]: Databricks adapter: Connection(session-id=01f09159-b7d3-145f-bdbc-4cbfc134d91e) - Closing
[0m16:28:18.014010 [info ] [Thread-2 (]: 5 of 5 PASS unique_bronze_sales_sales_id ....................................... [[32mPASS[0m in 1.95s]
[0m16:28:18.015433 [debug] [Thread-2 (]: Finished running node test.dbt_anirudh.unique_bronze_sales_sales_id.3c35aa753d
[0m16:28:18.017905 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=master) - Creating connection
[0m16:28:18.018871 [debug] [MainThread]: Acquiring new databricks connection 'master'
[0m16:28:18.019923 [info ] [MainThread]: 
[0m16:28:18.020781 [info ] [MainThread]: Finished running 5 data tests in 0 hours 0 minutes and 12.18 seconds (12.18s).
[0m16:28:18.024049 [debug] [MainThread]: Command end result
[0m16:28:18.131020 [debug] [MainThread]: Wrote artifact WritableManifest to /home/aniruth/AI/DBT/DBT_Master/dbt_anirudh/target/manifest.json
[0m16:28:18.132411 [debug] [MainThread]: Wrote artifact SemanticManifest to /home/aniruth/AI/DBT/DBT_Master/dbt_anirudh/target/semantic_manifest.json
[0m16:28:18.137172 [debug] [MainThread]: Wrote artifact RunExecutionResult to /home/aniruth/AI/DBT/DBT_Master/dbt_anirudh/target/run_results.json
[0m16:28:18.137444 [info ] [MainThread]: 
[0m16:28:18.137727 [info ] [MainThread]: [31mCompleted with 1 error, 0 partial successes, and 1 warning:[0m
[0m16:28:18.137995 [info ] [MainThread]: 
[0m16:28:18.138295 [error] [MainThread]: [31mFailure in test non_negative (tests/non_negative.sql)[0m
[0m16:28:18.138637 [error] [MainThread]:   Got 7173 results, configured to fail if != 0
[0m16:28:18.138903 [info ] [MainThread]: 
[0m16:28:18.139178 [info ] [MainThread]:   compiled code at target/compiled/dbt_anirudh/tests/non_negative.sql
[0m16:28:18.139420 [info ] [MainThread]: 
[0m16:28:18.139762 [warn ] [MainThread]: [33mWarning in test accepted_values_bronze_store_store_name__MegaMar_Manhattan__MegaMart_Brooklyn__MegaMart_Austin__MegaMart_San_Jose__MegaMart_Toronto (models/bronze/properties.yml)[0m
[0m16:28:18.140049 [warn ] [MainThread]: Got 1 result, configured to warn if != 0
[0m16:28:18.140278 [info ] [MainThread]: 
[0m16:28:18.140556 [info ] [MainThread]:   compiled code at target/compiled/dbt_anirudh/models/bronze/properties.yml/accepted_values_bronze_store_8308937ffa06d226d8f7cff5d272d129.sql
[0m16:28:18.140793 [info ] [MainThread]: 
[0m16:28:18.141059 [info ] [MainThread]: Done. PASS=3 WARN=1 ERROR=1 SKIP=0 NO-OP=0 TOTAL=5
[0m16:28:18.141745 [debug] [MainThread]: Resource report: {"command_name": "test", "command_success": false, "command_wall_clock_time": 13.727287, "process_in_blocks": "0", "process_kernel_time": 0.171628, "process_mem_max_rss": "245636", "process_out_blocks": "3240", "process_user_time": 4.075188}
[0m16:28:18.142107 [debug] [MainThread]: Command `dbt test` failed at 16:28:18.142036 after 13.73 seconds
[0m16:28:18.142404 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x72d7e8506090>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x72d7c1b3fda0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x72d7c0aa4530>]}
[0m16:28:18.142696 [debug] [MainThread]: Flushing usage events
[0m16:28:19.102099 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m16:51:13.678952 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x77f433308410>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x77f432eb3140>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x77f432eb07d0>]}


============================== 16:51:13.681475 | 30060d2c-7293-47e6-859e-75308edba010 ==============================
[0m16:51:13.681475 [info ] [MainThread]: Running with dbt=1.10.10
[0m16:51:13.681930 [debug] [MainThread]: running dbt with arguments {'empty': 'None', 'send_anonymous_usage_stats': 'True', 'static_parser': 'True', 'log_cache_events': 'False', 'log_format': 'default', 'log_path': '/home/aniruth/AI/DBT/DBT_Master/dbt_anirudh/logs', 'target_path': 'None', 'partial_parse': 'True', 'no_print': 'None', 'invocation_command': 'dbt test', 'warn_error': 'None', 'version_check': 'True', 'profiles_dir': '/home/aniruth/AI/DBT/DBT_Master/dbt_anirudh', 'introspect': 'True', 'write_json': 'True', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'use_experimental_parser': 'False', 'fail_fast': 'False', 'quiet': 'False', 'cache_selected_only': 'False', 'printer_width': '80', 'debug': 'False', 'indirect_selection': 'eager', 'use_colors': 'True'}
[0m16:51:14.247256 [debug] [MainThread]: Spark adapter: Setting pyhive.hive logging to ERROR
[0m16:51:14.247678 [debug] [MainThread]: Spark adapter: Setting thrift.transport logging to ERROR
[0m16:51:14.247942 [debug] [MainThread]: Spark adapter: Setting thrift.protocol logging to ERROR
[0m16:51:14.741849 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '30060d2c-7293-47e6-859e-75308edba010', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x77f418e03e00>]}
[0m16:51:14.786166 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '30060d2c-7293-47e6-859e-75308edba010', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x77f434a92810>]}
[0m16:51:14.786742 [info ] [MainThread]: Registered adapter: databricks=1.10.9
[0m16:51:14.865194 [debug] [MainThread]: checksum: 502a0dc23e9052e1ae09f7c44ee219ef7a02dfea7e7d66580d54c304c14d553b, vars: {}, profile: , target: , version: 1.10.10
[0m16:51:14.953804 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m16:51:14.954354 [debug] [MainThread]: Partial parsing: updated file: dbt_anirudh://models/bronze/properties.yml
[0m16:51:15.199929 [warn ] [MainThread]: [[33mWARNING[0m][MissingArgumentsPropertyInGenericTestDeprecation]: Deprecated
functionality
Found top-level arguments to test `generic_non_negative`. Arguments to generic
tests should be nested under the `arguments` property.`
[0m16:51:15.200368 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'deprecation', 'label': '30060d2c-7293-47e6-859e-75308edba010', 'property_': 'warn', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x77f410115880>]}
[0m16:51:15.200860 [error] [MainThread]: Encountered an error:
Compilation Error
  Invalid generic test configuration given in models/bronze/properties.yml: 
  Test arguments include "model", which is a reserved argument
  	@: UnparsedModelUpdate(original_file_path='mode...ne)
[0m16:51:15.201255 [warn ] [MainThread]: [[33mWARNING[0m][DeprecationsSummary]: Deprecated functionality
Summary of encountered deprecations:
- MissingArgumentsPropertyInGenericTestDeprecation: 1 occurrence
To see all deprecation instances instead of just the first occurrence of each,
run command again with the `--show-all-deprecations` flag. You may also need to
run with `--no-partial-parse` as some deprecations are only encountered during
parsing.
[0m16:51:15.202030 [debug] [MainThread]: Resource report: {"command_name": "test", "command_success": false, "command_wall_clock_time": 1.5644263, "process_in_blocks": "24", "process_kernel_time": 0.17633, "process_mem_max_rss": "239216", "process_out_blocks": "16", "process_user_time": 3.388133}
[0m16:51:15.202607 [debug] [MainThread]: Command `dbt test` failed at 16:51:15.202512 after 1.57 seconds
[0m16:51:15.202954 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x77f432eb3140>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x77f4114ddd30>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x77f4112fe990>]}
[0m16:51:15.203240 [debug] [MainThread]: Flushing usage events
[0m16:51:16.196315 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m16:56:24.532707 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5220c31430>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5220ec6db0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5220798fb0>]}


============================== 16:56:24.535488 | 20dccbf1-4307-40a8-bcc0-e6b911317442 ==============================
[0m16:56:24.535488 [info ] [MainThread]: Running with dbt=1.10.10
[0m16:56:24.536087 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'invocation_command': 'dbt test', 'no_print': 'None', 'profiles_dir': '/home/aniruth/AI/DBT/DBT_Master/dbt_anirudh', 'debug': 'False', 'send_anonymous_usage_stats': 'True', 'partial_parse': 'True', 'log_format': 'default', 'static_parser': 'True', 'warn_error': 'None', 'log_path': '/home/aniruth/AI/DBT/DBT_Master/dbt_anirudh/logs', 'empty': 'None', 'write_json': 'True', 'quiet': 'False', 'indirect_selection': 'eager', 'cache_selected_only': 'False', 'target_path': 'None', 'introspect': 'True', 'fail_fast': 'False', 'use_experimental_parser': 'False', 'version_check': 'True', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'use_colors': 'True', 'log_cache_events': 'False'}
[0m16:56:25.187113 [debug] [MainThread]: Spark adapter: Setting pyhive.hive logging to ERROR
[0m16:56:25.187670 [debug] [MainThread]: Spark adapter: Setting thrift.transport logging to ERROR
[0m16:56:25.188014 [debug] [MainThread]: Spark adapter: Setting thrift.protocol logging to ERROR
[0m16:56:25.790627 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '20dccbf1-4307-40a8-bcc0-e6b911317442', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f51fbf4fc80>]}
[0m16:56:25.841189 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '20dccbf1-4307-40a8-bcc0-e6b911317442', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f521bb7f8c0>]}
[0m16:56:25.841770 [info ] [MainThread]: Registered adapter: databricks=1.10.9
[0m16:56:25.921654 [debug] [MainThread]: checksum: 502a0dc23e9052e1ae09f7c44ee219ef7a02dfea7e7d66580d54c304c14d553b, vars: {}, profile: , target: , version: 1.10.10
[0m16:56:26.022211 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m16:56:26.022602 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m16:56:26.028614 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 2 unused configuration paths:
- models.dbt_anirudh.gold
- models.dbt_anirudh.silver
[0m16:56:26.066207 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '20dccbf1-4307-40a8-bcc0-e6b911317442', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f521e4db290>]}
[0m16:56:26.144674 [debug] [MainThread]: Wrote artifact WritableManifest to /home/aniruth/AI/DBT/DBT_Master/dbt_anirudh/target/manifest.json
[0m16:56:26.147244 [debug] [MainThread]: Wrote artifact SemanticManifest to /home/aniruth/AI/DBT/DBT_Master/dbt_anirudh/target/semantic_manifest.json
[0m16:56:26.162370 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '20dccbf1-4307-40a8-bcc0-e6b911317442', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f51face49b0>]}
[0m16:56:26.163251 [info ] [MainThread]: Found 6 models, 6 data tests, 6 sources, 687 macros
[0m16:56:26.163833 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '20dccbf1-4307-40a8-bcc0-e6b911317442', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f51fb3b1100>]}
[0m16:56:26.165808 [info ] [MainThread]: 
[0m16:56:26.166154 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m16:56:26.166407 [info ] [MainThread]: 
[0m16:56:26.166835 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=master) - Creating connection
[0m16:56:26.167090 [debug] [MainThread]: Acquiring new databricks connection 'master'
[0m16:56:26.172273 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=list_dbt_learning_bronze) - Creating connection
[0m16:56:26.172632 [debug] [ThreadPool]: Acquiring new databricks connection 'list_dbt_learning_bronze'
[0m16:56:26.183081 [debug] [ThreadPool]: Using databricks connection "list_dbt_learning_bronze"
[0m16:56:26.183707 [debug] [ThreadPool]: On list_dbt_learning_bronze: /* {"app": "dbt", "dbt_version": "1.10.10", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_anirudh", "target_name": "dev", "connection_name": "list_dbt_learning_bronze"} */

    
SELECT
  table_name,
  if(table_type IN ('EXTERNAL', 'MANAGED', 'MANAGED_SHALLOW_CLONE', 'EXTERNAL_SHALLOW_CLONE'), 'table', lower(table_type)) AS table_type,
  lower(data_source_format) AS file_format,
  table_owner,
  if(
    table_type IN (
      'EXTERNAL',
      'MANAGED',
      'MANAGED_SHALLOW_CLONE',
      'EXTERNAL_SHALLOW_CLONE'
    ),
    lower(table_type),
    NULL
  ) AS databricks_table_type
FROM `system`.`information_schema`.`tables`
WHERE table_catalog = 'dbt_learning' 
  AND table_schema = 'bronze'

  
[0m16:56:26.184120 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m16:56:27.525093 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f0915d-a740-106d-9bb0-3561028d62c3) - Created
[0m17:04:50.801883 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7155b5765dc0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7155b53d6e70>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7155b53d7080>]}


============================== 17:04:50.804799 | fab10918-c79a-4e7b-a6f8-8cce76518668 ==============================
[0m17:04:50.804799 [info ] [MainThread]: Running with dbt=1.10.10
[0m17:04:50.805291 [debug] [MainThread]: running dbt with arguments {'use_experimental_parser': 'False', 'send_anonymous_usage_stats': 'True', 'no_print': 'None', 'warn_error': 'None', 'debug': 'False', 'target_path': 'None', 'version_check': 'True', 'partial_parse': 'True', 'empty': 'None', 'write_json': 'True', 'log_path': '/home/aniruth/AI/DBT/DBT_Master/dbt_anirudh/logs', 'cache_selected_only': 'False', 'printer_width': '80', 'indirect_selection': 'eager', 'fail_fast': 'False', 'profiles_dir': '/home/aniruth/AI/DBT/DBT_Master/dbt_anirudh', 'static_parser': 'True', 'log_cache_events': 'False', 'introspect': 'True', 'log_format': 'default', 'invocation_command': 'dbt test', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'use_colors': 'True', 'quiet': 'False'}
[0m17:04:51.377151 [debug] [MainThread]: Spark adapter: Setting pyhive.hive logging to ERROR
[0m17:04:51.377653 [debug] [MainThread]: Spark adapter: Setting thrift.transport logging to ERROR
[0m17:04:51.377981 [debug] [MainThread]: Spark adapter: Setting thrift.protocol logging to ERROR
[0m17:04:51.898075 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'fab10918-c79a-4e7b-a6f8-8cce76518668', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x71559430e480>]}
[0m17:04:51.942111 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'fab10918-c79a-4e7b-a6f8-8cce76518668', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x71559430c050>]}
[0m17:04:51.942710 [info ] [MainThread]: Registered adapter: databricks=1.10.9
[0m17:04:52.018444 [debug] [MainThread]: checksum: 502a0dc23e9052e1ae09f7c44ee219ef7a02dfea7e7d66580d54c304c14d553b, vars: {}, profile: , target: , version: 1.10.10
[0m17:04:52.107615 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m17:04:52.107974 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m17:04:52.113373 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 2 unused configuration paths:
- models.dbt_anirudh.gold
- models.dbt_anirudh.silver
[0m17:04:52.149198 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'fab10918-c79a-4e7b-a6f8-8cce76518668', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7155940c8b90>]}
[0m17:04:52.223182 [debug] [MainThread]: Wrote artifact WritableManifest to /home/aniruth/AI/DBT/DBT_Master/dbt_anirudh/target/manifest.json
[0m17:04:52.224595 [debug] [MainThread]: Wrote artifact SemanticManifest to /home/aniruth/AI/DBT/DBT_Master/dbt_anirudh/target/semantic_manifest.json
[0m17:04:52.238003 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'fab10918-c79a-4e7b-a6f8-8cce76518668', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x71558fb60470>]}
[0m17:04:52.238394 [info ] [MainThread]: Found 6 models, 5 data tests, 6 sources, 687 macros
[0m17:04:52.238677 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'fab10918-c79a-4e7b-a6f8-8cce76518668', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7155940c9d00>]}
[0m17:04:52.240038 [info ] [MainThread]: 
[0m17:04:52.240353 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m17:04:52.240606 [info ] [MainThread]: 
[0m17:04:52.241015 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=master) - Creating connection
[0m17:04:52.241255 [debug] [MainThread]: Acquiring new databricks connection 'master'
[0m17:04:52.246307 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=list_dbt_learning_bronze) - Creating connection
[0m17:04:52.246704 [debug] [ThreadPool]: Acquiring new databricks connection 'list_dbt_learning_bronze'
[0m17:04:52.257900 [debug] [ThreadPool]: Using databricks connection "list_dbt_learning_bronze"
[0m17:04:52.258376 [debug] [ThreadPool]: On list_dbt_learning_bronze: /* {"app": "dbt", "dbt_version": "1.10.10", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_anirudh", "target_name": "dev", "connection_name": "list_dbt_learning_bronze"} */

    
SELECT
  table_name,
  if(table_type IN ('EXTERNAL', 'MANAGED', 'MANAGED_SHALLOW_CLONE', 'EXTERNAL_SHALLOW_CLONE'), 'table', lower(table_type)) AS table_type,
  lower(data_source_format) AS file_format,
  table_owner,
  if(
    table_type IN (
      'EXTERNAL',
      'MANAGED',
      'MANAGED_SHALLOW_CLONE',
      'EXTERNAL_SHALLOW_CLONE'
    ),
    lower(table_type),
    NULL
  ) AS databricks_table_type
FROM `system`.`information_schema`.`tables`
WHERE table_catalog = 'dbt_learning' 
  AND table_schema = 'bronze'

  
[0m17:04:52.258672 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m17:04:53.500955 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f0915e-d4e8-16bb-88a2-24ec25961810) - Created
[0m17:04:55.011884 [debug] [ThreadPool]: SQL status: OK in 2.750 seconds
[0m17:04:55.020574 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01f0915e-d4e8-16bb-88a2-24ec25961810, command-id=01f0915e-d520-16f2-933c-0952f0ca8df0) - Closing
[0m17:04:55.021714 [debug] [ThreadPool]: On list_dbt_learning_bronze: Close
[0m17:04:55.022234 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f0915e-d4e8-16bb-88a2-24ec25961810) - Closing
[0m17:04:55.409627 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'fab10918-c79a-4e7b-a6f8-8cce76518668', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7155b2e53350>]}
[0m17:04:55.414460 [debug] [Thread-2 (]: Began running node test.dbt_anirudh.accepted_values_bronze_store_store_name__MegaMar_Manhattan__MegaMart_Brooklyn__MegaMart_Austin__MegaMart_San_Jose__MegaMart_Toronto.b983752665
[0m17:04:55.415641 [info ] [Thread-2 (]: 1 of 5 START test accepted_values_bronze_store_store_name__MegaMar_Manhattan__MegaMart_Brooklyn__MegaMart_Austin__MegaMart_San_Jose__MegaMart_Toronto  [RUN]
[0m17:04:55.417077 [debug] [Thread-2 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=test.dbt_anirudh.accepted_values_bronze_store_store_name__MegaMar_Manhattan__MegaMart_Brooklyn__MegaMart_Austin__MegaMart_San_Jose__MegaMart_Toronto.b983752665) - Creating connection
[0m17:04:55.418027 [debug] [Thread-2 (]: Acquiring new databricks connection 'test.dbt_anirudh.accepted_values_bronze_store_store_name__MegaMar_Manhattan__MegaMart_Brooklyn__MegaMart_Austin__MegaMart_San_Jose__MegaMart_Toronto.b983752665'
[0m17:04:55.419058 [debug] [Thread-2 (]: Began compiling node test.dbt_anirudh.accepted_values_bronze_store_store_name__MegaMar_Manhattan__MegaMart_Brooklyn__MegaMart_Austin__MegaMart_San_Jose__MegaMart_Toronto.b983752665
[0m17:04:55.447458 [debug] [Thread-2 (]: Writing injected SQL for node "test.dbt_anirudh.accepted_values_bronze_store_store_name__MegaMar_Manhattan__MegaMart_Brooklyn__MegaMart_Austin__MegaMart_San_Jose__MegaMart_Toronto.b983752665"
[0m17:04:55.448048 [debug] [Thread-2 (]: Began executing node test.dbt_anirudh.accepted_values_bronze_store_store_name__MegaMar_Manhattan__MegaMart_Brooklyn__MegaMart_Austin__MegaMart_San_Jose__MegaMart_Toronto.b983752665
[0m17:04:55.461743 [debug] [Thread-2 (]: Writing runtime sql for node "test.dbt_anirudh.accepted_values_bronze_store_store_name__MegaMar_Manhattan__MegaMart_Brooklyn__MegaMart_Austin__MegaMart_San_Jose__MegaMart_Toronto.b983752665"
[0m17:04:55.462270 [debug] [Thread-2 (]: Using databricks connection "test.dbt_anirudh.accepted_values_bronze_store_store_name__MegaMar_Manhattan__MegaMart_Brooklyn__MegaMart_Austin__MegaMart_San_Jose__MegaMart_Toronto.b983752665"
[0m17:04:55.462700 [debug] [Thread-2 (]: On test.dbt_anirudh.accepted_values_bronze_store_store_name__MegaMar_Manhattan__MegaMart_Brooklyn__MegaMart_Austin__MegaMart_San_Jose__MegaMart_Toronto.b983752665: /* {"app": "dbt", "dbt_version": "1.10.10", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_anirudh", "target_name": "dev", "node_id": "test.dbt_anirudh.accepted_values_bronze_store_store_name__MegaMar_Manhattan__MegaMart_Brooklyn__MegaMart_Austin__MegaMart_San_Jose__MegaMart_Toronto.b983752665"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    

with all_values as (

    select
        store_name as value_field,
        count(*) as n_records

    from `dbt_learning`.`bronze`.`bronze_store`
    group by store_name

)

select *
from all_values
where value_field not in (
    'MegaMar Manhattan','MegaMart Brooklyn','MegaMart Austin','MegaMart San Jose','MegaMart Toronto'
)



  
  
      
    ) dbt_internal_test
[0m17:04:55.463002 [debug] [Thread-2 (]: Opening a new connection, currently in state init
[0m17:04:56.584890 [debug] [Thread-2 (]: Databricks adapter: Connection(session-id=01f0915e-d6bd-1abb-ba6c-205d8e7e3357) - Created
[0m17:05:00.585607 [debug] [Thread-2 (]: SQL status: OK in 5.120 seconds
[0m17:05:00.590662 [debug] [Thread-2 (]: Databricks adapter: Cursor(session-id=01f0915e-d6bd-1abb-ba6c-205d8e7e3357, command-id=01f0915e-d6eb-1bbb-b5bf-caf96226eafc) - Closing
[0m17:05:00.596082 [debug] [Thread-2 (]: On test.dbt_anirudh.accepted_values_bronze_store_store_name__MegaMar_Manhattan__MegaMart_Brooklyn__MegaMart_Austin__MegaMart_San_Jose__MegaMart_Toronto.b983752665: Close
[0m17:05:00.596719 [debug] [Thread-2 (]: Databricks adapter: Connection(session-id=01f0915e-d6bd-1abb-ba6c-205d8e7e3357) - Closing
[0m17:05:00.898633 [warn ] [Thread-2 (]: 1 of 5 WARN 1 accepted_values_bronze_store_store_name__MegaMar_Manhattan__MegaMart_Brooklyn__MegaMart_Austin__MegaMart_San_Jose__MegaMart_Toronto  [[33mWARN 1[0m in 5.48s]
[0m17:05:00.900241 [debug] [Thread-2 (]: Finished running node test.dbt_anirudh.accepted_values_bronze_store_store_name__MegaMar_Manhattan__MegaMart_Brooklyn__MegaMart_Austin__MegaMart_San_Jose__MegaMart_Toronto.b983752665
[0m17:05:00.901442 [debug] [Thread-2 (]: Began running node test.dbt_anirudh.non_negartive
[0m17:05:00.902605 [info ] [Thread-2 (]: 2 of 5 START test non_negartive ................................................ [RUN]
[0m17:05:00.904036 [debug] [Thread-2 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=test.dbt_anirudh.non_negartive) - Creating connection
[0m17:05:00.905049 [debug] [Thread-2 (]: Acquiring new databricks connection 'test.dbt_anirudh.non_negartive'
[0m17:05:00.905945 [debug] [Thread-2 (]: Began compiling node test.dbt_anirudh.non_negartive
[0m17:05:00.913514 [debug] [Thread-2 (]: Writing injected SQL for node "test.dbt_anirudh.non_negartive"
[0m17:05:00.914508 [debug] [Thread-2 (]: Began executing node test.dbt_anirudh.non_negartive
[0m17:05:00.918651 [debug] [Thread-2 (]: Writing runtime sql for node "test.dbt_anirudh.non_negartive"
[0m17:05:00.919569 [debug] [Thread-2 (]: Using databricks connection "test.dbt_anirudh.non_negartive"
[0m17:05:00.920127 [debug] [Thread-2 (]: On test.dbt_anirudh.non_negartive: /* {"app": "dbt", "dbt_version": "1.10.10", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_anirudh", "target_name": "dev", "node_id": "test.dbt_anirudh.non_negartive"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  SELECT
    *
FROM
    `dbt_learning`.`bronze`.`bronze_sales`
WHERE
    gross_amount < 0 AND net_amount < 0
  
  
      
    ) dbt_internal_test
[0m17:05:00.920570 [debug] [Thread-2 (]: Opening a new connection, currently in state init
[0m17:05:02.124009 [debug] [Thread-2 (]: Databricks adapter: Connection(session-id=01f0915e-da0b-1cf2-bc55-dbc342a12668) - Created
[0m17:05:03.447094 [debug] [Thread-2 (]: SQL status: OK in 2.530 seconds
[0m17:05:03.451766 [debug] [Thread-2 (]: Databricks adapter: Cursor(session-id=01f0915e-da0b-1cf2-bc55-dbc342a12668, command-id=01f0915e-da3b-1835-b693-f0316c51eb36) - Closing
[0m17:05:03.453647 [debug] [Thread-2 (]: On test.dbt_anirudh.non_negartive: Close
[0m17:05:03.454794 [debug] [Thread-2 (]: Databricks adapter: Connection(session-id=01f0915e-da0b-1cf2-bc55-dbc342a12668) - Closing
[0m17:05:03.773138 [info ] [Thread-2 (]: 2 of 5 PASS non_negartive ...................................................... [[32mPASS[0m in 2.87s]
[0m17:05:03.774865 [debug] [Thread-2 (]: Finished running node test.dbt_anirudh.non_negartive
[0m17:05:03.776003 [debug] [Thread-2 (]: Began running node test.dbt_anirudh.non_negative
[0m17:05:03.777117 [info ] [Thread-2 (]: 3 of 5 START test non_negative ................................................. [RUN]
[0m17:05:03.778522 [debug] [Thread-2 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=test.dbt_anirudh.non_negative) - Creating connection
[0m17:05:03.779631 [debug] [Thread-2 (]: Acquiring new databricks connection 'test.dbt_anirudh.non_negative'
[0m17:05:03.780831 [debug] [Thread-2 (]: Began compiling node test.dbt_anirudh.non_negative
[0m17:05:03.788544 [debug] [Thread-2 (]: Writing injected SQL for node "test.dbt_anirudh.non_negative"
[0m17:05:03.789745 [debug] [Thread-2 (]: Began executing node test.dbt_anirudh.non_negative
[0m17:05:03.793246 [debug] [Thread-2 (]: Writing runtime sql for node "test.dbt_anirudh.non_negative"
[0m17:05:03.794014 [debug] [Thread-2 (]: Using databricks connection "test.dbt_anirudh.non_negative"
[0m17:05:03.794483 [debug] [Thread-2 (]: On test.dbt_anirudh.non_negative: /* {"app": "dbt", "dbt_version": "1.10.10", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_anirudh", "target_name": "dev", "node_id": "test.dbt_anirudh.non_negative"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  SELECT
    *
FROM
    `dbt_learning`.`bronze`.`bronze_sales`
  
  
      
    ) dbt_internal_test
[0m17:05:03.794852 [debug] [Thread-2 (]: Opening a new connection, currently in state init
[0m17:05:04.865190 [debug] [Thread-2 (]: Databricks adapter: Connection(session-id=01f0915e-dbb1-1e99-a669-395554099e32) - Created
[0m17:05:05.860129 [debug] [Thread-2 (]: SQL status: OK in 2.070 seconds
[0m17:05:05.865218 [debug] [Thread-2 (]: Databricks adapter: Cursor(session-id=01f0915e-dbb1-1e99-a669-395554099e32, command-id=01f0915e-dbdc-1076-b3c9-5b00f48c88c0) - Closing
[0m17:05:05.866748 [debug] [Thread-2 (]: On test.dbt_anirudh.non_negative: Close
[0m17:05:05.867704 [debug] [Thread-2 (]: Databricks adapter: Connection(session-id=01f0915e-dbb1-1e99-a669-395554099e32) - Closing
[0m17:05:06.152356 [error] [Thread-2 (]: 3 of 5 FAIL 7173 non_negative .................................................. [[31mFAIL 7173[0m in 2.37s]
[0m17:05:06.154187 [debug] [Thread-2 (]: Finished running node test.dbt_anirudh.non_negative
[0m17:05:06.155244 [debug] [Thread-2 (]: Began running node test.dbt_anirudh.not_null_bronze_sales_sales_id.e4b1b997fb
[0m17:05:06.156566 [info ] [Thread-2 (]: 4 of 5 START test not_null_bronze_sales_sales_id ............................... [RUN]
[0m17:05:06.157900 [debug] [Thread-2 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=test.dbt_anirudh.not_null_bronze_sales_sales_id.e4b1b997fb) - Creating connection
[0m17:05:06.158860 [debug] [Thread-2 (]: Acquiring new databricks connection 'test.dbt_anirudh.not_null_bronze_sales_sales_id.e4b1b997fb'
[0m17:05:06.160025 [debug] [Thread-2 (]: Began compiling node test.dbt_anirudh.not_null_bronze_sales_sales_id.e4b1b997fb
[0m17:05:06.170335 [debug] [Thread-2 (]: Writing injected SQL for node "test.dbt_anirudh.not_null_bronze_sales_sales_id.e4b1b997fb"
[0m17:05:06.170916 [debug] [Thread-2 (]: Began executing node test.dbt_anirudh.not_null_bronze_sales_sales_id.e4b1b997fb
[0m17:05:06.173501 [debug] [Thread-2 (]: Writing runtime sql for node "test.dbt_anirudh.not_null_bronze_sales_sales_id.e4b1b997fb"
[0m17:05:06.174177 [debug] [Thread-2 (]: Using databricks connection "test.dbt_anirudh.not_null_bronze_sales_sales_id.e4b1b997fb"
[0m17:05:06.174547 [debug] [Thread-2 (]: On test.dbt_anirudh.not_null_bronze_sales_sales_id.e4b1b997fb: /* {"app": "dbt", "dbt_version": "1.10.10", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_anirudh", "target_name": "dev", "node_id": "test.dbt_anirudh.not_null_bronze_sales_sales_id.e4b1b997fb"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select sales_id
from `dbt_learning`.`bronze`.`bronze_sales`
where sales_id is null



  
  
      
    ) dbt_internal_test
[0m17:05:06.174827 [debug] [Thread-2 (]: Opening a new connection, currently in state init
[0m17:05:07.293796 [debug] [Thread-2 (]: Databricks adapter: Connection(session-id=01f0915e-dd24-1a6d-a379-8820c2c3ea24) - Created
[0m17:05:08.069574 [debug] [Thread-2 (]: SQL status: OK in 1.890 seconds
[0m17:05:08.074014 [debug] [Thread-2 (]: Databricks adapter: Cursor(session-id=01f0915e-dd24-1a6d-a379-8820c2c3ea24, command-id=01f0915e-dd50-1522-9f8a-d5064e3ef0f3) - Closing
[0m17:05:08.075608 [debug] [Thread-2 (]: On test.dbt_anirudh.not_null_bronze_sales_sales_id.e4b1b997fb: Close
[0m17:05:08.076703 [debug] [Thread-2 (]: Databricks adapter: Connection(session-id=01f0915e-dd24-1a6d-a379-8820c2c3ea24) - Closing
[0m17:05:08.390918 [info ] [Thread-2 (]: 4 of 5 PASS not_null_bronze_sales_sales_id ..................................... [[32mPASS[0m in 2.23s]
[0m17:05:08.392651 [debug] [Thread-2 (]: Finished running node test.dbt_anirudh.not_null_bronze_sales_sales_id.e4b1b997fb
[0m17:05:08.393848 [debug] [Thread-2 (]: Began running node test.dbt_anirudh.unique_bronze_sales_sales_id.3c35aa753d
[0m17:05:08.394859 [info ] [Thread-2 (]: 5 of 5 START test unique_bronze_sales_sales_id ................................. [RUN]
[0m17:05:08.396506 [debug] [Thread-2 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=test.dbt_anirudh.unique_bronze_sales_sales_id.3c35aa753d) - Creating connection
[0m17:05:08.397634 [debug] [Thread-2 (]: Acquiring new databricks connection 'test.dbt_anirudh.unique_bronze_sales_sales_id.3c35aa753d'
[0m17:05:08.398633 [debug] [Thread-2 (]: Began compiling node test.dbt_anirudh.unique_bronze_sales_sales_id.3c35aa753d
[0m17:05:08.413448 [debug] [Thread-2 (]: Writing injected SQL for node "test.dbt_anirudh.unique_bronze_sales_sales_id.3c35aa753d"
[0m17:05:08.414353 [debug] [Thread-2 (]: Began executing node test.dbt_anirudh.unique_bronze_sales_sales_id.3c35aa753d
[0m17:05:08.416851 [debug] [Thread-2 (]: Writing runtime sql for node "test.dbt_anirudh.unique_bronze_sales_sales_id.3c35aa753d"
[0m17:05:08.417371 [debug] [Thread-2 (]: Using databricks connection "test.dbt_anirudh.unique_bronze_sales_sales_id.3c35aa753d"
[0m17:05:08.417756 [debug] [Thread-2 (]: On test.dbt_anirudh.unique_bronze_sales_sales_id.3c35aa753d: /* {"app": "dbt", "dbt_version": "1.10.10", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_anirudh", "target_name": "dev", "node_id": "test.dbt_anirudh.unique_bronze_sales_sales_id.3c35aa753d"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    

select
    sales_id as unique_field,
    count(*) as n_records

from `dbt_learning`.`bronze`.`bronze_sales`
where sales_id is not null
group by sales_id
having count(*) > 1



  
  
      
    ) dbt_internal_test
[0m17:05:08.418175 [debug] [Thread-2 (]: Opening a new connection, currently in state init
[0m17:05:09.512926 [debug] [Thread-2 (]: Databricks adapter: Connection(session-id=01f0915e-de77-1382-b9e0-12084937faee) - Created
[0m17:05:10.335068 [debug] [Thread-2 (]: SQL status: OK in 1.920 seconds
[0m17:05:10.339964 [debug] [Thread-2 (]: Databricks adapter: Cursor(session-id=01f0915e-de77-1382-b9e0-12084937faee, command-id=01f0915e-dea1-1f64-8273-3d4083aed5eb) - Closing
[0m17:05:10.341672 [debug] [Thread-2 (]: On test.dbt_anirudh.unique_bronze_sales_sales_id.3c35aa753d: Close
[0m17:05:10.342429 [debug] [Thread-2 (]: Databricks adapter: Connection(session-id=01f0915e-de77-1382-b9e0-12084937faee) - Closing
[0m17:05:10.649162 [info ] [Thread-2 (]: 5 of 5 PASS unique_bronze_sales_sales_id ....................................... [[32mPASS[0m in 2.25s]
[0m17:05:10.651503 [debug] [Thread-2 (]: Finished running node test.dbt_anirudh.unique_bronze_sales_sales_id.3c35aa753d
[0m17:05:10.654266 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=master) - Creating connection
[0m17:05:10.655374 [debug] [MainThread]: Acquiring new databricks connection 'master'
[0m17:05:10.656843 [info ] [MainThread]: 
[0m17:05:10.657785 [info ] [MainThread]: Finished running 5 data tests in 0 hours 0 minutes and 18.42 seconds (18.42s).
[0m17:05:10.660556 [debug] [MainThread]: Command end result
[0m17:05:10.764651 [debug] [MainThread]: Wrote artifact WritableManifest to /home/aniruth/AI/DBT/DBT_Master/dbt_anirudh/target/manifest.json
[0m17:05:10.766046 [debug] [MainThread]: Wrote artifact SemanticManifest to /home/aniruth/AI/DBT/DBT_Master/dbt_anirudh/target/semantic_manifest.json
[0m17:05:10.770624 [debug] [MainThread]: Wrote artifact RunExecutionResult to /home/aniruth/AI/DBT/DBT_Master/dbt_anirudh/target/run_results.json
[0m17:05:10.770916 [info ] [MainThread]: 
[0m17:05:10.771178 [info ] [MainThread]: [31mCompleted with 1 error, 0 partial successes, and 1 warning:[0m
[0m17:05:10.771422 [info ] [MainThread]: 
[0m17:05:10.771731 [error] [MainThread]: [31mFailure in test non_negative (tests/non_negative.sql)[0m
[0m17:05:10.771992 [error] [MainThread]:   Got 7173 results, configured to fail if != 0
[0m17:05:10.772201 [info ] [MainThread]: 
[0m17:05:10.772454 [info ] [MainThread]:   compiled code at target/compiled/dbt_anirudh/tests/non_negative.sql
[0m17:05:10.772692 [info ] [MainThread]: 
[0m17:05:10.772958 [warn ] [MainThread]: [33mWarning in test accepted_values_bronze_store_store_name__MegaMar_Manhattan__MegaMart_Brooklyn__MegaMart_Austin__MegaMart_San_Jose__MegaMart_Toronto (models/bronze/properties.yml)[0m
[0m17:05:10.773217 [warn ] [MainThread]: Got 1 result, configured to warn if != 0
[0m17:05:10.773418 [info ] [MainThread]: 
[0m17:05:10.773692 [info ] [MainThread]:   compiled code at target/compiled/dbt_anirudh/models/bronze/properties.yml/accepted_values_bronze_store_8308937ffa06d226d8f7cff5d272d129.sql
[0m17:05:10.773913 [info ] [MainThread]: 
[0m17:05:10.774149 [info ] [MainThread]: Done. PASS=3 WARN=1 ERROR=1 SKIP=0 NO-OP=0 TOTAL=5
[0m17:05:10.774847 [debug] [MainThread]: Resource report: {"command_name": "test", "command_success": false, "command_wall_clock_time": 20.01249, "process_in_blocks": "15408", "process_kernel_time": 0.202702, "process_mem_max_rss": "245656", "process_out_blocks": "3248", "process_user_time": 4.172879}
[0m17:05:10.775203 [debug] [MainThread]: Command `dbt test` failed at 17:05:10.775133 after 20.01 seconds
[0m17:05:10.775488 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7155b76111c0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7155b537e570>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x71558c2219d0>]}
[0m17:05:10.775787 [debug] [MainThread]: Flushing usage events
[0m17:05:11.751315 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m17:07:31.458119 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7e4d6cbe3170>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7e4d6c2db0e0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7e4d6c9e8bf0>]}


============================== 17:07:31.460477 | b251adc6-7c50-4672-a569-29115496bcf4 ==============================
[0m17:07:31.460477 [info ] [MainThread]: Running with dbt=1.10.10
[0m17:07:31.461018 [debug] [MainThread]: running dbt with arguments {'write_json': 'True', 'empty': 'None', 'fail_fast': 'False', 'introspect': 'True', 'printer_width': '80', 'no_print': 'None', 'quiet': 'False', 'profiles_dir': '/home/aniruth/AI/DBT/DBT_Master/dbt_anirudh', 'static_parser': 'True', 'version_check': 'True', 'debug': 'False', 'partial_parse': 'True', 'warn_error': 'None', 'log_cache_events': 'False', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'use_colors': 'True', 'log_path': '/home/aniruth/AI/DBT/DBT_Master/dbt_anirudh/logs', 'send_anonymous_usage_stats': 'True', 'invocation_command': 'dbt test', 'cache_selected_only': 'False', 'indirect_selection': 'eager', 'log_format': 'default', 'use_experimental_parser': 'False', 'target_path': 'None'}
[0m17:07:32.076189 [debug] [MainThread]: Spark adapter: Setting pyhive.hive logging to ERROR
[0m17:07:32.076675 [debug] [MainThread]: Spark adapter: Setting thrift.transport logging to ERROR
[0m17:07:32.077067 [debug] [MainThread]: Spark adapter: Setting thrift.protocol logging to ERROR
[0m17:07:32.597532 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'b251adc6-7c50-4672-a569-29115496bcf4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7e4d47b53bc0>]}
[0m17:07:32.647901 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'b251adc6-7c50-4672-a569-29115496bcf4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7e4d6becb6e0>]}
[0m17:07:32.648549 [info ] [MainThread]: Registered adapter: databricks=1.10.9
[0m17:07:32.735316 [debug] [MainThread]: checksum: 502a0dc23e9052e1ae09f7c44ee219ef7a02dfea7e7d66580d54c304c14d553b, vars: {}, profile: , target: , version: 1.10.10
[0m17:07:32.836046 [debug] [MainThread]: Partial parsing enabled: 1 files deleted, 0 files added, 0 files changed.
[0m17:07:32.836529 [debug] [MainThread]: Partial parsing: deleted file: dbt_anirudh://tests/non_negative.sql
[0m17:07:32.903574 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 2 unused configuration paths:
- models.dbt_anirudh.gold
- models.dbt_anirudh.silver
[0m17:07:32.914578 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'b251adc6-7c50-4672-a569-29115496bcf4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7e4d46f7fd70>]}
[0m17:07:32.999991 [debug] [MainThread]: Wrote artifact WritableManifest to /home/aniruth/AI/DBT/DBT_Master/dbt_anirudh/target/manifest.json
[0m17:07:33.001473 [debug] [MainThread]: Wrote artifact SemanticManifest to /home/aniruth/AI/DBT/DBT_Master/dbt_anirudh/target/semantic_manifest.json
[0m17:07:33.014685 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'b251adc6-7c50-4672-a569-29115496bcf4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7e4d46a7f710>]}
[0m17:07:33.015092 [info ] [MainThread]: Found 6 models, 4 data tests, 6 sources, 687 macros
[0m17:07:33.015418 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'b251adc6-7c50-4672-a569-29115496bcf4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7e4d6be7aa20>]}
[0m17:07:33.016909 [info ] [MainThread]: 
[0m17:07:33.017241 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m17:07:33.017551 [info ] [MainThread]: 
[0m17:07:33.018013 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=master) - Creating connection
[0m17:07:33.018282 [debug] [MainThread]: Acquiring new databricks connection 'master'
[0m17:07:33.024179 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=list_dbt_learning_bronze) - Creating connection
[0m17:07:33.024611 [debug] [ThreadPool]: Acquiring new databricks connection 'list_dbt_learning_bronze'
[0m17:07:33.036021 [debug] [ThreadPool]: Using databricks connection "list_dbt_learning_bronze"
[0m17:07:33.036387 [debug] [ThreadPool]: On list_dbt_learning_bronze: /* {"app": "dbt", "dbt_version": "1.10.10", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_anirudh", "target_name": "dev", "connection_name": "list_dbt_learning_bronze"} */

    
SELECT
  table_name,
  if(table_type IN ('EXTERNAL', 'MANAGED', 'MANAGED_SHALLOW_CLONE', 'EXTERNAL_SHALLOW_CLONE'), 'table', lower(table_type)) AS table_type,
  lower(data_source_format) AS file_format,
  table_owner,
  if(
    table_type IN (
      'EXTERNAL',
      'MANAGED',
      'MANAGED_SHALLOW_CLONE',
      'EXTERNAL_SHALLOW_CLONE'
    ),
    lower(table_type),
    NULL
  ) AS databricks_table_type
FROM `system`.`information_schema`.`tables`
WHERE table_catalog = 'dbt_learning' 
  AND table_schema = 'bronze'

  
[0m17:07:33.036703 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m17:07:34.227152 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f0915f-34b7-1ca3-a3ac-e053a60952c8) - Created
[0m17:07:34.949625 [debug] [ThreadPool]: SQL status: OK in 1.910 seconds
[0m17:07:34.957869 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01f0915f-34b7-1ca3-a3ac-e053a60952c8, command-id=01f0915f-34eb-15dc-ae5a-dc651d324f5f) - Closing
[0m17:07:34.959220 [debug] [ThreadPool]: On list_dbt_learning_bronze: Close
[0m17:07:34.959775 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f0915f-34b7-1ca3-a3ac-e053a60952c8) - Closing
[0m17:07:35.293084 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'b251adc6-7c50-4672-a569-29115496bcf4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7e4d470eec90>]}
[0m17:07:35.298063 [debug] [Thread-2 (]: Began running node test.dbt_anirudh.accepted_values_bronze_store_store_name__MegaMar_Manhattan__MegaMart_Brooklyn__MegaMart_Austin__MegaMart_San_Jose__MegaMart_Toronto.b983752665
[0m17:07:35.299260 [info ] [Thread-2 (]: 1 of 4 START test accepted_values_bronze_store_store_name__MegaMar_Manhattan__MegaMart_Brooklyn__MegaMart_Austin__MegaMart_San_Jose__MegaMart_Toronto  [RUN]
[0m17:07:35.300594 [debug] [Thread-2 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=test.dbt_anirudh.accepted_values_bronze_store_store_name__MegaMar_Manhattan__MegaMart_Brooklyn__MegaMart_Austin__MegaMart_San_Jose__MegaMart_Toronto.b983752665) - Creating connection
[0m17:07:35.301465 [debug] [Thread-2 (]: Acquiring new databricks connection 'test.dbt_anirudh.accepted_values_bronze_store_store_name__MegaMar_Manhattan__MegaMart_Brooklyn__MegaMart_Austin__MegaMart_San_Jose__MegaMart_Toronto.b983752665'
[0m17:07:35.302332 [debug] [Thread-2 (]: Began compiling node test.dbt_anirudh.accepted_values_bronze_store_store_name__MegaMar_Manhattan__MegaMart_Brooklyn__MegaMart_Austin__MegaMart_San_Jose__MegaMart_Toronto.b983752665
[0m17:07:35.330050 [debug] [Thread-2 (]: Writing injected SQL for node "test.dbt_anirudh.accepted_values_bronze_store_store_name__MegaMar_Manhattan__MegaMart_Brooklyn__MegaMart_Austin__MegaMart_San_Jose__MegaMart_Toronto.b983752665"
[0m17:07:35.330602 [debug] [Thread-2 (]: Began executing node test.dbt_anirudh.accepted_values_bronze_store_store_name__MegaMar_Manhattan__MegaMart_Brooklyn__MegaMart_Austin__MegaMart_San_Jose__MegaMart_Toronto.b983752665
[0m17:07:35.344783 [debug] [Thread-2 (]: Writing runtime sql for node "test.dbt_anirudh.accepted_values_bronze_store_store_name__MegaMar_Manhattan__MegaMart_Brooklyn__MegaMart_Austin__MegaMart_San_Jose__MegaMart_Toronto.b983752665"
[0m17:07:35.345332 [debug] [Thread-2 (]: Using databricks connection "test.dbt_anirudh.accepted_values_bronze_store_store_name__MegaMar_Manhattan__MegaMart_Brooklyn__MegaMart_Austin__MegaMart_San_Jose__MegaMart_Toronto.b983752665"
[0m17:07:35.345713 [debug] [Thread-2 (]: On test.dbt_anirudh.accepted_values_bronze_store_store_name__MegaMar_Manhattan__MegaMart_Brooklyn__MegaMart_Austin__MegaMart_San_Jose__MegaMart_Toronto.b983752665: /* {"app": "dbt", "dbt_version": "1.10.10", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_anirudh", "target_name": "dev", "node_id": "test.dbt_anirudh.accepted_values_bronze_store_store_name__MegaMar_Manhattan__MegaMart_Brooklyn__MegaMart_Austin__MegaMart_San_Jose__MegaMart_Toronto.b983752665"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    

with all_values as (

    select
        store_name as value_field,
        count(*) as n_records

    from `dbt_learning`.`bronze`.`bronze_store`
    group by store_name

)

select *
from all_values
where value_field not in (
    'MegaMar Manhattan','MegaMart Brooklyn','MegaMart Austin','MegaMart San Jose','MegaMart Toronto'
)



  
  
      
    ) dbt_internal_test
[0m17:07:35.346021 [debug] [Thread-2 (]: Opening a new connection, currently in state init
[0m17:07:36.522930 [debug] [Thread-2 (]: Databricks adapter: Connection(session-id=01f0915f-3616-1eca-984e-5b9eebb3e8c0) - Created
[0m17:07:37.167443 [debug] [Thread-2 (]: SQL status: OK in 1.820 seconds
[0m17:07:37.171535 [debug] [Thread-2 (]: Databricks adapter: Cursor(session-id=01f0915f-3616-1eca-984e-5b9eebb3e8c0, command-id=01f0915f-3642-1e0f-b11d-9a7258ce5e5c) - Closing
[0m17:07:37.175694 [debug] [Thread-2 (]: On test.dbt_anirudh.accepted_values_bronze_store_store_name__MegaMar_Manhattan__MegaMart_Brooklyn__MegaMart_Austin__MegaMart_San_Jose__MegaMart_Toronto.b983752665: Close
[0m17:07:37.176208 [debug] [Thread-2 (]: Databricks adapter: Connection(session-id=01f0915f-3616-1eca-984e-5b9eebb3e8c0) - Closing
[0m17:07:37.490695 [warn ] [Thread-2 (]: 1 of 4 WARN 1 accepted_values_bronze_store_store_name__MegaMar_Manhattan__MegaMart_Brooklyn__MegaMart_Austin__MegaMart_San_Jose__MegaMart_Toronto  [[33mWARN 1[0m in 2.19s]
[0m17:07:37.492236 [debug] [Thread-2 (]: Finished running node test.dbt_anirudh.accepted_values_bronze_store_store_name__MegaMar_Manhattan__MegaMart_Brooklyn__MegaMart_Austin__MegaMart_San_Jose__MegaMart_Toronto.b983752665
[0m17:07:37.493259 [debug] [Thread-2 (]: Began running node test.dbt_anirudh.non_negartive
[0m17:07:37.494324 [info ] [Thread-2 (]: 2 of 4 START test non_negartive ................................................ [RUN]
[0m17:07:37.495972 [debug] [Thread-2 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=test.dbt_anirudh.non_negartive) - Creating connection
[0m17:07:37.496840 [debug] [Thread-2 (]: Acquiring new databricks connection 'test.dbt_anirudh.non_negartive'
[0m17:07:37.497956 [debug] [Thread-2 (]: Began compiling node test.dbt_anirudh.non_negartive
[0m17:07:37.504016 [debug] [Thread-2 (]: Writing injected SQL for node "test.dbt_anirudh.non_negartive"
[0m17:07:37.504624 [debug] [Thread-2 (]: Began executing node test.dbt_anirudh.non_negartive
[0m17:07:37.506321 [debug] [Thread-2 (]: Writing runtime sql for node "test.dbt_anirudh.non_negartive"
[0m17:07:37.506715 [debug] [Thread-2 (]: Using databricks connection "test.dbt_anirudh.non_negartive"
[0m17:07:37.507031 [debug] [Thread-2 (]: On test.dbt_anirudh.non_negartive: /* {"app": "dbt", "dbt_version": "1.10.10", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_anirudh", "target_name": "dev", "node_id": "test.dbt_anirudh.non_negartive"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  SELECT
    *
FROM
    `dbt_learning`.`bronze`.`bronze_sales`
WHERE
    gross_amount < 0 AND net_amount < 0
  
  
      
    ) dbt_internal_test
[0m17:07:37.507299 [debug] [Thread-2 (]: Opening a new connection, currently in state init
[0m17:07:38.642102 [debug] [Thread-2 (]: Databricks adapter: Connection(session-id=01f0915f-3757-16c9-9544-d6fc0e41803f) - Created
[0m17:07:39.203648 [debug] [Thread-2 (]: SQL status: OK in 1.700 seconds
[0m17:07:39.207961 [debug] [Thread-2 (]: Databricks adapter: Cursor(session-id=01f0915f-3757-16c9-9544-d6fc0e41803f, command-id=01f0915f-3785-1ce2-a9c7-10dfc671b79b) - Closing
[0m17:07:39.209207 [debug] [Thread-2 (]: On test.dbt_anirudh.non_negartive: Close
[0m17:07:39.210009 [debug] [Thread-2 (]: Databricks adapter: Connection(session-id=01f0915f-3757-16c9-9544-d6fc0e41803f) - Closing
[0m17:07:39.517405 [info ] [Thread-2 (]: 2 of 4 PASS non_negartive ...................................................... [[32mPASS[0m in 2.02s]
[0m17:07:39.518353 [debug] [Thread-2 (]: Finished running node test.dbt_anirudh.non_negartive
[0m17:07:39.518952 [debug] [Thread-2 (]: Began running node test.dbt_anirudh.not_null_bronze_sales_sales_id.e4b1b997fb
[0m17:07:39.519596 [info ] [Thread-2 (]: 3 of 4 START test not_null_bronze_sales_sales_id ............................... [RUN]
[0m17:07:39.520334 [debug] [Thread-2 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=test.dbt_anirudh.not_null_bronze_sales_sales_id.e4b1b997fb) - Creating connection
[0m17:07:39.520732 [debug] [Thread-2 (]: Acquiring new databricks connection 'test.dbt_anirudh.not_null_bronze_sales_sales_id.e4b1b997fb'
[0m17:07:39.521090 [debug] [Thread-2 (]: Began compiling node test.dbt_anirudh.not_null_bronze_sales_sales_id.e4b1b997fb
[0m17:07:39.531125 [debug] [Thread-2 (]: Writing injected SQL for node "test.dbt_anirudh.not_null_bronze_sales_sales_id.e4b1b997fb"
[0m17:07:39.531777 [debug] [Thread-2 (]: Began executing node test.dbt_anirudh.not_null_bronze_sales_sales_id.e4b1b997fb
[0m17:07:39.533502 [debug] [Thread-2 (]: Writing runtime sql for node "test.dbt_anirudh.not_null_bronze_sales_sales_id.e4b1b997fb"
[0m17:07:39.533958 [debug] [Thread-2 (]: Using databricks connection "test.dbt_anirudh.not_null_bronze_sales_sales_id.e4b1b997fb"
[0m17:07:39.534280 [debug] [Thread-2 (]: On test.dbt_anirudh.not_null_bronze_sales_sales_id.e4b1b997fb: /* {"app": "dbt", "dbt_version": "1.10.10", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_anirudh", "target_name": "dev", "node_id": "test.dbt_anirudh.not_null_bronze_sales_sales_id.e4b1b997fb"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select sales_id
from `dbt_learning`.`bronze`.`bronze_sales`
where sales_id is null



  
  
      
    ) dbt_internal_test
[0m17:07:39.534577 [debug] [Thread-2 (]: Opening a new connection, currently in state init
[0m17:07:40.684736 [debug] [Thread-2 (]: Databricks adapter: Connection(session-id=01f0915f-388c-1fab-8caa-2cff1a1755c8) - Created
[0m17:07:41.210606 [debug] [Thread-2 (]: SQL status: OK in 1.680 seconds
[0m17:07:41.214155 [debug] [Thread-2 (]: Databricks adapter: Cursor(session-id=01f0915f-388c-1fab-8caa-2cff1a1755c8, command-id=01f0915f-38bd-1005-984b-dbb95b2d37ca) - Closing
[0m17:07:41.215329 [debug] [Thread-2 (]: On test.dbt_anirudh.not_null_bronze_sales_sales_id.e4b1b997fb: Close
[0m17:07:41.215749 [debug] [Thread-2 (]: Databricks adapter: Connection(session-id=01f0915f-388c-1fab-8caa-2cff1a1755c8) - Closing
[0m17:07:41.533978 [info ] [Thread-2 (]: 3 of 4 PASS not_null_bronze_sales_sales_id ..................................... [[32mPASS[0m in 2.01s]
[0m17:07:41.535637 [debug] [Thread-2 (]: Finished running node test.dbt_anirudh.not_null_bronze_sales_sales_id.e4b1b997fb
[0m17:07:41.536431 [debug] [Thread-2 (]: Began running node test.dbt_anirudh.unique_bronze_sales_sales_id.3c35aa753d
[0m17:07:41.537271 [info ] [Thread-2 (]: 4 of 4 START test unique_bronze_sales_sales_id ................................. [RUN]
[0m17:07:41.538464 [debug] [Thread-2 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=test.dbt_anirudh.unique_bronze_sales_sales_id.3c35aa753d) - Creating connection
[0m17:07:41.539196 [debug] [Thread-2 (]: Acquiring new databricks connection 'test.dbt_anirudh.unique_bronze_sales_sales_id.3c35aa753d'
[0m17:07:41.539947 [debug] [Thread-2 (]: Began compiling node test.dbt_anirudh.unique_bronze_sales_sales_id.3c35aa753d
[0m17:07:41.554742 [debug] [Thread-2 (]: Writing injected SQL for node "test.dbt_anirudh.unique_bronze_sales_sales_id.3c35aa753d"
[0m17:07:41.555908 [debug] [Thread-2 (]: Began executing node test.dbt_anirudh.unique_bronze_sales_sales_id.3c35aa753d
[0m17:07:41.558474 [debug] [Thread-2 (]: Writing runtime sql for node "test.dbt_anirudh.unique_bronze_sales_sales_id.3c35aa753d"
[0m17:07:41.559041 [debug] [Thread-2 (]: Using databricks connection "test.dbt_anirudh.unique_bronze_sales_sales_id.3c35aa753d"
[0m17:07:41.559462 [debug] [Thread-2 (]: On test.dbt_anirudh.unique_bronze_sales_sales_id.3c35aa753d: /* {"app": "dbt", "dbt_version": "1.10.10", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_anirudh", "target_name": "dev", "node_id": "test.dbt_anirudh.unique_bronze_sales_sales_id.3c35aa753d"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    

select
    sales_id as unique_field,
    count(*) as n_records

from `dbt_learning`.`bronze`.`bronze_sales`
where sales_id is not null
group by sales_id
having count(*) > 1



  
  
      
    ) dbt_internal_test
[0m17:07:41.559834 [debug] [Thread-2 (]: Opening a new connection, currently in state init
[0m17:07:42.685436 [debug] [Thread-2 (]: Databricks adapter: Connection(session-id=01f0915f-39c1-1b41-bd5d-52d329b2016b) - Created
[0m17:07:43.318814 [debug] [Thread-2 (]: SQL status: OK in 1.760 seconds
[0m17:07:43.323343 [debug] [Thread-2 (]: Databricks adapter: Cursor(session-id=01f0915f-39c1-1b41-bd5d-52d329b2016b, command-id=01f0915f-39ee-158e-967b-aee5974d27ea) - Closing
[0m17:07:43.324818 [debug] [Thread-2 (]: On test.dbt_anirudh.unique_bronze_sales_sales_id.3c35aa753d: Close
[0m17:07:43.325759 [debug] [Thread-2 (]: Databricks adapter: Connection(session-id=01f0915f-39c1-1b41-bd5d-52d329b2016b) - Closing
[0m17:07:43.639148 [info ] [Thread-2 (]: 4 of 4 PASS unique_bronze_sales_sales_id ....................................... [[32mPASS[0m in 2.10s]
[0m17:07:43.640713 [debug] [Thread-2 (]: Finished running node test.dbt_anirudh.unique_bronze_sales_sales_id.3c35aa753d
[0m17:07:43.643309 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=master) - Creating connection
[0m17:07:43.644197 [debug] [MainThread]: Acquiring new databricks connection 'master'
[0m17:07:43.645450 [info ] [MainThread]: 
[0m17:07:43.646718 [info ] [MainThread]: Finished running 4 data tests in 0 hours 0 minutes and 10.63 seconds (10.63s).
[0m17:07:43.650423 [debug] [MainThread]: Command end result
[0m17:07:43.765574 [debug] [MainThread]: Wrote artifact WritableManifest to /home/aniruth/AI/DBT/DBT_Master/dbt_anirudh/target/manifest.json
[0m17:07:43.767023 [debug] [MainThread]: Wrote artifact SemanticManifest to /home/aniruth/AI/DBT/DBT_Master/dbt_anirudh/target/semantic_manifest.json
[0m17:07:43.771965 [debug] [MainThread]: Wrote artifact RunExecutionResult to /home/aniruth/AI/DBT/DBT_Master/dbt_anirudh/target/run_results.json
[0m17:07:43.772235 [info ] [MainThread]: 
[0m17:07:43.772520 [info ] [MainThread]: [33mCompleted with 1 warning:[0m
[0m17:07:43.772803 [info ] [MainThread]: 
[0m17:07:43.773099 [warn ] [MainThread]: [33mWarning in test accepted_values_bronze_store_store_name__MegaMar_Manhattan__MegaMart_Brooklyn__MegaMart_Austin__MegaMart_San_Jose__MegaMart_Toronto (models/bronze/properties.yml)[0m
[0m17:07:43.773378 [warn ] [MainThread]: Got 1 result, configured to warn if != 0
[0m17:07:43.773619 [info ] [MainThread]: 
[0m17:07:43.773903 [info ] [MainThread]:   compiled code at target/compiled/dbt_anirudh/models/bronze/properties.yml/accepted_values_bronze_store_8308937ffa06d226d8f7cff5d272d129.sql
[0m17:07:43.774127 [info ] [MainThread]: 
[0m17:07:43.774402 [info ] [MainThread]: Done. PASS=3 WARN=1 ERROR=0 SKIP=0 NO-OP=0 TOTAL=4
[0m17:07:43.775271 [debug] [MainThread]: Resource report: {"command_name": "test", "command_success": true, "command_wall_clock_time": 12.360963, "process_in_blocks": "0", "process_kernel_time": 0.184981, "process_mem_max_rss": "248252", "process_out_blocks": "4744", "process_user_time": 4.239583}
[0m17:07:43.775848 [debug] [MainThread]: Command `dbt test` succeeded at 17:07:43.775588 after 12.36 seconds
[0m17:07:43.776159 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7e4d6a04f560>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7e4d461f6ae0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7e4d461f69f0>]}
[0m17:07:43.776543 [debug] [MainThread]: Flushing usage events
[0m17:07:44.812727 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m17:08:01.709770 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7552e1523170>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7552e11ebb90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7552e13035c0>]}


============================== 17:08:01.712128 | b036439c-f4e4-4344-ab7e-796bd93bde15 ==============================
[0m17:08:01.712128 [info ] [MainThread]: Running with dbt=1.10.10
[0m17:08:01.712598 [debug] [MainThread]: running dbt with arguments {'log_format': 'default', 'send_anonymous_usage_stats': 'True', 'quiet': 'False', 'write_json': 'True', 'use_colors': 'True', 'use_experimental_parser': 'False', 'version_check': 'True', 'target_path': 'None', 'printer_width': '80', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'static_parser': 'True', 'introspect': 'True', 'invocation_command': 'dbt test', 'warn_error': 'None', 'profiles_dir': '/home/aniruth/AI/DBT/DBT_Master/dbt_anirudh', 'fail_fast': 'False', 'no_print': 'None', 'log_path': '/home/aniruth/AI/DBT/DBT_Master/dbt_anirudh/logs', 'empty': 'None', 'indirect_selection': 'eager', 'debug': 'False', 'log_cache_events': 'False', 'cache_selected_only': 'False', 'partial_parse': 'True'}
[0m17:08:02.313285 [debug] [MainThread]: Spark adapter: Setting pyhive.hive logging to ERROR
[0m17:08:02.314003 [debug] [MainThread]: Spark adapter: Setting thrift.transport logging to ERROR
[0m17:08:02.314389 [debug] [MainThread]: Spark adapter: Setting thrift.protocol logging to ERROR
[0m17:08:02.835438 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'b036439c-f4e4-4344-ab7e-796bd93bde15', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7552e2ece660>]}
[0m17:08:02.885138 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'b036439c-f4e4-4344-ab7e-796bd93bde15', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7552e2df5580>]}
[0m17:08:02.885751 [info ] [MainThread]: Registered adapter: databricks=1.10.9
[0m17:08:02.969472 [debug] [MainThread]: checksum: 502a0dc23e9052e1ae09f7c44ee219ef7a02dfea7e7d66580d54c304c14d553b, vars: {}, profile: , target: , version: 1.10.10
[0m17:08:03.067676 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m17:08:03.068060 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m17:08:03.073943 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 2 unused configuration paths:
- models.dbt_anirudh.gold
- models.dbt_anirudh.silver
[0m17:08:03.112044 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'b036439c-f4e4-4344-ab7e-796bd93bde15', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7552bb35a0f0>]}
[0m17:08:03.192457 [debug] [MainThread]: Wrote artifact WritableManifest to /home/aniruth/AI/DBT/DBT_Master/dbt_anirudh/target/manifest.json
[0m17:08:03.193885 [debug] [MainThread]: Wrote artifact SemanticManifest to /home/aniruth/AI/DBT/DBT_Master/dbt_anirudh/target/semantic_manifest.json
[0m17:08:03.206830 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'b036439c-f4e4-4344-ab7e-796bd93bde15', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7552bb200440>]}
[0m17:08:03.207226 [info ] [MainThread]: Found 6 models, 5 data tests, 6 sources, 687 macros
[0m17:08:03.207504 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'b036439c-f4e4-4344-ab7e-796bd93bde15', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7552bb688aa0>]}
[0m17:08:03.208958 [info ] [MainThread]: 
[0m17:08:03.209279 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m17:08:03.209550 [info ] [MainThread]: 
[0m17:08:03.210002 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=master) - Creating connection
[0m17:08:03.210266 [debug] [MainThread]: Acquiring new databricks connection 'master'
[0m17:08:03.215895 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=list_dbt_learning_bronze) - Creating connection
[0m17:08:03.216285 [debug] [ThreadPool]: Acquiring new databricks connection 'list_dbt_learning_bronze'
[0m17:08:03.228763 [debug] [ThreadPool]: Using databricks connection "list_dbt_learning_bronze"
[0m17:08:03.229266 [debug] [ThreadPool]: On list_dbt_learning_bronze: /* {"app": "dbt", "dbt_version": "1.10.10", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_anirudh", "target_name": "dev", "connection_name": "list_dbt_learning_bronze"} */

    
SELECT
  table_name,
  if(table_type IN ('EXTERNAL', 'MANAGED', 'MANAGED_SHALLOW_CLONE', 'EXTERNAL_SHALLOW_CLONE'), 'table', lower(table_type)) AS table_type,
  lower(data_source_format) AS file_format,
  table_owner,
  if(
    table_type IN (
      'EXTERNAL',
      'MANAGED',
      'MANAGED_SHALLOW_CLONE',
      'EXTERNAL_SHALLOW_CLONE'
    ),
    lower(table_type),
    NULL
  ) AS databricks_table_type
FROM `system`.`information_schema`.`tables`
WHERE table_catalog = 'dbt_learning' 
  AND table_schema = 'bronze'

  
[0m17:08:03.229538 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m17:08:04.358761 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f0915f-46ab-19db-a734-0f90a497b8e8) - Created
[0m17:08:04.951470 [debug] [ThreadPool]: SQL status: OK in 1.720 seconds
[0m17:08:04.957819 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01f0915f-46ab-19db-a734-0f90a497b8e8, command-id=01f0915f-46d9-107e-8bcd-e1063b8ae951) - Closing
[0m17:08:04.958919 [debug] [ThreadPool]: On list_dbt_learning_bronze: Close
[0m17:08:04.959470 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f0915f-46ab-19db-a734-0f90a497b8e8) - Closing
[0m17:08:05.251921 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'b036439c-f4e4-4344-ab7e-796bd93bde15', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7552de556060>]}
[0m17:08:05.257088 [debug] [Thread-2 (]: Began running node test.dbt_anirudh.accepted_values_bronze_store_store_name__MegaMar_Manhattan__MegaMart_Brooklyn__MegaMart_Austin__MegaMart_San_Jose__MegaMart_Toronto.b983752665
[0m17:08:05.258329 [info ] [Thread-2 (]: 1 of 5 START test accepted_values_bronze_store_store_name__MegaMar_Manhattan__MegaMart_Brooklyn__MegaMart_Austin__MegaMart_San_Jose__MegaMart_Toronto  [RUN]
[0m17:08:05.259885 [debug] [Thread-2 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=test.dbt_anirudh.accepted_values_bronze_store_store_name__MegaMar_Manhattan__MegaMart_Brooklyn__MegaMart_Austin__MegaMart_San_Jose__MegaMart_Toronto.b983752665) - Creating connection
[0m17:08:05.260991 [debug] [Thread-2 (]: Acquiring new databricks connection 'test.dbt_anirudh.accepted_values_bronze_store_store_name__MegaMar_Manhattan__MegaMart_Brooklyn__MegaMart_Austin__MegaMart_San_Jose__MegaMart_Toronto.b983752665'
[0m17:08:05.262075 [debug] [Thread-2 (]: Began compiling node test.dbt_anirudh.accepted_values_bronze_store_store_name__MegaMar_Manhattan__MegaMart_Brooklyn__MegaMart_Austin__MegaMart_San_Jose__MegaMart_Toronto.b983752665
[0m17:08:05.284355 [debug] [Thread-2 (]: Writing injected SQL for node "test.dbt_anirudh.accepted_values_bronze_store_store_name__MegaMar_Manhattan__MegaMart_Brooklyn__MegaMart_Austin__MegaMart_San_Jose__MegaMart_Toronto.b983752665"
[0m17:08:05.284895 [debug] [Thread-2 (]: Began executing node test.dbt_anirudh.accepted_values_bronze_store_store_name__MegaMar_Manhattan__MegaMart_Brooklyn__MegaMart_Austin__MegaMart_San_Jose__MegaMart_Toronto.b983752665
[0m17:08:05.298576 [debug] [Thread-2 (]: Writing runtime sql for node "test.dbt_anirudh.accepted_values_bronze_store_store_name__MegaMar_Manhattan__MegaMart_Brooklyn__MegaMart_Austin__MegaMart_San_Jose__MegaMart_Toronto.b983752665"
[0m17:08:05.299342 [debug] [Thread-2 (]: Using databricks connection "test.dbt_anirudh.accepted_values_bronze_store_store_name__MegaMar_Manhattan__MegaMart_Brooklyn__MegaMart_Austin__MegaMart_San_Jose__MegaMart_Toronto.b983752665"
[0m17:08:05.299728 [debug] [Thread-2 (]: On test.dbt_anirudh.accepted_values_bronze_store_store_name__MegaMar_Manhattan__MegaMart_Brooklyn__MegaMart_Austin__MegaMart_San_Jose__MegaMart_Toronto.b983752665: /* {"app": "dbt", "dbt_version": "1.10.10", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_anirudh", "target_name": "dev", "node_id": "test.dbt_anirudh.accepted_values_bronze_store_store_name__MegaMar_Manhattan__MegaMart_Brooklyn__MegaMart_Austin__MegaMart_San_Jose__MegaMart_Toronto.b983752665"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    

with all_values as (

    select
        store_name as value_field,
        count(*) as n_records

    from `dbt_learning`.`bronze`.`bronze_store`
    group by store_name

)

select *
from all_values
where value_field not in (
    'MegaMar Manhattan','MegaMart Brooklyn','MegaMart Austin','MegaMart San Jose','MegaMart Toronto'
)



  
  
      
    ) dbt_internal_test
[0m17:08:05.300023 [debug] [Thread-2 (]: Opening a new connection, currently in state init
[0m17:08:06.426641 [debug] [Thread-2 (]: Databricks adapter: Connection(session-id=01f0915f-47e8-1d49-bc93-ddab34b61d02) - Created
[0m17:08:06.926841 [debug] [Thread-2 (]: SQL status: OK in 1.630 seconds
[0m17:08:06.932295 [debug] [Thread-2 (]: Databricks adapter: Cursor(session-id=01f0915f-47e8-1d49-bc93-ddab34b61d02, command-id=01f0915f-4815-17a8-8a9b-ffb521aad1d8) - Closing
[0m17:08:06.938394 [debug] [Thread-2 (]: On test.dbt_anirudh.accepted_values_bronze_store_store_name__MegaMar_Manhattan__MegaMart_Brooklyn__MegaMart_Austin__MegaMart_San_Jose__MegaMart_Toronto.b983752665: Close
[0m17:08:06.939177 [debug] [Thread-2 (]: Databricks adapter: Connection(session-id=01f0915f-47e8-1d49-bc93-ddab34b61d02) - Closing
[0m17:08:07.250320 [warn ] [Thread-2 (]: 1 of 5 WARN 1 accepted_values_bronze_store_store_name__MegaMar_Manhattan__MegaMart_Brooklyn__MegaMart_Austin__MegaMart_San_Jose__MegaMart_Toronto  [[33mWARN 1[0m in 1.99s]
[0m17:08:07.252111 [debug] [Thread-2 (]: Finished running node test.dbt_anirudh.accepted_values_bronze_store_store_name__MegaMar_Manhattan__MegaMart_Brooklyn__MegaMart_Austin__MegaMart_San_Jose__MegaMart_Toronto.b983752665
[0m17:08:07.253249 [debug] [Thread-2 (]: Began running node test.dbt_anirudh.generic_non_negative_bronze_sales_gross_amount.770bebc5b1
[0m17:08:07.254429 [info ] [Thread-2 (]: 2 of 5 START test generic_non_negative_bronze_sales_gross_amount ............... [RUN]
[0m17:08:07.255862 [debug] [Thread-2 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=test.dbt_anirudh.generic_non_negative_bronze_sales_gross_amount.770bebc5b1) - Creating connection
[0m17:08:07.257005 [debug] [Thread-2 (]: Acquiring new databricks connection 'test.dbt_anirudh.generic_non_negative_bronze_sales_gross_amount.770bebc5b1'
[0m17:08:07.258024 [debug] [Thread-2 (]: Began compiling node test.dbt_anirudh.generic_non_negative_bronze_sales_gross_amount.770bebc5b1
[0m17:08:07.268531 [debug] [Thread-2 (]: Writing injected SQL for node "test.dbt_anirudh.generic_non_negative_bronze_sales_gross_amount.770bebc5b1"
[0m17:08:07.269249 [debug] [Thread-2 (]: Began executing node test.dbt_anirudh.generic_non_negative_bronze_sales_gross_amount.770bebc5b1
[0m17:08:07.271315 [debug] [Thread-2 (]: Writing runtime sql for node "test.dbt_anirudh.generic_non_negative_bronze_sales_gross_amount.770bebc5b1"
[0m17:08:07.271760 [debug] [Thread-2 (]: Using databricks connection "test.dbt_anirudh.generic_non_negative_bronze_sales_gross_amount.770bebc5b1"
[0m17:08:07.272117 [debug] [Thread-2 (]: On test.dbt_anirudh.generic_non_negative_bronze_sales_gross_amount.770bebc5b1: /* {"app": "dbt", "dbt_version": "1.10.10", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_anirudh", "target_name": "dev", "node_id": "test.dbt_anirudh.generic_non_negative_bronze_sales_gross_amount.770bebc5b1"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  

SELECT 
    *
FROM 
    `dbt_learning`.`bronze`.`bronze_sales`
WHERE
    gross_amount < 0


  
  
      
    ) dbt_internal_test
[0m17:08:07.272435 [debug] [Thread-2 (]: Opening a new connection, currently in state init
[0m17:08:08.424696 [debug] [Thread-2 (]: Databricks adapter: Connection(session-id=01f0915f-4919-1d3f-a5d9-68aa335646b8) - Created
[0m17:08:10.086611 [debug] [Thread-2 (]: SQL status: OK in 2.810 seconds
[0m17:08:10.091380 [debug] [Thread-2 (]: Databricks adapter: Cursor(session-id=01f0915f-4919-1d3f-a5d9-68aa335646b8, command-id=01f0915f-4945-1081-99a7-0a8dd012fd3b) - Closing
[0m17:08:10.093030 [debug] [Thread-2 (]: On test.dbt_anirudh.generic_non_negative_bronze_sales_gross_amount.770bebc5b1: Close
[0m17:08:10.093945 [debug] [Thread-2 (]: Databricks adapter: Connection(session-id=01f0915f-4919-1d3f-a5d9-68aa335646b8) - Closing
[0m17:08:10.405892 [info ] [Thread-2 (]: 2 of 5 PASS generic_non_negative_bronze_sales_gross_amount ..................... [[32mPASS[0m in 3.15s]
[0m17:08:10.407493 [debug] [Thread-2 (]: Finished running node test.dbt_anirudh.generic_non_negative_bronze_sales_gross_amount.770bebc5b1
[0m17:08:10.408511 [debug] [Thread-2 (]: Began running node test.dbt_anirudh.non_negartive
[0m17:08:10.409597 [info ] [Thread-2 (]: 3 of 5 START test non_negartive ................................................ [RUN]
[0m17:08:10.410717 [debug] [Thread-2 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=test.dbt_anirudh.non_negartive) - Creating connection
[0m17:08:10.411433 [debug] [Thread-2 (]: Acquiring new databricks connection 'test.dbt_anirudh.non_negartive'
[0m17:08:10.412115 [debug] [Thread-2 (]: Began compiling node test.dbt_anirudh.non_negartive
[0m17:08:10.420432 [debug] [Thread-2 (]: Writing injected SQL for node "test.dbt_anirudh.non_negartive"
[0m17:08:10.421247 [debug] [Thread-2 (]: Began executing node test.dbt_anirudh.non_negartive
[0m17:08:10.424021 [debug] [Thread-2 (]: Writing runtime sql for node "test.dbt_anirudh.non_negartive"
[0m17:08:10.424711 [debug] [Thread-2 (]: Using databricks connection "test.dbt_anirudh.non_negartive"
[0m17:08:10.425111 [debug] [Thread-2 (]: On test.dbt_anirudh.non_negartive: /* {"app": "dbt", "dbt_version": "1.10.10", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_anirudh", "target_name": "dev", "node_id": "test.dbt_anirudh.non_negartive"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  SELECT
    *
FROM
    `dbt_learning`.`bronze`.`bronze_sales`
WHERE
    gross_amount < 0 AND net_amount < 0
  
  
      
    ) dbt_internal_test
[0m17:08:10.425391 [debug] [Thread-2 (]: Opening a new connection, currently in state init
[0m17:08:11.543323 [debug] [Thread-2 (]: Databricks adapter: Connection(session-id=01f0915f-4af6-105c-bff3-0674dd21c24c) - Created
[0m17:08:12.094800 [debug] [Thread-2 (]: SQL status: OK in 1.670 seconds
[0m17:08:12.099621 [debug] [Thread-2 (]: Databricks adapter: Cursor(session-id=01f0915f-4af6-105c-bff3-0674dd21c24c, command-id=01f0915f-4b21-1ea3-90f3-4602f0fd061b) - Closing
[0m17:08:12.101404 [debug] [Thread-2 (]: On test.dbt_anirudh.non_negartive: Close
[0m17:08:12.102557 [debug] [Thread-2 (]: Databricks adapter: Connection(session-id=01f0915f-4af6-105c-bff3-0674dd21c24c) - Closing
[0m17:08:12.398908 [info ] [Thread-2 (]: 3 of 5 PASS non_negartive ...................................................... [[32mPASS[0m in 1.99s]
[0m17:08:12.400608 [debug] [Thread-2 (]: Finished running node test.dbt_anirudh.non_negartive
[0m17:08:12.401714 [debug] [Thread-2 (]: Began running node test.dbt_anirudh.not_null_bronze_sales_sales_id.e4b1b997fb
[0m17:08:12.402794 [info ] [Thread-2 (]: 4 of 5 START test not_null_bronze_sales_sales_id ............................... [RUN]
[0m17:08:12.404559 [debug] [Thread-2 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=test.dbt_anirudh.not_null_bronze_sales_sales_id.e4b1b997fb) - Creating connection
[0m17:08:12.405656 [debug] [Thread-2 (]: Acquiring new databricks connection 'test.dbt_anirudh.not_null_bronze_sales_sales_id.e4b1b997fb'
[0m17:08:12.407020 [debug] [Thread-2 (]: Began compiling node test.dbt_anirudh.not_null_bronze_sales_sales_id.e4b1b997fb
[0m17:08:12.419870 [debug] [Thread-2 (]: Writing injected SQL for node "test.dbt_anirudh.not_null_bronze_sales_sales_id.e4b1b997fb"
[0m17:08:12.420801 [debug] [Thread-2 (]: Began executing node test.dbt_anirudh.not_null_bronze_sales_sales_id.e4b1b997fb
[0m17:08:12.422982 [debug] [Thread-2 (]: Writing runtime sql for node "test.dbt_anirudh.not_null_bronze_sales_sales_id.e4b1b997fb"
[0m17:08:12.423553 [debug] [Thread-2 (]: Using databricks connection "test.dbt_anirudh.not_null_bronze_sales_sales_id.e4b1b997fb"
[0m17:08:12.423920 [debug] [Thread-2 (]: On test.dbt_anirudh.not_null_bronze_sales_sales_id.e4b1b997fb: /* {"app": "dbt", "dbt_version": "1.10.10", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_anirudh", "target_name": "dev", "node_id": "test.dbt_anirudh.not_null_bronze_sales_sales_id.e4b1b997fb"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select sales_id
from `dbt_learning`.`bronze`.`bronze_sales`
where sales_id is null



  
  
      
    ) dbt_internal_test
[0m17:08:12.424216 [debug] [Thread-2 (]: Opening a new connection, currently in state init
[0m17:08:13.509463 [debug] [Thread-2 (]: Databricks adapter: Connection(session-id=01f0915f-4c21-1dfd-a9ed-6c54751a4a8f) - Created
[0m17:08:14.034835 [debug] [Thread-2 (]: SQL status: OK in 1.610 seconds
[0m17:08:14.039335 [debug] [Thread-2 (]: Databricks adapter: Cursor(session-id=01f0915f-4c21-1dfd-a9ed-6c54751a4a8f, command-id=01f0915f-4c4c-1b6c-a2f8-dad3d241173a) - Closing
[0m17:08:14.040812 [debug] [Thread-2 (]: On test.dbt_anirudh.not_null_bronze_sales_sales_id.e4b1b997fb: Close
[0m17:08:14.041767 [debug] [Thread-2 (]: Databricks adapter: Connection(session-id=01f0915f-4c21-1dfd-a9ed-6c54751a4a8f) - Closing
[0m17:08:14.339269 [info ] [Thread-2 (]: 4 of 5 PASS not_null_bronze_sales_sales_id ..................................... [[32mPASS[0m in 1.93s]
[0m17:08:14.340911 [debug] [Thread-2 (]: Finished running node test.dbt_anirudh.not_null_bronze_sales_sales_id.e4b1b997fb
[0m17:08:14.341918 [debug] [Thread-2 (]: Began running node test.dbt_anirudh.unique_bronze_sales_sales_id.3c35aa753d
[0m17:08:14.342939 [info ] [Thread-2 (]: 5 of 5 START test unique_bronze_sales_sales_id ................................. [RUN]
[0m17:08:14.344398 [debug] [Thread-2 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=test.dbt_anirudh.unique_bronze_sales_sales_id.3c35aa753d) - Creating connection
[0m17:08:14.345456 [debug] [Thread-2 (]: Acquiring new databricks connection 'test.dbt_anirudh.unique_bronze_sales_sales_id.3c35aa753d'
[0m17:08:14.346479 [debug] [Thread-2 (]: Began compiling node test.dbt_anirudh.unique_bronze_sales_sales_id.3c35aa753d
[0m17:08:14.359641 [debug] [Thread-2 (]: Writing injected SQL for node "test.dbt_anirudh.unique_bronze_sales_sales_id.3c35aa753d"
[0m17:08:14.360639 [debug] [Thread-2 (]: Began executing node test.dbt_anirudh.unique_bronze_sales_sales_id.3c35aa753d
[0m17:08:14.363224 [debug] [Thread-2 (]: Writing runtime sql for node "test.dbt_anirudh.unique_bronze_sales_sales_id.3c35aa753d"
[0m17:08:14.363837 [debug] [Thread-2 (]: Using databricks connection "test.dbt_anirudh.unique_bronze_sales_sales_id.3c35aa753d"
[0m17:08:14.364218 [debug] [Thread-2 (]: On test.dbt_anirudh.unique_bronze_sales_sales_id.3c35aa753d: /* {"app": "dbt", "dbt_version": "1.10.10", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_anirudh", "target_name": "dev", "node_id": "test.dbt_anirudh.unique_bronze_sales_sales_id.3c35aa753d"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    

select
    sales_id as unique_field,
    count(*) as n_records

from `dbt_learning`.`bronze`.`bronze_sales`
where sales_id is not null
group by sales_id
having count(*) > 1



  
  
      
    ) dbt_internal_test
[0m17:08:14.364528 [debug] [Thread-2 (]: Opening a new connection, currently in state init
[0m17:08:15.459353 [debug] [Thread-2 (]: Databricks adapter: Connection(session-id=01f0915f-4d4b-1ce1-b4f0-500add55a348) - Created
[0m17:08:15.973391 [debug] [Thread-2 (]: SQL status: OK in 1.610 seconds
[0m17:08:15.977801 [debug] [Thread-2 (]: Databricks adapter: Cursor(session-id=01f0915f-4d4b-1ce1-b4f0-500add55a348, command-id=01f0915f-4d76-1dd7-8fec-f2da6c0bd976) - Closing
[0m17:08:15.979259 [debug] [Thread-2 (]: On test.dbt_anirudh.unique_bronze_sales_sales_id.3c35aa753d: Close
[0m17:08:15.980259 [debug] [Thread-2 (]: Databricks adapter: Connection(session-id=01f0915f-4d4b-1ce1-b4f0-500add55a348) - Closing
[0m17:08:16.292392 [info ] [Thread-2 (]: 5 of 5 PASS unique_bronze_sales_sales_id ....................................... [[32mPASS[0m in 1.95s]
[0m17:08:16.294097 [debug] [Thread-2 (]: Finished running node test.dbt_anirudh.unique_bronze_sales_sales_id.3c35aa753d
[0m17:08:16.296855 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=master) - Creating connection
[0m17:08:16.297769 [debug] [MainThread]: Acquiring new databricks connection 'master'
[0m17:08:16.298858 [info ] [MainThread]: 
[0m17:08:16.299944 [info ] [MainThread]: Finished running 5 data tests in 0 hours 0 minutes and 13.09 seconds (13.09s).
[0m17:08:16.303287 [debug] [MainThread]: Command end result
[0m17:08:16.411268 [debug] [MainThread]: Wrote artifact WritableManifest to /home/aniruth/AI/DBT/DBT_Master/dbt_anirudh/target/manifest.json
[0m17:08:16.412641 [debug] [MainThread]: Wrote artifact SemanticManifest to /home/aniruth/AI/DBT/DBT_Master/dbt_anirudh/target/semantic_manifest.json
[0m17:08:16.417068 [debug] [MainThread]: Wrote artifact RunExecutionResult to /home/aniruth/AI/DBT/DBT_Master/dbt_anirudh/target/run_results.json
[0m17:08:16.417337 [info ] [MainThread]: 
[0m17:08:16.417643 [info ] [MainThread]: [33mCompleted with 1 warning:[0m
[0m17:08:16.417942 [info ] [MainThread]: 
[0m17:08:16.418275 [warn ] [MainThread]: [33mWarning in test accepted_values_bronze_store_store_name__MegaMar_Manhattan__MegaMart_Brooklyn__MegaMart_Austin__MegaMart_San_Jose__MegaMart_Toronto (models/bronze/properties.yml)[0m
[0m17:08:16.418608 [warn ] [MainThread]: Got 1 result, configured to warn if != 0
[0m17:08:16.418867 [info ] [MainThread]: 
[0m17:08:16.419169 [info ] [MainThread]:   compiled code at target/compiled/dbt_anirudh/models/bronze/properties.yml/accepted_values_bronze_store_8308937ffa06d226d8f7cff5d272d129.sql
[0m17:08:16.419437 [info ] [MainThread]: 
[0m17:08:16.419743 [info ] [MainThread]: Done. PASS=4 WARN=1 ERROR=0 SKIP=0 NO-OP=0 TOTAL=5
[0m17:08:16.420409 [debug] [MainThread]: Resource report: {"command_name": "test", "command_success": true, "command_wall_clock_time": 14.753635, "process_in_blocks": "0", "process_kernel_time": 0.21098, "process_mem_max_rss": "245692", "process_out_blocks": "3248", "process_user_time": 4.177609}
[0m17:08:16.420762 [debug] [MainThread]: Command `dbt test` succeeded at 17:08:16.420692 after 14.75 seconds
[0m17:08:16.421037 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7552e0b85160>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7552b813d220>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7552b813ca70>]}
[0m17:08:16.421307 [debug] [MainThread]: Flushing usage events
[0m17:08:17.414945 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m13:07:16.499533 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7157344fc440>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7157341dda60>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7157335f1970>]}


============================== 13:07:16.502291 | 22f4d87b-b2ca-4cca-be3c-12a5275d6758 ==============================
[0m13:07:16.502291 [info ] [MainThread]: Running with dbt=1.10.10
[0m13:07:16.502736 [debug] [MainThread]: running dbt with arguments {'cache_selected_only': 'False', 'static_parser': 'True', 'empty': 'None', 'profiles_dir': '/home/aniruth/AI/DBT/DBT_Master/dbt_anirudh', 'write_json': 'True', 'partial_parse': 'True', 'fail_fast': 'False', 'introspect': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'log_cache_events': 'False', 'use_colors': 'True', 'log_path': '/home/aniruth/AI/DBT/DBT_Master/dbt_anirudh/logs', 'log_format': 'default', 'indirect_selection': 'eager', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'version_check': 'True', 'warn_error': 'None', 'send_anonymous_usage_stats': 'True', 'printer_width': '80', 'target_path': 'None', 'debug': 'False', 'invocation_command': 'dbt test', 'quiet': 'False'}
[0m13:07:17.073292 [debug] [MainThread]: Spark adapter: Setting pyhive.hive logging to ERROR
[0m13:07:17.073697 [debug] [MainThread]: Spark adapter: Setting thrift.transport logging to ERROR
[0m13:07:17.074037 [debug] [MainThread]: Spark adapter: Setting thrift.protocol logging to ERROR
[0m13:07:17.557057 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '22f4d87b-b2ca-4cca-be3c-12a5275d6758', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x71570e5e3d40>]}
[0m13:07:17.601462 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '22f4d87b-b2ca-4cca-be3c-12a5275d6758', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7157310c2630>]}
[0m13:07:17.601969 [info ] [MainThread]: Registered adapter: databricks=1.10.9
[0m13:07:17.681890 [debug] [MainThread]: checksum: 502a0dc23e9052e1ae09f7c44ee219ef7a02dfea7e7d66580d54c304c14d553b, vars: {}, profile: , target: , version: 1.10.10
[0m13:07:17.770479 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m13:07:17.770820 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m13:07:17.776194 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 2 unused configuration paths:
- models.dbt_anirudh.gold
- models.dbt_anirudh.silver
[0m13:07:17.811642 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '22f4d87b-b2ca-4cca-be3c-12a5275d6758', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x71570e3bca70>]}
[0m13:07:17.883663 [debug] [MainThread]: Wrote artifact WritableManifest to /home/aniruth/AI/DBT/DBT_Master/dbt_anirudh/target/manifest.json
[0m13:07:17.885231 [debug] [MainThread]: Wrote artifact SemanticManifest to /home/aniruth/AI/DBT/DBT_Master/dbt_anirudh/target/semantic_manifest.json
[0m13:07:17.898612 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '22f4d87b-b2ca-4cca-be3c-12a5275d6758', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x71570dda8380>]}
[0m13:07:17.899018 [info ] [MainThread]: Found 6 models, 5 data tests, 6 sources, 687 macros
[0m13:07:17.899329 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '22f4d87b-b2ca-4cca-be3c-12a5275d6758', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x71570e2a8aa0>]}
[0m13:07:17.900712 [info ] [MainThread]: 
[0m13:07:17.901003 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m13:07:17.901277 [info ] [MainThread]: 
[0m13:07:17.901686 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=master) - Creating connection
[0m13:07:17.901931 [debug] [MainThread]: Acquiring new databricks connection 'master'
[0m13:07:17.907081 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=list_dbt_learning_bronze) - Creating connection
[0m13:07:17.907448 [debug] [ThreadPool]: Acquiring new databricks connection 'list_dbt_learning_bronze'
[0m13:07:17.918128 [debug] [ThreadPool]: Using databricks connection "list_dbt_learning_bronze"
[0m13:07:17.918537 [debug] [ThreadPool]: On list_dbt_learning_bronze: /* {"app": "dbt", "dbt_version": "1.10.10", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_anirudh", "target_name": "dev", "connection_name": "list_dbt_learning_bronze"} */

    
SELECT
  table_name,
  if(table_type IN ('EXTERNAL', 'MANAGED', 'MANAGED_SHALLOW_CLONE', 'EXTERNAL_SHALLOW_CLONE'), 'table', lower(table_type)) AS table_type,
  lower(data_source_format) AS file_format,
  table_owner,
  if(
    table_type IN (
      'EXTERNAL',
      'MANAGED',
      'MANAGED_SHALLOW_CLONE',
      'EXTERNAL_SHALLOW_CLONE'
    ),
    lower(table_type),
    NULL
  ) AS databricks_table_type
FROM `system`.`information_schema`.`tables`
WHERE table_catalog = 'dbt_learning' 
  AND table_schema = 'bronze'

  
[0m13:07:17.918793 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m13:07:19.515771 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f092cf-f9b5-11ae-97e1-6c1590929659) - Created
[0m13:07:21.428938 [debug] [ThreadPool]: SQL status: OK in 3.510 seconds
[0m13:07:21.434866 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01f092cf-f9b5-11ae-97e1-6c1590929659, command-id=01f092cf-f9ea-12da-b71a-c3b469b00d6b) - Closing
[0m13:07:21.435817 [debug] [ThreadPool]: On list_dbt_learning_bronze: Close
[0m13:07:21.436205 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f092cf-f9b5-11ae-97e1-6c1590929659) - Closing
[0m13:07:21.835446 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '22f4d87b-b2ca-4cca-be3c-12a5275d6758', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x71570df5ade0>]}
[0m13:07:21.841438 [debug] [Thread-2 (]: Began running node test.dbt_anirudh.accepted_values_bronze_store_store_name__MegaMar_Manhattan__MegaMart_Brooklyn__MegaMart_Austin__MegaMart_San_Jose__MegaMart_Toronto.b983752665
[0m13:07:21.842485 [info ] [Thread-2 (]: 1 of 5 START test accepted_values_bronze_store_store_name__MegaMar_Manhattan__MegaMart_Brooklyn__MegaMart_Austin__MegaMart_San_Jose__MegaMart_Toronto  [RUN]
[0m13:07:21.843793 [debug] [Thread-2 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=test.dbt_anirudh.accepted_values_bronze_store_store_name__MegaMar_Manhattan__MegaMart_Brooklyn__MegaMart_Austin__MegaMart_San_Jose__MegaMart_Toronto.b983752665) - Creating connection
[0m13:07:21.844596 [debug] [Thread-2 (]: Acquiring new databricks connection 'test.dbt_anirudh.accepted_values_bronze_store_store_name__MegaMar_Manhattan__MegaMart_Brooklyn__MegaMart_Austin__MegaMart_San_Jose__MegaMart_Toronto.b983752665'
[0m13:07:21.845350 [debug] [Thread-2 (]: Began compiling node test.dbt_anirudh.accepted_values_bronze_store_store_name__MegaMar_Manhattan__MegaMart_Brooklyn__MegaMart_Austin__MegaMart_San_Jose__MegaMart_Toronto.b983752665
[0m13:07:21.867449 [debug] [Thread-2 (]: Writing injected SQL for node "test.dbt_anirudh.accepted_values_bronze_store_store_name__MegaMar_Manhattan__MegaMart_Brooklyn__MegaMart_Austin__MegaMart_San_Jose__MegaMart_Toronto.b983752665"
[0m13:07:21.868492 [debug] [Thread-2 (]: Began executing node test.dbt_anirudh.accepted_values_bronze_store_store_name__MegaMar_Manhattan__MegaMart_Brooklyn__MegaMart_Austin__MegaMart_San_Jose__MegaMart_Toronto.b983752665
[0m13:07:21.883724 [debug] [Thread-2 (]: Writing runtime sql for node "test.dbt_anirudh.accepted_values_bronze_store_store_name__MegaMar_Manhattan__MegaMart_Brooklyn__MegaMart_Austin__MegaMart_San_Jose__MegaMart_Toronto.b983752665"
[0m13:07:21.884779 [debug] [Thread-2 (]: Using databricks connection "test.dbt_anirudh.accepted_values_bronze_store_store_name__MegaMar_Manhattan__MegaMart_Brooklyn__MegaMart_Austin__MegaMart_San_Jose__MegaMart_Toronto.b983752665"
[0m13:07:21.885176 [debug] [Thread-2 (]: On test.dbt_anirudh.accepted_values_bronze_store_store_name__MegaMar_Manhattan__MegaMart_Brooklyn__MegaMart_Austin__MegaMart_San_Jose__MegaMart_Toronto.b983752665: /* {"app": "dbt", "dbt_version": "1.10.10", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_anirudh", "target_name": "dev", "node_id": "test.dbt_anirudh.accepted_values_bronze_store_store_name__MegaMar_Manhattan__MegaMart_Brooklyn__MegaMart_Austin__MegaMart_San_Jose__MegaMart_Toronto.b983752665"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    

with all_values as (

    select
        store_name as value_field,
        count(*) as n_records

    from `dbt_learning`.`bronze`.`bronze_store`
    group by store_name

)

select *
from all_values
where value_field not in (
    'MegaMar Manhattan','MegaMart Brooklyn','MegaMart Austin','MegaMart San Jose','MegaMart Toronto'
)



  
  
      
    ) dbt_internal_test
[0m13:07:21.885515 [debug] [Thread-2 (]: Opening a new connection, currently in state init
[0m13:07:23.302901 [debug] [Thread-2 (]: Databricks adapter: Connection(session-id=01f092cf-fbf8-1112-9f94-ee66d2a039c6) - Created
[0m13:07:25.313692 [debug] [Thread-2 (]: SQL status: OK in 3.430 seconds
[0m13:07:25.317076 [debug] [Thread-2 (]: Databricks adapter: Cursor(session-id=01f092cf-fbf8-1112-9f94-ee66d2a039c6, command-id=01f092cf-fc2c-1424-9ed1-d08579763eaf) - Closing
[0m13:07:25.321813 [debug] [Thread-2 (]: On test.dbt_anirudh.accepted_values_bronze_store_store_name__MegaMar_Manhattan__MegaMart_Brooklyn__MegaMart_Austin__MegaMart_San_Jose__MegaMart_Toronto.b983752665: Close
[0m13:07:25.322472 [debug] [Thread-2 (]: Databricks adapter: Connection(session-id=01f092cf-fbf8-1112-9f94-ee66d2a039c6) - Closing
[0m13:07:25.668604 [warn ] [Thread-2 (]: 1 of 5 WARN 1 accepted_values_bronze_store_store_name__MegaMar_Manhattan__MegaMart_Brooklyn__MegaMart_Austin__MegaMart_San_Jose__MegaMart_Toronto  [[33mWARN 1[0m in 3.82s]
[0m13:07:25.669240 [debug] [Thread-2 (]: Finished running node test.dbt_anirudh.accepted_values_bronze_store_store_name__MegaMar_Manhattan__MegaMart_Brooklyn__MegaMart_Austin__MegaMart_San_Jose__MegaMart_Toronto.b983752665
[0m13:07:25.669648 [debug] [Thread-2 (]: Began running node test.dbt_anirudh.generic_non_negative_bronze_sales_gross_amount.770bebc5b1
[0m13:07:25.670077 [info ] [Thread-2 (]: 2 of 5 START test generic_non_negative_bronze_sales_gross_amount ............... [RUN]
[0m13:07:25.670629 [debug] [Thread-2 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=test.dbt_anirudh.generic_non_negative_bronze_sales_gross_amount.770bebc5b1) - Creating connection
[0m13:07:25.670970 [debug] [Thread-2 (]: Acquiring new databricks connection 'test.dbt_anirudh.generic_non_negative_bronze_sales_gross_amount.770bebc5b1'
[0m13:07:25.671305 [debug] [Thread-2 (]: Began compiling node test.dbt_anirudh.generic_non_negative_bronze_sales_gross_amount.770bebc5b1
[0m13:07:25.679738 [debug] [Thread-2 (]: Writing injected SQL for node "test.dbt_anirudh.generic_non_negative_bronze_sales_gross_amount.770bebc5b1"
[0m13:07:25.680380 [debug] [Thread-2 (]: Began executing node test.dbt_anirudh.generic_non_negative_bronze_sales_gross_amount.770bebc5b1
[0m13:07:25.682125 [debug] [Thread-2 (]: Writing runtime sql for node "test.dbt_anirudh.generic_non_negative_bronze_sales_gross_amount.770bebc5b1"
[0m13:07:25.682527 [debug] [Thread-2 (]: Using databricks connection "test.dbt_anirudh.generic_non_negative_bronze_sales_gross_amount.770bebc5b1"
[0m13:07:25.682840 [debug] [Thread-2 (]: On test.dbt_anirudh.generic_non_negative_bronze_sales_gross_amount.770bebc5b1: /* {"app": "dbt", "dbt_version": "1.10.10", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_anirudh", "target_name": "dev", "node_id": "test.dbt_anirudh.generic_non_negative_bronze_sales_gross_amount.770bebc5b1"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  

SELECT 
    *
FROM 
    `dbt_learning`.`bronze`.`bronze_sales`
WHERE
    gross_amount < 0


  
  
      
    ) dbt_internal_test
[0m13:07:25.683111 [debug] [Thread-2 (]: Opening a new connection, currently in state init
[0m13:07:26.979484 [debug] [Thread-2 (]: Databricks adapter: Connection(session-id=01f092cf-fe28-1362-b259-930023749129) - Created
[0m13:07:28.296981 [debug] [Thread-2 (]: SQL status: OK in 2.610 seconds
[0m13:07:28.301288 [debug] [Thread-2 (]: Databricks adapter: Cursor(session-id=01f092cf-fe28-1362-b259-930023749129, command-id=01f092cf-fe5b-1a7c-8bf4-e3fc90ec7232) - Closing
[0m13:07:28.302835 [debug] [Thread-2 (]: On test.dbt_anirudh.generic_non_negative_bronze_sales_gross_amount.770bebc5b1: Close
[0m13:07:28.303789 [debug] [Thread-2 (]: Databricks adapter: Connection(session-id=01f092cf-fe28-1362-b259-930023749129) - Closing
[0m13:07:28.700580 [info ] [Thread-2 (]: 2 of 5 PASS generic_non_negative_bronze_sales_gross_amount ..................... [[32mPASS[0m in 3.03s]
[0m13:07:28.702271 [debug] [Thread-2 (]: Finished running node test.dbt_anirudh.generic_non_negative_bronze_sales_gross_amount.770bebc5b1
[0m13:07:28.703668 [debug] [Thread-2 (]: Began running node test.dbt_anirudh.non_negartive
[0m13:07:28.705097 [info ] [Thread-2 (]: 3 of 5 START test non_negartive ................................................ [RUN]
[0m13:07:28.707134 [debug] [Thread-2 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=test.dbt_anirudh.non_negartive) - Creating connection
[0m13:07:28.708491 [debug] [Thread-2 (]: Acquiring new databricks connection 'test.dbt_anirudh.non_negartive'
[0m13:07:28.709787 [debug] [Thread-2 (]: Began compiling node test.dbt_anirudh.non_negartive
[0m13:07:28.718366 [debug] [Thread-2 (]: Writing injected SQL for node "test.dbt_anirudh.non_negartive"
[0m13:07:28.719617 [debug] [Thread-2 (]: Began executing node test.dbt_anirudh.non_negartive
[0m13:07:28.723088 [debug] [Thread-2 (]: Writing runtime sql for node "test.dbt_anirudh.non_negartive"
[0m13:07:28.724053 [debug] [Thread-2 (]: Using databricks connection "test.dbt_anirudh.non_negartive"
[0m13:07:28.724740 [debug] [Thread-2 (]: On test.dbt_anirudh.non_negartive: /* {"app": "dbt", "dbt_version": "1.10.10", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_anirudh", "target_name": "dev", "node_id": "test.dbt_anirudh.non_negartive"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  SELECT
    *
FROM
    `dbt_learning`.`bronze`.`bronze_sales`
WHERE
    gross_amount < 0 AND net_amount < 0
  
  
      
    ) dbt_internal_test
[0m13:07:28.725221 [debug] [Thread-2 (]: Opening a new connection, currently in state init
[0m13:07:30.057142 [debug] [Thread-2 (]: Databricks adapter: Connection(session-id=01f092cf-ffff-1bc7-a0eb-39384f713f39) - Created
[0m13:07:31.459295 [debug] [Thread-2 (]: SQL status: OK in 2.730 seconds
[0m13:07:31.464305 [debug] [Thread-2 (]: Databricks adapter: Cursor(session-id=01f092cf-ffff-1bc7-a0eb-39384f713f39, command-id=01f092d0-0032-19da-89a3-b54eb86341fe) - Closing
[0m13:07:31.465696 [debug] [Thread-2 (]: On test.dbt_anirudh.non_negartive: Close
[0m13:07:31.466512 [debug] [Thread-2 (]: Databricks adapter: Connection(session-id=01f092cf-ffff-1bc7-a0eb-39384f713f39) - Closing
[0m13:07:31.867246 [info ] [Thread-2 (]: 3 of 5 PASS non_negartive ...................................................... [[32mPASS[0m in 3.16s]
[0m13:07:31.868765 [debug] [Thread-2 (]: Finished running node test.dbt_anirudh.non_negartive
[0m13:07:31.869730 [debug] [Thread-2 (]: Began running node test.dbt_anirudh.not_null_bronze_sales_sales_id.e4b1b997fb
[0m13:07:31.870883 [info ] [Thread-2 (]: 4 of 5 START test not_null_bronze_sales_sales_id ............................... [RUN]
[0m13:07:31.872289 [debug] [Thread-2 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=test.dbt_anirudh.not_null_bronze_sales_sales_id.e4b1b997fb) - Creating connection
[0m13:07:31.872868 [debug] [Thread-2 (]: Acquiring new databricks connection 'test.dbt_anirudh.not_null_bronze_sales_sales_id.e4b1b997fb'
[0m13:07:31.873568 [debug] [Thread-2 (]: Began compiling node test.dbt_anirudh.not_null_bronze_sales_sales_id.e4b1b997fb
[0m13:07:31.883573 [debug] [Thread-2 (]: Writing injected SQL for node "test.dbt_anirudh.not_null_bronze_sales_sales_id.e4b1b997fb"
[0m13:07:31.884393 [debug] [Thread-2 (]: Began executing node test.dbt_anirudh.not_null_bronze_sales_sales_id.e4b1b997fb
[0m13:07:31.887210 [debug] [Thread-2 (]: Writing runtime sql for node "test.dbt_anirudh.not_null_bronze_sales_sales_id.e4b1b997fb"
[0m13:07:31.887856 [debug] [Thread-2 (]: Using databricks connection "test.dbt_anirudh.not_null_bronze_sales_sales_id.e4b1b997fb"
[0m13:07:31.888366 [debug] [Thread-2 (]: On test.dbt_anirudh.not_null_bronze_sales_sales_id.e4b1b997fb: /* {"app": "dbt", "dbt_version": "1.10.10", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_anirudh", "target_name": "dev", "node_id": "test.dbt_anirudh.not_null_bronze_sales_sales_id.e4b1b997fb"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select sales_id
from `dbt_learning`.`bronze`.`bronze_sales`
where sales_id is null



  
  
      
    ) dbt_internal_test
[0m13:07:31.888703 [debug] [Thread-2 (]: Opening a new connection, currently in state init
[0m13:07:33.203139 [debug] [Thread-2 (]: Databricks adapter: Connection(session-id=01f092d0-01e1-1239-ad9e-148baa4da787) - Created
[0m13:07:34.224236 [debug] [Thread-2 (]: SQL status: OK in 2.340 seconds
[0m13:07:34.228708 [debug] [Thread-2 (]: Databricks adapter: Cursor(session-id=01f092d0-01e1-1239-ad9e-148baa4da787, command-id=01f092d0-0210-1824-86aa-2b2916b03c41) - Closing
[0m13:07:34.230206 [debug] [Thread-2 (]: On test.dbt_anirudh.not_null_bronze_sales_sales_id.e4b1b997fb: Close
[0m13:07:34.231189 [debug] [Thread-2 (]: Databricks adapter: Connection(session-id=01f092d0-01e1-1239-ad9e-148baa4da787) - Closing
[0m13:07:34.554546 [info ] [Thread-2 (]: 4 of 5 PASS not_null_bronze_sales_sales_id ..................................... [[32mPASS[0m in 2.68s]
[0m13:07:34.555159 [debug] [Thread-2 (]: Finished running node test.dbt_anirudh.not_null_bronze_sales_sales_id.e4b1b997fb
[0m13:07:34.555515 [debug] [Thread-2 (]: Began running node test.dbt_anirudh.unique_bronze_sales_sales_id.3c35aa753d
[0m13:07:34.555843 [info ] [Thread-2 (]: 5 of 5 START test unique_bronze_sales_sales_id ................................. [RUN]
[0m13:07:34.556300 [debug] [Thread-2 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=test.dbt_anirudh.unique_bronze_sales_sales_id.3c35aa753d) - Creating connection
[0m13:07:34.556615 [debug] [Thread-2 (]: Acquiring new databricks connection 'test.dbt_anirudh.unique_bronze_sales_sales_id.3c35aa753d'
[0m13:07:34.556897 [debug] [Thread-2 (]: Began compiling node test.dbt_anirudh.unique_bronze_sales_sales_id.3c35aa753d
[0m13:07:34.564827 [debug] [Thread-2 (]: Writing injected SQL for node "test.dbt_anirudh.unique_bronze_sales_sales_id.3c35aa753d"
[0m13:07:34.565452 [debug] [Thread-2 (]: Began executing node test.dbt_anirudh.unique_bronze_sales_sales_id.3c35aa753d
[0m13:07:34.567485 [debug] [Thread-2 (]: Writing runtime sql for node "test.dbt_anirudh.unique_bronze_sales_sales_id.3c35aa753d"
[0m13:07:34.568242 [debug] [Thread-2 (]: Using databricks connection "test.dbt_anirudh.unique_bronze_sales_sales_id.3c35aa753d"
[0m13:07:34.568827 [debug] [Thread-2 (]: On test.dbt_anirudh.unique_bronze_sales_sales_id.3c35aa753d: /* {"app": "dbt", "dbt_version": "1.10.10", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_anirudh", "target_name": "dev", "node_id": "test.dbt_anirudh.unique_bronze_sales_sales_id.3c35aa753d"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    

select
    sales_id as unique_field,
    count(*) as n_records

from `dbt_learning`.`bronze`.`bronze_sales`
where sales_id is not null
group by sales_id
having count(*) > 1



  
  
      
    ) dbt_internal_test
[0m13:07:34.569139 [debug] [Thread-2 (]: Opening a new connection, currently in state init
[0m13:07:35.876916 [debug] [Thread-2 (]: Databricks adapter: Connection(session-id=01f092d0-0379-1670-b587-7c347250e073) - Created
[0m13:07:37.214864 [debug] [Thread-2 (]: SQL status: OK in 2.650 seconds
[0m13:07:37.219375 [debug] [Thread-2 (]: Databricks adapter: Cursor(session-id=01f092d0-0379-1670-b587-7c347250e073, command-id=01f092d0-03aa-1e78-825e-cbfe1aec5746) - Closing
[0m13:07:37.221014 [debug] [Thread-2 (]: On test.dbt_anirudh.unique_bronze_sales_sales_id.3c35aa753d: Close
[0m13:07:37.221941 [debug] [Thread-2 (]: Databricks adapter: Connection(session-id=01f092d0-0379-1670-b587-7c347250e073) - Closing
[0m13:07:37.569192 [info ] [Thread-2 (]: 5 of 5 PASS unique_bronze_sales_sales_id ....................................... [[32mPASS[0m in 3.01s]
[0m13:07:37.570662 [debug] [Thread-2 (]: Finished running node test.dbt_anirudh.unique_bronze_sales_sales_id.3c35aa753d
[0m13:07:37.572980 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=master) - Creating connection
[0m13:07:37.573794 [debug] [MainThread]: Acquiring new databricks connection 'master'
[0m13:07:37.574866 [info ] [MainThread]: 
[0m13:07:37.576109 [info ] [MainThread]: Finished running 5 data tests in 0 hours 0 minutes and 19.67 seconds (19.67s).
[0m13:07:37.579516 [debug] [MainThread]: Command end result
[0m13:07:37.694077 [debug] [MainThread]: Wrote artifact WritableManifest to /home/aniruth/AI/DBT/DBT_Master/dbt_anirudh/target/manifest.json
[0m13:07:37.695981 [debug] [MainThread]: Wrote artifact SemanticManifest to /home/aniruth/AI/DBT/DBT_Master/dbt_anirudh/target/semantic_manifest.json
[0m13:07:37.701493 [debug] [MainThread]: Wrote artifact RunExecutionResult to /home/aniruth/AI/DBT/DBT_Master/dbt_anirudh/target/run_results.json
[0m13:07:37.701810 [info ] [MainThread]: 
[0m13:07:37.702100 [info ] [MainThread]: [33mCompleted with 1 warning:[0m
[0m13:07:37.702369 [info ] [MainThread]: 
[0m13:07:37.702674 [warn ] [MainThread]: [33mWarning in test accepted_values_bronze_store_store_name__MegaMar_Manhattan__MegaMart_Brooklyn__MegaMart_Austin__MegaMart_San_Jose__MegaMart_Toronto (models/bronze/properties.yml)[0m
[0m13:07:37.702951 [warn ] [MainThread]: Got 1 result, configured to warn if != 0
[0m13:07:37.703164 [info ] [MainThread]: 
[0m13:07:37.703443 [info ] [MainThread]:   compiled code at target/compiled/dbt_anirudh/models/bronze/properties.yml/accepted_values_bronze_store_8308937ffa06d226d8f7cff5d272d129.sql
[0m13:07:37.703679 [info ] [MainThread]: 
[0m13:07:37.703937 [info ] [MainThread]: Done. PASS=4 WARN=1 ERROR=0 SKIP=0 NO-OP=0 TOTAL=5
[0m13:07:37.704875 [debug] [MainThread]: Resource report: {"command_name": "test", "command_success": true, "command_wall_clock_time": 21.245584, "process_in_blocks": "2128", "process_kernel_time": 0.180529, "process_mem_max_rss": "246008", "process_out_blocks": "3248", "process_user_time": 4.099315}
[0m13:07:37.705262 [debug] [MainThread]: Command `dbt test` succeeded at 13:07:37.705175 after 21.25 seconds
[0m13:07:37.705594 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7157335f1970>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x715733649a00>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x71573364b0b0>]}
[0m13:07:37.705923 [debug] [MainThread]: Flushing usage events
[0m13:07:39.238857 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m22:36:58.939953 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x79201b09d610>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x79201becb290>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x79201b679a00>]}


============================== 22:36:58.943510 | 23bfc21d-7576-414a-a0ea-66ab3a608244 ==============================
[0m22:36:58.943510 [info ] [MainThread]: Running with dbt=1.10.10
[0m22:36:58.943943 [debug] [MainThread]: running dbt with arguments {'log_path': '/home/aniruth/AI/DBT/DBT_Master/dbt_anirudh/logs', 'profiles_dir': '/home/aniruth/AI/DBT/DBT_Master/dbt_anirudh', 'fail_fast': 'False', 'indirect_selection': 'eager', 'log_format': 'default', 'quiet': 'False', 'target_path': 'None', 'log_cache_events': 'False', 'invocation_command': 'dbt seed', 'write_json': 'True', 'no_print': 'None', 'version_check': 'True', 'cache_selected_only': 'False', 'debug': 'False', 'printer_width': '80', 'empty': 'None', 'use_experimental_parser': 'False', 'send_anonymous_usage_stats': 'True', 'partial_parse': 'True', 'introspect': 'True', 'static_parser': 'True', 'use_colors': 'True', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'warn_error': 'None'}
[0m22:36:59.582376 [debug] [MainThread]: Spark adapter: Setting pyhive.hive logging to ERROR
[0m22:36:59.582788 [debug] [MainThread]: Spark adapter: Setting thrift.transport logging to ERROR
[0m22:36:59.583063 [debug] [MainThread]: Spark adapter: Setting thrift.protocol logging to ERROR
[0m22:37:00.294059 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '23bfc21d-7576-414a-a0ea-66ab3a608244', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x791ff61ef020>]}
[0m22:37:00.339168 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '23bfc21d-7576-414a-a0ea-66ab3a608244', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x79201b3d2ea0>]}
[0m22:37:00.339833 [info ] [MainThread]: Registered adapter: databricks=1.10.9
[0m22:37:00.418014 [debug] [MainThread]: checksum: 502a0dc23e9052e1ae09f7c44ee219ef7a02dfea7e7d66580d54c304c14d553b, vars: {}, profile: , target: , version: 1.10.10
[0m22:37:00.503007 [info ] [MainThread]: Unable to do partial parsing because a project config has changed
[0m22:37:00.503446 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': '23bfc21d-7576-414a-a0ea-66ab3a608244', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x79201afc99d0>]}
[0m22:37:01.744261 [error] [MainThread]: Encountered an error:
Compilation Error
  dbt found two schema.yml entries for the same resource named bronze_store. Resources and their associated columns may only be described a single time. To fix this, remove one of the resource entries for bronze_store in this file:
   - models/bronze/properties.yml
  
[0m22:37:01.745242 [debug] [MainThread]: Resource report: {"command_name": "seed", "command_success": false, "command_wall_clock_time": 2.8451903, "process_in_blocks": "298960", "process_kernel_time": 0.238428, "process_mem_max_rss": "238556", "process_out_blocks": "16", "process_user_time": 4.485243}
[0m22:37:01.745775 [debug] [MainThread]: Command `dbt seed` failed at 22:37:01.745690 after 2.85 seconds
[0m22:37:01.746121 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x79201b3a88f0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x791ff5c39df0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7920191b1970>]}
[0m22:37:01.746422 [debug] [MainThread]: Flushing usage events
[0m22:37:02.753379 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m22:42:24.955694 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7c28b16f8680>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7c28b2e9df70>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7c28b12a3320>]}


============================== 22:42:24.959722 | 8b659cec-1854-41a6-87a0-817b46b1b6dd ==============================
[0m22:42:24.959722 [info ] [MainThread]: Running with dbt=1.10.10
[0m22:42:24.960161 [debug] [MainThread]: running dbt with arguments {'log_cache_events': 'False', 'invocation_command': 'dbt seed', 'static_parser': 'True', 'printer_width': '80', 'debug': 'False', 'introspect': 'True', 'indirect_selection': 'eager', 'no_print': 'None', 'quiet': 'False', 'empty': 'None', 'write_json': 'True', 'warn_error': 'None', 'send_anonymous_usage_stats': 'True', 'target_path': 'None', 'profiles_dir': '/home/aniruth/AI/DBT/DBT_Master/dbt_anirudh', 'cache_selected_only': 'False', 'version_check': 'True', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'use_experimental_parser': 'False', 'partial_parse': 'True', 'log_path': '/home/aniruth/AI/DBT/DBT_Master/dbt_anirudh/logs', 'fail_fast': 'False', 'use_colors': 'True', 'log_format': 'default'}
[0m22:42:25.629940 [debug] [MainThread]: Spark adapter: Setting pyhive.hive logging to ERROR
[0m22:42:25.630345 [debug] [MainThread]: Spark adapter: Setting thrift.transport logging to ERROR
[0m22:42:25.630646 [debug] [MainThread]: Spark adapter: Setting thrift.protocol logging to ERROR
[0m22:42:26.353761 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '8b659cec-1854-41a6-87a0-817b46b1b6dd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7c2890c7a480>]}
[0m22:42:26.399251 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '8b659cec-1854-41a6-87a0-817b46b1b6dd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7c2891d15e50>]}
[0m22:42:26.399803 [info ] [MainThread]: Registered adapter: databricks=1.10.9
[0m22:42:26.479930 [debug] [MainThread]: checksum: 502a0dc23e9052e1ae09f7c44ee219ef7a02dfea7e7d66580d54c304c14d553b, vars: {}, profile: , target: , version: 1.10.10
[0m22:42:26.566871 [info ] [MainThread]: Unable to do partial parsing because a project config has changed
[0m22:42:26.567261 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': '8b659cec-1854-41a6-87a0-817b46b1b6dd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7c28ae678e30>]}
[0m22:42:28.047284 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 2 unused configuration paths:
- models.dbt_anirudh.gold
- models.dbt_anirudh.silver
[0m22:42:28.055020 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '8b659cec-1854-41a6-87a0-817b46b1b6dd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7c288b540920>]}
[0m22:42:28.134490 [debug] [MainThread]: Wrote artifact WritableManifest to /home/aniruth/AI/DBT/DBT_Master/dbt_anirudh/target/manifest.json
[0m22:42:28.136475 [debug] [MainThread]: Wrote artifact SemanticManifest to /home/aniruth/AI/DBT/DBT_Master/dbt_anirudh/target/semantic_manifest.json
[0m22:42:28.145989 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '8b659cec-1854-41a6-87a0-817b46b1b6dd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7c2889c957f0>]}
[0m22:42:28.146413 [info ] [MainThread]: Found 6 models, 5 data tests, 1 seed, 6 sources, 687 macros
[0m22:42:28.146751 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '8b659cec-1854-41a6-87a0-817b46b1b6dd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7c2889f58410>]}
[0m22:42:28.148060 [info ] [MainThread]: 
[0m22:42:28.148394 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m22:42:28.148678 [info ] [MainThread]: 
[0m22:42:28.149115 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=master) - Creating connection
[0m22:42:28.149417 [debug] [MainThread]: Acquiring new databricks connection 'master'
[0m22:42:28.150134 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=list_dbt_learning) - Creating connection
[0m22:42:28.150463 [debug] [ThreadPool]: Acquiring new databricks connection 'list_dbt_learning'
[0m22:42:28.150719 [debug] [ThreadPool]: Using databricks connection "list_dbt_learning"
[0m22:42:28.150954 [debug] [ThreadPool]: On list_dbt_learning: GetSchemas(database=dbt_learning, schema=None)
[0m22:42:28.151167 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m22:42:29.691043 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f09320-5345-14eb-978b-e3d81e5e1a19) - Created
[0m22:43:31.666622 [debug] [ThreadPool]: SQL status: OK in 63.520 seconds
[0m22:43:31.669770 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01f09320-5345-14eb-978b-e3d81e5e1a19, command-id=01f09320-778b-14ba-939a-e8ae8e38131e) - Closing
[0m22:43:31.670724 [debug] [ThreadPool]: On list_dbt_learning: Close
[0m22:43:31.671304 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f09320-5345-14eb-978b-e3d81e5e1a19) - Closing
[0m22:43:32.009502 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=list_dbt_learning_bronze) - Creating connection
[0m22:43:32.010145 [debug] [ThreadPool]: Acquiring new databricks connection 'list_dbt_learning_bronze'
[0m22:43:32.028996 [debug] [ThreadPool]: Using databricks connection "list_dbt_learning_bronze"
[0m22:43:32.029408 [debug] [ThreadPool]: On list_dbt_learning_bronze: /* {"app": "dbt", "dbt_version": "1.10.10", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_anirudh", "target_name": "dev", "connection_name": "list_dbt_learning_bronze"} */

    
SELECT
  table_name,
  if(table_type IN ('EXTERNAL', 'MANAGED', 'MANAGED_SHALLOW_CLONE', 'EXTERNAL_SHALLOW_CLONE'), 'table', lower(table_type)) AS table_type,
  lower(data_source_format) AS file_format,
  table_owner,
  if(
    table_type IN (
      'EXTERNAL',
      'MANAGED',
      'MANAGED_SHALLOW_CLONE',
      'EXTERNAL_SHALLOW_CLONE'
    ),
    lower(table_type),
    NULL
  ) AS databricks_table_type
FROM `system`.`information_schema`.`tables`
WHERE table_catalog = 'dbt_learning' 
  AND table_schema = 'bronze'

  
[0m22:43:32.029660 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m22:43:33.302292 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f09320-7949-1a87-9a7d-4c141bb5a5cf) - Created
[0m22:43:36.100025 [debug] [ThreadPool]: SQL status: OK in 4.070 seconds
[0m22:43:36.111624 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01f09320-7949-1a87-9a7d-4c141bb5a5cf, command-id=01f09320-7978-1d13-9357-3cc0681c5002) - Closing
[0m22:43:36.113123 [debug] [ThreadPool]: On list_dbt_learning_bronze: Close
[0m22:43:36.113969 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f09320-7949-1a87-9a7d-4c141bb5a5cf) - Closing
[0m22:43:36.433101 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '8b659cec-1854-41a6-87a0-817b46b1b6dd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7c2889e19c70>]}
[0m22:43:36.438732 [debug] [Thread-3 (]: Began running node seed.dbt_anirudh.lookup
[0m22:43:36.440004 [info ] [Thread-3 (]: 1 of 1 START seed file bronze.lookup ........................................... [RUN]
[0m22:43:36.441390 [debug] [Thread-3 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=seed.dbt_anirudh.lookup) - Creating connection
[0m22:43:36.442308 [debug] [Thread-3 (]: Acquiring new databricks connection 'seed.dbt_anirudh.lookup'
[0m22:43:36.443122 [debug] [Thread-3 (]: Began compiling node seed.dbt_anirudh.lookup
[0m22:43:36.443924 [debug] [Thread-3 (]: Began executing node seed.dbt_anirudh.lookup
[0m22:43:36.452527 [warn ] [Thread-3 (]: [[33mWARNING[0m]: Use revamped materializations based on separating create and insert.  This allows more performant column comments, as well as new column features.
You may opt into the new behavior sooner by setting `flags.use_materialization_v2` to `True` in `dbt_project.yml`.
Visit https://docs.getdbt.com/reference/global-configs/behavior-changes for more information.
[0m22:43:36.453292 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'BehaviorChangeEvent', 'label': '8b659cec-1854-41a6-87a0-817b46b1b6dd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7c2889b8d3d0>]}
[0m22:43:36.472967 [debug] [Thread-3 (]: Compilation Error in seed lookup (seeds/lookup.csv)
  Row 0 has 4 values, but Table only has 3 columns.
  
  > in macro create_seed_v1 (macros/materializations/seeds/seeds.sql)
  > called by macro materialization_seed_databricks (macros/materializations/seeds/seeds.sql)
  > called by seed lookup (seeds/lookup.csv)
[0m22:43:36.474566 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '8b659cec-1854-41a6-87a0-817b46b1b6dd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7c2889ed18e0>]}
[0m22:43:36.475117 [error] [Thread-3 (]: 1 of 1 ERROR loading seed file bronze.lookup ................................... [[31mERROR[0m in 0.03s]
[0m22:43:36.475621 [debug] [Thread-3 (]: Finished running node seed.dbt_anirudh.lookup
[0m22:43:36.476163 [debug] [Thread-6 (]: Marking all children of 'seed.dbt_anirudh.lookup' to be skipped because of status 'error'.  Reason: Compilation Error in seed lookup (seeds/lookup.csv)
  Row 0 has 4 values, but Table only has 3 columns.
  
  > in macro create_seed_v1 (macros/materializations/seeds/seeds.sql)
  > called by macro materialization_seed_databricks (macros/materializations/seeds/seeds.sql)
  > called by seed lookup (seeds/lookup.csv).
[0m22:43:36.477443 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=master) - Creating connection
[0m22:43:36.477724 [debug] [MainThread]: Acquiring new databricks connection 'master'
[0m22:43:36.478075 [info ] [MainThread]: 
[0m22:43:36.478347 [info ] [MainThread]: Finished running 1 seed in 0 hours 1 minutes and 8.33 seconds (68.33s).
[0m22:43:36.478935 [debug] [MainThread]: Command end result
[0m22:43:36.499658 [debug] [MainThread]: Wrote artifact WritableManifest to /home/aniruth/AI/DBT/DBT_Master/dbt_anirudh/target/manifest.json
[0m22:43:36.502596 [debug] [MainThread]: Wrote artifact SemanticManifest to /home/aniruth/AI/DBT/DBT_Master/dbt_anirudh/target/semantic_manifest.json
[0m22:43:36.506975 [debug] [MainThread]: Wrote artifact RunExecutionResult to /home/aniruth/AI/DBT/DBT_Master/dbt_anirudh/target/run_results.json
[0m22:43:36.507258 [info ] [MainThread]: 
[0m22:43:36.507614 [info ] [MainThread]: [31mCompleted with 1 error, 0 partial successes, and 0 warnings:[0m
[0m22:43:36.507895 [info ] [MainThread]: 
[0m22:43:36.508216 [error] [MainThread]: [31mFailure in seed lookup (seeds/lookup.csv)[0m
[0m22:43:36.508523 [error] [MainThread]:   Compilation Error in seed lookup (seeds/lookup.csv)
  Row 0 has 4 values, but Table only has 3 columns.
  
  > in macro create_seed_v1 (macros/materializations/seeds/seeds.sql)
  > called by macro materialization_seed_databricks (macros/materializations/seeds/seeds.sql)
  > called by seed lookup (seeds/lookup.csv)
[0m22:43:36.508761 [info ] [MainThread]: 
[0m22:43:36.509016 [info ] [MainThread]: Done. PASS=0 WARN=0 ERROR=1 SKIP=0 NO-OP=0 TOTAL=1
[0m22:43:36.509938 [debug] [MainThread]: Resource report: {"command_name": "seed", "command_success": false, "command_wall_clock_time": 71.597855, "process_in_blocks": "309680", "process_kernel_time": 0.287649, "process_mem_max_rss": "253224", "process_out_blocks": "4688", "process_user_time": 5.169673}
[0m22:43:36.510290 [debug] [MainThread]: Command `dbt seed` failed at 22:43:36.510220 after 71.60 seconds
[0m22:43:36.510599 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7c28b0607680>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7c288b051910>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7c28b0adf920>]}
[0m22:43:36.510870 [debug] [MainThread]: Flushing usage events
[0m22:43:37.780053 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m22:48:13.187205 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7c2bed483aa0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7c2bed3cb080>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7c2bed3ca5a0>]}


============================== 22:48:13.193011 | 41038093-8886-4752-bfc7-e2641d89c90c ==============================
[0m22:48:13.193011 [info ] [MainThread]: Running with dbt=1.10.10
[0m22:48:13.193977 [debug] [MainThread]: running dbt with arguments {'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'send_anonymous_usage_stats': 'True', 'log_cache_events': 'False', 'debug': 'False', 'log_format': 'default', 'indirect_selection': 'eager', 'warn_error': 'None', 'no_print': 'None', 'quiet': 'False', 'fail_fast': 'False', 'use_experimental_parser': 'False', 'empty': 'None', 'printer_width': '80', 'version_check': 'True', 'cache_selected_only': 'False', 'log_path': '/home/aniruth/AI/DBT/DBT_Master/dbt_anirudh/logs', 'introspect': 'True', 'target_path': 'None', 'invocation_command': 'dbt seed', 'profiles_dir': '/home/aniruth/AI/DBT/DBT_Master/dbt_anirudh', 'static_parser': 'True', 'write_json': 'True', 'use_colors': 'True', 'partial_parse': 'True'}
[0m22:48:14.029708 [debug] [MainThread]: Spark adapter: Setting pyhive.hive logging to ERROR
[0m22:48:14.030358 [debug] [MainThread]: Spark adapter: Setting thrift.transport logging to ERROR
[0m22:48:14.030907 [debug] [MainThread]: Spark adapter: Setting thrift.protocol logging to ERROR
[0m22:48:15.039282 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '41038093-8886-4752-bfc7-e2641d89c90c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7c2bc7af2480>]}
[0m22:48:15.092330 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '41038093-8886-4752-bfc7-e2641d89c90c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7c2bc79521b0>]}
[0m22:48:15.092965 [info ] [MainThread]: Registered adapter: databricks=1.10.9
[0m22:48:15.273786 [debug] [MainThread]: checksum: 502a0dc23e9052e1ae09f7c44ee219ef7a02dfea7e7d66580d54c304c14d553b, vars: {}, profile: , target: , version: 1.10.10
[0m22:48:15.419249 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m22:48:15.419832 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m22:48:15.429464 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 2 unused configuration paths:
- models.dbt_anirudh.silver
- models.dbt_anirudh.gold
[0m22:48:15.503426 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '41038093-8886-4752-bfc7-e2641d89c90c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7c2bcc12b5c0>]}
[0m22:48:15.658672 [debug] [MainThread]: Wrote artifact WritableManifest to /home/aniruth/AI/DBT/DBT_Master/dbt_anirudh/target/manifest.json
[0m22:48:15.664412 [debug] [MainThread]: Wrote artifact SemanticManifest to /home/aniruth/AI/DBT/DBT_Master/dbt_anirudh/target/semantic_manifest.json
[0m22:48:15.685712 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '41038093-8886-4752-bfc7-e2641d89c90c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7c2bc701eb70>]}
[0m22:48:15.686763 [info ] [MainThread]: Found 6 models, 5 data tests, 1 seed, 6 sources, 687 macros
[0m22:48:15.687310 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '41038093-8886-4752-bfc7-e2641d89c90c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7c2bc79aca70>]}
[0m22:48:15.689699 [info ] [MainThread]: 
[0m22:48:15.690362 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m22:48:15.690773 [info ] [MainThread]: 
[0m22:48:15.691601 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=master) - Creating connection
[0m22:48:15.692042 [debug] [MainThread]: Acquiring new databricks connection 'master'
[0m22:48:15.694623 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=list_dbt_learning) - Creating connection
[0m22:48:15.695106 [debug] [ThreadPool]: Acquiring new databricks connection 'list_dbt_learning'
[0m22:48:15.695502 [debug] [ThreadPool]: Using databricks connection "list_dbt_learning"
[0m22:48:15.695781 [debug] [ThreadPool]: On list_dbt_learning: GetSchemas(database=dbt_learning, schema=None)
[0m22:48:15.696008 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m22:48:17.008449 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f09321-2265-1104-950a-0e69dc3db6aa) - Created
[0m22:48:17.653081 [debug] [ThreadPool]: SQL status: OK in 1.950 seconds
[0m22:48:17.663454 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01f09321-2265-1104-950a-0e69dc3db6aa, command-id=01f09321-2293-1cb0-a9e4-c3ba1503b44c) - Closing
[0m22:48:17.664647 [debug] [ThreadPool]: On list_dbt_learning: Close
[0m22:48:17.665951 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f09321-2265-1104-950a-0e69dc3db6aa) - Closing
[0m22:48:18.031055 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=list_dbt_learning_bronze) - Creating connection
[0m22:48:18.033017 [debug] [ThreadPool]: Acquiring new databricks connection 'list_dbt_learning_bronze'
[0m22:48:18.063322 [debug] [ThreadPool]: Using databricks connection "list_dbt_learning_bronze"
[0m22:48:18.064284 [debug] [ThreadPool]: On list_dbt_learning_bronze: /* {"app": "dbt", "dbt_version": "1.10.10", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_anirudh", "target_name": "dev", "connection_name": "list_dbt_learning_bronze"} */

    
SELECT
  table_name,
  if(table_type IN ('EXTERNAL', 'MANAGED', 'MANAGED_SHALLOW_CLONE', 'EXTERNAL_SHALLOW_CLONE'), 'table', lower(table_type)) AS table_type,
  lower(data_source_format) AS file_format,
  table_owner,
  if(
    table_type IN (
      'EXTERNAL',
      'MANAGED',
      'MANAGED_SHALLOW_CLONE',
      'EXTERNAL_SHALLOW_CLONE'
    ),
    lower(table_type),
    NULL
  ) AS databricks_table_type
FROM `system`.`information_schema`.`tables`
WHERE table_catalog = 'dbt_learning' 
  AND table_schema = 'bronze'

  
[0m22:48:18.064980 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m22:48:19.287551 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f09321-23c1-16bd-b72f-c0920a858419) - Created
[0m22:48:20.174846 [debug] [ThreadPool]: SQL status: OK in 2.110 seconds
[0m22:48:20.201002 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01f09321-23c1-16bd-b72f-c0920a858419, command-id=01f09321-23ef-17f4-b421-4cee9bd695b8) - Closing
[0m22:48:20.202645 [debug] [ThreadPool]: On list_dbt_learning_bronze: Close
[0m22:48:20.203380 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f09321-23c1-16bd-b72f-c0920a858419) - Closing
[0m22:48:20.501141 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '41038093-8886-4752-bfc7-e2641d89c90c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7c2bc786bd70>]}
[0m22:48:20.507934 [debug] [Thread-3 (]: Began running node seed.dbt_anirudh.lookup
[0m22:48:20.509260 [info ] [Thread-3 (]: 1 of 1 START seed file bronze.lookup ........................................... [RUN]
[0m22:48:20.510674 [debug] [Thread-3 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=seed.dbt_anirudh.lookup) - Creating connection
[0m22:48:20.511626 [debug] [Thread-3 (]: Acquiring new databricks connection 'seed.dbt_anirudh.lookup'
[0m22:48:20.512519 [debug] [Thread-3 (]: Began compiling node seed.dbt_anirudh.lookup
[0m22:48:20.513380 [debug] [Thread-3 (]: Began executing node seed.dbt_anirudh.lookup
[0m22:48:20.524115 [warn ] [Thread-3 (]: [[33mWARNING[0m]: Use revamped materializations based on separating create and insert.  This allows more performant column comments, as well as new column features.
You may opt into the new behavior sooner by setting `flags.use_materialization_v2` to `True` in `dbt_project.yml`.
Visit https://docs.getdbt.com/reference/global-configs/behavior-changes for more information.
[0m22:48:20.525432 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'BehaviorChangeEvent', 'label': '41038093-8886-4752-bfc7-e2641d89c90c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7c2bc70a4d40>]}
[0m22:48:20.570680 [debug] [Thread-3 (]: Using databricks connection "seed.dbt_anirudh.lookup"
[0m22:48:20.571135 [debug] [Thread-3 (]: On seed.dbt_anirudh.lookup: /* {"app": "dbt", "dbt_version": "1.10.10", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_anirudh", "target_name": "dev", "node_id": "seed.dbt_anirudh.lookup"} */

    create  table `dbt_learning`.`bronze`.`lookup` (`customer_id` bigint ,`customer_name` string ,`customer_mail` string )
    
  using delta
    
    
    
    
    
  
[0m22:48:20.571478 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m22:48:21.713516 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f09321-2534-1908-bd02-492cc327f16b) - Created
[0m22:48:25.848142 [debug] [Thread-3 (]: SQL status: OK in 5.280 seconds
[0m22:48:25.850538 [debug] [Thread-3 (]: Databricks adapter: Cursor(session-id=01f09321-2534-1908-bd02-492cc327f16b, command-id=01f09321-2561-1822-ad97-a82a8e109861) - Closing
[0m22:48:25.866833 [debug] [Thread-3 (]: Using databricks connection "seed.dbt_anirudh.lookup"
[0m22:48:25.867241 [debug] [Thread-3 (]: On seed.dbt_anirudh.lookup: 
          insert overwrite `dbt_learning`.`bronze`.`lookup` values
          (%s,%s,%s),(%s,%s,%s),(%s,%s,%s)
      ...
[0m22:48:31.246539 [debug] [Thread-3 (]: SQL status: OK in 5.380 seconds
[0m22:48:31.247729 [debug] [Thread-3 (]: Databricks adapter: Cursor(session-id=01f09321-2534-1908-bd02-492cc327f16b, command-id=01f09321-27db-1e64-9093-2b1579367232) - Closing
[0m22:48:31.258617 [debug] [Thread-3 (]: Writing runtime SQL for node "seed.dbt_anirudh.lookup"
[0m22:48:31.271680 [debug] [Thread-3 (]: On seed.dbt_anirudh.lookup: Close
[0m22:48:31.272100 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f09321-2534-1908-bd02-492cc327f16b) - Closing
[0m22:48:31.587055 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '41038093-8886-4752-bfc7-e2641d89c90c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7c2beec056a0>]}
[0m22:48:31.588705 [info ] [Thread-3 (]: 1 of 1 OK loaded seed file bronze.lookup ....................................... [[32mINSERT 3[0m in 11.07s]
[0m22:48:31.590528 [debug] [Thread-3 (]: Finished running node seed.dbt_anirudh.lookup
[0m22:48:31.592858 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=master) - Creating connection
[0m22:48:31.593784 [debug] [MainThread]: Acquiring new databricks connection 'master'
[0m22:48:31.594932 [info ] [MainThread]: 
[0m22:48:31.596037 [info ] [MainThread]: Finished running 1 seed in 0 hours 0 minutes and 15.90 seconds (15.90s).
[0m22:48:31.597786 [debug] [MainThread]: Command end result
[0m22:48:31.632530 [debug] [MainThread]: Wrote artifact WritableManifest to /home/aniruth/AI/DBT/DBT_Master/dbt_anirudh/target/manifest.json
[0m22:48:31.635792 [debug] [MainThread]: Wrote artifact SemanticManifest to /home/aniruth/AI/DBT/DBT_Master/dbt_anirudh/target/semantic_manifest.json
[0m22:48:31.641868 [debug] [MainThread]: Wrote artifact RunExecutionResult to /home/aniruth/AI/DBT/DBT_Master/dbt_anirudh/target/run_results.json
[0m22:48:31.642197 [info ] [MainThread]: 
[0m22:48:31.642523 [info ] [MainThread]: [32mCompleted successfully[0m
[0m22:48:31.642766 [info ] [MainThread]: 
[0m22:48:31.643041 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 NO-OP=0 TOTAL=1
[0m22:48:31.649351 [debug] [MainThread]: Resource report: {"command_name": "seed", "command_success": true, "command_wall_clock_time": 18.536066, "process_in_blocks": "489784", "process_kernel_time": 0.488319, "process_mem_max_rss": "201612", "process_out_blocks": "3192", "process_user_time": 5.048639}
[0m22:48:31.649738 [debug] [MainThread]: Command `dbt seed` succeeded at 22:48:31.649660 after 18.54 seconds
[0m22:48:31.650027 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7c2bec4a4d70>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7c2bf0eefa70>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7c2bec8f2f30>]}
[0m22:48:31.650310 [debug] [MainThread]: Flushing usage events
[0m22:48:32.659246 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m11:55:22.329853 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7a8069f38110>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7a806b8d98b0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7a806a8a9700>]}


============================== 11:55:22.339018 | bd4cc7cf-1a8a-4242-8e33-7249a2890b69 ==============================
[0m11:55:22.339018 [info ] [MainThread]: Running with dbt=1.10.10
[0m11:55:22.340746 [debug] [MainThread]: running dbt with arguments {'send_anonymous_usage_stats': 'True', 'fail_fast': 'False', 'indirect_selection': 'eager', 'quiet': 'False', 'empty': 'None', 'use_experimental_parser': 'False', 'debug': 'False', 'profiles_dir': '/home/aniruth/AI/DBT/DBT_Master/dbt_anirudh', 'invocation_command': 'dbt ', 'cache_selected_only': 'False', 'target_path': 'None', 'no_print': 'None', 'version_check': 'True', 'use_colors': 'True', 'partial_parse': 'True', 'introspect': 'True', 'static_parser': 'True', 'log_path': '/home/aniruth/AI/DBT/DBT_Master/dbt_anirudh/logs', 'write_json': 'True', 'warn_error': 'None', 'log_cache_events': 'False', 'printer_width': '80', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'log_format': 'default'}
[0m11:55:22.517119 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'bd4cc7cf-1a8a-4242-8e33-7249a2890b69', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7a80692cef30>]}
[0m11:55:22.536101 [info ] [MainThread]: Warning: No packages were found in packages.yml
[0m11:55:22.537436 [info ] [MainThread]: Warning: No packages were found in packages.yml
[0m11:55:22.538897 [debug] [MainThread]: Resource report: {"command_name": "deps", "command_success": true, "command_wall_clock_time": 0.31031606, "process_in_blocks": "368", "process_kernel_time": 0.175949, "process_mem_max_rss": "100784", "process_out_blocks": "8", "process_user_time": 2.025902}
[0m11:55:22.539568 [debug] [MainThread]: Command `cli deps` succeeded at 11:55:22.539444 after 0.31 seconds
[0m11:55:22.539998 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7a806d9bf8f0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7a8068e35df0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7a8068e27f20>]}
[0m11:55:22.540496 [debug] [MainThread]: Flushing usage events
[0m11:55:24.285268 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m16:08:57.999588 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x77f18b13c0e0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x77f18b11bc50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x77f18abb1220>]}


============================== 16:08:58.007404 | 37796723-0f0e-47c3-b490-208c32a76847 ==============================
[0m16:08:58.007404 [info ] [MainThread]: Running with dbt=1.10.10
[0m16:08:58.008938 [debug] [MainThread]: running dbt with arguments {'quiet': 'False', 'write_json': 'True', 'profiles_dir': '/home/aniruth/AI/DBT/DBT_Master/dbt_anirudh', 'indirect_selection': 'eager', 'warn_error': 'None', 'version_check': 'True', 'invocation_command': 'dbt ', 'use_experimental_parser': 'False', 'log_path': '/home/aniruth/AI/DBT/DBT_Master/dbt_anirudh/logs', 'use_colors': 'True', 'log_format': 'default', 'static_parser': 'True', 'send_anonymous_usage_stats': 'True', 'empty': 'None', 'log_cache_events': 'False', 'cache_selected_only': 'False', 'no_print': 'None', 'introspect': 'True', 'partial_parse': 'True', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'printer_width': '80', 'target_path': 'None', 'debug': 'False', 'fail_fast': 'False'}
[0m16:08:58.233643 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '37796723-0f0e-47c3-b490-208c32a76847', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x77f18a073830>]}
[0m16:08:58.254736 [info ] [MainThread]: Warning: No packages were found in packages.yml
[0m16:08:58.255896 [info ] [MainThread]: Warning: No packages were found in packages.yml
[0m16:08:58.257982 [debug] [MainThread]: Resource report: {"command_name": "deps", "command_success": true, "command_wall_clock_time": 0.39919683, "process_in_blocks": "41824", "process_kernel_time": 0.310886, "process_mem_max_rss": "100216", "process_out_blocks": "8", "process_user_time": 3.099898}
[0m16:08:58.258898 [debug] [MainThread]: Command `cli deps` succeeded at 16:08:58.258688 after 0.40 seconds
[0m16:08:58.259690 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x77f18a715760>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x77f18c7c7b30>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x77f18a4f0650>]}
[0m16:08:58.260866 [debug] [MainThread]: Flushing usage events
[0m16:08:59.624983 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m13:50:32.620418 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6fea165580>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6feb96bb90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6fea7fe570>]}


============================== 13:50:32.624882 | 90164133-f73f-42f6-a85c-851f33211618 ==============================
[0m13:50:32.624882 [info ] [MainThread]: Running with dbt=1.10.10
[0m13:50:32.625565 [debug] [MainThread]: running dbt with arguments {'introspect': 'True', 'write_json': 'True', 'use_experimental_parser': 'False', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'cache_selected_only': 'False', 'static_parser': 'True', 'indirect_selection': 'eager', 'no_print': 'None', 'fail_fast': 'False', 'quiet': 'False', 'warn_error': 'None', 'empty': 'None', 'partial_parse': 'True', 'target_path': 'None', 'printer_width': '80', 'version_check': 'True', 'log_cache_events': 'False', 'use_colors': 'True', 'send_anonymous_usage_stats': 'True', 'profiles_dir': '/home/aniruth/AI/DBT/DBT_Master/dbt_anirudh', 'log_path': '/home/aniruth/AI/DBT/DBT_Master/dbt_anirudh/logs', 'debug': 'False', 'log_format': 'default', 'invocation_command': 'dbt '}
[0m13:50:32.810317 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '90164133-f73f-42f6-a85c-851f33211618', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6fe98bffb0>]}
[0m13:50:32.828172 [info ] [MainThread]: Warning: No packages were found in packages.yml
[0m13:50:32.829587 [info ] [MainThread]: Warning: No packages were found in packages.yml
[0m13:50:32.830998 [debug] [MainThread]: Resource report: {"command_name": "deps", "command_success": true, "command_wall_clock_time": 0.2812182, "process_in_blocks": "38752", "process_kernel_time": 0.233235, "process_mem_max_rss": "100240", "process_out_blocks": "16", "process_user_time": 2.245269}
[0m13:50:32.831661 [debug] [MainThread]: Command `cli deps` succeeded at 13:50:32.831502 after 0.28 seconds
[0m13:50:32.832121 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6fe9a4a3c0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6fe992a2a0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6fe976ff20>]}
[0m13:50:32.832582 [debug] [MainThread]: Flushing usage events
[0m13:50:33.878373 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m11:50:53.133404 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x77c3f2ce0b30>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x77c3f2b41520>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x77c3f3368a40>]}


============================== 11:50:53.137096 | 0eff2490-66ac-4ea4-89c7-91c007d88085 ==============================
[0m11:50:53.137096 [info ] [MainThread]: Running with dbt=1.10.10
[0m11:50:53.137560 [debug] [MainThread]: running dbt with arguments {'partial_parse': 'True', 'profiles_dir': '/home/aniruth/AI/DBT/DBT_Master/dbt_anirudh', 'log_path': '/home/aniruth/AI/DBT/DBT_Master/dbt_anirudh/logs', 'send_anonymous_usage_stats': 'True', 'empty': 'False', 'fail_fast': 'False', 'invocation_command': 'dbt run --select models/silver', 'log_cache_events': 'False', 'write_json': 'True', 'log_format': 'default', 'cache_selected_only': 'False', 'target_path': 'None', 'introspect': 'True', 'quiet': 'False', 'static_parser': 'True', 'debug': 'False', 'use_experimental_parser': 'False', 'warn_error': 'None', 'printer_width': '80', 'version_check': 'True', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'no_print': 'None', 'use_colors': 'True', 'indirect_selection': 'eager'}
[0m11:50:53.740394 [debug] [MainThread]: Spark adapter: Setting pyhive.hive logging to ERROR
[0m11:50:53.740925 [debug] [MainThread]: Spark adapter: Setting thrift.transport logging to ERROR
[0m11:50:53.741305 [debug] [MainThread]: Spark adapter: Setting thrift.protocol logging to ERROR
[0m11:50:54.341582 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '0eff2490-66ac-4ea4-89c7-91c007d88085', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x77c3d1a83b30>]}
[0m11:50:54.387153 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '0eff2490-66ac-4ea4-89c7-91c007d88085', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x77c3d17ccec0>]}
[0m11:50:54.387667 [info ] [MainThread]: Registered adapter: databricks=1.10.9
[0m11:50:54.467563 [debug] [MainThread]: checksum: 502a0dc23e9052e1ae09f7c44ee219ef7a02dfea7e7d66580d54c304c14d553b, vars: {}, profile: , target: , version: 1.10.10
[0m11:50:54.591450 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m11:50:54.591773 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m11:50:54.597597 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.dbt_anirudh.gold
[0m11:50:54.649947 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '0eff2490-66ac-4ea4-89c7-91c007d88085', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x77c3d11777d0>]}
[0m11:50:54.742937 [debug] [MainThread]: Wrote artifact WritableManifest to /home/aniruth/AI/DBT/DBT_Master/dbt_anirudh/target/manifest.json
[0m11:50:54.744938 [debug] [MainThread]: Wrote artifact SemanticManifest to /home/aniruth/AI/DBT/DBT_Master/dbt_anirudh/target/semantic_manifest.json
[0m11:50:54.754037 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '0eff2490-66ac-4ea4-89c7-91c007d88085', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x77c3d1199940>]}
[0m11:50:54.754433 [info ] [MainThread]: Found 7 models, 6 analyses, 5 data tests, 1 seed, 6 sources, 688 macros
[0m11:50:54.754711 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '0eff2490-66ac-4ea4-89c7-91c007d88085', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x77c3f38aa750>]}
[0m11:50:54.756450 [info ] [MainThread]: 
[0m11:50:54.756763 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m11:50:54.757032 [info ] [MainThread]: 
[0m11:50:54.757476 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=master) - Creating connection
[0m11:50:54.757742 [debug] [MainThread]: Acquiring new databricks connection 'master'
[0m11:50:54.758448 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=list_dbt_learning) - Creating connection
[0m11:50:54.758776 [debug] [ThreadPool]: Acquiring new databricks connection 'list_dbt_learning'
[0m11:50:54.759037 [debug] [ThreadPool]: Using databricks connection "list_dbt_learning"
[0m11:50:54.759274 [debug] [ThreadPool]: On list_dbt_learning: GetSchemas(database=dbt_learning, schema=None)
[0m11:50:54.759501 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m11:50:56.534474 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f099d7-cbc0-1b69-8902-da3bdd5ffb02) - Created
[0m11:50:57.449288 [debug] [ThreadPool]: SQL status: OK in 2.690 seconds
[0m11:50:57.452212 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01f099d7-cbc0-1b69-8902-da3bdd5ffb02, command-id=01f099d7-cbfc-16a0-8185-2cfec391bb94) - Closing
[0m11:50:57.453239 [debug] [ThreadPool]: On list_dbt_learning: Close
[0m11:50:57.454118 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f099d7-cbc0-1b69-8902-da3bdd5ffb02) - Closing
[0m11:50:57.856674 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=create_dbt_learning_silver) - Creating connection
[0m11:50:57.857454 [debug] [ThreadPool]: Acquiring new databricks connection 'create_dbt_learning_silver'
[0m11:50:57.858331 [debug] [ThreadPool]: Creating schema "database: "dbt_learning"
schema: "silver"
"
[0m11:50:57.870974 [debug] [ThreadPool]: Using databricks connection "create_dbt_learning_silver"
[0m11:50:57.871275 [debug] [ThreadPool]: On create_dbt_learning_silver: /* {"app": "dbt", "dbt_version": "1.10.10", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_anirudh", "target_name": "dev", "connection_name": "create_dbt_learning_silver"} */
create schema if not exists `dbt_learning`.`silver`
  
[0m11:50:57.871536 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m11:50:59.538629 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f099d7-cd89-1dd5-81c8-10a43ef0f8b8) - Created
[0m11:51:00.452463 [debug] [ThreadPool]: SQL status: OK in 2.580 seconds
[0m11:51:00.453325 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01f099d7-cd89-1dd5-81c8-10a43ef0f8b8, command-id=01f099d7-cdc2-14c1-bbc1-6f2a460c479e) - Closing
[0m11:51:00.453675 [debug] [ThreadPool]: On create_dbt_learning_silver: Close
[0m11:51:00.453966 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f099d7-cd89-1dd5-81c8-10a43ef0f8b8) - Closing
[0m11:51:00.856387 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=list_dbt_learning_bronze) - Creating connection
[0m11:51:00.856955 [debug] [ThreadPool]: Acquiring new databricks connection 'list_dbt_learning_bronze'
[0m11:51:00.866917 [debug] [ThreadPool]: Using databricks connection "list_dbt_learning_bronze"
[0m11:51:00.867655 [debug] [ThreadPool]: On list_dbt_learning_bronze: /* {"app": "dbt", "dbt_version": "1.10.10", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_anirudh", "target_name": "dev", "connection_name": "list_dbt_learning_bronze"} */

    
SELECT
  table_name,
  if(table_type IN ('EXTERNAL', 'MANAGED', 'MANAGED_SHALLOW_CLONE', 'EXTERNAL_SHALLOW_CLONE'), 'table', lower(table_type)) AS table_type,
  lower(data_source_format) AS file_format,
  table_owner,
  if(
    table_type IN (
      'EXTERNAL',
      'MANAGED',
      'MANAGED_SHALLOW_CLONE',
      'EXTERNAL_SHALLOW_CLONE'
    ),
    lower(table_type),
    NULL
  ) AS databricks_table_type
FROM `system`.`information_schema`.`tables`
WHERE table_catalog = 'dbt_learning' 
  AND table_schema = 'bronze'

  
[0m11:51:00.868114 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m11:51:02.567832 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f099d7-cf50-150f-99c8-4a9a1ae41e4d) - Created
[0m11:51:03.599351 [debug] [ThreadPool]: SQL status: OK in 2.730 seconds
[0m11:51:03.606910 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01f099d7-cf50-150f-99c8-4a9a1ae41e4d, command-id=01f099d7-cf8e-18df-a978-f5bd63f78f03) - Closing
[0m11:51:03.607813 [debug] [ThreadPool]: On list_dbt_learning_bronze: Close
[0m11:51:03.608224 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f099d7-cf50-150f-99c8-4a9a1ae41e4d) - Closing
[0m11:51:03.999712 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=list_dbt_learning_silver) - Creating connection
[0m11:51:04.000956 [debug] [ThreadPool]: Acquiring new databricks connection 'list_dbt_learning_silver'
[0m11:51:04.002813 [debug] [ThreadPool]: Using databricks connection "list_dbt_learning_silver"
[0m11:51:04.003131 [debug] [ThreadPool]: On list_dbt_learning_silver: /* {"app": "dbt", "dbt_version": "1.10.10", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_anirudh", "target_name": "dev", "connection_name": "list_dbt_learning_silver"} */

    
SELECT
  table_name,
  if(table_type IN ('EXTERNAL', 'MANAGED', 'MANAGED_SHALLOW_CLONE', 'EXTERNAL_SHALLOW_CLONE'), 'table', lower(table_type)) AS table_type,
  lower(data_source_format) AS file_format,
  table_owner,
  if(
    table_type IN (
      'EXTERNAL',
      'MANAGED',
      'MANAGED_SHALLOW_CLONE',
      'EXTERNAL_SHALLOW_CLONE'
    ),
    lower(table_type),
    NULL
  ) AS databricks_table_type
FROM `system`.`information_schema`.`tables`
WHERE table_catalog = 'dbt_learning' 
  AND table_schema = 'silver'

  
[0m11:51:04.003370 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m11:51:05.649645 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f099d7-d126-1b12-aae9-7be059c3a500) - Created
[0m11:51:06.464355 [debug] [ThreadPool]: SQL status: OK in 2.460 seconds
[0m11:51:06.468546 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01f099d7-d126-1b12-aae9-7be059c3a500, command-id=01f099d7-d166-1791-9f55-8af58bcc30f6) - Closing
[0m11:51:06.469650 [debug] [ThreadPool]: On list_dbt_learning_silver: Close
[0m11:51:06.470394 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f099d7-d126-1b12-aae9-7be059c3a500) - Closing
[0m11:51:06.868396 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '0eff2490-66ac-4ea4-89c7-91c007d88085', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x77c3d1b14b60>]}
[0m11:51:06.874976 [debug] [Thread-5 (]: Began running node model.dbt_anirudh.silver_sales_info
[0m11:51:06.876346 [info ] [Thread-5 (]: 1 of 1 START sql table model silver.silver_sales_info .......................... [RUN]
[0m11:51:06.877817 [debug] [Thread-5 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.dbt_anirudh.silver_sales_info) - Creating connection
[0m11:51:06.878785 [debug] [Thread-5 (]: Acquiring new databricks connection 'model.dbt_anirudh.silver_sales_info'
[0m11:51:06.879707 [debug] [Thread-5 (]: Began compiling node model.dbt_anirudh.silver_sales_info
[0m11:51:06.902892 [debug] [Thread-5 (]: Writing injected SQL for node "model.dbt_anirudh.silver_sales_info"
[0m11:51:06.904117 [debug] [Thread-5 (]: Began executing node model.dbt_anirudh.silver_sales_info
[0m11:51:06.917838 [debug] [Thread-5 (]: MATERIALIZING TABLE
[0m11:51:06.918335 [warn ] [Thread-5 (]: [[33mWARNING[0m]: Use revamped materializations based on separating create and insert.  This allows more performant column comments, as well as new column features.
You may opt into the new behavior sooner by setting `flags.use_materialization_v2` to `True` in `dbt_project.yml`.
Visit https://docs.getdbt.com/reference/global-configs/behavior-changes for more information.
[0m11:51:06.918697 [debug] [Thread-5 (]: Sending event: {'category': 'dbt', 'action': 'BehaviorChangeEvent', 'label': '0eff2490-66ac-4ea4-89c7-91c007d88085', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x77c3d106b5c0>]}
[0m11:51:06.952525 [debug] [Thread-5 (]: Writing runtime sql for node "model.dbt_anirudh.silver_sales_info"
[0m11:51:06.953570 [debug] [Thread-5 (]: Using databricks connection "model.dbt_anirudh.silver_sales_info"
[0m11:51:06.953996 [debug] [Thread-5 (]: On model.dbt_anirudh.silver_sales_info: /* {"app": "dbt", "dbt_version": "1.10.10", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_anirudh", "target_name": "dev", "node_id": "model.dbt_anirudh.silver_sales_info"} */

  
    
        create or replace table `dbt_learning`.`silver`.`silver_sales_info`
      
      
  using delta
      
      
      
      
      
      
      
      as
      WITH sales AS
(
    SELECT
        sales_id,
        product_sk,
        customer_sk,
        
    quantity * unit_price
 as calculated_gross_amount,
        gross_amount,
        payment_method
    FROM
        `dbt_learning`.`bronze`.`bronze_sales`
),

customer AS
(
    SELECT
        customer_sk,
        concat(first_name, last_name) as c_name,
        gender,
        signup_date
    FROM
        `dbt_learning`.`bronze`.`bronze_customer`
),

product AS
(
    SELECT
        product_sk,
        category
    FROM
        `dbt_learning`.`bronze`.`bronze_product`
),

joined_query AS
(
    SELECT
        sales.sales_id,
        sales.calculated_gross_amount,
        sales.payment_method,
        product.category,
        customer.gender
    FROM
        sales       
    INNER JOIN customer 
        ON customer.customer_sk = sales.customer_sk
    INNER JOIN product
        ON product.product_sk = sales.product_sk
)    

SELECT
    category,
    gender,
    sum(calculated_gross_amount) as total_sales
FROM
    joined_query
GROUP BY 1,2
ORDER BY 1 ASC, 3 DESC
  
[0m11:51:06.954310 [debug] [Thread-5 (]: Opening a new connection, currently in state init
[0m11:51:08.506008 [debug] [Thread-5 (]: Databricks adapter: Connection(session-id=01f099d7-d2dc-1085-a99a-1e6844e068f7) - Created
[0m11:51:16.495395 [debug] [Thread-5 (]: SQL status: OK in 9.540 seconds
[0m11:51:16.497888 [debug] [Thread-5 (]: Databricks adapter: Cursor(session-id=01f099d7-d2dc-1085-a99a-1e6844e068f7, command-id=01f099d7-d319-1cc6-8b11-41fe1806a4bd) - Closing
[0m11:51:16.921998 [debug] [Thread-5 (]: Applying tags to relation None
[0m11:51:16.933952 [debug] [Thread-5 (]: On model.dbt_anirudh.silver_sales_info: Close
[0m11:51:16.934277 [debug] [Thread-5 (]: Databricks adapter: Connection(session-id=01f099d7-d2dc-1085-a99a-1e6844e068f7) - Closing
[0m11:51:17.294377 [debug] [Thread-5 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '0eff2490-66ac-4ea4-89c7-91c007d88085', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x77c3f4c91e20>]}
[0m11:51:17.296219 [info ] [Thread-5 (]: 1 of 1 OK created sql table model silver.silver_sales_info ..................... [[32mOK[0m in 10.41s]
[0m11:51:17.297818 [debug] [Thread-5 (]: Finished running node model.dbt_anirudh.silver_sales_info
[0m11:51:17.300354 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=master) - Creating connection
[0m11:51:17.301281 [debug] [MainThread]: Acquiring new databricks connection 'master'
[0m11:51:17.302351 [info ] [MainThread]: 
[0m11:51:17.303207 [info ] [MainThread]: Finished running 1 table model in 0 hours 0 minutes and 22.55 seconds (22.55s).
[0m11:51:17.304903 [debug] [MainThread]: Command end result
[0m11:51:17.339276 [debug] [MainThread]: Wrote artifact WritableManifest to /home/aniruth/AI/DBT/DBT_Master/dbt_anirudh/target/manifest.json
[0m11:51:17.341676 [debug] [MainThread]: Wrote artifact SemanticManifest to /home/aniruth/AI/DBT/DBT_Master/dbt_anirudh/target/semantic_manifest.json
[0m11:51:17.346825 [debug] [MainThread]: Wrote artifact RunExecutionResult to /home/aniruth/AI/DBT/DBT_Master/dbt_anirudh/target/run_results.json
[0m11:51:17.347153 [info ] [MainThread]: 
[0m11:51:17.347473 [info ] [MainThread]: [32mCompleted successfully[0m
[0m11:51:17.347734 [info ] [MainThread]: 
[0m11:51:17.348045 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 NO-OP=0 TOTAL=1
[0m11:51:17.348952 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 24.259846, "process_in_blocks": "125392", "process_kernel_time": 0.228503, "process_mem_max_rss": "248520", "process_out_blocks": "3240", "process_user_time": 4.025865}
[0m11:51:17.349320 [debug] [MainThread]: Command `dbt run` succeeded at 11:51:17.349248 after 24.26 seconds
[0m11:51:17.349628 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x77c3f2ff0e60>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x77c3d16c2f60>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x77c3f2db7050>]}
[0m11:51:17.349954 [debug] [MainThread]: Flushing usage events
[0m11:51:18.732767 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m12:17:29.607420 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7dbaf13ad970>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7dbaf1ee2570>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7dbaf17b9ee0>]}


============================== 12:17:29.610343 | ec5e3102-e117-49a9-a02b-e9b7f3ecf000 ==============================
[0m12:17:29.610343 [info ] [MainThread]: Running with dbt=1.10.10
[0m12:17:29.610817 [debug] [MainThread]: running dbt with arguments {'fail_fast': 'False', 'send_anonymous_usage_stats': 'True', 'cache_selected_only': 'False', 'target_path': 'None', 'invocation_command': 'dbt run --select models/silver', 'use_colors': 'True', 'debug': 'False', 'log_cache_events': 'False', 'indirect_selection': 'eager', 'write_json': 'True', 'profiles_dir': '/home/aniruth/AI/DBT/DBT_Master/dbt_anirudh', 'quiet': 'False', 'warn_error': 'None', 'log_path': '/home/aniruth/AI/DBT/DBT_Master/dbt_anirudh/logs', 'empty': 'False', 'no_print': 'None', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'version_check': 'True', 'static_parser': 'True', 'use_experimental_parser': 'False', 'printer_width': '80', 'introspect': 'True', 'log_format': 'default', 'partial_parse': 'True'}
[0m12:17:30.261365 [debug] [MainThread]: Spark adapter: Setting pyhive.hive logging to ERROR
[0m12:17:30.261794 [debug] [MainThread]: Spark adapter: Setting thrift.transport logging to ERROR
[0m12:17:30.262134 [debug] [MainThread]: Spark adapter: Setting thrift.protocol logging to ERROR
[0m12:17:30.789658 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'ec5e3102-e117-49a9-a02b-e9b7f3ecf000', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7dbad0e3f3b0>]}
[0m12:17:30.834827 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'ec5e3102-e117-49a9-a02b-e9b7f3ecf000', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7dbad05b0a40>]}
[0m12:17:30.835385 [info ] [MainThread]: Registered adapter: databricks=1.10.9
[0m12:17:30.914579 [debug] [MainThread]: checksum: 502a0dc23e9052e1ae09f7c44ee219ef7a02dfea7e7d66580d54c304c14d553b, vars: {}, profile: , target: , version: 1.10.10
[0m12:17:31.021022 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m12:17:31.021406 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m12:17:31.027002 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.dbt_anirudh.gold
[0m12:17:31.075503 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'ec5e3102-e117-49a9-a02b-e9b7f3ecf000', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7dbad013f380>]}
[0m12:17:31.166467 [debug] [MainThread]: Wrote artifact WritableManifest to /home/aniruth/AI/DBT/DBT_Master/dbt_anirudh/target/manifest.json
[0m12:17:31.169270 [debug] [MainThread]: Wrote artifact SemanticManifest to /home/aniruth/AI/DBT/DBT_Master/dbt_anirudh/target/semantic_manifest.json
[0m12:17:31.176415 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'ec5e3102-e117-49a9-a02b-e9b7f3ecf000', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7dbacbb5e690>]}
[0m12:17:31.176818 [info ] [MainThread]: Found 8 models, 6 analyses, 5 data tests, 1 seed, 6 sources, 688 macros
[0m12:17:31.177135 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'ec5e3102-e117-49a9-a02b-e9b7f3ecf000', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7dbacbf0a1e0>]}
[0m12:17:31.178787 [info ] [MainThread]: 
[0m12:17:31.179094 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m12:17:31.179348 [info ] [MainThread]: 
[0m12:17:31.179770 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=master) - Creating connection
[0m12:17:31.180032 [debug] [MainThread]: Acquiring new databricks connection 'master'
[0m12:17:31.184818 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=list_dbt_learning) - Creating connection
[0m12:17:31.185218 [debug] [ThreadPool]: Acquiring new databricks connection 'list_dbt_learning'
[0m12:17:31.185482 [debug] [ThreadPool]: Using databricks connection "list_dbt_learning"
[0m12:17:31.185736 [debug] [ThreadPool]: On list_dbt_learning: GetSchemas(database=dbt_learning, schema=None)
[0m12:17:31.185962 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m12:17:32.653465 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f099db-8314-11a3-9ddd-eb0bd108f9eb) - Created
[0m12:17:33.274886 [debug] [ThreadPool]: SQL status: OK in 2.090 seconds
[0m12:17:33.277922 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01f099db-8314-11a3-9ddd-eb0bd108f9eb, command-id=01f099db-834f-1d32-9b66-cd04bb0ca094) - Closing
[0m12:17:33.278913 [debug] [ThreadPool]: On list_dbt_learning: Close
[0m12:17:33.279826 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f099db-8314-11a3-9ddd-eb0bd108f9eb) - Closing
[0m12:17:33.646996 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=list_dbt_learning_silver) - Creating connection
[0m12:17:33.648173 [debug] [ThreadPool]: Acquiring new databricks connection 'list_dbt_learning_silver'
[0m12:17:33.667982 [debug] [ThreadPool]: Using databricks connection "list_dbt_learning_silver"
[0m12:17:33.668309 [debug] [ThreadPool]: On list_dbt_learning_silver: /* {"app": "dbt", "dbt_version": "1.10.10", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_anirudh", "target_name": "dev", "connection_name": "list_dbt_learning_silver"} */

    
SELECT
  table_name,
  if(table_type IN ('EXTERNAL', 'MANAGED', 'MANAGED_SHALLOW_CLONE', 'EXTERNAL_SHALLOW_CLONE'), 'table', lower(table_type)) AS table_type,
  lower(data_source_format) AS file_format,
  table_owner,
  if(
    table_type IN (
      'EXTERNAL',
      'MANAGED',
      'MANAGED_SHALLOW_CLONE',
      'EXTERNAL_SHALLOW_CLONE'
    ),
    lower(table_type),
    NULL
  ) AS databricks_table_type
FROM `system`.`information_schema`.`tables`
WHERE table_catalog = 'dbt_learning' 
  AND table_schema = 'silver'

  
[0m12:17:33.668557 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m12:17:35.277372 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f099db-84a8-1728-86d8-1538f406b321) - Created
[0m12:17:35.931864 [debug] [ThreadPool]: SQL status: OK in 2.260 seconds
[0m12:17:35.938059 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01f099db-84a8-1728-86d8-1538f406b321, command-id=01f099db-84e0-16e8-82f7-7afaa024786d) - Closing
[0m12:17:35.939408 [debug] [ThreadPool]: On list_dbt_learning_silver: Close
[0m12:17:35.940269 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f099db-84a8-1728-86d8-1538f406b321) - Closing
[0m12:17:36.312897 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=list_dbt_learning_bronze) - Creating connection
[0m12:17:36.314537 [debug] [ThreadPool]: Acquiring new databricks connection 'list_dbt_learning_bronze'
[0m12:17:36.322285 [debug] [ThreadPool]: Using databricks connection "list_dbt_learning_bronze"
[0m12:17:36.323035 [debug] [ThreadPool]: On list_dbt_learning_bronze: /* {"app": "dbt", "dbt_version": "1.10.10", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_anirudh", "target_name": "dev", "connection_name": "list_dbt_learning_bronze"} */

    
SELECT
  table_name,
  if(table_type IN ('EXTERNAL', 'MANAGED', 'MANAGED_SHALLOW_CLONE', 'EXTERNAL_SHALLOW_CLONE'), 'table', lower(table_type)) AS table_type,
  lower(data_source_format) AS file_format,
  table_owner,
  if(
    table_type IN (
      'EXTERNAL',
      'MANAGED',
      'MANAGED_SHALLOW_CLONE',
      'EXTERNAL_SHALLOW_CLONE'
    ),
    lower(table_type),
    NULL
  ) AS databricks_table_type
FROM `system`.`information_schema`.`tables`
WHERE table_catalog = 'dbt_learning' 
  AND table_schema = 'bronze'

  
[0m12:17:36.323551 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m12:17:37.694479 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f099db-861e-1e58-9362-54a08ab89a49) - Created
[0m12:17:38.289895 [debug] [ThreadPool]: SQL status: OK in 1.970 seconds
[0m12:17:38.294788 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01f099db-861e-1e58-9362-54a08ab89a49, command-id=01f099db-8651-17fa-a2ff-74434dbf313a) - Closing
[0m12:17:38.296338 [debug] [ThreadPool]: On list_dbt_learning_bronze: Close
[0m12:17:38.297168 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f099db-861e-1e58-9362-54a08ab89a49) - Closing
[0m12:17:38.649268 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'ec5e3102-e117-49a9-a02b-e9b7f3ecf000', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7dbaf3523bf0>]}
[0m12:17:38.655364 [debug] [Thread-4 (]: Began running node model.dbt_anirudh.silver_returns_info
[0m12:17:38.656754 [info ] [Thread-4 (]: 1 of 2 START sql table model silver.silver_returns_info ........................ [RUN]
[0m12:17:38.658170 [debug] [Thread-4 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.dbt_anirudh.silver_returns_info) - Creating connection
[0m12:17:38.659158 [debug] [Thread-4 (]: Acquiring new databricks connection 'model.dbt_anirudh.silver_returns_info'
[0m12:17:38.660062 [debug] [Thread-4 (]: Began compiling node model.dbt_anirudh.silver_returns_info
[0m12:17:38.674049 [debug] [Thread-4 (]: Writing injected SQL for node "model.dbt_anirudh.silver_returns_info"
[0m12:17:38.675334 [debug] [Thread-4 (]: Began executing node model.dbt_anirudh.silver_returns_info
[0m12:17:38.693107 [debug] [Thread-4 (]: MATERIALIZING TABLE
[0m12:17:38.693608 [warn ] [Thread-4 (]: [[33mWARNING[0m]: Use revamped materializations based on separating create and insert.  This allows more performant column comments, as well as new column features.
You may opt into the new behavior sooner by setting `flags.use_materialization_v2` to `True` in `dbt_project.yml`.
Visit https://docs.getdbt.com/reference/global-configs/behavior-changes for more information.
[0m12:17:38.694168 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'BehaviorChangeEvent', 'label': 'ec5e3102-e117-49a9-a02b-e9b7f3ecf000', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7dbacba07b90>]}
[0m12:17:38.727072 [debug] [Thread-4 (]: Writing runtime sql for node "model.dbt_anirudh.silver_returns_info"
[0m12:17:38.728169 [debug] [Thread-4 (]: Using databricks connection "model.dbt_anirudh.silver_returns_info"
[0m12:17:38.728553 [debug] [Thread-4 (]: On model.dbt_anirudh.silver_returns_info: /* {"app": "dbt", "dbt_version": "1.10.10", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_anirudh", "target_name": "dev", "node_id": "model.dbt_anirudh.silver_returns_info"} */

  
    
        create or replace table `dbt_learning`.`silver`.`silver_returns_info`
      
      
  using delta
      
      
      
      
      
      
      
      as
      WITH return_data AS
(
    SELECT
        sales_id,
        product_sk,
        return_reason,
        refund_amount
    FROM
        `dbt_learning`.`bronze`.`bronze_returns`
),
product_data AS
(
    SELECT
        product_sk,
        category,
        department
    FROM
        `dbt_learning`.`bronze`.`bronze_product`
),
customer_data AS
(
    SELECT
        customer_sk,
        gender
    FROM
        `dbt_learning`.`bronze`.`bronze_customer`
),
sales_data AS
(
    SELECT
        sales_id,
        customer_sk
    FROM
        `dbt_learning`.`bronze`.`bronze_sales`
),
joined_query AS
(
    SELECT
        product_data.category,
        product_data.department,
        customer_data.gender,
        return_data.refund_amount
    FROM
        return_data
    INNER JOIN sales_data ON sales_data.sales_id = return_data.sales_id
    INNER JOIN customer_data ON customer_data.customer_sk = sales_data.customer_sk
    INNER JOIN product_data ON product_data.product_sk = return_data.product_sk
)
SELECT
    category,
    department,
    gender,
    sum(refund_amount) as total_refund
FROM
    joined_query
GROUP BY 1,2,3
ORDER BY 1,2,3 ASC, 4 DESC
  
[0m12:17:38.728855 [debug] [Thread-4 (]: Opening a new connection, currently in state init
[0m12:17:40.362607 [debug] [Thread-4 (]: Databricks adapter: Connection(session-id=01f099db-87b7-192f-8dea-07ae0c30befe) - Created
[0m12:17:44.329650 [debug] [Thread-4 (]: SQL status: OK in 5.600 seconds
[0m12:17:44.332030 [debug] [Thread-4 (]: Databricks adapter: Cursor(session-id=01f099db-87b7-192f-8dea-07ae0c30befe, command-id=01f099db-87e9-1d6a-9ca5-05dfc6114e98) - Closing
[0m12:17:44.349336 [debug] [Thread-4 (]: Applying tags to relation None
[0m12:17:44.361484 [debug] [Thread-4 (]: On model.dbt_anirudh.silver_returns_info: Close
[0m12:17:44.361805 [debug] [Thread-4 (]: Databricks adapter: Connection(session-id=01f099db-87b7-192f-8dea-07ae0c30befe) - Closing
[0m12:17:44.744955 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'ec5e3102-e117-49a9-a02b-e9b7f3ecf000', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7dbacba3a570>]}
[0m12:17:44.746514 [info ] [Thread-4 (]: 1 of 2 OK created sql table model silver.silver_returns_info ................... [[32mOK[0m in 6.08s]
[0m12:17:44.748089 [debug] [Thread-4 (]: Finished running node model.dbt_anirudh.silver_returns_info
[0m12:17:44.749128 [debug] [Thread-4 (]: Began running node model.dbt_anirudh.silver_sales_info
[0m12:17:44.750368 [info ] [Thread-4 (]: 2 of 2 START sql table model silver.silver_sales_info .......................... [RUN]
[0m12:17:44.752132 [debug] [Thread-4 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.dbt_anirudh.silver_sales_info) - Creating connection
[0m12:17:44.753219 [debug] [Thread-4 (]: Acquiring new databricks connection 'model.dbt_anirudh.silver_sales_info'
[0m12:17:44.754230 [debug] [Thread-4 (]: Began compiling node model.dbt_anirudh.silver_sales_info
[0m12:17:44.761417 [debug] [Thread-4 (]: Writing injected SQL for node "model.dbt_anirudh.silver_sales_info"
[0m12:17:44.762262 [debug] [Thread-4 (]: Began executing node model.dbt_anirudh.silver_sales_info
[0m12:17:44.765081 [debug] [Thread-4 (]: MATERIALIZING TABLE
[0m12:17:44.766976 [debug] [Thread-4 (]: Writing runtime sql for node "model.dbt_anirudh.silver_sales_info"
[0m12:17:44.767587 [debug] [Thread-4 (]: Using databricks connection "model.dbt_anirudh.silver_sales_info"
[0m12:17:44.768007 [debug] [Thread-4 (]: On model.dbt_anirudh.silver_sales_info: /* {"app": "dbt", "dbt_version": "1.10.10", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_anirudh", "target_name": "dev", "node_id": "model.dbt_anirudh.silver_sales_info"} */

  
    
        create or replace table `dbt_learning`.`silver`.`silver_sales_info`
      
      
  using delta
      
      
      
      
      
      
      
      as
      WITH sales AS
(
    SELECT
        sales_id,
        product_sk,
        customer_sk,
        
    quantity * unit_price
 as calculated_gross_amount,
        gross_amount,
        payment_method
    FROM
        `dbt_learning`.`bronze`.`bronze_sales`
),

customer AS
(
    SELECT
        customer_sk,
        concat(first_name, last_name) as c_name,
        gender,
        signup_date
    FROM
        `dbt_learning`.`bronze`.`bronze_customer`
),

product AS
(
    SELECT
        product_sk,
        category
    FROM
        `dbt_learning`.`bronze`.`bronze_product`
),

joined_query AS
(
    SELECT
        sales.sales_id,
        sales.calculated_gross_amount,
        sales.payment_method,
        product.category,
        customer.gender
    FROM
        sales       
    INNER JOIN customer 
        ON customer.customer_sk = sales.customer_sk
    INNER JOIN product
        ON product.product_sk = sales.product_sk
)    

SELECT
    category,
    gender,
    sum(calculated_gross_amount) as total_sales
FROM
    joined_query
GROUP BY 1,2
ORDER BY 1 ASC, 3 DESC
  
[0m12:17:44.768305 [debug] [Thread-4 (]: Opening a new connection, currently in state init
[0m12:17:46.175510 [debug] [Thread-4 (]: Databricks adapter: Connection(session-id=01f099db-8b2d-144b-8d22-3e3792548fa5) - Created
[0m12:17:49.041078 [debug] [Thread-4 (]: SQL status: OK in 4.270 seconds
[0m12:17:49.043626 [debug] [Thread-4 (]: Databricks adapter: Cursor(session-id=01f099db-8b2d-144b-8d22-3e3792548fa5, command-id=01f099db-8b5f-1405-bd77-0a5e0438e11e) - Closing
[0m12:17:49.052104 [debug] [Thread-4 (]: Applying tags to relation None
[0m12:17:49.054020 [debug] [Thread-4 (]: On model.dbt_anirudh.silver_sales_info: Close
[0m12:17:49.054703 [debug] [Thread-4 (]: Databricks adapter: Connection(session-id=01f099db-8b2d-144b-8d22-3e3792548fa5) - Closing
[0m12:17:49.449944 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'ec5e3102-e117-49a9-a02b-e9b7f3ecf000', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7dbacba04bc0>]}
[0m12:17:49.451463 [info ] [Thread-4 (]: 2 of 2 OK created sql table model silver.silver_sales_info ..................... [[32mOK[0m in 4.70s]
[0m12:17:49.452862 [debug] [Thread-4 (]: Finished running node model.dbt_anirudh.silver_sales_info
[0m12:17:49.455390 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=master) - Creating connection
[0m12:17:49.456456 [debug] [MainThread]: Acquiring new databricks connection 'master'
[0m12:17:49.457574 [info ] [MainThread]: 
[0m12:17:49.458608 [info ] [MainThread]: Finished running 2 table models in 0 hours 0 minutes and 18.28 seconds (18.28s).
[0m12:17:49.460607 [debug] [MainThread]: Command end result
[0m12:17:49.495746 [debug] [MainThread]: Wrote artifact WritableManifest to /home/aniruth/AI/DBT/DBT_Master/dbt_anirudh/target/manifest.json
[0m12:17:49.497421 [debug] [MainThread]: Wrote artifact SemanticManifest to /home/aniruth/AI/DBT/DBT_Master/dbt_anirudh/target/semantic_manifest.json
[0m12:17:49.502054 [debug] [MainThread]: Wrote artifact RunExecutionResult to /home/aniruth/AI/DBT/DBT_Master/dbt_anirudh/target/run_results.json
[0m12:17:49.502330 [info ] [MainThread]: 
[0m12:17:49.502616 [info ] [MainThread]: [32mCompleted successfully[0m
[0m12:17:49.502861 [info ] [MainThread]: 
[0m12:17:49.503114 [info ] [MainThread]: Done. PASS=2 WARN=0 ERROR=0 SKIP=0 NO-OP=0 TOTAL=2
[0m12:17:49.503924 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 19.941517, "process_in_blocks": "11240", "process_kernel_time": 0.182506, "process_mem_max_rss": "245868", "process_out_blocks": "3296", "process_user_time": 4.185678}
[0m12:17:49.504290 [debug] [MainThread]: Command `dbt run` succeeded at 12:17:49.504219 after 19.94 seconds
[0m12:17:49.504576 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7dbaf12a0140>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7dbaf15a5a30>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7dbacbe6dee0>]}
[0m12:17:49.504883 [debug] [MainThread]: Flushing usage events
[0m12:17:51.161001 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m12:18:54.204821 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7bcc2b158aa0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7bcc2b8ddbe0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7bcc2b15aab0>]}


============================== 12:18:54.207186 | cbcf2d6d-d4a9-4ffe-8876-4da372aa8b39 ==============================
[0m12:18:54.207186 [info ] [MainThread]: Running with dbt=1.10.10
[0m12:18:54.207655 [debug] [MainThread]: running dbt with arguments {'use_experimental_parser': 'False', 'target_path': 'None', 'warn_error': 'None', 'partial_parse': 'True', 'send_anonymous_usage_stats': 'True', 'printer_width': '80', 'static_parser': 'True', 'empty': 'False', 'write_json': 'True', 'profiles_dir': '/home/aniruth/AI/DBT/DBT_Master/dbt_anirudh', 'use_colors': 'True', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'indirect_selection': 'eager', 'introspect': 'True', 'quiet': 'False', 'log_path': '/home/aniruth/AI/DBT/DBT_Master/dbt_anirudh/logs', 'invocation_command': 'dbt run --select models/silver', 'log_cache_events': 'False', 'log_format': 'default', 'version_check': 'True', 'no_print': 'None', 'cache_selected_only': 'False', 'fail_fast': 'False', 'debug': 'False'}
[0m12:18:54.777021 [debug] [MainThread]: Spark adapter: Setting pyhive.hive logging to ERROR
[0m12:18:54.777764 [debug] [MainThread]: Spark adapter: Setting thrift.transport logging to ERROR
[0m12:18:54.778212 [debug] [MainThread]: Spark adapter: Setting thrift.protocol logging to ERROR
[0m12:18:55.284234 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'cbcf2d6d-d4a9-4ffe-8876-4da372aa8b39', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7bcc2d14ac30>]}
[0m12:18:55.329083 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'cbcf2d6d-d4a9-4ffe-8876-4da372aa8b39', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7bcc0a730470>]}
[0m12:18:55.329601 [info ] [MainThread]: Registered adapter: databricks=1.10.9
[0m12:18:55.410406 [debug] [MainThread]: checksum: 502a0dc23e9052e1ae09f7c44ee219ef7a02dfea7e7d66580d54c304c14d553b, vars: {}, profile: , target: , version: 1.10.10
[0m12:18:55.514915 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m12:18:55.515251 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m12:18:55.520641 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.dbt_anirudh.gold
[0m12:18:55.568286 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'cbcf2d6d-d4a9-4ffe-8876-4da372aa8b39', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7bcc099290a0>]}
[0m12:18:55.655428 [debug] [MainThread]: Wrote artifact WritableManifest to /home/aniruth/AI/DBT/DBT_Master/dbt_anirudh/target/manifest.json
[0m12:18:55.658542 [debug] [MainThread]: Wrote artifact SemanticManifest to /home/aniruth/AI/DBT/DBT_Master/dbt_anirudh/target/semantic_manifest.json
[0m12:18:55.665156 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'cbcf2d6d-d4a9-4ffe-8876-4da372aa8b39', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7bcc09625ee0>]}
[0m12:18:55.665534 [info ] [MainThread]: Found 8 models, 6 analyses, 5 data tests, 1 seed, 6 sources, 688 macros
[0m12:18:55.665837 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'cbcf2d6d-d4a9-4ffe-8876-4da372aa8b39', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7bcc09666cc0>]}
[0m12:18:55.667553 [info ] [MainThread]: 
[0m12:18:55.667850 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m12:18:55.668093 [info ] [MainThread]: 
[0m12:18:55.668473 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=master) - Creating connection
[0m12:18:55.668707 [debug] [MainThread]: Acquiring new databricks connection 'master'
[0m12:18:55.673631 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=list_dbt_learning) - Creating connection
[0m12:18:55.674022 [debug] [ThreadPool]: Acquiring new databricks connection 'list_dbt_learning'
[0m12:18:55.674301 [debug] [ThreadPool]: Using databricks connection "list_dbt_learning"
[0m12:18:55.674545 [debug] [ThreadPool]: On list_dbt_learning: GetSchemas(database=dbt_learning, schema=None)
[0m12:18:55.674766 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m12:18:57.274065 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f099db-b58c-1bfc-a069-33837da4a3a4) - Created
[0m12:18:57.750926 [debug] [ThreadPool]: SQL status: OK in 2.080 seconds
[0m12:18:57.752528 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01f099db-b58c-1bfc-a069-33837da4a3a4, command-id=01f099db-b5c0-1c59-b5e8-d1cf1edc48d7) - Closing
[0m12:18:57.753089 [debug] [ThreadPool]: On list_dbt_learning: Close
[0m12:18:57.753513 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f099db-b58c-1bfc-a069-33837da4a3a4) - Closing
[0m12:18:58.109347 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=list_dbt_learning_silver) - Creating connection
[0m12:18:58.110415 [debug] [ThreadPool]: Acquiring new databricks connection 'list_dbt_learning_silver'
[0m12:18:58.126332 [debug] [ThreadPool]: Using databricks connection "list_dbt_learning_silver"
[0m12:18:58.126837 [debug] [ThreadPool]: On list_dbt_learning_silver: /* {"app": "dbt", "dbt_version": "1.10.10", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_anirudh", "target_name": "dev", "connection_name": "list_dbt_learning_silver"} */

    
SELECT
  table_name,
  if(table_type IN ('EXTERNAL', 'MANAGED', 'MANAGED_SHALLOW_CLONE', 'EXTERNAL_SHALLOW_CLONE'), 'table', lower(table_type)) AS table_type,
  lower(data_source_format) AS file_format,
  table_owner,
  if(
    table_type IN (
      'EXTERNAL',
      'MANAGED',
      'MANAGED_SHALLOW_CLONE',
      'EXTERNAL_SHALLOW_CLONE'
    ),
    lower(table_type),
    NULL
  ) AS databricks_table_type
FROM `system`.`information_schema`.`tables`
WHERE table_catalog = 'dbt_learning' 
  AND table_schema = 'silver'

  
[0m12:18:58.127127 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m12:18:59.510840 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f099db-b6e2-1fce-acfa-7729eb340872) - Created
[0m12:19:00.212551 [debug] [ThreadPool]: SQL status: OK in 2.090 seconds
[0m12:19:00.218220 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01f099db-b6e2-1fce-acfa-7729eb340872, command-id=01f099db-b717-1219-928d-35e57dec5737) - Closing
[0m12:19:00.219148 [debug] [ThreadPool]: On list_dbt_learning_silver: Close
[0m12:19:00.219810 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f099db-b6e2-1fce-acfa-7729eb340872) - Closing
[0m12:19:00.623063 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=list_dbt_learning_bronze) - Creating connection
[0m12:19:00.624695 [debug] [ThreadPool]: Acquiring new databricks connection 'list_dbt_learning_bronze'
[0m12:19:00.629390 [debug] [ThreadPool]: Using databricks connection "list_dbt_learning_bronze"
[0m12:19:00.629937 [debug] [ThreadPool]: On list_dbt_learning_bronze: /* {"app": "dbt", "dbt_version": "1.10.10", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_anirudh", "target_name": "dev", "connection_name": "list_dbt_learning_bronze"} */

    
SELECT
  table_name,
  if(table_type IN ('EXTERNAL', 'MANAGED', 'MANAGED_SHALLOW_CLONE', 'EXTERNAL_SHALLOW_CLONE'), 'table', lower(table_type)) AS table_type,
  lower(data_source_format) AS file_format,
  table_owner,
  if(
    table_type IN (
      'EXTERNAL',
      'MANAGED',
      'MANAGED_SHALLOW_CLONE',
      'EXTERNAL_SHALLOW_CLONE'
    ),
    lower(table_type),
    NULL
  ) AS databricks_table_type
FROM `system`.`information_schema`.`tables`
WHERE table_catalog = 'dbt_learning' 
  AND table_schema = 'bronze'

  
[0m12:19:00.630412 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m12:19:02.255277 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f099db-b87a-1ade-9d5f-c48dc12e47a3) - Created
[0m12:19:02.978183 [debug] [ThreadPool]: SQL status: OK in 2.350 seconds
[0m12:19:02.983137 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01f099db-b87a-1ade-9d5f-c48dc12e47a3, command-id=01f099db-b8b9-1208-a11e-ff0fd3763d80) - Closing
[0m12:19:02.984674 [debug] [ThreadPool]: On list_dbt_learning_bronze: Close
[0m12:19:02.985468 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f099db-b87a-1ade-9d5f-c48dc12e47a3) - Closing
[0m12:19:03.384391 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'cbcf2d6d-d4a9-4ffe-8876-4da372aa8b39', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7bcc096658b0>]}
[0m12:19:03.390157 [debug] [Thread-4 (]: Began running node model.dbt_anirudh.silver_returns_info
[0m12:19:03.391393 [info ] [Thread-4 (]: 1 of 2 START sql table model silver.silver_returns_info ........................ [RUN]
[0m12:19:03.392639 [debug] [Thread-4 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.dbt_anirudh.silver_returns_info) - Creating connection
[0m12:19:03.393524 [debug] [Thread-4 (]: Acquiring new databricks connection 'model.dbt_anirudh.silver_returns_info'
[0m12:19:03.394368 [debug] [Thread-4 (]: Began compiling node model.dbt_anirudh.silver_returns_info
[0m12:19:03.409662 [debug] [Thread-4 (]: Writing injected SQL for node "model.dbt_anirudh.silver_returns_info"
[0m12:19:03.410422 [debug] [Thread-4 (]: Began executing node model.dbt_anirudh.silver_returns_info
[0m12:19:03.428701 [debug] [Thread-4 (]: MATERIALIZING TABLE
[0m12:19:03.429266 [warn ] [Thread-4 (]: [[33mWARNING[0m]: Use revamped materializations based on separating create and insert.  This allows more performant column comments, as well as new column features.
You may opt into the new behavior sooner by setting `flags.use_materialization_v2` to `True` in `dbt_project.yml`.
Visit https://docs.getdbt.com/reference/global-configs/behavior-changes for more information.
[0m12:19:03.429684 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'BehaviorChangeEvent', 'label': 'cbcf2d6d-d4a9-4ffe-8876-4da372aa8b39', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7bcc094b2ff0>]}
[0m12:19:03.463526 [debug] [Thread-4 (]: Writing runtime sql for node "model.dbt_anirudh.silver_returns_info"
[0m12:19:03.464240 [debug] [Thread-4 (]: Using databricks connection "model.dbt_anirudh.silver_returns_info"
[0m12:19:03.464650 [debug] [Thread-4 (]: On model.dbt_anirudh.silver_returns_info: /* {"app": "dbt", "dbt_version": "1.10.10", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_anirudh", "target_name": "dev", "node_id": "model.dbt_anirudh.silver_returns_info"} */

  
    
        create or replace table `dbt_learning`.`silver`.`silver_returns_info`
      
      
  using delta
      
      
      
      
      
      
      
      as
      WITH return_data AS
(
    SELECT
        sales_id,
        product_sk,
        return_reason,
        refund_amount
    FROM
        `dbt_learning`.`bronze`.`bronze_returns`
),
product_data AS
(
    SELECT
        product_sk,
        category,
        department
    FROM
        `dbt_learning`.`bronze`.`bronze_product`
),
customer_data AS
(
    SELECT
        customer_sk,
        gender
    FROM
        `dbt_learning`.`bronze`.`bronze_customer`
),
sales_data AS
(
    SELECT
        sales_id,
        customer_sk
    FROM
        `dbt_learning`.`bronze`.`bronze_sales`
),
joined_query AS
(
    SELECT
        product_data.category,
        product_data.department,
        customer_data.gender,
        return_data.refund_amount
    FROM
        return_data
    INNER JOIN sales_data ON sales_data.sales_id = return_data.sales_id
    INNER JOIN customer_data ON customer_data.customer_sk = sales_data.customer_sk
    INNER JOIN product_data ON product_data.product_sk = return_data.product_sk
)
SELECT
    category,
    department,
    gender,
    sum(refund_amount) as total_refund
FROM
    joined_query
GROUP BY 1,2,3
ORDER BY 1,2 ASC, 4 DESC
  
[0m12:19:03.465005 [debug] [Thread-4 (]: Opening a new connection, currently in state init
[0m12:19:05.020753 [debug] [Thread-4 (]: Databricks adapter: Connection(session-id=01f099db-ba1f-1458-9450-4887376b51b5) - Created
[0m12:19:07.889898 [debug] [Thread-4 (]: SQL status: OK in 4.420 seconds
[0m12:19:07.892400 [debug] [Thread-4 (]: Databricks adapter: Cursor(session-id=01f099db-ba1f-1458-9450-4887376b51b5, command-id=01f099db-ba5d-1bf2-bc42-bfe32a5b69b1) - Closing
[0m12:19:07.910727 [debug] [Thread-4 (]: Applying tags to relation None
[0m12:19:07.922409 [debug] [Thread-4 (]: On model.dbt_anirudh.silver_returns_info: Close
[0m12:19:07.922750 [debug] [Thread-4 (]: Databricks adapter: Connection(session-id=01f099db-ba1f-1458-9450-4887376b51b5) - Closing
[0m12:19:08.303439 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'cbcf2d6d-d4a9-4ffe-8876-4da372aa8b39', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7bcc2b738140>]}
[0m12:19:08.305173 [info ] [Thread-4 (]: 1 of 2 OK created sql table model silver.silver_returns_info ................... [[32mOK[0m in 4.91s]
[0m12:19:08.306756 [debug] [Thread-4 (]: Finished running node model.dbt_anirudh.silver_returns_info
[0m12:19:08.307811 [debug] [Thread-4 (]: Began running node model.dbt_anirudh.silver_sales_info
[0m12:19:08.309132 [info ] [Thread-4 (]: 2 of 2 START sql table model silver.silver_sales_info .......................... [RUN]
[0m12:19:08.310641 [debug] [Thread-4 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.dbt_anirudh.silver_sales_info) - Creating connection
[0m12:19:08.311482 [debug] [Thread-4 (]: Acquiring new databricks connection 'model.dbt_anirudh.silver_sales_info'
[0m12:19:08.312424 [debug] [Thread-4 (]: Began compiling node model.dbt_anirudh.silver_sales_info
[0m12:19:08.318138 [debug] [Thread-4 (]: Writing injected SQL for node "model.dbt_anirudh.silver_sales_info"
[0m12:19:08.318764 [debug] [Thread-4 (]: Began executing node model.dbt_anirudh.silver_sales_info
[0m12:19:08.321055 [debug] [Thread-4 (]: MATERIALIZING TABLE
[0m12:19:08.322450 [debug] [Thread-4 (]: Writing runtime sql for node "model.dbt_anirudh.silver_sales_info"
[0m12:19:08.323015 [debug] [Thread-4 (]: Using databricks connection "model.dbt_anirudh.silver_sales_info"
[0m12:19:08.323381 [debug] [Thread-4 (]: On model.dbt_anirudh.silver_sales_info: /* {"app": "dbt", "dbt_version": "1.10.10", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_anirudh", "target_name": "dev", "node_id": "model.dbt_anirudh.silver_sales_info"} */

  
    
        create or replace table `dbt_learning`.`silver`.`silver_sales_info`
      
      
  using delta
      
      
      
      
      
      
      
      as
      WITH sales AS
(
    SELECT
        sales_id,
        product_sk,
        customer_sk,
        
    quantity * unit_price
 as calculated_gross_amount,
        gross_amount,
        payment_method
    FROM
        `dbt_learning`.`bronze`.`bronze_sales`
),

customer AS
(
    SELECT
        customer_sk,
        concat(first_name, last_name) as c_name,
        gender,
        signup_date
    FROM
        `dbt_learning`.`bronze`.`bronze_customer`
),

product AS
(
    SELECT
        product_sk,
        category
    FROM
        `dbt_learning`.`bronze`.`bronze_product`
),

joined_query AS
(
    SELECT
        sales.sales_id,
        sales.calculated_gross_amount,
        sales.payment_method,
        product.category,
        customer.gender
    FROM
        sales       
    INNER JOIN customer 
        ON customer.customer_sk = sales.customer_sk
    INNER JOIN product
        ON product.product_sk = sales.product_sk
)    

SELECT
    category,
    gender,
    sum(calculated_gross_amount) as total_sales
FROM
    joined_query
GROUP BY 1,2
ORDER BY 1 ASC, 3 DESC
  
[0m12:19:08.323676 [debug] [Thread-4 (]: Opening a new connection, currently in state init
[0m12:19:09.771991 [debug] [Thread-4 (]: Databricks adapter: Connection(session-id=01f099db-bcff-101b-b4c8-b8798de88023) - Created
[0m12:19:12.294110 [debug] [Thread-4 (]: SQL status: OK in 3.970 seconds
[0m12:19:12.296475 [debug] [Thread-4 (]: Databricks adapter: Cursor(session-id=01f099db-bcff-101b-b4c8-b8798de88023, command-id=01f099db-bd33-13a3-8327-a96a7cb246fd) - Closing
[0m12:19:12.298225 [debug] [Thread-4 (]: Applying tags to relation None
[0m12:19:12.301210 [debug] [Thread-4 (]: On model.dbt_anirudh.silver_sales_info: Close
[0m12:19:12.301990 [debug] [Thread-4 (]: Databricks adapter: Connection(session-id=01f099db-bcff-101b-b4c8-b8798de88023) - Closing
[0m12:19:12.703213 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'cbcf2d6d-d4a9-4ffe-8876-4da372aa8b39', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7bcc09623f50>]}
[0m12:19:12.704050 [info ] [Thread-4 (]: 2 of 2 OK created sql table model silver.silver_sales_info ..................... [[32mOK[0m in 4.39s]
[0m12:19:12.704743 [debug] [Thread-4 (]: Finished running node model.dbt_anirudh.silver_sales_info
[0m12:19:12.706290 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=master) - Creating connection
[0m12:19:12.706851 [debug] [MainThread]: Acquiring new databricks connection 'master'
[0m12:19:12.707576 [info ] [MainThread]: 
[0m12:19:12.708225 [info ] [MainThread]: Finished running 2 table models in 0 hours 0 minutes and 17.04 seconds (17.04s).
[0m12:19:12.709585 [debug] [MainThread]: Command end result
[0m12:19:12.743626 [debug] [MainThread]: Wrote artifact WritableManifest to /home/aniruth/AI/DBT/DBT_Master/dbt_anirudh/target/manifest.json
[0m12:19:12.745202 [debug] [MainThread]: Wrote artifact SemanticManifest to /home/aniruth/AI/DBT/DBT_Master/dbt_anirudh/target/semantic_manifest.json
[0m12:19:12.749621 [debug] [MainThread]: Wrote artifact RunExecutionResult to /home/aniruth/AI/DBT/DBT_Master/dbt_anirudh/target/run_results.json
[0m12:19:12.749919 [info ] [MainThread]: 
[0m12:19:12.750230 [info ] [MainThread]: [32mCompleted successfully[0m
[0m12:19:12.750562 [info ] [MainThread]: 
[0m12:19:12.750899 [info ] [MainThread]: Done. PASS=2 WARN=0 ERROR=0 SKIP=0 NO-OP=0 TOTAL=2
[0m12:19:12.751929 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 18.593695, "process_in_blocks": "15848", "process_kernel_time": 0.182496, "process_mem_max_rss": "245624", "process_out_blocks": "3296", "process_user_time": 4.027889}
[0m12:19:12.752464 [debug] [MainThread]: Command `dbt run` succeeded at 12:19:12.752361 after 18.59 seconds
[0m12:19:12.752938 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7bcc2d3c8200>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7bcc2a9957c0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7bcc099bb9e0>]}
[0m12:19:12.753415 [debug] [MainThread]: Flushing usage events
[0m12:19:14.235092 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m08:46:14.783591 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x75bd4aab8290>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x75bd4b2db200>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x75bd4a78b8f0>]}


============================== 08:46:14.788325 | 9c1fcf61-0adf-4406-b18b-f2e0f4d5dec4 ==============================
[0m08:46:14.788325 [info ] [MainThread]: Running with dbt=1.10.10
[0m08:46:14.789169 [debug] [MainThread]: running dbt with arguments {'no_print': 'None', 'target_path': 'None', 'write_json': 'True', 'profiles_dir': '/home/aniruth/AI/DBT/DBT_Master/dbt_anirudh', 'indirect_selection': 'eager', 'send_anonymous_usage_stats': 'True', 'log_cache_events': 'False', 'debug': 'False', 'printer_width': '80', 'quiet': 'False', 'version_check': 'True', 'cache_selected_only': 'False', 'fail_fast': 'False', 'static_parser': 'True', 'use_colors': 'True', 'empty': 'False', 'partial_parse': 'True', 'invocation_command': 'dbt snapshot', 'log_format': 'default', 'warn_error': 'None', 'log_path': '/home/aniruth/AI/DBT/DBT_Master/dbt_anirudh/logs', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'use_experimental_parser': 'False', 'introspect': 'True'}
[0m08:46:15.730434 [debug] [MainThread]: Spark adapter: Setting pyhive.hive logging to ERROR
[0m08:46:15.731064 [debug] [MainThread]: Spark adapter: Setting thrift.transport logging to ERROR
[0m08:46:15.731537 [debug] [MainThread]: Spark adapter: Setting thrift.protocol logging to ERROR
[0m08:46:16.871419 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '9c1fcf61-0adf-4406-b18b-f2e0f4d5dec4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x75bd2ac31670>]}
[0m08:46:16.944519 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '9c1fcf61-0adf-4406-b18b-f2e0f4d5dec4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x75bd2a0f0c80>]}
[0m08:46:16.945542 [info ] [MainThread]: Registered adapter: databricks=1.10.9
[0m08:46:17.090644 [debug] [MainThread]: checksum: 502a0dc23e9052e1ae09f7c44ee219ef7a02dfea7e7d66580d54c304c14d553b, vars: {}, profile: , target: , version: 1.10.10
[0m08:46:17.298922 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m08:46:17.300237 [debug] [MainThread]: Partial parsing: updated file: dbt_anirudh://snapshots/gold_items.sql
[0m08:46:17.460216 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '9c1fcf61-0adf-4406-b18b-f2e0f4d5dec4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x75bd290bb620>]}
[0m08:46:17.594752 [debug] [MainThread]: Wrote artifact WritableManifest to /home/aniruth/AI/DBT/DBT_Master/dbt_anirudh/target/manifest.json
[0m08:46:17.597170 [debug] [MainThread]: Wrote artifact SemanticManifest to /home/aniruth/AI/DBT/DBT_Master/dbt_anirudh/target/semantic_manifest.json
[0m08:46:17.611673 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '9c1fcf61-0adf-4406-b18b-f2e0f4d5dec4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x75bd290f1b20>]}
[0m08:46:17.612268 [info ] [MainThread]: Found 6 analyses, 1 seed, 9 models, 5 data tests, 7 sources, 688 macros
[0m08:46:17.612659 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '9c1fcf61-0adf-4406-b18b-f2e0f4d5dec4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x75bd486f3b60>]}
[0m08:46:17.614656 [warn ] [MainThread]: Nothing to do. Try checking your model configs and model specification args
[0m08:46:17.615299 [debug] [MainThread]: Command end result
[0m08:46:17.653793 [debug] [MainThread]: Wrote artifact WritableManifest to /home/aniruth/AI/DBT/DBT_Master/dbt_anirudh/target/manifest.json
[0m08:46:17.655893 [debug] [MainThread]: Wrote artifact SemanticManifest to /home/aniruth/AI/DBT/DBT_Master/dbt_anirudh/target/semantic_manifest.json
[0m08:46:17.659944 [debug] [MainThread]: Wrote artifact RunExecutionResult to /home/aniruth/AI/DBT/DBT_Master/dbt_anirudh/target/run_results.json
[0m08:46:17.661756 [debug] [MainThread]: Resource report: {"command_name": "snapshot", "command_success": true, "command_wall_clock_time": 2.9374573, "process_in_blocks": "317032", "process_kernel_time": 0.466992, "process_mem_max_rss": "226776", "process_out_blocks": "4824", "process_user_time": 4.960539}
[0m08:46:17.662448 [debug] [MainThread]: Command `dbt snapshot` succeeded at 08:46:17.662333 after 2.94 seconds
[0m08:46:17.662922 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x75bd4c315a60>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x75bd4c283c50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x75bd28fc31a0>]}
[0m08:46:17.663398 [debug] [MainThread]: Flushing usage events
[0m08:46:18.971286 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m08:51:07.466447 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7b7870da79e0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7b78718fef00>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7b7871161fd0>]}


============================== 08:51:07.470966 | 938f4114-a330-4aa6-b79d-f08bebd84455 ==============================
[0m08:51:07.470966 [info ] [MainThread]: Running with dbt=1.10.10
[0m08:51:07.471681 [debug] [MainThread]: running dbt with arguments {'use_experimental_parser': 'False', 'partial_parse': 'True', 'indirect_selection': 'eager', 'fail_fast': 'False', 'quiet': 'False', 'printer_width': '80', 'no_print': 'None', 'send_anonymous_usage_stats': 'True', 'version_check': 'True', 'use_colors': 'True', 'log_cache_events': 'False', 'profiles_dir': '/home/aniruth/AI/DBT/DBT_Master/dbt_anirudh', 'empty': 'False', 'static_parser': 'True', 'log_format': 'default', 'warn_error': 'None', 'write_json': 'True', 'cache_selected_only': 'False', 'debug': 'False', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'target_path': 'None', 'introspect': 'True', 'log_path': '/home/aniruth/AI/DBT/DBT_Master/dbt_anirudh/logs', 'invocation_command': 'dbt build'}
[0m08:51:08.788263 [debug] [MainThread]: Spark adapter: Setting pyhive.hive logging to ERROR
[0m08:51:08.789013 [debug] [MainThread]: Spark adapter: Setting thrift.transport logging to ERROR
[0m08:51:08.789833 [debug] [MainThread]: Spark adapter: Setting thrift.protocol logging to ERROR
[0m08:51:10.058138 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '938f4114-a330-4aa6-b79d-f08bebd84455', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7b785096b200>]}
[0m08:51:10.165253 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '938f4114-a330-4aa6-b79d-f08bebd84455', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7b7851d09be0>]}
[0m08:51:10.168213 [info ] [MainThread]: Registered adapter: databricks=1.10.9
[0m08:51:10.597905 [debug] [MainThread]: checksum: 502a0dc23e9052e1ae09f7c44ee219ef7a02dfea7e7d66580d54c304c14d553b, vars: {}, profile: , target: , version: 1.10.10
[0m08:51:10.898597 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m08:51:10.899543 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m08:51:11.003951 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '938f4114-a330-4aa6-b79d-f08bebd84455', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7b7850088bf0>]}
[0m08:51:11.170144 [debug] [MainThread]: Wrote artifact WritableManifest to /home/aniruth/AI/DBT/DBT_Master/dbt_anirudh/target/manifest.json
[0m08:51:11.174118 [debug] [MainThread]: Wrote artifact SemanticManifest to /home/aniruth/AI/DBT/DBT_Master/dbt_anirudh/target/semantic_manifest.json
[0m08:51:11.211297 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '938f4114-a330-4aa6-b79d-f08bebd84455', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7b784b5d91f0>]}
[0m08:51:11.211967 [info ] [MainThread]: Found 6 analyses, 1 seed, 9 models, 5 data tests, 7 sources, 688 macros
[0m08:51:11.215780 [info ] [MainThread]: 
[0m08:51:11.216824 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m08:51:11.217257 [info ] [MainThread]: 
[0m08:51:11.218116 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=master) - Creating connection
[0m08:51:11.218591 [debug] [MainThread]: Acquiring new databricks connection 'master'
[0m08:51:11.227742 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=list_dbt_learning) - Creating connection
[0m08:51:11.228477 [debug] [ThreadPool]: Acquiring new databricks connection 'list_dbt_learning'
[0m08:51:11.228929 [debug] [ThreadPool]: Using databricks connection "list_dbt_learning"
[0m08:51:11.229327 [debug] [ThreadPool]: On list_dbt_learning: GetSchemas(database=dbt_learning, schema=None)
[0m08:51:11.229686 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m08:51:12.625633 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f09a87-da58-18d9-9370-6c6f7c39442a) - Created
[0m08:52:14.549545 [debug] [ThreadPool]: SQL status: OK in 63.320 seconds
[0m08:52:14.555714 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01f09a87-da58-18d9-9370-6c6f7c39442a, command-id=01f09a87-fe91-16ef-bb80-b6f7d1863713) - Closing
[0m08:52:14.557074 [debug] [ThreadPool]: On list_dbt_learning: Close
[0m08:52:14.557829 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f09a87-da58-18d9-9370-6c6f7c39442a) - Closing
[0m08:52:14.926774 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=list_dbt_learning) - Creating connection
[0m08:52:14.928065 [debug] [ThreadPool]: Acquiring new databricks connection 'list_dbt_learning'
[0m08:52:14.929091 [debug] [ThreadPool]: Using databricks connection "list_dbt_learning"
[0m08:52:14.929705 [debug] [ThreadPool]: On list_dbt_learning: GetSchemas(database=dbt_learning, schema=None)
[0m08:52:14.930438 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m08:52:16.193924 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f09a88-004c-1091-a1f4-38a2140b2e26) - Created
[0m08:52:16.627056 [debug] [ThreadPool]: SQL status: OK in 1.700 seconds
[0m08:52:16.630951 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01f09a88-004c-1091-a1f4-38a2140b2e26, command-id=01f09a88-007c-197d-9f4e-c4de3e294430) - Closing
[0m08:52:16.631978 [debug] [ThreadPool]: On list_dbt_learning: Close
[0m08:52:16.632852 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f09a88-004c-1091-a1f4-38a2140b2e26) - Closing
[0m08:52:16.942419 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=list_dbt_learning) - Creating connection
[0m08:52:16.943762 [debug] [ThreadPool]: Acquiring new databricks connection 'list_dbt_learning'
[0m08:52:16.944745 [debug] [ThreadPool]: Using databricks connection "list_dbt_learning"
[0m08:52:16.945551 [debug] [ThreadPool]: On list_dbt_learning: GetSchemas(database=dbt_learning, schema=None)
[0m08:52:16.946272 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m08:52:18.227563 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f09a88-0184-10ee-b39d-f7f2b66af205) - Created
[0m08:52:18.725817 [debug] [ThreadPool]: SQL status: OK in 1.780 seconds
[0m08:52:18.729739 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01f09a88-0184-10ee-b39d-f7f2b66af205, command-id=01f09a88-01b3-1154-99a6-7358848306d2) - Closing
[0m08:52:18.731444 [debug] [ThreadPool]: On list_dbt_learning: Close
[0m08:52:18.732508 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f09a88-0184-10ee-b39d-f7f2b66af205) - Closing
[0m08:52:19.050449 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=list_dbt_learning_silver) - Creating connection
[0m08:52:19.051577 [debug] [ThreadPool]: Acquiring new databricks connection 'list_dbt_learning_silver'
[0m08:52:19.106686 [debug] [ThreadPool]: Using databricks connection "list_dbt_learning_silver"
[0m08:52:19.107630 [debug] [ThreadPool]: On list_dbt_learning_silver: /* {"app": "dbt", "dbt_version": "1.10.10", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_anirudh", "target_name": "dev", "connection_name": "list_dbt_learning_silver"} */

    
SELECT
  table_name,
  if(table_type IN ('EXTERNAL', 'MANAGED', 'MANAGED_SHALLOW_CLONE', 'EXTERNAL_SHALLOW_CLONE'), 'table', lower(table_type)) AS table_type,
  lower(data_source_format) AS file_format,
  table_owner,
  if(
    table_type IN (
      'EXTERNAL',
      'MANAGED',
      'MANAGED_SHALLOW_CLONE',
      'EXTERNAL_SHALLOW_CLONE'
    ),
    lower(table_type),
    NULL
  ) AS databricks_table_type
FROM `system`.`information_schema`.`tables`
WHERE table_catalog = 'dbt_learning' 
  AND table_schema = 'silver'

  
[0m08:52:19.108404 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m08:52:20.275873 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f09a88-02bf-10ab-a84a-9d0097e5a17c) - Created
[0m08:52:23.649827 [debug] [ThreadPool]: SQL status: OK in 4.540 seconds
[0m08:52:23.686234 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01f09a88-02bf-10ab-a84a-9d0097e5a17c, command-id=01f09a88-02ea-134a-8f5d-5af69049f3eb) - Closing
[0m08:52:23.688918 [debug] [ThreadPool]: On list_dbt_learning_silver: Close
[0m08:52:23.690550 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f09a88-02bf-10ab-a84a-9d0097e5a17c) - Closing
[0m08:52:23.993273 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=list_dbt_learning_bronze) - Creating connection
[0m08:52:23.995305 [debug] [ThreadPool]: Acquiring new databricks connection 'list_dbt_learning_bronze'
[0m08:52:24.001572 [debug] [ThreadPool]: Using databricks connection "list_dbt_learning_bronze"
[0m08:52:24.002622 [debug] [ThreadPool]: On list_dbt_learning_bronze: /* {"app": "dbt", "dbt_version": "1.10.10", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_anirudh", "target_name": "dev", "connection_name": "list_dbt_learning_bronze"} */

    
SELECT
  table_name,
  if(table_type IN ('EXTERNAL', 'MANAGED', 'MANAGED_SHALLOW_CLONE', 'EXTERNAL_SHALLOW_CLONE'), 'table', lower(table_type)) AS table_type,
  lower(data_source_format) AS file_format,
  table_owner,
  if(
    table_type IN (
      'EXTERNAL',
      'MANAGED',
      'MANAGED_SHALLOW_CLONE',
      'EXTERNAL_SHALLOW_CLONE'
    ),
    lower(table_type),
    NULL
  ) AS databricks_table_type
FROM `system`.`information_schema`.`tables`
WHERE table_catalog = 'dbt_learning' 
  AND table_schema = 'bronze'

  
[0m08:52:24.003461 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m08:52:25.248398 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f09a88-05b1-1e18-bd2e-6b097a060f72) - Created
[0m08:52:26.203528 [debug] [ThreadPool]: SQL status: OK in 2.200 seconds
[0m08:52:26.219405 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01f09a88-05b1-1e18-bd2e-6b097a060f72, command-id=01f09a88-05e1-1b4d-b7f8-80f9373e2e0b) - Closing
[0m08:52:26.221443 [debug] [ThreadPool]: On list_dbt_learning_bronze: Close
[0m08:52:26.222382 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f09a88-05b1-1e18-bd2e-6b097a060f72) - Closing
[0m08:52:26.527548 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=list_dbt_learning_gold) - Creating connection
[0m08:52:26.532433 [debug] [ThreadPool]: Acquiring new databricks connection 'list_dbt_learning_gold'
[0m08:52:26.541853 [debug] [ThreadPool]: Using databricks connection "list_dbt_learning_gold"
[0m08:52:26.542897 [debug] [ThreadPool]: On list_dbt_learning_gold: /* {"app": "dbt", "dbt_version": "1.10.10", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_anirudh", "target_name": "dev", "connection_name": "list_dbt_learning_gold"} */

    
SELECT
  table_name,
  if(table_type IN ('EXTERNAL', 'MANAGED', 'MANAGED_SHALLOW_CLONE', 'EXTERNAL_SHALLOW_CLONE'), 'table', lower(table_type)) AS table_type,
  lower(data_source_format) AS file_format,
  table_owner,
  if(
    table_type IN (
      'EXTERNAL',
      'MANAGED',
      'MANAGED_SHALLOW_CLONE',
      'EXTERNAL_SHALLOW_CLONE'
    ),
    lower(table_type),
    NULL
  ) AS databricks_table_type
FROM `system`.`information_schema`.`tables`
WHERE table_catalog = 'dbt_learning' 
  AND table_schema = 'gold'

  
[0m08:52:26.543794 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m08:52:27.740156 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f09a88-0732-16f7-9e0f-73631536fa7e) - Created
[0m08:52:28.476670 [debug] [ThreadPool]: SQL status: OK in 1.930 seconds
[0m08:52:28.481811 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01f09a88-0732-16f7-9e0f-73631536fa7e, command-id=01f09a88-075e-10d1-ade6-fa98169974ba) - Closing
[0m08:52:28.483007 [debug] [ThreadPool]: On list_dbt_learning_gold: Close
[0m08:52:28.483860 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f09a88-0732-16f7-9e0f-73631536fa7e) - Closing
[0m08:52:28.799509 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '938f4114-a330-4aa6-b79d-f08bebd84455', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7b784bd6cf80>]}
[0m08:52:28.809368 [debug] [Thread-7 (]: Began running node model.dbt_anirudh.bronze_customer
[0m08:52:28.810847 [info ] [Thread-7 (]: 1 of 15 START sql table model bronze.bronze_customer ........................... [RUN]
[0m08:52:28.812229 [debug] [Thread-7 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.dbt_anirudh.bronze_customer) - Creating connection
[0m08:52:28.813100 [debug] [Thread-7 (]: Acquiring new databricks connection 'model.dbt_anirudh.bronze_customer'
[0m08:52:28.814042 [debug] [Thread-7 (]: Began compiling node model.dbt_anirudh.bronze_customer
[0m08:52:28.841029 [debug] [Thread-7 (]: Writing injected SQL for node "model.dbt_anirudh.bronze_customer"
[0m08:52:28.844268 [debug] [Thread-7 (]: Began executing node model.dbt_anirudh.bronze_customer
[0m08:52:28.879867 [debug] [Thread-7 (]: MATERIALIZING TABLE
[0m08:52:28.881323 [warn ] [Thread-7 (]: [[33mWARNING[0m]: Use revamped materializations based on separating create and insert.  This allows more performant column comments, as well as new column features.
You may opt into the new behavior sooner by setting `flags.use_materialization_v2` to `True` in `dbt_project.yml`.
Visit https://docs.getdbt.com/reference/global-configs/behavior-changes for more information.
[0m08:52:28.883591 [debug] [Thread-7 (]: Sending event: {'category': 'dbt', 'action': 'BehaviorChangeEvent', 'label': '938f4114-a330-4aa6-b79d-f08bebd84455', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7b784b560560>]}
[0m08:52:28.955483 [debug] [Thread-7 (]: Writing runtime sql for node "model.dbt_anirudh.bronze_customer"
[0m08:52:28.957544 [debug] [Thread-7 (]: Using databricks connection "model.dbt_anirudh.bronze_customer"
[0m08:52:28.958439 [debug] [Thread-7 (]: On model.dbt_anirudh.bronze_customer: /* {"app": "dbt", "dbt_version": "1.10.10", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_anirudh", "target_name": "dev", "node_id": "model.dbt_anirudh.bronze_customer"} */

  
    
        create or replace table `dbt_learning`.`bronze`.`bronze_customer`
      
      
  using delta
      
      
      
      
      
      
      
      as
      SELECT 
    *
FROM
    `dbt_learning`.`source`.`dim_customer`
  
[0m08:52:28.958979 [debug] [Thread-7 (]: Opening a new connection, currently in state init
[0m08:52:30.201845 [debug] [Thread-7 (]: Databricks adapter: Connection(session-id=01f09a88-08a7-11f3-b300-bd4006eae8ab) - Created
[0m08:52:40.186012 [debug] [Thread-7 (]: SQL status: OK in 11.220 seconds
[0m08:52:40.189973 [debug] [Thread-7 (]: Databricks adapter: Cursor(session-id=01f09a88-08a7-11f3-b300-bd4006eae8ab, command-id=01f09a88-08d4-1942-a203-477fce5ce561) - Closing
[0m08:52:40.532929 [debug] [Thread-7 (]: Applying tags to relation None
[0m08:52:40.579958 [debug] [Thread-7 (]: On model.dbt_anirudh.bronze_customer: Close
[0m08:52:40.580550 [debug] [Thread-7 (]: Databricks adapter: Connection(session-id=01f09a88-08a7-11f3-b300-bd4006eae8ab) - Closing
[0m08:52:40.881523 [debug] [Thread-7 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '938f4114-a330-4aa6-b79d-f08bebd84455', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7b787183d160>]}
[0m08:52:40.883790 [info ] [Thread-7 (]: 1 of 15 OK created sql table model bronze.bronze_customer ...................... [[32mOK[0m in 12.06s]
[0m08:52:40.885283 [debug] [Thread-7 (]: Finished running node model.dbt_anirudh.bronze_customer
[0m08:52:40.886282 [debug] [Thread-7 (]: Began running node model.dbt_anirudh.bronze_date
[0m08:52:40.887851 [info ] [Thread-7 (]: 2 of 15 START sql view model bronze.bronze_date ................................ [RUN]
[0m08:52:40.889389 [debug] [Thread-7 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.dbt_anirudh.bronze_date) - Creating connection
[0m08:52:40.890324 [debug] [Thread-7 (]: Acquiring new databricks connection 'model.dbt_anirudh.bronze_date'
[0m08:52:40.891510 [debug] [Thread-7 (]: Began compiling node model.dbt_anirudh.bronze_date
[0m08:52:40.898898 [debug] [Thread-7 (]: Writing injected SQL for node "model.dbt_anirudh.bronze_date"
[0m08:52:40.901928 [debug] [Thread-7 (]: Began executing node model.dbt_anirudh.bronze_date
[0m08:52:40.938374 [debug] [Thread-7 (]: MATERIALIZING VIEW
[0m08:52:40.962244 [debug] [Thread-7 (]: Creating view `dbt_learning`.`bronze`.`bronze_date`
[0m08:52:40.963684 [debug] [Thread-7 (]: Writing runtime sql for node "model.dbt_anirudh.bronze_date"
[0m08:52:40.965513 [debug] [Thread-7 (]: Using databricks connection "model.dbt_anirudh.bronze_date"
[0m08:52:40.966232 [debug] [Thread-7 (]: On model.dbt_anirudh.bronze_date: /* {"app": "dbt", "dbt_version": "1.10.10", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_anirudh", "target_name": "dev", "node_id": "model.dbt_anirudh.bronze_date"} */

  
  
  create or replace view `dbt_learning`.`bronze`.`bronze_date`
  
  as (
    SELECT  
    *
FROM
    `dbt_learning`.`source`.`dim_date`
  )

[0m08:52:40.966891 [debug] [Thread-7 (]: Opening a new connection, currently in state init
[0m08:52:42.162386 [debug] [Thread-7 (]: Databricks adapter: Connection(session-id=01f09a88-0fca-19a6-90e9-99ac2d25341a) - Created
[0m08:52:43.517862 [debug] [Thread-7 (]: SQL status: OK in 2.550 seconds
[0m08:52:43.520991 [debug] [Thread-7 (]: Databricks adapter: Cursor(session-id=01f09a88-0fca-19a6-90e9-99ac2d25341a, command-id=01f09a88-0ff6-19e5-a2cd-1c7febc7b5c1) - Closing
[0m08:52:43.522561 [debug] [Thread-7 (]: Applying tags to relation None
[0m08:52:43.532349 [debug] [Thread-7 (]: On model.dbt_anirudh.bronze_date: Close
[0m08:52:43.533490 [debug] [Thread-7 (]: Databricks adapter: Connection(session-id=01f09a88-0fca-19a6-90e9-99ac2d25341a) - Closing
[0m08:52:43.825332 [debug] [Thread-7 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '938f4114-a330-4aa6-b79d-f08bebd84455', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7b784b50ea80>]}
[0m08:52:43.827762 [info ] [Thread-7 (]: 2 of 15 OK created sql view model bronze.bronze_date ........................... [[32mOK[0m in 2.94s]
[0m08:52:43.829144 [debug] [Thread-7 (]: Finished running node model.dbt_anirudh.bronze_date
[0m08:52:43.830125 [debug] [Thread-7 (]: Began running node model.dbt_anirudh.bronze_product
[0m08:52:43.831434 [info ] [Thread-7 (]: 3 of 15 START sql table model bronze.bronze_product ............................ [RUN]
[0m08:52:43.832823 [debug] [Thread-7 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.dbt_anirudh.bronze_product) - Creating connection
[0m08:52:43.833742 [debug] [Thread-7 (]: Acquiring new databricks connection 'model.dbt_anirudh.bronze_product'
[0m08:52:43.834694 [debug] [Thread-7 (]: Began compiling node model.dbt_anirudh.bronze_product
[0m08:52:43.847667 [debug] [Thread-7 (]: Writing injected SQL for node "model.dbt_anirudh.bronze_product"
[0m08:52:43.849872 [debug] [Thread-7 (]: Began executing node model.dbt_anirudh.bronze_product
[0m08:52:43.855499 [debug] [Thread-7 (]: MATERIALIZING TABLE
[0m08:52:43.859589 [debug] [Thread-7 (]: Writing runtime sql for node "model.dbt_anirudh.bronze_product"
[0m08:52:43.860955 [debug] [Thread-7 (]: Using databricks connection "model.dbt_anirudh.bronze_product"
[0m08:52:43.862208 [debug] [Thread-7 (]: On model.dbt_anirudh.bronze_product: /* {"app": "dbt", "dbt_version": "1.10.10", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_anirudh", "target_name": "dev", "node_id": "model.dbt_anirudh.bronze_product"} */

  
    
        create or replace table `dbt_learning`.`bronze`.`bronze_product`
      
      
  using delta
      
      
      
      
      
      
      
      as
      SELECT
    *
FROM
    `dbt_learning`.`source`.`dim_product`
  
[0m08:52:43.863085 [debug] [Thread-7 (]: Opening a new connection, currently in state init
[0m08:52:45.096621 [debug] [Thread-7 (]: Databricks adapter: Connection(session-id=01f09a88-1182-1350-9a68-20d33b77da64) - Created
[0m08:52:48.479036 [debug] [Thread-7 (]: SQL status: OK in 4.610 seconds
[0m08:52:48.482978 [debug] [Thread-7 (]: Databricks adapter: Cursor(session-id=01f09a88-1182-1350-9a68-20d33b77da64, command-id=01f09a88-11b4-1eae-a230-5870a8b1a30e) - Closing
[0m08:52:48.485358 [debug] [Thread-7 (]: Applying tags to relation None
[0m08:52:48.488222 [debug] [Thread-7 (]: On model.dbt_anirudh.bronze_product: Close
[0m08:52:48.489240 [debug] [Thread-7 (]: Databricks adapter: Connection(session-id=01f09a88-1182-1350-9a68-20d33b77da64) - Closing
[0m08:52:48.806815 [debug] [Thread-7 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '938f4114-a330-4aa6-b79d-f08bebd84455', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7b78483dc980>]}
[0m08:52:48.809068 [info ] [Thread-7 (]: 3 of 15 OK created sql table model bronze.bronze_product ....................... [[32mOK[0m in 4.97s]
[0m08:52:48.810754 [debug] [Thread-7 (]: Finished running node model.dbt_anirudh.bronze_product
[0m08:52:48.811552 [debug] [Thread-7 (]: Began running node model.dbt_anirudh.bronze_returns
[0m08:52:48.812383 [info ] [Thread-7 (]: 4 of 15 START sql table model bronze.bronze_returns ............................ [RUN]
[0m08:52:48.813117 [debug] [Thread-7 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.dbt_anirudh.bronze_returns) - Creating connection
[0m08:52:48.813617 [debug] [Thread-7 (]: Acquiring new databricks connection 'model.dbt_anirudh.bronze_returns'
[0m08:52:48.814049 [debug] [Thread-7 (]: Began compiling node model.dbt_anirudh.bronze_returns
[0m08:52:48.833949 [debug] [Thread-7 (]: Writing injected SQL for node "model.dbt_anirudh.bronze_returns"
[0m08:52:48.836254 [debug] [Thread-7 (]: Began executing node model.dbt_anirudh.bronze_returns
[0m08:52:48.841264 [debug] [Thread-7 (]: MATERIALIZING TABLE
[0m08:52:48.843599 [debug] [Thread-7 (]: Writing runtime sql for node "model.dbt_anirudh.bronze_returns"
[0m08:52:48.845011 [debug] [Thread-7 (]: Using databricks connection "model.dbt_anirudh.bronze_returns"
[0m08:52:48.845533 [debug] [Thread-7 (]: On model.dbt_anirudh.bronze_returns: /* {"app": "dbt", "dbt_version": "1.10.10", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_anirudh", "target_name": "dev", "node_id": "model.dbt_anirudh.bronze_returns"} */

  
    
        create or replace table `dbt_learning`.`bronze`.`bronze_returns`
      
      
  using delta
      
      
      
      
      
      
      
      as
      SELECT
    *
FROM
    `dbt_learning`.`source`.`fact_returns`
  
[0m08:52:48.845973 [debug] [Thread-7 (]: Opening a new connection, currently in state init
[0m08:52:50.135725 [debug] [Thread-7 (]: Databricks adapter: Connection(session-id=01f09a88-148a-1c7d-8997-18fa74847ed7) - Created
[0m08:52:54.334589 [debug] [Thread-7 (]: SQL status: OK in 5.490 seconds
[0m08:52:54.338308 [debug] [Thread-7 (]: Databricks adapter: Cursor(session-id=01f09a88-148a-1c7d-8997-18fa74847ed7, command-id=01f09a88-14b6-188b-898e-dbd76b99fe13) - Closing
[0m08:52:54.340699 [debug] [Thread-7 (]: Applying tags to relation None
[0m08:52:54.343214 [debug] [Thread-7 (]: On model.dbt_anirudh.bronze_returns: Close
[0m08:52:54.344122 [debug] [Thread-7 (]: Databricks adapter: Connection(session-id=01f09a88-148a-1c7d-8997-18fa74847ed7) - Closing
[0m08:52:54.653939 [debug] [Thread-7 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '938f4114-a330-4aa6-b79d-f08bebd84455', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7b78483d3500>]}
[0m08:52:54.656278 [info ] [Thread-7 (]: 4 of 15 OK created sql table model bronze.bronze_returns ....................... [[32mOK[0m in 5.84s]
[0m08:52:54.657643 [debug] [Thread-7 (]: Finished running node model.dbt_anirudh.bronze_returns
[0m08:52:54.658636 [debug] [Thread-7 (]: Began running node model.dbt_anirudh.bronze_sales
[0m08:52:54.660008 [info ] [Thread-7 (]: 5 of 15 START sql view model bronze.bronze_sales ............................... [RUN]
[0m08:52:54.661359 [debug] [Thread-7 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.dbt_anirudh.bronze_sales) - Creating connection
[0m08:52:54.662320 [debug] [Thread-7 (]: Acquiring new databricks connection 'model.dbt_anirudh.bronze_sales'
[0m08:52:54.663196 [debug] [Thread-7 (]: Began compiling node model.dbt_anirudh.bronze_sales
[0m08:52:54.679246 [debug] [Thread-7 (]: Writing injected SQL for node "model.dbt_anirudh.bronze_sales"
[0m08:52:54.681941 [debug] [Thread-7 (]: Began executing node model.dbt_anirudh.bronze_sales
[0m08:52:54.875110 [debug] [Thread-7 (]: MATERIALIZING VIEW
[0m08:52:54.876577 [debug] [Thread-7 (]: Creating view `dbt_learning`.`bronze`.`bronze_sales`
[0m08:52:54.877400 [debug] [Thread-7 (]: Writing runtime sql for node "model.dbt_anirudh.bronze_sales"
[0m08:52:54.878675 [debug] [Thread-7 (]: Using databricks connection "model.dbt_anirudh.bronze_sales"
[0m08:52:54.879223 [debug] [Thread-7 (]: On model.dbt_anirudh.bronze_sales: /* {"app": "dbt", "dbt_version": "1.10.10", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_anirudh", "target_name": "dev", "node_id": "model.dbt_anirudh.bronze_sales"} */

  
  
  create or replace view `dbt_learning`.`bronze`.`bronze_sales`
  
  as (
    -- block level config


SELECT 
    * 
FROM
    
    `dbt_learning`.`source`.`fact_sales`
  )

[0m08:52:54.879653 [debug] [Thread-7 (]: Opening a new connection, currently in state init
[0m08:52:56.032201 [debug] [Thread-7 (]: Databricks adapter: Connection(session-id=01f09a88-180f-162d-87ee-c9b0a48db180) - Created
[0m08:52:57.085926 [debug] [Thread-7 (]: SQL status: OK in 2.210 seconds
[0m08:52:57.088521 [debug] [Thread-7 (]: Databricks adapter: Cursor(session-id=01f09a88-180f-162d-87ee-c9b0a48db180, command-id=01f09a88-183b-135b-9053-51176c9f50e8) - Closing
[0m08:52:57.090112 [debug] [Thread-7 (]: Applying tags to relation None
[0m08:52:57.094663 [debug] [Thread-7 (]: On model.dbt_anirudh.bronze_sales: Close
[0m08:52:57.095606 [debug] [Thread-7 (]: Databricks adapter: Connection(session-id=01f09a88-180f-162d-87ee-c9b0a48db180) - Closing
[0m08:52:57.396434 [debug] [Thread-7 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '938f4114-a330-4aa6-b79d-f08bebd84455', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7b78483d2a20>]}
[0m08:52:57.398246 [info ] [Thread-7 (]: 5 of 15 OK created sql view model bronze.bronze_sales .......................... [[32mOK[0m in 2.73s]
[0m08:52:57.399824 [debug] [Thread-7 (]: Finished running node model.dbt_anirudh.bronze_sales
[0m08:52:57.400914 [debug] [Thread-7 (]: Began running node model.dbt_anirudh.bronze_store
[0m08:52:57.402321 [info ] [Thread-7 (]: 6 of 15 START sql table model bronze.bronze_store .............................. [RUN]
[0m08:52:57.404318 [debug] [Thread-7 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.dbt_anirudh.bronze_store) - Creating connection
[0m08:52:57.405362 [debug] [Thread-7 (]: Acquiring new databricks connection 'model.dbt_anirudh.bronze_store'
[0m08:52:57.406549 [debug] [Thread-7 (]: Began compiling node model.dbt_anirudh.bronze_store
[0m08:52:57.418104 [debug] [Thread-7 (]: Writing injected SQL for node "model.dbt_anirudh.bronze_store"
[0m08:52:57.420261 [debug] [Thread-7 (]: Began executing node model.dbt_anirudh.bronze_store
[0m08:52:57.425545 [debug] [Thread-7 (]: MATERIALIZING TABLE
[0m08:52:57.440588 [debug] [Thread-7 (]: Applying DROP to: `dbt_learning`.`bronze`.`bronze_store`
[0m08:52:57.451448 [debug] [Thread-7 (]: Using databricks connection "model.dbt_anirudh.bronze_store"
[0m08:52:57.452682 [debug] [Thread-7 (]: On model.dbt_anirudh.bronze_store: /* {"app": "dbt", "dbt_version": "1.10.10", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_anirudh", "target_name": "dev", "node_id": "model.dbt_anirudh.bronze_store"} */
DROP VIEW IF EXISTS `dbt_learning`.`bronze`.`bronze_store`
[0m08:52:57.453525 [debug] [Thread-7 (]: Opening a new connection, currently in state init
[0m08:52:58.615962 [debug] [Thread-7 (]: Databricks adapter: Connection(session-id=01f09a88-1999-1110-9009-6757e036030d) - Created
[0m08:52:59.895784 [debug] [Thread-7 (]: SQL status: OK in 2.440 seconds
[0m08:52:59.898092 [debug] [Thread-7 (]: Databricks adapter: Cursor(session-id=01f09a88-1999-1110-9009-6757e036030d, command-id=01f09a88-19c4-1ba2-ae2c-9b9d6c1ac400) - Closing
[0m08:52:59.900948 [debug] [Thread-7 (]: Writing runtime sql for node "model.dbt_anirudh.bronze_store"
[0m08:52:59.902208 [debug] [Thread-7 (]: Using databricks connection "model.dbt_anirudh.bronze_store"
[0m08:52:59.902940 [debug] [Thread-7 (]: On model.dbt_anirudh.bronze_store: /* {"app": "dbt", "dbt_version": "1.10.10", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_anirudh", "target_name": "dev", "node_id": "model.dbt_anirudh.bronze_store"} */

  
    
        create or replace table `dbt_learning`.`bronze`.`bronze_store`
      
      
  using delta
      
      
      
      
      
      
      
      as
      SELECT
    *
FROM
    `dbt_learning`.`source`.`dim_store`
  
[0m08:53:03.897727 [debug] [Thread-7 (]: SQL status: OK in 3.990 seconds
[0m08:53:03.900192 [debug] [Thread-7 (]: Databricks adapter: Cursor(session-id=01f09a88-1999-1110-9009-6757e036030d, command-id=01f09a88-1a88-1da5-a9ee-d01d0e5fa940) - Closing
[0m08:53:03.902080 [debug] [Thread-7 (]: Applying tags to relation None
[0m08:53:03.904949 [debug] [Thread-7 (]: On model.dbt_anirudh.bronze_store: Close
[0m08:53:03.906509 [debug] [Thread-7 (]: Databricks adapter: Connection(session-id=01f09a88-1999-1110-9009-6757e036030d) - Closing
[0m08:53:04.212813 [debug] [Thread-7 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '938f4114-a330-4aa6-b79d-f08bebd84455', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7b784b4d95b0>]}
[0m08:53:04.213818 [info ] [Thread-7 (]: 6 of 15 OK created sql table model bronze.bronze_store ......................... [[32mOK[0m in 6.81s]
[0m08:53:04.214581 [debug] [Thread-7 (]: Finished running node model.dbt_anirudh.bronze_store
[0m08:53:04.215123 [debug] [Thread-7 (]: Began running node model.dbt_anirudh.gold_items_source
[0m08:53:04.215810 [info ] [Thread-7 (]: 7 of 15 START sql table model gold.gold_items_source ........................... [RUN]
[0m08:53:04.216632 [debug] [Thread-7 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.dbt_anirudh.gold_items_source) - Creating connection
[0m08:53:04.217138 [debug] [Thread-7 (]: Acquiring new databricks connection 'model.dbt_anirudh.gold_items_source'
[0m08:53:04.217630 [debug] [Thread-7 (]: Began compiling node model.dbt_anirudh.gold_items_source
[0m08:53:04.221735 [debug] [Thread-7 (]: Writing injected SQL for node "model.dbt_anirudh.gold_items_source"
[0m08:53:04.224113 [debug] [Thread-7 (]: Began executing node model.dbt_anirudh.gold_items_source
[0m08:53:04.227442 [debug] [Thread-7 (]: MATERIALIZING TABLE
[0m08:53:04.229387 [debug] [Thread-7 (]: Writing runtime sql for node "model.dbt_anirudh.gold_items_source"
[0m08:53:04.230789 [debug] [Thread-7 (]: Using databricks connection "model.dbt_anirudh.gold_items_source"
[0m08:53:04.231931 [debug] [Thread-7 (]: On model.dbt_anirudh.gold_items_source: /* {"app": "dbt", "dbt_version": "1.10.10", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_anirudh", "target_name": "dev", "node_id": "model.dbt_anirudh.gold_items_source"} */

  
    
        create or replace table `dbt_learning`.`gold`.`gold_items_source`
      
      
  using delta
      
      
      
      
      
      
      
      as
      WITH deduplication_DATA AS
(
    SELECT
        *,
        ROW_NUMBER() OVER (partition by id ORDER BY updateDate DESC) as deduplication_id
    FROM
        `dbt_learning`.`source`.`items`
)
SELECT
    id, name, category, updateDate
FROM deduplication_DATA
WHERE
    deduplication_id = 1
  
[0m08:53:04.232886 [debug] [Thread-7 (]: Opening a new connection, currently in state init
[0m08:53:05.472237 [debug] [Thread-7 (]: Databricks adapter: Connection(session-id=01f09a88-1dae-17ef-88cd-b8a3b4b551e9) - Created
[0m08:53:09.496505 [debug] [Thread-7 (]: SQL status: OK in 5.260 seconds
[0m08:53:09.498919 [debug] [Thread-7 (]: Databricks adapter: Cursor(session-id=01f09a88-1dae-17ef-88cd-b8a3b4b551e9, command-id=01f09a88-1ddc-1177-be4a-162e18701385) - Closing
[0m08:53:09.500396 [debug] [Thread-7 (]: Applying tags to relation None
[0m08:53:09.502761 [debug] [Thread-7 (]: On model.dbt_anirudh.gold_items_source: Close
[0m08:53:09.503694 [debug] [Thread-7 (]: Databricks adapter: Connection(session-id=01f09a88-1dae-17ef-88cd-b8a3b4b551e9) - Closing
[0m08:53:09.815934 [debug] [Thread-7 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '938f4114-a330-4aa6-b79d-f08bebd84455', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7b784bd48560>]}
[0m08:53:09.817951 [info ] [Thread-7 (]: 7 of 15 OK created sql table model gold.gold_items_source ...................... [[32mOK[0m in 5.60s]
[0m08:53:09.819414 [debug] [Thread-7 (]: Finished running node model.dbt_anirudh.gold_items_source
[0m08:53:09.820408 [debug] [Thread-7 (]: Began running node seed.dbt_anirudh.lookup
[0m08:53:09.821608 [info ] [Thread-7 (]: 8 of 15 START seed file bronze.lookup .......................................... [RUN]
[0m08:53:09.822891 [debug] [Thread-7 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=seed.dbt_anirudh.lookup) - Creating connection
[0m08:53:09.823813 [debug] [Thread-7 (]: Acquiring new databricks connection 'seed.dbt_anirudh.lookup'
[0m08:53:09.824779 [debug] [Thread-7 (]: Began compiling node seed.dbt_anirudh.lookup
[0m08:53:09.825752 [debug] [Thread-7 (]: Began executing node seed.dbt_anirudh.lookup
[0m08:53:09.897059 [debug] [Thread-7 (]: Using databricks connection "seed.dbt_anirudh.lookup"
[0m08:53:09.897683 [debug] [Thread-7 (]: On seed.dbt_anirudh.lookup: /* {"app": "dbt", "dbt_version": "1.10.10", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_anirudh", "target_name": "dev", "node_id": "seed.dbt_anirudh.lookup"} */

    create or replace table `dbt_learning`.`bronze`.`lookup` (`customer_id` bigint ,`customer_name` string ,`customer_mail` string )
    
  using delta
    
    
    
    
    
  
[0m08:53:09.898240 [debug] [Thread-7 (]: Opening a new connection, currently in state init
[0m08:53:11.074579 [debug] [Thread-7 (]: Databricks adapter: Connection(session-id=01f09a88-2106-1106-ab67-0d239629828e) - Created
[0m08:53:12.875521 [debug] [Thread-7 (]: SQL status: OK in 2.980 seconds
[0m08:53:12.877998 [debug] [Thread-7 (]: Databricks adapter: Cursor(session-id=01f09a88-2106-1106-ab67-0d239629828e, command-id=01f09a88-2131-1f06-9309-8f17ca25255d) - Closing
[0m08:53:12.909840 [debug] [Thread-7 (]: Using databricks connection "seed.dbt_anirudh.lookup"
[0m08:53:12.910828 [debug] [Thread-7 (]: On seed.dbt_anirudh.lookup: 
          insert overwrite `dbt_learning`.`bronze`.`lookup` values
          (%s,%s,%s),(%s,%s,%s),(%s,%s,%s)
      ...
[0m08:53:14.820740 [debug] [Thread-7 (]: SQL status: OK in 1.910 seconds
[0m08:53:14.821890 [debug] [Thread-7 (]: Databricks adapter: Cursor(session-id=01f09a88-2106-1106-ab67-0d239629828e, command-id=01f09a88-224a-12e5-bf2d-1aae586a9a41) - Closing
[0m08:53:14.834728 [debug] [Thread-7 (]: Writing runtime SQL for node "seed.dbt_anirudh.lookup"
[0m08:53:14.840082 [debug] [Thread-7 (]: On seed.dbt_anirudh.lookup: Close
[0m08:53:14.841064 [debug] [Thread-7 (]: Databricks adapter: Connection(session-id=01f09a88-2106-1106-ab67-0d239629828e) - Closing
[0m08:53:15.146878 [debug] [Thread-7 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '938f4114-a330-4aa6-b79d-f08bebd84455', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7b784bac4b30>]}
[0m08:53:15.148598 [info ] [Thread-7 (]: 8 of 15 OK loaded seed file bronze.lookup ...................................... [[32mINSERT 3[0m in 5.32s]
[0m08:53:15.150606 [debug] [Thread-7 (]: Finished running node seed.dbt_anirudh.lookup
[0m08:53:15.151933 [debug] [Thread-7 (]: Began running node test.dbt_anirudh.generic_non_negative_bronze_sales_gross_amount.770bebc5b1
[0m08:53:15.153106 [info ] [Thread-7 (]: 9 of 15 START test generic_non_negative_bronze_sales_gross_amount .............. [RUN]
[0m08:53:15.154735 [debug] [Thread-7 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=test.dbt_anirudh.generic_non_negative_bronze_sales_gross_amount.770bebc5b1) - Creating connection
[0m08:53:15.155883 [debug] [Thread-7 (]: Acquiring new databricks connection 'test.dbt_anirudh.generic_non_negative_bronze_sales_gross_amount.770bebc5b1'
[0m08:53:15.156805 [debug] [Thread-7 (]: Began compiling node test.dbt_anirudh.generic_non_negative_bronze_sales_gross_amount.770bebc5b1
[0m08:53:15.175213 [debug] [Thread-7 (]: Writing injected SQL for node "test.dbt_anirudh.generic_non_negative_bronze_sales_gross_amount.770bebc5b1"
[0m08:53:15.176910 [debug] [Thread-7 (]: Began executing node test.dbt_anirudh.generic_non_negative_bronze_sales_gross_amount.770bebc5b1
[0m08:53:15.211923 [debug] [Thread-7 (]: Writing runtime sql for node "test.dbt_anirudh.generic_non_negative_bronze_sales_gross_amount.770bebc5b1"
[0m08:53:15.212914 [debug] [Thread-7 (]: Using databricks connection "test.dbt_anirudh.generic_non_negative_bronze_sales_gross_amount.770bebc5b1"
[0m08:53:15.213453 [debug] [Thread-7 (]: On test.dbt_anirudh.generic_non_negative_bronze_sales_gross_amount.770bebc5b1: /* {"app": "dbt", "dbt_version": "1.10.10", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_anirudh", "target_name": "dev", "node_id": "test.dbt_anirudh.generic_non_negative_bronze_sales_gross_amount.770bebc5b1"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  

SELECT 
    *
FROM 
    `dbt_learning`.`bronze`.`bronze_sales`
WHERE
    gross_amount < 0


  
  
      
    ) dbt_internal_test
[0m08:53:15.213869 [debug] [Thread-7 (]: Opening a new connection, currently in state init
[0m08:53:16.411446 [debug] [Thread-7 (]: Databricks adapter: Connection(session-id=01f09a88-2433-18f9-922c-cd45e6377ff3) - Created
[0m08:53:17.783048 [debug] [Thread-7 (]: SQL status: OK in 2.570 seconds
[0m08:53:17.808128 [debug] [Thread-7 (]: Databricks adapter: Cursor(session-id=01f09a88-2433-18f9-922c-cd45e6377ff3, command-id=01f09a88-2461-1578-8311-bff9bf39a731) - Closing
[0m08:53:17.815849 [debug] [Thread-7 (]: On test.dbt_anirudh.generic_non_negative_bronze_sales_gross_amount.770bebc5b1: Close
[0m08:53:17.816930 [debug] [Thread-7 (]: Databricks adapter: Connection(session-id=01f09a88-2433-18f9-922c-cd45e6377ff3) - Closing
[0m08:53:18.121433 [info ] [Thread-7 (]: 9 of 15 PASS generic_non_negative_bronze_sales_gross_amount .................... [[32mPASS[0m in 2.97s]
[0m08:53:18.123068 [debug] [Thread-7 (]: Finished running node test.dbt_anirudh.generic_non_negative_bronze_sales_gross_amount.770bebc5b1
[0m08:53:18.124277 [debug] [Thread-7 (]: Began running node test.dbt_anirudh.non_negartive
[0m08:53:18.125386 [info ] [Thread-7 (]: 10 of 15 START test non_negartive .............................................. [RUN]
[0m08:53:18.126696 [debug] [Thread-7 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=test.dbt_anirudh.non_negartive) - Creating connection
[0m08:53:18.127672 [debug] [Thread-7 (]: Acquiring new databricks connection 'test.dbt_anirudh.non_negartive'
[0m08:53:18.128722 [debug] [Thread-7 (]: Began compiling node test.dbt_anirudh.non_negartive
[0m08:53:18.138904 [debug] [Thread-7 (]: Writing injected SQL for node "test.dbt_anirudh.non_negartive"
[0m08:53:18.141239 [debug] [Thread-7 (]: Began executing node test.dbt_anirudh.non_negartive
[0m08:53:18.146539 [debug] [Thread-7 (]: Writing runtime sql for node "test.dbt_anirudh.non_negartive"
[0m08:53:18.148004 [debug] [Thread-7 (]: Using databricks connection "test.dbt_anirudh.non_negartive"
[0m08:53:18.149034 [debug] [Thread-7 (]: On test.dbt_anirudh.non_negartive: /* {"app": "dbt", "dbt_version": "1.10.10", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_anirudh", "target_name": "dev", "node_id": "test.dbt_anirudh.non_negartive"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  SELECT
    *
FROM
    `dbt_learning`.`bronze`.`bronze_sales`
WHERE
    gross_amount < 0 AND net_amount < 0
  
  
      
    ) dbt_internal_test
[0m08:53:18.149880 [debug] [Thread-7 (]: Opening a new connection, currently in state init
[0m08:53:19.381501 [debug] [Thread-7 (]: Databricks adapter: Connection(session-id=01f09a88-25f8-1d2e-a1fe-b3d592751f85) - Created
[0m08:53:20.143269 [debug] [Thread-7 (]: SQL status: OK in 1.990 seconds
[0m08:53:20.147682 [debug] [Thread-7 (]: Databricks adapter: Cursor(session-id=01f09a88-25f8-1d2e-a1fe-b3d592751f85, command-id=01f09a88-2625-1d50-af75-90f7cc127a56) - Closing
[0m08:53:20.149256 [debug] [Thread-7 (]: On test.dbt_anirudh.non_negartive: Close
[0m08:53:20.150248 [debug] [Thread-7 (]: Databricks adapter: Connection(session-id=01f09a88-25f8-1d2e-a1fe-b3d592751f85) - Closing
[0m08:53:20.472845 [info ] [Thread-7 (]: 10 of 15 PASS non_negartive .................................................... [[32mPASS[0m in 2.35s]
[0m08:53:20.474716 [debug] [Thread-7 (]: Finished running node test.dbt_anirudh.non_negartive
[0m08:53:20.475851 [debug] [Thread-7 (]: Began running node test.dbt_anirudh.not_null_bronze_sales_sales_id.e4b1b997fb
[0m08:53:20.477062 [info ] [Thread-7 (]: 11 of 15 START test not_null_bronze_sales_sales_id ............................. [RUN]
[0m08:53:20.478778 [debug] [Thread-7 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=test.dbt_anirudh.not_null_bronze_sales_sales_id.e4b1b997fb) - Creating connection
[0m08:53:20.479798 [debug] [Thread-7 (]: Acquiring new databricks connection 'test.dbt_anirudh.not_null_bronze_sales_sales_id.e4b1b997fb'
[0m08:53:20.480857 [debug] [Thread-7 (]: Began compiling node test.dbt_anirudh.not_null_bronze_sales_sales_id.e4b1b997fb
[0m08:53:20.501131 [debug] [Thread-7 (]: Writing injected SQL for node "test.dbt_anirudh.not_null_bronze_sales_sales_id.e4b1b997fb"
[0m08:53:20.503472 [debug] [Thread-7 (]: Began executing node test.dbt_anirudh.not_null_bronze_sales_sales_id.e4b1b997fb
[0m08:53:20.516684 [debug] [Thread-7 (]: Writing runtime sql for node "test.dbt_anirudh.not_null_bronze_sales_sales_id.e4b1b997fb"
[0m08:53:20.518038 [debug] [Thread-7 (]: Using databricks connection "test.dbt_anirudh.not_null_bronze_sales_sales_id.e4b1b997fb"
[0m08:53:20.519091 [debug] [Thread-7 (]: On test.dbt_anirudh.not_null_bronze_sales_sales_id.e4b1b997fb: /* {"app": "dbt", "dbt_version": "1.10.10", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_anirudh", "target_name": "dev", "node_id": "test.dbt_anirudh.not_null_bronze_sales_sales_id.e4b1b997fb"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select sales_id
from `dbt_learning`.`bronze`.`bronze_sales`
where sales_id is null



  
  
      
    ) dbt_internal_test
[0m08:53:20.519949 [debug] [Thread-7 (]: Opening a new connection, currently in state init
[0m08:53:21.704455 [debug] [Thread-7 (]: Databricks adapter: Connection(session-id=01f09a88-275c-1c3e-9604-1434ed149c01) - Created
[0m08:53:22.508822 [debug] [Thread-7 (]: SQL status: OK in 1.990 seconds
[0m08:53:22.515413 [debug] [Thread-7 (]: Databricks adapter: Cursor(session-id=01f09a88-275c-1c3e-9604-1434ed149c01, command-id=01f09a88-2788-1583-9c0c-78c81f3d36a9) - Closing
[0m08:53:22.517222 [debug] [Thread-7 (]: On test.dbt_anirudh.not_null_bronze_sales_sales_id.e4b1b997fb: Close
[0m08:53:22.518265 [debug] [Thread-7 (]: Databricks adapter: Connection(session-id=01f09a88-275c-1c3e-9604-1434ed149c01) - Closing
[0m08:53:22.824154 [info ] [Thread-7 (]: 11 of 15 PASS not_null_bronze_sales_sales_id ................................... [[32mPASS[0m in 2.34s]
[0m08:53:22.825973 [debug] [Thread-7 (]: Finished running node test.dbt_anirudh.not_null_bronze_sales_sales_id.e4b1b997fb
[0m08:53:22.827097 [debug] [Thread-7 (]: Began running node test.dbt_anirudh.unique_bronze_sales_sales_id.3c35aa753d
[0m08:53:22.828388 [info ] [Thread-7 (]: 12 of 15 START test unique_bronze_sales_sales_id ............................... [RUN]
[0m08:53:22.830365 [debug] [Thread-7 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=test.dbt_anirudh.unique_bronze_sales_sales_id.3c35aa753d) - Creating connection
[0m08:53:22.831551 [debug] [Thread-7 (]: Acquiring new databricks connection 'test.dbt_anirudh.unique_bronze_sales_sales_id.3c35aa753d'
[0m08:53:22.832540 [debug] [Thread-7 (]: Began compiling node test.dbt_anirudh.unique_bronze_sales_sales_id.3c35aa753d
[0m08:53:22.851594 [debug] [Thread-7 (]: Writing injected SQL for node "test.dbt_anirudh.unique_bronze_sales_sales_id.3c35aa753d"
[0m08:53:22.853474 [debug] [Thread-7 (]: Began executing node test.dbt_anirudh.unique_bronze_sales_sales_id.3c35aa753d
[0m08:53:22.858617 [debug] [Thread-7 (]: Writing runtime sql for node "test.dbt_anirudh.unique_bronze_sales_sales_id.3c35aa753d"
[0m08:53:22.859780 [debug] [Thread-7 (]: Using databricks connection "test.dbt_anirudh.unique_bronze_sales_sales_id.3c35aa753d"
[0m08:53:22.860818 [debug] [Thread-7 (]: On test.dbt_anirudh.unique_bronze_sales_sales_id.3c35aa753d: /* {"app": "dbt", "dbt_version": "1.10.10", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_anirudh", "target_name": "dev", "node_id": "test.dbt_anirudh.unique_bronze_sales_sales_id.3c35aa753d"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    

select
    sales_id as unique_field,
    count(*) as n_records

from `dbt_learning`.`bronze`.`bronze_sales`
where sales_id is not null
group by sales_id
having count(*) > 1



  
  
      
    ) dbt_internal_test
[0m08:53:22.861693 [debug] [Thread-7 (]: Opening a new connection, currently in state init
[0m08:53:24.047599 [debug] [Thread-7 (]: Databricks adapter: Connection(session-id=01f09a88-28c1-148e-88b6-5b26b76093d6) - Created
[0m08:53:25.070043 [debug] [Thread-7 (]: SQL status: OK in 2.210 seconds
[0m08:53:25.074808 [debug] [Thread-7 (]: Databricks adapter: Cursor(session-id=01f09a88-28c1-148e-88b6-5b26b76093d6, command-id=01f09a88-28ed-1887-8607-a3b60ca64ef0) - Closing
[0m08:53:25.076381 [debug] [Thread-7 (]: On test.dbt_anirudh.unique_bronze_sales_sales_id.3c35aa753d: Close
[0m08:53:25.077358 [debug] [Thread-7 (]: Databricks adapter: Connection(session-id=01f09a88-28c1-148e-88b6-5b26b76093d6) - Closing
[0m08:53:25.383063 [info ] [Thread-7 (]: 12 of 15 PASS unique_bronze_sales_sales_id ..................................... [[32mPASS[0m in 2.55s]
[0m08:53:25.384833 [debug] [Thread-7 (]: Finished running node test.dbt_anirudh.unique_bronze_sales_sales_id.3c35aa753d
[0m08:53:25.385974 [debug] [Thread-7 (]: Began running node test.dbt_anirudh.accepted_values_bronze_store_store_name__MegaMar_Manhattan__MegaMart_Brooklyn__MegaMart_Austin__MegaMart_San_Jose__MegaMart_Toronto.b983752665
[0m08:53:25.387314 [info ] [Thread-7 (]: 13 of 15 START test accepted_values_bronze_store_store_name__MegaMar_Manhattan__MegaMart_Brooklyn__MegaMart_Austin__MegaMart_San_Jose__MegaMart_Toronto  [RUN]
[0m08:53:25.389314 [debug] [Thread-7 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=test.dbt_anirudh.accepted_values_bronze_store_store_name__MegaMar_Manhattan__MegaMart_Brooklyn__MegaMart_Austin__MegaMart_San_Jose__MegaMart_Toronto.b983752665) - Creating connection
[0m08:53:25.390540 [debug] [Thread-7 (]: Acquiring new databricks connection 'test.dbt_anirudh.accepted_values_bronze_store_store_name__MegaMar_Manhattan__MegaMart_Brooklyn__MegaMart_Austin__MegaMart_San_Jose__MegaMart_Toronto.b983752665'
[0m08:53:25.391553 [debug] [Thread-7 (]: Began compiling node test.dbt_anirudh.accepted_values_bronze_store_store_name__MegaMar_Manhattan__MegaMart_Brooklyn__MegaMart_Austin__MegaMart_San_Jose__MegaMart_Toronto.b983752665
[0m08:53:25.421618 [debug] [Thread-7 (]: Writing injected SQL for node "test.dbt_anirudh.accepted_values_bronze_store_store_name__MegaMar_Manhattan__MegaMart_Brooklyn__MegaMart_Austin__MegaMart_San_Jose__MegaMart_Toronto.b983752665"
[0m08:53:25.423095 [debug] [Thread-7 (]: Began executing node test.dbt_anirudh.accepted_values_bronze_store_store_name__MegaMar_Manhattan__MegaMart_Brooklyn__MegaMart_Austin__MegaMart_San_Jose__MegaMart_Toronto.b983752665
[0m08:53:25.428425 [debug] [Thread-7 (]: Writing runtime sql for node "test.dbt_anirudh.accepted_values_bronze_store_store_name__MegaMar_Manhattan__MegaMart_Brooklyn__MegaMart_Austin__MegaMart_San_Jose__MegaMart_Toronto.b983752665"
[0m08:53:25.429659 [debug] [Thread-7 (]: Using databricks connection "test.dbt_anirudh.accepted_values_bronze_store_store_name__MegaMar_Manhattan__MegaMart_Brooklyn__MegaMart_Austin__MegaMart_San_Jose__MegaMart_Toronto.b983752665"
[0m08:53:25.430791 [debug] [Thread-7 (]: On test.dbt_anirudh.accepted_values_bronze_store_store_name__MegaMar_Manhattan__MegaMart_Brooklyn__MegaMart_Austin__MegaMart_San_Jose__MegaMart_Toronto.b983752665: /* {"app": "dbt", "dbt_version": "1.10.10", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_anirudh", "target_name": "dev", "node_id": "test.dbt_anirudh.accepted_values_bronze_store_store_name__MegaMar_Manhattan__MegaMart_Brooklyn__MegaMart_Austin__MegaMart_San_Jose__MegaMart_Toronto.b983752665"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    

with all_values as (

    select
        store_name as value_field,
        count(*) as n_records

    from `dbt_learning`.`bronze`.`bronze_store`
    group by store_name

)

select *
from all_values
where value_field not in (
    'MegaMar Manhattan','MegaMart Brooklyn','MegaMart Austin','MegaMart San Jose','MegaMart Toronto'
)



  
  
      
    ) dbt_internal_test
[0m08:53:25.431746 [debug] [Thread-7 (]: Opening a new connection, currently in state init
[0m08:53:26.595212 [debug] [Thread-7 (]: Databricks adapter: Connection(session-id=01f09a88-2a45-1794-8835-6fe3c50752aa) - Created
[0m08:53:27.554564 [debug] [Thread-7 (]: SQL status: OK in 2.120 seconds
[0m08:53:27.559530 [debug] [Thread-7 (]: Databricks adapter: Cursor(session-id=01f09a88-2a45-1794-8835-6fe3c50752aa, command-id=01f09a88-2a71-1e99-9dcd-ed037d5adb6e) - Closing
[0m08:53:27.561301 [debug] [Thread-7 (]: On test.dbt_anirudh.accepted_values_bronze_store_store_name__MegaMar_Manhattan__MegaMart_Brooklyn__MegaMart_Austin__MegaMart_San_Jose__MegaMart_Toronto.b983752665: Close
[0m08:53:27.562372 [debug] [Thread-7 (]: Databricks adapter: Connection(session-id=01f09a88-2a45-1794-8835-6fe3c50752aa) - Closing
[0m08:53:27.868809 [warn ] [Thread-7 (]: 13 of 15 WARN 1 accepted_values_bronze_store_store_name__MegaMar_Manhattan__MegaMart_Brooklyn__MegaMart_Austin__MegaMart_San_Jose__MegaMart_Toronto  [[33mWARN 1[0m in 2.48s]
[0m08:53:27.870388 [debug] [Thread-7 (]: Finished running node test.dbt_anirudh.accepted_values_bronze_store_store_name__MegaMar_Manhattan__MegaMart_Brooklyn__MegaMart_Austin__MegaMart_San_Jose__MegaMart_Toronto.b983752665
[0m08:53:27.871440 [debug] [Thread-7 (]: Began running node model.dbt_anirudh.silver_returns_info
[0m08:53:27.872585 [info ] [Thread-7 (]: 14 of 15 START sql table model silver.silver_returns_info ...................... [RUN]
[0m08:53:27.873842 [debug] [Thread-7 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.dbt_anirudh.silver_returns_info) - Creating connection
[0m08:53:27.874852 [debug] [Thread-7 (]: Acquiring new databricks connection 'model.dbt_anirudh.silver_returns_info'
[0m08:53:27.875782 [debug] [Thread-7 (]: Began compiling node model.dbt_anirudh.silver_returns_info
[0m08:53:27.888234 [debug] [Thread-7 (]: Writing injected SQL for node "model.dbt_anirudh.silver_returns_info"
[0m08:53:27.890953 [debug] [Thread-7 (]: Began executing node model.dbt_anirudh.silver_returns_info
[0m08:53:27.895528 [debug] [Thread-7 (]: MATERIALIZING TABLE
[0m08:53:27.898583 [debug] [Thread-7 (]: Writing runtime sql for node "model.dbt_anirudh.silver_returns_info"
[0m08:53:27.899912 [debug] [Thread-7 (]: Using databricks connection "model.dbt_anirudh.silver_returns_info"
[0m08:53:27.901056 [debug] [Thread-7 (]: On model.dbt_anirudh.silver_returns_info: /* {"app": "dbt", "dbt_version": "1.10.10", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_anirudh", "target_name": "dev", "node_id": "model.dbt_anirudh.silver_returns_info"} */

  
    
        create or replace table `dbt_learning`.`silver`.`silver_returns_info`
      
      
  using delta
      
      
      
      
      
      
      
      as
      WITH return_data AS
(
    SELECT
        sales_id,
        product_sk,
        return_reason,
        refund_amount
    FROM
        `dbt_learning`.`bronze`.`bronze_returns`
),
product_data AS
(
    SELECT
        product_sk,
        category,
        department
    FROM
        `dbt_learning`.`bronze`.`bronze_product`
),
customer_data AS
(
    SELECT
        customer_sk,
        gender
    FROM
        `dbt_learning`.`bronze`.`bronze_customer`
),
sales_data AS
(
    SELECT
        sales_id,
        customer_sk
    FROM
        `dbt_learning`.`bronze`.`bronze_sales`
),
joined_query AS
(
    SELECT
        product_data.category,
        product_data.department,
        customer_data.gender,
        return_data.refund_amount
    FROM
        return_data
    INNER JOIN sales_data ON sales_data.sales_id = return_data.sales_id
    INNER JOIN customer_data ON customer_data.customer_sk = sales_data.customer_sk
    INNER JOIN product_data ON product_data.product_sk = return_data.product_sk
)
SELECT
    category,
    department,
    gender,
    sum(refund_amount) as total_refund
FROM
    joined_query
GROUP BY 1,2,3
ORDER BY 1,2 ASC, 4 DESC
  
[0m08:53:27.902020 [debug] [Thread-7 (]: Opening a new connection, currently in state init
[0m08:53:29.062692 [debug] [Thread-7 (]: Databricks adapter: Connection(session-id=01f09a88-2bbe-11c0-a863-7f9f9d0b4e71) - Created
[0m08:53:33.276433 [debug] [Thread-7 (]: SQL status: OK in 5.370 seconds
[0m08:53:33.278969 [debug] [Thread-7 (]: Databricks adapter: Cursor(session-id=01f09a88-2bbe-11c0-a863-7f9f9d0b4e71, command-id=01f09a88-2bea-142d-a419-909fd41556a2) - Closing
[0m08:53:33.280731 [debug] [Thread-7 (]: Applying tags to relation None
[0m08:53:33.283221 [debug] [Thread-7 (]: On model.dbt_anirudh.silver_returns_info: Close
[0m08:53:33.284100 [debug] [Thread-7 (]: Databricks adapter: Connection(session-id=01f09a88-2bbe-11c0-a863-7f9f9d0b4e71) - Closing
[0m08:53:33.594362 [debug] [Thread-7 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '938f4114-a330-4aa6-b79d-f08bebd84455', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7b784b50c260>]}
[0m08:53:33.596026 [info ] [Thread-7 (]: 14 of 15 OK created sql table model silver.silver_returns_info ................. [[32mOK[0m in 5.72s]
[0m08:53:33.597549 [debug] [Thread-7 (]: Finished running node model.dbt_anirudh.silver_returns_info
[0m08:53:33.598512 [debug] [Thread-7 (]: Began running node model.dbt_anirudh.silver_sales_info
[0m08:53:33.599851 [info ] [Thread-7 (]: 15 of 15 START sql table model silver.silver_sales_info ........................ [RUN]
[0m08:53:33.601549 [debug] [Thread-7 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.dbt_anirudh.silver_sales_info) - Creating connection
[0m08:53:33.602594 [debug] [Thread-7 (]: Acquiring new databricks connection 'model.dbt_anirudh.silver_sales_info'
[0m08:53:33.604008 [debug] [Thread-7 (]: Began compiling node model.dbt_anirudh.silver_sales_info
[0m08:53:33.614976 [debug] [Thread-7 (]: Writing injected SQL for node "model.dbt_anirudh.silver_sales_info"
[0m08:53:33.616617 [debug] [Thread-7 (]: Began executing node model.dbt_anirudh.silver_sales_info
[0m08:53:33.626849 [debug] [Thread-7 (]: MATERIALIZING TABLE
[0m08:53:33.629530 [debug] [Thread-7 (]: Writing runtime sql for node "model.dbt_anirudh.silver_sales_info"
[0m08:53:33.630338 [debug] [Thread-7 (]: Using databricks connection "model.dbt_anirudh.silver_sales_info"
[0m08:53:33.631037 [debug] [Thread-7 (]: On model.dbt_anirudh.silver_sales_info: /* {"app": "dbt", "dbt_version": "1.10.10", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_anirudh", "target_name": "dev", "node_id": "model.dbt_anirudh.silver_sales_info"} */

  
    
        create or replace table `dbt_learning`.`silver`.`silver_sales_info`
      
      
  using delta
      
      
      
      
      
      
      
      as
      WITH sales AS
(
    SELECT
        sales_id,
        product_sk,
        customer_sk,
        
    quantity * unit_price
 as calculated_gross_amount,
        gross_amount,
        payment_method
    FROM
        `dbt_learning`.`bronze`.`bronze_sales`
),

customer AS
(
    SELECT
        customer_sk,
        concat(first_name, last_name) as c_name,
        gender,
        signup_date
    FROM
        `dbt_learning`.`bronze`.`bronze_customer`
),

product AS
(
    SELECT
        product_sk,
        category
    FROM
        `dbt_learning`.`bronze`.`bronze_product`
),

joined_query AS
(
    SELECT
        sales.sales_id,
        sales.calculated_gross_amount,
        sales.payment_method,
        product.category,
        customer.gender
    FROM
        sales       
    INNER JOIN customer 
        ON customer.customer_sk = sales.customer_sk
    INNER JOIN product
        ON product.product_sk = sales.product_sk
)    

SELECT
    category,
    gender,
    sum(calculated_gross_amount) as total_sales
FROM
    joined_query
GROUP BY 1,2
ORDER BY 1 ASC, 3 DESC
  
[0m08:53:33.631631 [debug] [Thread-7 (]: Opening a new connection, currently in state init
[0m08:53:34.831901 [debug] [Thread-7 (]: Databricks adapter: Connection(session-id=01f09a88-2f2c-1f08-841c-d65901e23983) - Created
[0m08:53:38.080484 [debug] [Thread-7 (]: SQL status: OK in 4.450 seconds
[0m08:53:38.083011 [debug] [Thread-7 (]: Databricks adapter: Cursor(session-id=01f09a88-2f2c-1f08-841c-d65901e23983, command-id=01f09a88-2f5b-122c-9db3-c5a8d07f000e) - Closing
[0m08:53:38.084871 [debug] [Thread-7 (]: Applying tags to relation None
[0m08:53:38.087329 [debug] [Thread-7 (]: On model.dbt_anirudh.silver_sales_info: Close
[0m08:53:38.088292 [debug] [Thread-7 (]: Databricks adapter: Connection(session-id=01f09a88-2f2c-1f08-841c-d65901e23983) - Closing
[0m08:53:38.394853 [debug] [Thread-7 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '938f4114-a330-4aa6-b79d-f08bebd84455', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7b7870b5b5f0>]}
[0m08:53:38.396652 [info ] [Thread-7 (]: 15 of 15 OK created sql table model silver.silver_sales_info ................... [[32mOK[0m in 4.79s]
[0m08:53:38.398214 [debug] [Thread-7 (]: Finished running node model.dbt_anirudh.silver_sales_info
[0m08:53:38.403603 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=master) - Creating connection
[0m08:53:38.404727 [debug] [MainThread]: Acquiring new databricks connection 'master'
[0m08:53:38.406021 [info ] [MainThread]: 
[0m08:53:38.407018 [info ] [MainThread]: Finished running 1 seed, 7 table models, 5 data tests, 2 view models in 0 hours 2 minutes and 27.19 seconds (147.19s).
[0m08:53:38.413398 [debug] [MainThread]: Command end result
[0m08:53:38.471106 [debug] [MainThread]: Wrote artifact WritableManifest to /home/aniruth/AI/DBT/DBT_Master/dbt_anirudh/target/manifest.json
[0m08:53:38.475064 [debug] [MainThread]: Wrote artifact SemanticManifest to /home/aniruth/AI/DBT/DBT_Master/dbt_anirudh/target/semantic_manifest.json
[0m08:53:38.481672 [debug] [MainThread]: Wrote artifact RunExecutionResult to /home/aniruth/AI/DBT/DBT_Master/dbt_anirudh/target/run_results.json
[0m08:53:38.482134 [info ] [MainThread]: 
[0m08:53:38.482572 [info ] [MainThread]: [33mCompleted with 1 warning:[0m
[0m08:53:38.482975 [info ] [MainThread]: 
[0m08:53:38.483475 [warn ] [MainThread]: [33mWarning in test accepted_values_bronze_store_store_name__MegaMar_Manhattan__MegaMart_Brooklyn__MegaMart_Austin__MegaMart_San_Jose__MegaMart_Toronto (models/bronze/properties.yml)[0m
[0m08:53:38.483904 [warn ] [MainThread]: Got 1 result, configured to warn if != 0
[0m08:53:38.484298 [info ] [MainThread]: 
[0m08:53:38.484696 [info ] [MainThread]:   compiled code at target/compiled/dbt_anirudh/models/bronze/properties.yml/accepted_values_bronze_store_8308937ffa06d226d8f7cff5d272d129.sql
[0m08:53:38.485040 [info ] [MainThread]: 
[0m08:53:38.485953 [info ] [MainThread]: Done. PASS=14 WARN=1 ERROR=0 SKIP=0 NO-OP=0 TOTAL=15
[0m08:53:38.495293 [debug] [MainThread]: Resource report: {"command_name": "build", "command_success": true, "command_wall_clock_time": 151.09409, "process_in_blocks": "666728", "process_kernel_time": 0.903044, "process_mem_max_rss": "213248", "process_out_blocks": "3704", "process_user_time": 10.247948}
[0m08:53:38.495985 [debug] [MainThread]: Command `dbt build` succeeded at 08:53:38.495861 after 151.10 seconds
[0m08:53:38.496582 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7b78575f3920>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7b784b515280>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7b7870da79b0>]}
[0m08:53:38.497017 [debug] [MainThread]: Flushing usage events
[0m08:53:39.762847 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m08:57:38.056704 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x729cdfe9d610>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x729ce0d63380>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x729ce27dca40>]}


============================== 08:57:38.061988 | 9929bc40-92fa-472b-b42a-8cbc79a9db57 ==============================
[0m08:57:38.061988 [info ] [MainThread]: Running with dbt=1.10.10
[0m08:57:38.062761 [debug] [MainThread]: running dbt with arguments {'profiles_dir': '/home/aniruth/AI/DBT/DBT_Master/dbt_anirudh', 'log_cache_events': 'False', 'fail_fast': 'False', 'partial_parse': 'True', 'quiet': 'False', 'version_check': 'True', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'use_colors': 'True', 'target_path': 'None', 'no_print': 'None', 'static_parser': 'True', 'log_format': 'default', 'send_anonymous_usage_stats': 'True', 'invocation_command': 'dbt snapshot', 'write_json': 'True', 'introspect': 'True', 'log_path': '/home/aniruth/AI/DBT/DBT_Master/dbt_anirudh/logs', 'warn_error': 'None', 'cache_selected_only': 'False', 'use_experimental_parser': 'False', 'indirect_selection': 'eager', 'printer_width': '80', 'debug': 'False', 'empty': 'False'}
[0m08:57:39.054096 [debug] [MainThread]: Spark adapter: Setting pyhive.hive logging to ERROR
[0m08:57:39.054796 [debug] [MainThread]: Spark adapter: Setting thrift.transport logging to ERROR
[0m08:57:39.055224 [debug] [MainThread]: Spark adapter: Setting thrift.protocol logging to ERROR
[0m08:57:40.140056 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '9929bc40-92fa-472b-b42a-8cbc79a9db57', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x729cbafd6c30>]}
[0m08:57:40.214802 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '9929bc40-92fa-472b-b42a-8cbc79a9db57', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x729cc0266090>]}
[0m08:57:40.215589 [info ] [MainThread]: Registered adapter: databricks=1.10.9
[0m08:57:40.375086 [debug] [MainThread]: checksum: 502a0dc23e9052e1ae09f7c44ee219ef7a02dfea7e7d66580d54c304c14d553b, vars: {}, profile: , target: , version: 1.10.10
[0m08:57:40.580900 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m08:57:40.581590 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m08:57:40.664873 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '9929bc40-92fa-472b-b42a-8cbc79a9db57', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x729cddcbb6b0>]}
[0m08:57:40.802571 [debug] [MainThread]: Wrote artifact WritableManifest to /home/aniruth/AI/DBT/DBT_Master/dbt_anirudh/target/manifest.json
[0m08:57:40.805201 [debug] [MainThread]: Wrote artifact SemanticManifest to /home/aniruth/AI/DBT/DBT_Master/dbt_anirudh/target/semantic_manifest.json
[0m08:57:40.819069 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '9929bc40-92fa-472b-b42a-8cbc79a9db57', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x729cbab397f0>]}
[0m08:57:40.819686 [info ] [MainThread]: Found 6 analyses, 1 seed, 9 models, 5 data tests, 7 sources, 688 macros
[0m08:57:40.820123 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '9929bc40-92fa-472b-b42a-8cbc79a9db57', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x729cbab7ff80>]}
[0m08:57:40.822073 [warn ] [MainThread]: Nothing to do. Try checking your model configs and model specification args
[0m08:57:40.824155 [debug] [MainThread]: Command end result
[0m08:57:40.862796 [debug] [MainThread]: Wrote artifact WritableManifest to /home/aniruth/AI/DBT/DBT_Master/dbt_anirudh/target/manifest.json
[0m08:57:40.864936 [debug] [MainThread]: Wrote artifact SemanticManifest to /home/aniruth/AI/DBT/DBT_Master/dbt_anirudh/target/semantic_manifest.json
[0m08:57:40.869083 [debug] [MainThread]: Wrote artifact RunExecutionResult to /home/aniruth/AI/DBT/DBT_Master/dbt_anirudh/target/run_results.json
[0m08:57:40.870330 [debug] [MainThread]: Resource report: {"command_name": "snapshot", "command_success": true, "command_wall_clock_time": 2.8761697, "process_in_blocks": "319296", "process_kernel_time": 0.418984, "process_mem_max_rss": "226052", "process_out_blocks": "3240", "process_user_time": 4.912267}
[0m08:57:40.871097 [debug] [MainThread]: Command `dbt snapshot` succeeded at 08:57:40.870973 after 2.88 seconds
[0m08:57:40.871633 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x729ce06ed430>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x729ce06efcb0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x729cba9e3170>]}
[0m08:57:40.872092 [debug] [MainThread]: Flushing usage events
[0m08:57:41.964794 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m08:58:23.988076 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcb2434a030>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcb244d3cb0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcb244d2b40>]}


============================== 08:58:23.992561 | 6e3136b1-8816-4c3a-9cb6-f7821abaa926 ==============================
[0m08:58:23.992561 [info ] [MainThread]: Running with dbt=1.10.10
[0m08:58:23.993263 [debug] [MainThread]: running dbt with arguments {'send_anonymous_usage_stats': 'True', 'quiet': 'False', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'log_path': '/home/aniruth/AI/DBT/DBT_Master/dbt_anirudh/logs', 'target_path': 'None', 'indirect_selection': 'eager', 'fail_fast': 'False', 'printer_width': '80', 'log_format': 'default', 'static_parser': 'True', 'debug': 'False', 'no_print': 'None', 'empty': 'False', 'version_check': 'True', 'profiles_dir': '/home/aniruth/AI/DBT/DBT_Master/dbt_anirudh', 'use_colors': 'True', 'cache_selected_only': 'False', 'invocation_command': 'dbt snapshot', 'introspect': 'True', 'warn_error': 'None', 'use_experimental_parser': 'False', 'log_cache_events': 'False', 'partial_parse': 'True', 'write_json': 'True'}
[0m08:58:25.003719 [debug] [MainThread]: Spark adapter: Setting pyhive.hive logging to ERROR
[0m08:58:25.004330 [debug] [MainThread]: Spark adapter: Setting thrift.transport logging to ERROR
[0m08:58:25.004760 [debug] [MainThread]: Spark adapter: Setting thrift.protocol logging to ERROR
[0m08:58:26.201485 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '6e3136b1-8816-4c3a-9cb6-f7821abaa926', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcaff30ee10>]}
[0m08:58:26.268812 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '6e3136b1-8816-4c3a-9cb6-f7821abaa926', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcb245ab8c0>]}
[0m08:58:26.269584 [info ] [MainThread]: Registered adapter: databricks=1.10.9
[0m08:58:26.397697 [debug] [MainThread]: checksum: 502a0dc23e9052e1ae09f7c44ee219ef7a02dfea7e7d66580d54c304c14d553b, vars: {}, profile: , target: , version: 1.10.10
[0m08:58:26.590306 [debug] [MainThread]: Partial parsing enabled: 1 files deleted, 1 files added, 0 files changed.
[0m08:58:26.591009 [debug] [MainThread]: Partial parsing: added file: dbt_anirudh://snapshots/gold_items.yml
[0m08:58:26.591468 [debug] [MainThread]: Partial parsing: deleted file: dbt_anirudh://snapshots/gold_items.sql
[0m08:58:26.983222 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '6e3136b1-8816-4c3a-9cb6-f7821abaa926', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcafe726510>]}
[0m08:58:27.231242 [debug] [MainThread]: Wrote artifact WritableManifest to /home/aniruth/AI/DBT/DBT_Master/dbt_anirudh/target/manifest.json
[0m08:58:27.233540 [debug] [MainThread]: Wrote artifact SemanticManifest to /home/aniruth/AI/DBT/DBT_Master/dbt_anirudh/target/semantic_manifest.json
[0m08:58:27.246217 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '6e3136b1-8816-4c3a-9cb6-f7821abaa926', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcafe6671a0>]}
[0m08:58:27.246822 [info ] [MainThread]: Found 6 analyses, 1 seed, 9 models, 5 data tests, 1 snapshot, 7 sources, 688 macros
[0m08:58:27.247278 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '6e3136b1-8816-4c3a-9cb6-f7821abaa926', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcb24fd8800>]}
[0m08:58:27.249433 [info ] [MainThread]: 
[0m08:58:27.249946 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m08:58:27.250327 [info ] [MainThread]: 
[0m08:58:27.250951 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=master) - Creating connection
[0m08:58:27.251356 [debug] [MainThread]: Acquiring new databricks connection 'master'
[0m08:58:27.252702 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=list_dbt_learning) - Creating connection
[0m08:58:27.253294 [debug] [ThreadPool]: Acquiring new databricks connection 'list_dbt_learning'
[0m08:58:27.253782 [debug] [ThreadPool]: Using databricks connection "list_dbt_learning"
[0m08:58:27.254246 [debug] [ThreadPool]: On list_dbt_learning: GetSchemas(database=dbt_learning, schema=None)
[0m08:58:27.254606 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m08:58:28.490396 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f09a88-de35-1c86-af31-b41b0e973fac) - Created
[0m08:58:29.170003 [debug] [ThreadPool]: SQL status: OK in 1.920 seconds
[0m08:58:29.173254 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01f09a88-de35-1c86-af31-b41b0e973fac, command-id=01f09a88-de68-1ad5-ac2c-48a2644ea0a2) - Closing
[0m08:58:29.174250 [debug] [ThreadPool]: On list_dbt_learning: Close
[0m08:58:29.175097 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f09a88-de35-1c86-af31-b41b0e973fac) - Closing
[0m08:58:29.484623 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=list_dbt_learning_bronze) - Creating connection
[0m08:58:29.485862 [debug] [ThreadPool]: Acquiring new databricks connection 'list_dbt_learning_bronze'
[0m08:58:29.511300 [debug] [ThreadPool]: Using databricks connection "list_dbt_learning_bronze"
[0m08:58:29.512524 [debug] [ThreadPool]: On list_dbt_learning_bronze: /* {"app": "dbt", "dbt_version": "1.10.10", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_anirudh", "target_name": "dev", "connection_name": "list_dbt_learning_bronze"} */

    
SELECT
  table_name,
  if(table_type IN ('EXTERNAL', 'MANAGED', 'MANAGED_SHALLOW_CLONE', 'EXTERNAL_SHALLOW_CLONE'), 'table', lower(table_type)) AS table_type,
  lower(data_source_format) AS file_format,
  table_owner,
  if(
    table_type IN (
      'EXTERNAL',
      'MANAGED',
      'MANAGED_SHALLOW_CLONE',
      'EXTERNAL_SHALLOW_CLONE'
    ),
    lower(table_type),
    NULL
  ) AS databricks_table_type
FROM `system`.`information_schema`.`tables`
WHERE table_catalog = 'dbt_learning' 
  AND table_schema = 'bronze'

  
[0m08:58:29.513798 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m08:58:30.650714 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f09a88-df81-133e-91f9-c84665d541d3) - Created
[0m08:58:31.308004 [debug] [ThreadPool]: SQL status: OK in 1.790 seconds
[0m08:58:31.318426 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01f09a88-df81-133e-91f9-c84665d541d3, command-id=01f09a88-dfab-1413-861b-75e30bda7b9e) - Closing
[0m08:58:31.319687 [debug] [ThreadPool]: On list_dbt_learning_bronze: Close
[0m08:58:31.320294 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f09a88-df81-133e-91f9-c84665d541d3) - Closing
[0m08:58:31.628426 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=list_dbt_learning_silver) - Creating connection
[0m08:58:31.631715 [debug] [ThreadPool]: Acquiring new databricks connection 'list_dbt_learning_silver'
[0m08:58:31.636041 [debug] [ThreadPool]: Using databricks connection "list_dbt_learning_silver"
[0m08:58:31.636953 [debug] [ThreadPool]: On list_dbt_learning_silver: /* {"app": "dbt", "dbt_version": "1.10.10", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_anirudh", "target_name": "dev", "connection_name": "list_dbt_learning_silver"} */

    
SELECT
  table_name,
  if(table_type IN ('EXTERNAL', 'MANAGED', 'MANAGED_SHALLOW_CLONE', 'EXTERNAL_SHALLOW_CLONE'), 'table', lower(table_type)) AS table_type,
  lower(data_source_format) AS file_format,
  table_owner,
  if(
    table_type IN (
      'EXTERNAL',
      'MANAGED',
      'MANAGED_SHALLOW_CLONE',
      'EXTERNAL_SHALLOW_CLONE'
    ),
    lower(table_type),
    NULL
  ) AS databricks_table_type
FROM `system`.`information_schema`.`tables`
WHERE table_catalog = 'dbt_learning' 
  AND table_schema = 'silver'

  
[0m08:58:31.637746 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m08:58:32.846714 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f09a88-e0ce-1dbf-8162-ad7b385949a9) - Created
[0m08:58:33.445134 [debug] [ThreadPool]: SQL status: OK in 1.810 seconds
[0m08:58:33.449385 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01f09a88-e0ce-1dbf-8162-ad7b385949a9, command-id=01f09a88-e0fc-122a-a526-42b9aee3f739) - Closing
[0m08:58:33.450636 [debug] [ThreadPool]: On list_dbt_learning_silver: Close
[0m08:58:33.451503 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f09a88-e0ce-1dbf-8162-ad7b385949a9) - Closing
[0m08:58:33.758900 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=list_dbt_learning_gold) - Creating connection
[0m08:58:33.760922 [debug] [ThreadPool]: Acquiring new databricks connection 'list_dbt_learning_gold'
[0m08:58:33.769241 [debug] [ThreadPool]: Using databricks connection "list_dbt_learning_gold"
[0m08:58:33.770188 [debug] [ThreadPool]: On list_dbt_learning_gold: /* {"app": "dbt", "dbt_version": "1.10.10", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_anirudh", "target_name": "dev", "connection_name": "list_dbt_learning_gold"} */

    
SELECT
  table_name,
  if(table_type IN ('EXTERNAL', 'MANAGED', 'MANAGED_SHALLOW_CLONE', 'EXTERNAL_SHALLOW_CLONE'), 'table', lower(table_type)) AS table_type,
  lower(data_source_format) AS file_format,
  table_owner,
  if(
    table_type IN (
      'EXTERNAL',
      'MANAGED',
      'MANAGED_SHALLOW_CLONE',
      'EXTERNAL_SHALLOW_CLONE'
    ),
    lower(table_type),
    NULL
  ) AS databricks_table_type
FROM `system`.`information_schema`.`tables`
WHERE table_catalog = 'dbt_learning' 
  AND table_schema = 'gold'

  
[0m08:58:33.770990 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m08:58:34.981368 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f09a88-e213-18ac-abc6-d8899c86f63f) - Created
[0m08:58:35.484316 [debug] [ThreadPool]: SQL status: OK in 1.710 seconds
[0m08:58:35.488431 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01f09a88-e213-18ac-abc6-d8899c86f63f, command-id=01f09a88-e240-1c0e-89fa-915dc3218ded) - Closing
[0m08:58:35.489657 [debug] [ThreadPool]: On list_dbt_learning_gold: Close
[0m08:58:35.490493 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f09a88-e213-18ac-abc6-d8899c86f63f) - Closing
[0m08:58:35.793921 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '6e3136b1-8816-4c3a-9cb6-f7821abaa926', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcafd78fda0>]}
[0m08:58:35.799947 [debug] [Thread-5 (]: Began running node snapshot.dbt_anirudh.gold_items
[0m08:58:35.801292 [info ] [Thread-5 (]: 1 of 1 START snapshot gold.gold_items .......................................... [RUN]
[0m08:58:35.802697 [debug] [Thread-5 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=snapshot.dbt_anirudh.gold_items) - Creating connection
[0m08:58:35.803632 [debug] [Thread-5 (]: Acquiring new databricks connection 'snapshot.dbt_anirudh.gold_items'
[0m08:58:35.804610 [debug] [Thread-5 (]: Began compiling node snapshot.dbt_anirudh.gold_items
[0m08:58:35.845063 [debug] [Thread-5 (]: Began executing node snapshot.dbt_anirudh.gold_items
[0m08:58:35.952137 [debug] [Thread-5 (]: Using databricks connection "snapshot.dbt_anirudh.gold_items"
[0m08:58:35.952958 [debug] [Thread-5 (]: On snapshot.dbt_anirudh.gold_items: /* {"app": "dbt", "dbt_version": "1.10.10", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_anirudh", "target_name": "dev", "node_id": "snapshot.dbt_anirudh.gold_items"} */
select * from (
        
    

    select *,
        md5(coalesce(cast(id as string ), '')
         || '|' || coalesce(cast(updateDate as string ), '')
        ) as dbt_scd_id,
        updateDate as dbt_updated_at,
        updateDate as dbt_valid_from,
        
  
  coalesce(nullif(updateDate, updateDate), to_date('9999-12-31'))
  as dbt_valid_to
from (
        select * from `dbt_learning`.`gold`.`gold_items_source`
    ) sbq



    ) as __dbt_sbq
    where false
    limit 0

[0m08:58:35.953548 [debug] [Thread-5 (]: Opening a new connection, currently in state init
[0m08:58:37.136603 [debug] [Thread-5 (]: Databricks adapter: Connection(session-id=01f09a88-e35d-1ff4-b67c-ef85c58a71a9) - Created
[0m08:58:37.757991 [debug] [Thread-5 (]: SQL status: OK in 1.800 seconds
[0m08:58:37.770244 [debug] [Thread-5 (]: Using databricks connection "snapshot.dbt_anirudh.gold_items"
[0m08:58:37.771295 [debug] [Thread-5 (]: On snapshot.dbt_anirudh.gold_items: /* {"app": "dbt", "dbt_version": "1.10.10", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_anirudh", "target_name": "dev", "node_id": "snapshot.dbt_anirudh.gold_items"} */
select * from (
        select 
    current_timestamp()
 as dbt_snapshot_time
    ) as __dbt_sbq
    where false
    limit 0

[0m08:58:37.772298 [debug] [Thread-5 (]: Databricks adapter: Cursor(session-id=01f09a88-e35d-1ff4-b67c-ef85c58a71a9, command-id=01f09a88-e38b-1051-8d08-658970705811) - Closing
[0m08:58:38.150621 [debug] [Thread-5 (]: SQL status: OK in 0.380 seconds
[0m08:58:38.152332 [debug] [Thread-5 (]: Writing runtime sql for node "snapshot.dbt_anirudh.gold_items"
[0m08:58:38.155542 [debug] [Thread-5 (]: Using databricks connection "snapshot.dbt_anirudh.gold_items"
[0m08:58:38.156713 [debug] [Thread-5 (]: On snapshot.dbt_anirudh.gold_items: /* {"app": "dbt", "dbt_version": "1.10.10", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_anirudh", "target_name": "dev", "node_id": "snapshot.dbt_anirudh.gold_items"} */

      
  
    
        create or replace table `dbt_learning`.`gold`.`gold_items`
      
      
  using delta
      
      
      
      
      
      
      
      as
      
    

    select *,
        md5(coalesce(cast(id as string ), '')
         || '|' || coalesce(cast(updateDate as string ), '')
        ) as dbt_scd_id,
        updateDate as dbt_updated_at,
        updateDate as dbt_valid_from,
        
  
  coalesce(nullif(updateDate, updateDate), to_date('9999-12-31'))
  as dbt_valid_to
from (
        select * from `dbt_learning`.`gold`.`gold_items_source`
    ) sbq



  
  
[0m08:58:38.157783 [debug] [Thread-5 (]: Databricks adapter: Cursor(session-id=01f09a88-e35d-1ff4-b67c-ef85c58a71a9, command-id=01f09a88-e3eb-1cb8-87a6-bf003f4413de) - Closing
[0m08:58:41.491557 [debug] [Thread-5 (]: SQL status: OK in 3.330 seconds
[0m08:58:41.494822 [debug] [Thread-5 (]: Databricks adapter: Cursor(session-id=01f09a88-e35d-1ff4-b67c-ef85c58a71a9, command-id=01f09a88-e426-1e91-b6ee-bd4a27faa8d7) - Closing
[0m08:58:41.553780 [debug] [Thread-5 (]: On snapshot.dbt_anirudh.gold_items: Close
[0m08:58:41.554637 [debug] [Thread-5 (]: Databricks adapter: Connection(session-id=01f09a88-e35d-1ff4-b67c-ef85c58a71a9) - Closing
[0m08:58:41.873098 [debug] [Thread-5 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '6e3136b1-8816-4c3a-9cb6-f7821abaa926', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcb25a35ac0>]}
[0m08:58:41.874208 [info ] [Thread-5 (]: 1 of 1 OK snapshotted gold.gold_items .......................................... [[32mOK[0m in 6.07s]
[0m08:58:41.875064 [debug] [Thread-5 (]: Finished running node snapshot.dbt_anirudh.gold_items
[0m08:58:41.876569 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=master) - Creating connection
[0m08:58:41.877105 [debug] [MainThread]: Acquiring new databricks connection 'master'
[0m08:58:41.877701 [info ] [MainThread]: 
[0m08:58:41.878120 [info ] [MainThread]: Finished running 1 snapshot in 0 hours 0 minutes and 14.63 seconds (14.63s).
[0m08:58:41.878916 [debug] [MainThread]: Command end result
[0m08:58:41.938259 [debug] [MainThread]: Wrote artifact WritableManifest to /home/aniruth/AI/DBT/DBT_Master/dbt_anirudh/target/manifest.json
[0m08:58:41.940948 [debug] [MainThread]: Wrote artifact SemanticManifest to /home/aniruth/AI/DBT/DBT_Master/dbt_anirudh/target/semantic_manifest.json
[0m08:58:41.947570 [debug] [MainThread]: Wrote artifact RunExecutionResult to /home/aniruth/AI/DBT/DBT_Master/dbt_anirudh/target/run_results.json
[0m08:58:41.947974 [info ] [MainThread]: 
[0m08:58:41.948443 [info ] [MainThread]: [32mCompleted successfully[0m
[0m08:58:41.948813 [info ] [MainThread]: 
[0m08:58:41.949209 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 NO-OP=0 TOTAL=1
[0m08:58:41.951526 [debug] [MainThread]: Resource report: {"command_name": "snapshot", "command_success": true, "command_wall_clock_time": 18.024899, "process_in_blocks": "274296", "process_kernel_time": 0.44589, "process_mem_max_rss": "247616", "process_out_blocks": "4848", "process_user_time": 6.48141}
[0m08:58:41.952186 [debug] [MainThread]: Command `dbt snapshot` succeeded at 08:58:41.952038 after 18.03 seconds
[0m08:58:41.952811 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcb2455c950>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcb2455f5c0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcafe8e7ef0>]}
[0m08:58:41.953370 [debug] [MainThread]: Flushing usage events
[0m08:58:43.010642 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m14:28:18.563311 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7a7062b9d3a0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7a70648d5b20>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7a706226b320>]}


============================== 14:28:18.566813 | 9878dc65-3525-4931-9c40-3058f9a2a7c8 ==============================
[0m14:28:18.566813 [info ] [MainThread]: Running with dbt=1.10.10
[0m14:28:18.567646 [debug] [MainThread]: running dbt with arguments {'cache_selected_only': 'False', 'empty': 'None', 'log_cache_events': 'False', 'version_check': 'True', 'static_parser': 'True', 'send_anonymous_usage_stats': 'True', 'log_path': '/home/aniruth/AI/DBT/DBT_Master/dbt_anirudh/logs', 'indirect_selection': 'eager', 'printer_width': '80', 'quiet': 'False', 'use_experimental_parser': 'False', 'invocation_command': 'dbt ', 'introspect': 'True', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'no_print': 'None', 'partial_parse': 'True', 'use_colors': 'True', 'fail_fast': 'False', 'target_path': 'None', 'debug': 'False', 'write_json': 'True', 'profiles_dir': '/home/aniruth/AI/DBT/DBT_Master/dbt_anirudh', 'warn_error': 'None', 'log_format': 'default'}
[0m14:28:18.678425 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '9878dc65-3525-4931-9c40-3058f9a2a7c8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7a7062419be0>]}
[0m14:28:18.690495 [info ] [MainThread]: Warning: No packages were found in packages.yml
[0m14:28:18.691518 [info ] [MainThread]: Warning: No packages were found in packages.yml
[0m14:28:18.693131 [debug] [MainThread]: Resource report: {"command_name": "deps", "command_success": true, "command_wall_clock_time": 0.1867221, "process_in_blocks": "408", "process_kernel_time": 0.136279, "process_mem_max_rss": "100608", "process_out_blocks": "8", "process_user_time": 1.566716}
[0m14:28:18.693659 [debug] [MainThread]: Command `cli deps` succeeded at 14:28:18.693552 after 0.19 seconds
[0m14:28:18.694056 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7a7062a7e570>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7a70624c55e0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7a7062b9d3a0>]}
[0m14:28:18.694412 [debug] [MainThread]: Flushing usage events
[0m14:28:20.135896 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m15:08:53.415043 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x748b1384b5f0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x748b12cc3140>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x748b150c5640>]}


============================== 15:08:53.417342 | 3e0ac330-3526-40ef-b915-a0a655991dfc ==============================
[0m15:08:53.417342 [info ] [MainThread]: Running with dbt=1.10.10
[0m15:08:53.417781 [debug] [MainThread]: running dbt with arguments {'use_colors': 'True', 'log_format': 'default', 'target_path': 'None', 'write_json': 'True', 'warn_error': 'None', 'invocation_command': 'dbt build', 'cache_selected_only': 'False', 'indirect_selection': 'eager', 'empty': 'False', 'partial_parse': 'True', 'use_experimental_parser': 'False', 'quiet': 'False', 'debug': 'False', 'log_path': '/home/aniruth/AI/DBT/DBT_Master/dbt_anirudh/logs', 'fail_fast': 'False', 'no_print': 'None', 'printer_width': '80', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'introspect': 'True', 'static_parser': 'True', 'profiles_dir': '/home/aniruth/AI/DBT/DBT_Master/dbt_anirudh', 'send_anonymous_usage_stats': 'True', 'version_check': 'True', 'log_cache_events': 'False'}
[0m15:08:54.001940 [debug] [MainThread]: Spark adapter: Setting pyhive.hive logging to ERROR
[0m15:08:54.002420 [debug] [MainThread]: Spark adapter: Setting thrift.transport logging to ERROR
[0m15:08:54.002743 [debug] [MainThread]: Spark adapter: Setting thrift.protocol logging to ERROR
[0m15:08:54.491876 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '3e0ac330-3526-40ef-b915-a0a655991dfc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x748b14f92a80>]}
[0m15:08:54.541357 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '3e0ac330-3526-40ef-b915-a0a655991dfc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x748af1b35bb0>]}
[0m15:08:54.541909 [info ] [MainThread]: Registered adapter: databricks=1.10.9
[0m15:08:54.629202 [debug] [MainThread]: checksum: 502a0dc23e9052e1ae09f7c44ee219ef7a02dfea7e7d66580d54c304c14d553b, vars: {}, profile: , target: , version: 1.10.10
[0m15:08:54.758261 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m15:08:54.758613 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m15:08:54.822321 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '3e0ac330-3526-40ef-b915-a0a655991dfc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x748b10af4050>]}
[0m15:08:54.921383 [debug] [MainThread]: Wrote artifact WritableManifest to /home/aniruth/AI/DBT/DBT_Master/dbt_anirudh/target/manifest.json
[0m15:08:54.925568 [debug] [MainThread]: Wrote artifact SemanticManifest to /home/aniruth/AI/DBT/DBT_Master/dbt_anirudh/target/semantic_manifest.json
[0m15:08:54.942961 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '3e0ac330-3526-40ef-b915-a0a655991dfc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x748af16efa40>]}
[0m15:08:54.943375 [info ] [MainThread]: Found 6 analyses, 1 seed, 9 models, 5 data tests, 1 snapshot, 7 sources, 688 macros
[0m15:08:54.945519 [info ] [MainThread]: 
[0m15:08:54.945844 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m15:08:54.946085 [info ] [MainThread]: 
[0m15:08:54.946483 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=master) - Creating connection
[0m15:08:54.946729 [debug] [MainThread]: Acquiring new databricks connection 'master'
[0m15:08:54.952219 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=list_dbt_learning) - Creating connection
[0m15:08:54.952628 [debug] [ThreadPool]: Acquiring new databricks connection 'list_dbt_learning'
[0m15:08:54.952926 [debug] [ThreadPool]: Using databricks connection "list_dbt_learning"
[0m15:08:54.953291 [debug] [ThreadPool]: On list_dbt_learning: GetSchemas(database=dbt_learning, schema=None)
[0m15:08:54.953657 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m15:08:56.475176 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f09abc-9f28-1409-a967-ba150f3fb2f5) - Created
[0m15:08:57.430708 [debug] [ThreadPool]: SQL status: OK in 2.480 seconds
[0m15:08:57.431755 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01f09abc-9f28-1409-a967-ba150f3fb2f5, command-id=01f09abc-9f5c-1a3d-9e1b-e8f1184120eb) - Closing
[0m15:08:57.432130 [debug] [ThreadPool]: On list_dbt_learning: Close
[0m15:08:57.432402 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f09abc-9f28-1409-a967-ba150f3fb2f5) - Closing
[0m15:08:57.751866 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=list_dbt_learning) - Creating connection
[0m15:08:57.753030 [debug] [ThreadPool]: Acquiring new databricks connection 'list_dbt_learning'
[0m15:08:57.753922 [debug] [ThreadPool]: Using databricks connection "list_dbt_learning"
[0m15:08:57.754755 [debug] [ThreadPool]: On list_dbt_learning: GetSchemas(database=dbt_learning, schema=None)
[0m15:08:57.755549 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m15:08:59.137503 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f09abc-a0bf-1e20-b008-06ac2e961d0e) - Created
[0m15:08:59.684877 [debug] [ThreadPool]: SQL status: OK in 1.930 seconds
[0m15:08:59.688019 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01f09abc-a0bf-1e20-b008-06ac2e961d0e, command-id=01f09abc-a0ef-1270-8310-d1f61c4df8ac) - Closing
[0m15:08:59.688990 [debug] [ThreadPool]: On list_dbt_learning: Close
[0m15:08:59.689818 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f09abc-a0bf-1e20-b008-06ac2e961d0e) - Closing
[0m15:09:00.012706 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=list_dbt_learning) - Creating connection
[0m15:09:00.013913 [debug] [ThreadPool]: Acquiring new databricks connection 'list_dbt_learning'
[0m15:09:00.014840 [debug] [ThreadPool]: Using databricks connection "list_dbt_learning"
[0m15:09:00.015643 [debug] [ThreadPool]: On list_dbt_learning: GetSchemas(database=dbt_learning, schema=None)
[0m15:09:00.016401 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m15:09:01.419893 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f09abc-a21c-1bd1-b3f0-87912088904d) - Created
[0m15:09:01.937147 [debug] [ThreadPool]: SQL status: OK in 1.920 seconds
[0m15:09:01.941245 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01f09abc-a21c-1bd1-b3f0-87912088904d, command-id=01f09abc-a24b-1551-be9e-a2b51356aa67) - Closing
[0m15:09:01.942220 [debug] [ThreadPool]: On list_dbt_learning: Close
[0m15:09:01.942935 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f09abc-a21c-1bd1-b3f0-87912088904d) - Closing
[0m15:09:02.263649 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=list_dbt_learning_gold) - Creating connection
[0m15:09:02.264743 [debug] [ThreadPool]: Acquiring new databricks connection 'list_dbt_learning_gold'
[0m15:09:02.288195 [debug] [ThreadPool]: Using databricks connection "list_dbt_learning_gold"
[0m15:09:02.288586 [debug] [ThreadPool]: On list_dbt_learning_gold: /* {"app": "dbt", "dbt_version": "1.10.10", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_anirudh", "target_name": "dev", "connection_name": "list_dbt_learning_gold"} */

    
SELECT
  table_name,
  if(table_type IN ('EXTERNAL', 'MANAGED', 'MANAGED_SHALLOW_CLONE', 'EXTERNAL_SHALLOW_CLONE'), 'table', lower(table_type)) AS table_type,
  lower(data_source_format) AS file_format,
  table_owner,
  if(
    table_type IN (
      'EXTERNAL',
      'MANAGED',
      'MANAGED_SHALLOW_CLONE',
      'EXTERNAL_SHALLOW_CLONE'
    ),
    lower(table_type),
    NULL
  ) AS databricks_table_type
FROM `system`.`information_schema`.`tables`
WHERE table_catalog = 'dbt_learning' 
  AND table_schema = 'gold'

  
[0m15:09:02.288848 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m15:09:03.579177 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f09abc-a365-1f03-86be-64c6bc544066) - Created
[0m15:09:04.810073 [debug] [ThreadPool]: SQL status: OK in 2.520 seconds
[0m15:09:04.821175 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01f09abc-a365-1f03-86be-64c6bc544066, command-id=01f09abc-a395-1eea-b358-82cfc05151ee) - Closing
[0m15:09:04.822720 [debug] [ThreadPool]: On list_dbt_learning_gold: Close
[0m15:09:04.823788 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f09abc-a365-1f03-86be-64c6bc544066) - Closing
[0m15:09:05.153697 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=list_dbt_learning_silver) - Creating connection
[0m15:09:05.154476 [debug] [ThreadPool]: Acquiring new databricks connection 'list_dbt_learning_silver'
[0m15:09:05.156077 [debug] [ThreadPool]: Using databricks connection "list_dbt_learning_silver"
[0m15:09:05.156359 [debug] [ThreadPool]: On list_dbt_learning_silver: /* {"app": "dbt", "dbt_version": "1.10.10", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_anirudh", "target_name": "dev", "connection_name": "list_dbt_learning_silver"} */

    
SELECT
  table_name,
  if(table_type IN ('EXTERNAL', 'MANAGED', 'MANAGED_SHALLOW_CLONE', 'EXTERNAL_SHALLOW_CLONE'), 'table', lower(table_type)) AS table_type,
  lower(data_source_format) AS file_format,
  table_owner,
  if(
    table_type IN (
      'EXTERNAL',
      'MANAGED',
      'MANAGED_SHALLOW_CLONE',
      'EXTERNAL_SHALLOW_CLONE'
    ),
    lower(table_type),
    NULL
  ) AS databricks_table_type
FROM `system`.`information_schema`.`tables`
WHERE table_catalog = 'dbt_learning' 
  AND table_schema = 'silver'

  
[0m15:09:05.156606 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m15:09:06.423187 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f09abc-a519-12ce-8e9c-ecb582b821bc) - Created
[0m15:09:07.163639 [debug] [ThreadPool]: SQL status: OK in 2.010 seconds
[0m15:09:07.168359 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01f09abc-a519-12ce-8e9c-ecb582b821bc, command-id=01f09abc-a545-14aa-a4ca-c551cc1b9dce) - Closing
[0m15:09:07.169763 [debug] [ThreadPool]: On list_dbt_learning_silver: Close
[0m15:09:07.170681 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f09abc-a519-12ce-8e9c-ecb582b821bc) - Closing
[0m15:09:07.476954 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=list_dbt_learning_bronze) - Creating connection
[0m15:09:07.479235 [debug] [ThreadPool]: Acquiring new databricks connection 'list_dbt_learning_bronze'
[0m15:09:07.487585 [debug] [ThreadPool]: Using databricks connection "list_dbt_learning_bronze"
[0m15:09:07.488619 [debug] [ThreadPool]: On list_dbt_learning_bronze: /* {"app": "dbt", "dbt_version": "1.10.10", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_anirudh", "target_name": "dev", "connection_name": "list_dbt_learning_bronze"} */

    
SELECT
  table_name,
  if(table_type IN ('EXTERNAL', 'MANAGED', 'MANAGED_SHALLOW_CLONE', 'EXTERNAL_SHALLOW_CLONE'), 'table', lower(table_type)) AS table_type,
  lower(data_source_format) AS file_format,
  table_owner,
  if(
    table_type IN (
      'EXTERNAL',
      'MANAGED',
      'MANAGED_SHALLOW_CLONE',
      'EXTERNAL_SHALLOW_CLONE'
    ),
    lower(table_type),
    NULL
  ) AS databricks_table_type
FROM `system`.`information_schema`.`tables`
WHERE table_catalog = 'dbt_learning' 
  AND table_schema = 'bronze'

  
[0m15:09:07.489354 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m15:09:08.807370 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f09abc-a681-1dc7-b4d8-d4fb57f7b6b0) - Created
[0m15:09:09.414369 [debug] [ThreadPool]: SQL status: OK in 1.920 seconds
[0m15:09:09.416079 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01f09abc-a681-1dc7-b4d8-d4fb57f7b6b0, command-id=01f09abc-a6b2-1e44-877f-46bd2958eb7e) - Closing
[0m15:09:09.416666 [debug] [ThreadPool]: On list_dbt_learning_bronze: Close
[0m15:09:09.417002 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f09abc-a681-1dc7-b4d8-d4fb57f7b6b0) - Closing
[0m15:09:09.750431 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '3e0ac330-3526-40ef-b915-a0a655991dfc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x748af38eec00>]}
[0m15:09:09.756680 [debug] [Thread-7 (]: Began running node model.dbt_anirudh.bronze_customer
[0m15:09:09.758134 [info ] [Thread-7 (]: 1 of 16 START sql table model bronze.bronze_customer ........................... [RUN]
[0m15:09:09.759530 [debug] [Thread-7 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.dbt_anirudh.bronze_customer) - Creating connection
[0m15:09:09.760509 [debug] [Thread-7 (]: Acquiring new databricks connection 'model.dbt_anirudh.bronze_customer'
[0m15:09:09.761358 [debug] [Thread-7 (]: Began compiling node model.dbt_anirudh.bronze_customer
[0m15:09:09.775674 [debug] [Thread-7 (]: Writing injected SQL for node "model.dbt_anirudh.bronze_customer"
[0m15:09:09.776553 [debug] [Thread-7 (]: Began executing node model.dbt_anirudh.bronze_customer
[0m15:09:09.791069 [debug] [Thread-7 (]: MATERIALIZING TABLE
[0m15:09:09.791700 [warn ] [Thread-7 (]: [[33mWARNING[0m]: Use revamped materializations based on separating create and insert.  This allows more performant column comments, as well as new column features.
You may opt into the new behavior sooner by setting `flags.use_materialization_v2` to `True` in `dbt_project.yml`.
Visit https://docs.getdbt.com/reference/global-configs/behavior-changes for more information.
[0m15:09:09.792218 [debug] [Thread-7 (]: Sending event: {'category': 'dbt', 'action': 'BehaviorChangeEvent', 'label': '3e0ac330-3526-40ef-b915-a0a655991dfc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x748af11b0800>]}
[0m15:09:09.831174 [debug] [Thread-7 (]: Writing runtime sql for node "model.dbt_anirudh.bronze_customer"
[0m15:09:09.831677 [debug] [Thread-7 (]: Using databricks connection "model.dbt_anirudh.bronze_customer"
[0m15:09:09.832007 [debug] [Thread-7 (]: On model.dbt_anirudh.bronze_customer: /* {"app": "dbt", "dbt_version": "1.10.10", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_anirudh", "target_name": "dev", "node_id": "model.dbt_anirudh.bronze_customer"} */

  
    
        create or replace table `dbt_learning`.`bronze`.`bronze_customer`
      
      
  using delta
      
      
      
      
      
      
      
      as
      SELECT 
    *
FROM
    `dbt_learning`.`source`.`dim_customer`
  
[0m15:09:09.832245 [debug] [Thread-7 (]: Opening a new connection, currently in state init
[0m15:09:11.152601 [debug] [Thread-7 (]: Databricks adapter: Connection(session-id=01f09abc-a7e9-1abb-add3-511c42b14c65) - Created
[0m15:09:14.735054 [debug] [Thread-7 (]: SQL status: OK in 4.900 seconds
[0m15:09:14.737540 [debug] [Thread-7 (]: Databricks adapter: Cursor(session-id=01f09abc-a7e9-1abb-add3-511c42b14c65, command-id=01f09abc-a819-10e1-b009-a7cae7393b2b) - Closing
[0m15:09:14.756239 [debug] [Thread-7 (]: Applying tags to relation None
[0m15:09:14.768436 [debug] [Thread-7 (]: On model.dbt_anirudh.bronze_customer: Close
[0m15:09:14.768795 [debug] [Thread-7 (]: Databricks adapter: Connection(session-id=01f09abc-a7e9-1abb-add3-511c42b14c65) - Closing
[0m15:09:15.145651 [debug] [Thread-7 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '3e0ac330-3526-40ef-b915-a0a655991dfc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x748b136082f0>]}
[0m15:09:15.146430 [info ] [Thread-7 (]: 1 of 16 OK created sql table model bronze.bronze_customer ...................... [[32mOK[0m in 5.38s]
[0m15:09:15.147044 [debug] [Thread-7 (]: Finished running node model.dbt_anirudh.bronze_customer
[0m15:09:15.147448 [debug] [Thread-7 (]: Began running node model.dbt_anirudh.bronze_date
[0m15:09:15.147949 [info ] [Thread-7 (]: 2 of 16 START sql view model bronze.bronze_date ................................ [RUN]
[0m15:09:15.148473 [debug] [Thread-7 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.dbt_anirudh.bronze_date) - Creating connection
[0m15:09:15.148789 [debug] [Thread-7 (]: Acquiring new databricks connection 'model.dbt_anirudh.bronze_date'
[0m15:09:15.149088 [debug] [Thread-7 (]: Began compiling node model.dbt_anirudh.bronze_date
[0m15:09:15.151267 [debug] [Thread-7 (]: Writing injected SQL for node "model.dbt_anirudh.bronze_date"
[0m15:09:15.151723 [debug] [Thread-7 (]: Began executing node model.dbt_anirudh.bronze_date
[0m15:09:15.163554 [debug] [Thread-7 (]: MATERIALIZING VIEW
[0m15:09:15.173476 [debug] [Thread-7 (]: Creating view `dbt_learning`.`bronze`.`bronze_date`
[0m15:09:15.174193 [debug] [Thread-7 (]: Writing runtime sql for node "model.dbt_anirudh.bronze_date"
[0m15:09:15.174731 [debug] [Thread-7 (]: Using databricks connection "model.dbt_anirudh.bronze_date"
[0m15:09:15.175086 [debug] [Thread-7 (]: On model.dbt_anirudh.bronze_date: /* {"app": "dbt", "dbt_version": "1.10.10", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_anirudh", "target_name": "dev", "node_id": "model.dbt_anirudh.bronze_date"} */

  
  
  create or replace view `dbt_learning`.`bronze`.`bronze_date`
  
  as (
    SELECT  
    *
FROM
    `dbt_learning`.`source`.`dim_date`
  )

[0m15:09:15.175385 [debug] [Thread-7 (]: Opening a new connection, currently in state init
[0m15:09:16.576656 [debug] [Thread-7 (]: Databricks adapter: Connection(session-id=01f09abc-ab24-1689-8660-b88f1798176d) - Created
[0m15:09:17.807852 [debug] [Thread-7 (]: SQL status: OK in 2.630 seconds
[0m15:09:17.810353 [debug] [Thread-7 (]: Databricks adapter: Cursor(session-id=01f09abc-ab24-1689-8660-b88f1798176d, command-id=01f09abc-ab52-1d62-8352-24e34edcf36b) - Closing
[0m15:09:17.811818 [debug] [Thread-7 (]: Applying tags to relation None
[0m15:09:17.813634 [debug] [Thread-7 (]: On model.dbt_anirudh.bronze_date: Close
[0m15:09:17.814510 [debug] [Thread-7 (]: Databricks adapter: Connection(session-id=01f09abc-ab24-1689-8660-b88f1798176d) - Closing
[0m15:09:18.130195 [debug] [Thread-7 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '3e0ac330-3526-40ef-b915-a0a655991dfc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x748af1156240>]}
[0m15:09:18.131841 [info ] [Thread-7 (]: 2 of 16 OK created sql view model bronze.bronze_date ........................... [[32mOK[0m in 2.98s]
[0m15:09:18.133209 [debug] [Thread-7 (]: Finished running node model.dbt_anirudh.bronze_date
[0m15:09:18.134185 [debug] [Thread-7 (]: Began running node model.dbt_anirudh.bronze_product
[0m15:09:18.135226 [info ] [Thread-7 (]: 3 of 16 START sql table model bronze.bronze_product ............................ [RUN]
[0m15:09:18.136383 [debug] [Thread-7 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.dbt_anirudh.bronze_product) - Creating connection
[0m15:09:18.137075 [debug] [Thread-7 (]: Acquiring new databricks connection 'model.dbt_anirudh.bronze_product'
[0m15:09:18.137724 [debug] [Thread-7 (]: Began compiling node model.dbt_anirudh.bronze_product
[0m15:09:18.145278 [debug] [Thread-7 (]: Writing injected SQL for node "model.dbt_anirudh.bronze_product"
[0m15:09:18.146051 [debug] [Thread-7 (]: Began executing node model.dbt_anirudh.bronze_product
[0m15:09:18.148396 [debug] [Thread-7 (]: MATERIALIZING TABLE
[0m15:09:18.149874 [debug] [Thread-7 (]: Writing runtime sql for node "model.dbt_anirudh.bronze_product"
[0m15:09:18.150312 [debug] [Thread-7 (]: Using databricks connection "model.dbt_anirudh.bronze_product"
[0m15:09:18.150631 [debug] [Thread-7 (]: On model.dbt_anirudh.bronze_product: /* {"app": "dbt", "dbt_version": "1.10.10", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_anirudh", "target_name": "dev", "node_id": "model.dbt_anirudh.bronze_product"} */

  
    
        create or replace table `dbt_learning`.`bronze`.`bronze_product`
      
      
  using delta
      
      
      
      
      
      
      
      as
      SELECT
    *
FROM
    `dbt_learning`.`source`.`dim_product`
  
[0m15:09:18.150931 [debug] [Thread-7 (]: Opening a new connection, currently in state init
[0m15:09:19.462136 [debug] [Thread-7 (]: Databricks adapter: Connection(session-id=01f09abc-acdb-1dc7-bb4e-6684bb8f6a9b) - Created
[0m15:09:22.318632 [debug] [Thread-7 (]: SQL status: OK in 4.170 seconds
[0m15:09:22.320801 [debug] [Thread-7 (]: Databricks adapter: Cursor(session-id=01f09abc-acdb-1dc7-bb4e-6684bb8f6a9b, command-id=01f09abc-ad0c-1f5a-9ab8-a34ec08819c2) - Closing
[0m15:09:22.321894 [debug] [Thread-7 (]: Applying tags to relation None
[0m15:09:22.323350 [debug] [Thread-7 (]: On model.dbt_anirudh.bronze_product: Close
[0m15:09:22.323766 [debug] [Thread-7 (]: Databricks adapter: Connection(session-id=01f09abc-acdb-1dc7-bb4e-6684bb8f6a9b) - Closing
[0m15:09:22.643372 [debug] [Thread-7 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '3e0ac330-3526-40ef-b915-a0a655991dfc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x748ae4738710>]}
[0m15:09:22.644028 [info ] [Thread-7 (]: 3 of 16 OK created sql table model bronze.bronze_product ....................... [[32mOK[0m in 4.51s]
[0m15:09:22.644636 [debug] [Thread-7 (]: Finished running node model.dbt_anirudh.bronze_product
[0m15:09:22.645065 [debug] [Thread-7 (]: Began running node model.dbt_anirudh.bronze_returns
[0m15:09:22.645585 [info ] [Thread-7 (]: 4 of 16 START sql table model bronze.bronze_returns ............................ [RUN]
[0m15:09:22.646147 [debug] [Thread-7 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.dbt_anirudh.bronze_returns) - Creating connection
[0m15:09:22.646466 [debug] [Thread-7 (]: Acquiring new databricks connection 'model.dbt_anirudh.bronze_returns'
[0m15:09:22.646755 [debug] [Thread-7 (]: Began compiling node model.dbt_anirudh.bronze_returns
[0m15:09:22.650600 [debug] [Thread-7 (]: Writing injected SQL for node "model.dbt_anirudh.bronze_returns"
[0m15:09:22.651126 [debug] [Thread-7 (]: Began executing node model.dbt_anirudh.bronze_returns
[0m15:09:22.652719 [debug] [Thread-7 (]: MATERIALIZING TABLE
[0m15:09:22.653797 [debug] [Thread-7 (]: Writing runtime sql for node "model.dbt_anirudh.bronze_returns"
[0m15:09:22.654201 [debug] [Thread-7 (]: Using databricks connection "model.dbt_anirudh.bronze_returns"
[0m15:09:22.654509 [debug] [Thread-7 (]: On model.dbt_anirudh.bronze_returns: /* {"app": "dbt", "dbt_version": "1.10.10", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_anirudh", "target_name": "dev", "node_id": "model.dbt_anirudh.bronze_returns"} */

  
    
        create or replace table `dbt_learning`.`bronze`.`bronze_returns`
      
      
  using delta
      
      
      
      
      
      
      
      as
      SELECT
    *
FROM
    `dbt_learning`.`source`.`fact_returns`
  
[0m15:09:22.654829 [debug] [Thread-7 (]: Opening a new connection, currently in state init
[0m15:09:23.963877 [debug] [Thread-7 (]: Databricks adapter: Connection(session-id=01f09abc-af8b-102a-bcc3-28e200a07a61) - Created
[0m15:09:26.410270 [debug] [Thread-7 (]: SQL status: OK in 3.760 seconds
[0m15:09:26.412162 [debug] [Thread-7 (]: Databricks adapter: Cursor(session-id=01f09abc-af8b-102a-bcc3-28e200a07a61, command-id=01f09abc-afbb-18a1-a334-5cb4a1b35ab6) - Closing
[0m15:09:26.413435 [debug] [Thread-7 (]: Applying tags to relation None
[0m15:09:26.414723 [debug] [Thread-7 (]: On model.dbt_anirudh.bronze_returns: Close
[0m15:09:26.415213 [debug] [Thread-7 (]: Databricks adapter: Connection(session-id=01f09abc-af8b-102a-bcc3-28e200a07a61) - Closing
[0m15:09:26.748103 [debug] [Thread-7 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '3e0ac330-3526-40ef-b915-a0a655991dfc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x748ae475f4d0>]}
[0m15:09:26.749831 [info ] [Thread-7 (]: 4 of 16 OK created sql table model bronze.bronze_returns ....................... [[32mOK[0m in 4.10s]
[0m15:09:26.751222 [debug] [Thread-7 (]: Finished running node model.dbt_anirudh.bronze_returns
[0m15:09:26.752166 [debug] [Thread-7 (]: Began running node model.dbt_anirudh.bronze_sales
[0m15:09:26.753457 [info ] [Thread-7 (]: 5 of 16 START sql view model bronze.bronze_sales ............................... [RUN]
[0m15:09:26.754814 [debug] [Thread-7 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.dbt_anirudh.bronze_sales) - Creating connection
[0m15:09:26.755693 [debug] [Thread-7 (]: Acquiring new databricks connection 'model.dbt_anirudh.bronze_sales'
[0m15:09:26.756483 [debug] [Thread-7 (]: Began compiling node model.dbt_anirudh.bronze_sales
[0m15:09:26.847449 [debug] [Thread-7 (]: Writing injected SQL for node "model.dbt_anirudh.bronze_sales"
[0m15:09:26.848006 [debug] [Thread-7 (]: Began executing node model.dbt_anirudh.bronze_sales
[0m15:09:26.849549 [debug] [Thread-7 (]: MATERIALIZING VIEW
[0m15:09:26.850226 [debug] [Thread-7 (]: Creating view `dbt_learning`.`bronze`.`bronze_sales`
[0m15:09:26.850706 [debug] [Thread-7 (]: Writing runtime sql for node "model.dbt_anirudh.bronze_sales"
[0m15:09:26.851082 [debug] [Thread-7 (]: Using databricks connection "model.dbt_anirudh.bronze_sales"
[0m15:09:26.851412 [debug] [Thread-7 (]: On model.dbt_anirudh.bronze_sales: /* {"app": "dbt", "dbt_version": "1.10.10", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_anirudh", "target_name": "dev", "node_id": "model.dbt_anirudh.bronze_sales"} */

  
  
  create or replace view `dbt_learning`.`bronze`.`bronze_sales`
  
  as (
    -- block level config


SELECT 
    * 
FROM
    
    `dbt_learning`.`source`.`fact_sales`
  )

[0m15:09:26.851685 [debug] [Thread-7 (]: Opening a new connection, currently in state init
[0m15:09:28.153736 [debug] [Thread-7 (]: Databricks adapter: Connection(session-id=01f09abc-b206-1877-8d21-e57e8f33ad2d) - Created
[0m15:09:29.170329 [debug] [Thread-7 (]: SQL status: OK in 2.320 seconds
[0m15:09:29.171265 [debug] [Thread-7 (]: Databricks adapter: Cursor(session-id=01f09abc-b206-1877-8d21-e57e8f33ad2d, command-id=01f09abc-b23a-1c45-99c3-212326b94806) - Closing
[0m15:09:29.171832 [debug] [Thread-7 (]: Applying tags to relation None
[0m15:09:29.172492 [debug] [Thread-7 (]: On model.dbt_anirudh.bronze_sales: Close
[0m15:09:29.172799 [debug] [Thread-7 (]: Databricks adapter: Connection(session-id=01f09abc-b206-1877-8d21-e57e8f33ad2d) - Closing
[0m15:09:29.498940 [debug] [Thread-7 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '3e0ac330-3526-40ef-b915-a0a655991dfc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x748b10af6d20>]}
[0m15:09:29.499583 [info ] [Thread-7 (]: 5 of 16 OK created sql view model bronze.bronze_sales .......................... [[32mOK[0m in 2.74s]
[0m15:09:29.500078 [debug] [Thread-7 (]: Finished running node model.dbt_anirudh.bronze_sales
[0m15:09:29.500388 [debug] [Thread-7 (]: Began running node model.dbt_anirudh.bronze_store
[0m15:09:29.500812 [info ] [Thread-7 (]: 6 of 16 START sql table model bronze.bronze_store .............................. [RUN]
[0m15:09:29.501393 [debug] [Thread-7 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.dbt_anirudh.bronze_store) - Creating connection
[0m15:09:29.501680 [debug] [Thread-7 (]: Acquiring new databricks connection 'model.dbt_anirudh.bronze_store'
[0m15:09:29.501960 [debug] [Thread-7 (]: Began compiling node model.dbt_anirudh.bronze_store
[0m15:09:29.504153 [debug] [Thread-7 (]: Writing injected SQL for node "model.dbt_anirudh.bronze_store"
[0m15:09:29.504594 [debug] [Thread-7 (]: Began executing node model.dbt_anirudh.bronze_store
[0m15:09:29.506138 [debug] [Thread-7 (]: MATERIALIZING TABLE
[0m15:09:29.507302 [debug] [Thread-7 (]: Writing runtime sql for node "model.dbt_anirudh.bronze_store"
[0m15:09:29.507777 [debug] [Thread-7 (]: Using databricks connection "model.dbt_anirudh.bronze_store"
[0m15:09:29.508135 [debug] [Thread-7 (]: On model.dbt_anirudh.bronze_store: /* {"app": "dbt", "dbt_version": "1.10.10", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_anirudh", "target_name": "dev", "node_id": "model.dbt_anirudh.bronze_store"} */

  
    
        create or replace table `dbt_learning`.`bronze`.`bronze_store`
      
      
  using delta
      
      
      
      
      
      
      
      as
      SELECT
    *
FROM
    `dbt_learning`.`source`.`dim_store`
  
[0m15:09:29.508429 [debug] [Thread-7 (]: Opening a new connection, currently in state init
[0m15:09:30.919511 [debug] [Thread-7 (]: Databricks adapter: Connection(session-id=01f09abc-b3b1-1657-b30e-ff4b554af8bc) - Created
[0m15:09:33.330109 [debug] [Thread-7 (]: SQL status: OK in 3.820 seconds
[0m15:09:33.332224 [debug] [Thread-7 (]: Databricks adapter: Cursor(session-id=01f09abc-b3b1-1657-b30e-ff4b554af8bc, command-id=01f09abc-b3e0-1c6a-97ee-fbe228a18d07) - Closing
[0m15:09:33.333720 [debug] [Thread-7 (]: Applying tags to relation None
[0m15:09:33.335495 [debug] [Thread-7 (]: On model.dbt_anirudh.bronze_store: Close
[0m15:09:33.336093 [debug] [Thread-7 (]: Databricks adapter: Connection(session-id=01f09abc-b3b1-1657-b30e-ff4b554af8bc) - Closing
[0m15:09:33.660631 [debug] [Thread-7 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '3e0ac330-3526-40ef-b915-a0a655991dfc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x748ae475f9e0>]}
[0m15:09:33.661303 [info ] [Thread-7 (]: 6 of 16 OK created sql table model bronze.bronze_store ......................... [[32mOK[0m in 4.16s]
[0m15:09:33.661842 [debug] [Thread-7 (]: Finished running node model.dbt_anirudh.bronze_store
[0m15:09:33.662181 [debug] [Thread-7 (]: Began running node model.dbt_anirudh.gold_items_source
[0m15:09:33.662623 [info ] [Thread-7 (]: 7 of 16 START sql table model gold.gold_items_source ........................... [RUN]
[0m15:09:33.663228 [debug] [Thread-7 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.dbt_anirudh.gold_items_source) - Creating connection
[0m15:09:33.663544 [debug] [Thread-7 (]: Acquiring new databricks connection 'model.dbt_anirudh.gold_items_source'
[0m15:09:33.663826 [debug] [Thread-7 (]: Began compiling node model.dbt_anirudh.gold_items_source
[0m15:09:33.667962 [debug] [Thread-7 (]: Writing injected SQL for node "model.dbt_anirudh.gold_items_source"
[0m15:09:33.668574 [debug] [Thread-7 (]: Began executing node model.dbt_anirudh.gold_items_source
[0m15:09:33.670310 [debug] [Thread-7 (]: MATERIALIZING TABLE
[0m15:09:33.671382 [debug] [Thread-7 (]: Writing runtime sql for node "model.dbt_anirudh.gold_items_source"
[0m15:09:33.671821 [debug] [Thread-7 (]: Using databricks connection "model.dbt_anirudh.gold_items_source"
[0m15:09:33.672153 [debug] [Thread-7 (]: On model.dbt_anirudh.gold_items_source: /* {"app": "dbt", "dbt_version": "1.10.10", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_anirudh", "target_name": "dev", "node_id": "model.dbt_anirudh.gold_items_source"} */

  
    
        create or replace table `dbt_learning`.`gold`.`gold_items_source`
      
      
  using delta
      
      
      
      
      
      
      
      as
      WITH deduplication_DATA AS
(
    SELECT
        *,
        ROW_NUMBER() OVER (partition by id ORDER BY updateDate DESC) as deduplication_id
    FROM
        `dbt_learning`.`source`.`items`
)
SELECT
    id, name, category, updateDate
FROM deduplication_DATA
WHERE
    deduplication_id = 1
  
[0m15:09:33.672434 [debug] [Thread-7 (]: Opening a new connection, currently in state init
[0m15:09:34.908371 [debug] [Thread-7 (]: Databricks adapter: Connection(session-id=01f09abc-b610-1b8d-ad51-91680a1ff922) - Created
[0m15:09:37.365075 [debug] [Thread-7 (]: SQL status: OK in 3.690 seconds
[0m15:09:37.367688 [debug] [Thread-7 (]: Databricks adapter: Cursor(session-id=01f09abc-b610-1b8d-ad51-91680a1ff922, command-id=01f09abc-b640-19c6-95f8-772f3fcfdac2) - Closing
[0m15:09:37.369536 [debug] [Thread-7 (]: Applying tags to relation None
[0m15:09:37.371942 [debug] [Thread-7 (]: On model.dbt_anirudh.gold_items_source: Close
[0m15:09:37.372851 [debug] [Thread-7 (]: Databricks adapter: Connection(session-id=01f09abc-b610-1b8d-ad51-91680a1ff922) - Closing
[0m15:09:37.682073 [debug] [Thread-7 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '3e0ac330-3526-40ef-b915-a0a655991dfc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x748af1121d30>]}
[0m15:09:37.683473 [info ] [Thread-7 (]: 7 of 16 OK created sql table model gold.gold_items_source ...................... [[32mOK[0m in 4.02s]
[0m15:09:37.684578 [debug] [Thread-7 (]: Finished running node model.dbt_anirudh.gold_items_source
[0m15:09:37.685410 [debug] [Thread-7 (]: Began running node seed.dbt_anirudh.lookup
[0m15:09:37.686292 [info ] [Thread-7 (]: 8 of 16 START seed file bronze.lookup .......................................... [RUN]
[0m15:09:37.686947 [debug] [Thread-7 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=seed.dbt_anirudh.lookup) - Creating connection
[0m15:09:37.687337 [debug] [Thread-7 (]: Acquiring new databricks connection 'seed.dbt_anirudh.lookup'
[0m15:09:37.687697 [debug] [Thread-7 (]: Began compiling node seed.dbt_anirudh.lookup
[0m15:09:37.688064 [debug] [Thread-7 (]: Began executing node seed.dbt_anirudh.lookup
[0m15:09:37.720096 [debug] [Thread-7 (]: Using databricks connection "seed.dbt_anirudh.lookup"
[0m15:09:37.720531 [debug] [Thread-7 (]: On seed.dbt_anirudh.lookup: /* {"app": "dbt", "dbt_version": "1.10.10", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_anirudh", "target_name": "dev", "node_id": "seed.dbt_anirudh.lookup"} */

    create or replace table `dbt_learning`.`bronze`.`lookup` (`customer_id` bigint ,`customer_name` string ,`customer_mail` string )
    
  using delta
    
    
    
    
    
  
[0m15:09:37.720957 [debug] [Thread-7 (]: Opening a new connection, currently in state init
[0m15:09:38.900469 [debug] [Thread-7 (]: Databricks adapter: Connection(session-id=01f09abc-b872-1019-bd4d-8c99817c3947) - Created
[0m15:09:40.438168 [debug] [Thread-7 (]: SQL status: OK in 2.720 seconds
[0m15:09:40.440748 [debug] [Thread-7 (]: Databricks adapter: Cursor(session-id=01f09abc-b872-1019-bd4d-8c99817c3947, command-id=01f09abc-b8a0-1cfc-845e-1aee52ac0a12) - Closing
[0m15:09:40.459226 [debug] [Thread-7 (]: Using databricks connection "seed.dbt_anirudh.lookup"
[0m15:09:40.459560 [debug] [Thread-7 (]: On seed.dbt_anirudh.lookup: 
          insert overwrite `dbt_learning`.`bronze`.`lookup` values
          (%s,%s,%s),(%s,%s,%s),(%s,%s,%s)
      ...
[0m15:09:42.186588 [debug] [Thread-7 (]: SQL status: OK in 1.730 seconds
[0m15:09:42.187786 [debug] [Thread-7 (]: Databricks adapter: Cursor(session-id=01f09abc-b872-1019-bd4d-8c99817c3947, command-id=01f09abc-b98f-12e8-a66a-4638524a5d26) - Closing
[0m15:09:42.199035 [debug] [Thread-7 (]: Writing runtime SQL for node "seed.dbt_anirudh.lookup"
[0m15:09:42.201375 [debug] [Thread-7 (]: On seed.dbt_anirudh.lookup: Close
[0m15:09:42.201801 [debug] [Thread-7 (]: Databricks adapter: Connection(session-id=01f09abc-b872-1019-bd4d-8c99817c3947) - Closing
[0m15:09:42.507584 [debug] [Thread-7 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '3e0ac330-3526-40ef-b915-a0a655991dfc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x748af118e9f0>]}
[0m15:09:42.509319 [info ] [Thread-7 (]: 8 of 16 OK loaded seed file bronze.lookup ...................................... [[32mINSERT 3[0m in 4.82s]
[0m15:09:42.510861 [debug] [Thread-7 (]: Finished running node seed.dbt_anirudh.lookup
[0m15:09:42.512017 [debug] [Thread-7 (]: Began running node test.dbt_anirudh.generic_non_negative_bronze_sales_gross_amount.770bebc5b1
[0m15:09:42.513091 [info ] [Thread-7 (]: 9 of 16 START test generic_non_negative_bronze_sales_gross_amount .............. [RUN]
[0m15:09:42.514326 [debug] [Thread-7 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=test.dbt_anirudh.generic_non_negative_bronze_sales_gross_amount.770bebc5b1) - Creating connection
[0m15:09:42.515185 [debug] [Thread-7 (]: Acquiring new databricks connection 'test.dbt_anirudh.generic_non_negative_bronze_sales_gross_amount.770bebc5b1'
[0m15:09:42.516062 [debug] [Thread-7 (]: Began compiling node test.dbt_anirudh.generic_non_negative_bronze_sales_gross_amount.770bebc5b1
[0m15:09:42.527000 [debug] [Thread-7 (]: Writing injected SQL for node "test.dbt_anirudh.generic_non_negative_bronze_sales_gross_amount.770bebc5b1"
[0m15:09:42.527717 [debug] [Thread-7 (]: Began executing node test.dbt_anirudh.generic_non_negative_bronze_sales_gross_amount.770bebc5b1
[0m15:09:42.543179 [debug] [Thread-7 (]: Writing runtime sql for node "test.dbt_anirudh.generic_non_negative_bronze_sales_gross_amount.770bebc5b1"
[0m15:09:42.543745 [debug] [Thread-7 (]: Using databricks connection "test.dbt_anirudh.generic_non_negative_bronze_sales_gross_amount.770bebc5b1"
[0m15:09:42.544110 [debug] [Thread-7 (]: On test.dbt_anirudh.generic_non_negative_bronze_sales_gross_amount.770bebc5b1: /* {"app": "dbt", "dbt_version": "1.10.10", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_anirudh", "target_name": "dev", "node_id": "test.dbt_anirudh.generic_non_negative_bronze_sales_gross_amount.770bebc5b1"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  

SELECT 
    *
FROM 
    `dbt_learning`.`bronze`.`bronze_sales`
WHERE
    gross_amount < 0


  
  
      
    ) dbt_internal_test
[0m15:09:42.544393 [debug] [Thread-7 (]: Opening a new connection, currently in state init
[0m15:09:43.800603 [debug] [Thread-7 (]: Databricks adapter: Connection(session-id=01f09abc-bb5f-1c08-93ae-90d7482aa919) - Created
[0m15:09:44.636276 [debug] [Thread-7 (]: SQL status: OK in 2.090 seconds
[0m15:09:44.640749 [debug] [Thread-7 (]: Databricks adapter: Cursor(session-id=01f09abc-bb5f-1c08-93ae-90d7482aa919, command-id=01f09abc-bb8c-1b7a-8908-a9aeb6c7d75d) - Closing
[0m15:09:44.645595 [debug] [Thread-7 (]: On test.dbt_anirudh.generic_non_negative_bronze_sales_gross_amount.770bebc5b1: Close
[0m15:09:44.646392 [debug] [Thread-7 (]: Databricks adapter: Connection(session-id=01f09abc-bb5f-1c08-93ae-90d7482aa919) - Closing
[0m15:09:44.956763 [info ] [Thread-7 (]: 9 of 16 PASS generic_non_negative_bronze_sales_gross_amount .................... [[32mPASS[0m in 2.44s]
[0m15:09:44.957320 [debug] [Thread-7 (]: Finished running node test.dbt_anirudh.generic_non_negative_bronze_sales_gross_amount.770bebc5b1
[0m15:09:44.957647 [debug] [Thread-7 (]: Began running node test.dbt_anirudh.non_negartive
[0m15:09:44.958000 [info ] [Thread-7 (]: 10 of 16 START test non_negartive .............................................. [RUN]
[0m15:09:44.958415 [debug] [Thread-7 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=test.dbt_anirudh.non_negartive) - Creating connection
[0m15:09:44.958696 [debug] [Thread-7 (]: Acquiring new databricks connection 'test.dbt_anirudh.non_negartive'
[0m15:09:44.958969 [debug] [Thread-7 (]: Began compiling node test.dbt_anirudh.non_negartive
[0m15:09:44.963486 [debug] [Thread-7 (]: Writing injected SQL for node "test.dbt_anirudh.non_negartive"
[0m15:09:44.964392 [debug] [Thread-7 (]: Began executing node test.dbt_anirudh.non_negartive
[0m15:09:44.967945 [debug] [Thread-7 (]: Writing runtime sql for node "test.dbt_anirudh.non_negartive"
[0m15:09:44.968792 [debug] [Thread-7 (]: Using databricks connection "test.dbt_anirudh.non_negartive"
[0m15:09:44.969384 [debug] [Thread-7 (]: On test.dbt_anirudh.non_negartive: /* {"app": "dbt", "dbt_version": "1.10.10", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_anirudh", "target_name": "dev", "node_id": "test.dbt_anirudh.non_negartive"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  SELECT
    *
FROM
    `dbt_learning`.`bronze`.`bronze_sales`
WHERE
    gross_amount < 0 AND net_amount < 0
  
  
      
    ) dbt_internal_test
[0m15:09:44.969875 [debug] [Thread-7 (]: Opening a new connection, currently in state init
[0m15:09:46.175656 [debug] [Thread-7 (]: Databricks adapter: Connection(session-id=01f09abc-bcc9-1c6a-bd50-e9e8de554169) - Created
[0m15:09:47.221680 [debug] [Thread-7 (]: SQL status: OK in 2.250 seconds
[0m15:09:47.223326 [debug] [Thread-7 (]: Databricks adapter: Cursor(session-id=01f09abc-bcc9-1c6a-bd50-e9e8de554169, command-id=01f09abc-bcf8-1699-9727-33d74f5adcdb) - Closing
[0m15:09:47.223961 [debug] [Thread-7 (]: On test.dbt_anirudh.non_negartive: Close
[0m15:09:47.224280 [debug] [Thread-7 (]: Databricks adapter: Connection(session-id=01f09abc-bcc9-1c6a-bd50-e9e8de554169) - Closing
[0m15:09:47.555034 [info ] [Thread-7 (]: 10 of 16 PASS non_negartive .................................................... [[32mPASS[0m in 2.60s]
[0m15:09:47.555579 [debug] [Thread-7 (]: Finished running node test.dbt_anirudh.non_negartive
[0m15:09:47.555910 [debug] [Thread-7 (]: Began running node test.dbt_anirudh.not_null_bronze_sales_sales_id.e4b1b997fb
[0m15:09:47.556251 [info ] [Thread-7 (]: 11 of 16 START test not_null_bronze_sales_sales_id ............................. [RUN]
[0m15:09:47.556656 [debug] [Thread-7 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=test.dbt_anirudh.not_null_bronze_sales_sales_id.e4b1b997fb) - Creating connection
[0m15:09:47.556954 [debug] [Thread-7 (]: Acquiring new databricks connection 'test.dbt_anirudh.not_null_bronze_sales_sales_id.e4b1b997fb'
[0m15:09:47.557228 [debug] [Thread-7 (]: Began compiling node test.dbt_anirudh.not_null_bronze_sales_sales_id.e4b1b997fb
[0m15:09:47.564728 [debug] [Thread-7 (]: Writing injected SQL for node "test.dbt_anirudh.not_null_bronze_sales_sales_id.e4b1b997fb"
[0m15:09:47.565424 [debug] [Thread-7 (]: Began executing node test.dbt_anirudh.not_null_bronze_sales_sales_id.e4b1b997fb
[0m15:09:47.571402 [debug] [Thread-7 (]: Writing runtime sql for node "test.dbt_anirudh.not_null_bronze_sales_sales_id.e4b1b997fb"
[0m15:09:47.572044 [debug] [Thread-7 (]: Using databricks connection "test.dbt_anirudh.not_null_bronze_sales_sales_id.e4b1b997fb"
[0m15:09:47.572444 [debug] [Thread-7 (]: On test.dbt_anirudh.not_null_bronze_sales_sales_id.e4b1b997fb: /* {"app": "dbt", "dbt_version": "1.10.10", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_anirudh", "target_name": "dev", "node_id": "test.dbt_anirudh.not_null_bronze_sales_sales_id.e4b1b997fb"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select sales_id
from `dbt_learning`.`bronze`.`bronze_sales`
where sales_id is null



  
  
      
    ) dbt_internal_test
[0m15:09:47.572744 [debug] [Thread-7 (]: Opening a new connection, currently in state init
[0m15:09:48.826629 [debug] [Thread-7 (]: Databricks adapter: Connection(session-id=01f09abc-be5f-176c-b54e-64b04fe4bd3d) - Created
[0m15:09:49.652370 [debug] [Thread-7 (]: SQL status: OK in 2.080 seconds
[0m15:09:49.654054 [debug] [Thread-7 (]: Databricks adapter: Cursor(session-id=01f09abc-be5f-176c-b54e-64b04fe4bd3d, command-id=01f09abc-be8d-16da-8067-a52a0848b270) - Closing
[0m15:09:49.654573 [debug] [Thread-7 (]: On test.dbt_anirudh.not_null_bronze_sales_sales_id.e4b1b997fb: Close
[0m15:09:49.654900 [debug] [Thread-7 (]: Databricks adapter: Connection(session-id=01f09abc-be5f-176c-b54e-64b04fe4bd3d) - Closing
[0m15:09:49.976598 [info ] [Thread-7 (]: 11 of 16 PASS not_null_bronze_sales_sales_id ................................... [[32mPASS[0m in 2.42s]
[0m15:09:49.978130 [debug] [Thread-7 (]: Finished running node test.dbt_anirudh.not_null_bronze_sales_sales_id.e4b1b997fb
[0m15:09:49.979338 [debug] [Thread-7 (]: Began running node test.dbt_anirudh.unique_bronze_sales_sales_id.3c35aa753d
[0m15:09:49.980510 [info ] [Thread-7 (]: 12 of 16 START test unique_bronze_sales_sales_id ............................... [RUN]
[0m15:09:49.982002 [debug] [Thread-7 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=test.dbt_anirudh.unique_bronze_sales_sales_id.3c35aa753d) - Creating connection
[0m15:09:49.983017 [debug] [Thread-7 (]: Acquiring new databricks connection 'test.dbt_anirudh.unique_bronze_sales_sales_id.3c35aa753d'
[0m15:09:49.983927 [debug] [Thread-7 (]: Began compiling node test.dbt_anirudh.unique_bronze_sales_sales_id.3c35aa753d
[0m15:09:49.994807 [debug] [Thread-7 (]: Writing injected SQL for node "test.dbt_anirudh.unique_bronze_sales_sales_id.3c35aa753d"
[0m15:09:49.996071 [debug] [Thread-7 (]: Began executing node test.dbt_anirudh.unique_bronze_sales_sales_id.3c35aa753d
[0m15:09:49.999442 [debug] [Thread-7 (]: Writing runtime sql for node "test.dbt_anirudh.unique_bronze_sales_sales_id.3c35aa753d"
[0m15:09:50.000135 [debug] [Thread-7 (]: Using databricks connection "test.dbt_anirudh.unique_bronze_sales_sales_id.3c35aa753d"
[0m15:09:50.000815 [debug] [Thread-7 (]: On test.dbt_anirudh.unique_bronze_sales_sales_id.3c35aa753d: /* {"app": "dbt", "dbt_version": "1.10.10", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_anirudh", "target_name": "dev", "node_id": "test.dbt_anirudh.unique_bronze_sales_sales_id.3c35aa753d"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    

select
    sales_id as unique_field,
    count(*) as n_records

from `dbt_learning`.`bronze`.`bronze_sales`
where sales_id is not null
group by sales_id
having count(*) > 1



  
  
      
    ) dbt_internal_test
[0m15:09:50.001113 [debug] [Thread-7 (]: Opening a new connection, currently in state init
[0m15:09:51.292085 [debug] [Thread-7 (]: Databricks adapter: Connection(session-id=01f09abc-bfd6-165e-bbcc-238d6f43823f) - Created
[0m15:09:52.056493 [debug] [Thread-7 (]: SQL status: OK in 2.060 seconds
[0m15:09:52.058495 [debug] [Thread-7 (]: Databricks adapter: Cursor(session-id=01f09abc-bfd6-165e-bbcc-238d6f43823f, command-id=01f09abc-c005-191a-bc72-786a1afab50e) - Closing
[0m15:09:52.059069 [debug] [Thread-7 (]: On test.dbt_anirudh.unique_bronze_sales_sales_id.3c35aa753d: Close
[0m15:09:52.059404 [debug] [Thread-7 (]: Databricks adapter: Connection(session-id=01f09abc-bfd6-165e-bbcc-238d6f43823f) - Closing
[0m15:09:52.425781 [info ] [Thread-7 (]: 12 of 16 PASS unique_bronze_sales_sales_id ..................................... [[32mPASS[0m in 2.44s]
[0m15:09:52.426447 [debug] [Thread-7 (]: Finished running node test.dbt_anirudh.unique_bronze_sales_sales_id.3c35aa753d
[0m15:09:52.426945 [debug] [Thread-7 (]: Began running node test.dbt_anirudh.accepted_values_bronze_store_store_name__MegaMar_Manhattan__MegaMart_Brooklyn__MegaMart_Austin__MegaMart_San_Jose__MegaMart_Toronto.b983752665
[0m15:09:52.427494 [info ] [Thread-7 (]: 13 of 16 START test accepted_values_bronze_store_store_name__MegaMar_Manhattan__MegaMart_Brooklyn__MegaMart_Austin__MegaMart_San_Jose__MegaMart_Toronto  [RUN]
[0m15:09:52.428096 [debug] [Thread-7 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=test.dbt_anirudh.accepted_values_bronze_store_store_name__MegaMar_Manhattan__MegaMart_Brooklyn__MegaMart_Austin__MegaMart_San_Jose__MegaMart_Toronto.b983752665) - Creating connection
[0m15:09:52.428408 [debug] [Thread-7 (]: Acquiring new databricks connection 'test.dbt_anirudh.accepted_values_bronze_store_store_name__MegaMar_Manhattan__MegaMart_Brooklyn__MegaMart_Austin__MegaMart_San_Jose__MegaMart_Toronto.b983752665'
[0m15:09:52.428677 [debug] [Thread-7 (]: Began compiling node test.dbt_anirudh.accepted_values_bronze_store_store_name__MegaMar_Manhattan__MegaMart_Brooklyn__MegaMart_Austin__MegaMart_San_Jose__MegaMart_Toronto.b983752665
[0m15:09:52.439430 [debug] [Thread-7 (]: Writing injected SQL for node "test.dbt_anirudh.accepted_values_bronze_store_store_name__MegaMar_Manhattan__MegaMart_Brooklyn__MegaMart_Austin__MegaMart_San_Jose__MegaMart_Toronto.b983752665"
[0m15:09:52.440030 [debug] [Thread-7 (]: Began executing node test.dbt_anirudh.accepted_values_bronze_store_store_name__MegaMar_Manhattan__MegaMart_Brooklyn__MegaMart_Austin__MegaMart_San_Jose__MegaMart_Toronto.b983752665
[0m15:09:52.442490 [debug] [Thread-7 (]: Writing runtime sql for node "test.dbt_anirudh.accepted_values_bronze_store_store_name__MegaMar_Manhattan__MegaMart_Brooklyn__MegaMart_Austin__MegaMart_San_Jose__MegaMart_Toronto.b983752665"
[0m15:09:52.443142 [debug] [Thread-7 (]: Using databricks connection "test.dbt_anirudh.accepted_values_bronze_store_store_name__MegaMar_Manhattan__MegaMart_Brooklyn__MegaMart_Austin__MegaMart_San_Jose__MegaMart_Toronto.b983752665"
[0m15:09:52.443667 [debug] [Thread-7 (]: On test.dbt_anirudh.accepted_values_bronze_store_store_name__MegaMar_Manhattan__MegaMart_Brooklyn__MegaMart_Austin__MegaMart_San_Jose__MegaMart_Toronto.b983752665: /* {"app": "dbt", "dbt_version": "1.10.10", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_anirudh", "target_name": "dev", "node_id": "test.dbt_anirudh.accepted_values_bronze_store_store_name__MegaMar_Manhattan__MegaMart_Brooklyn__MegaMart_Austin__MegaMart_San_Jose__MegaMart_Toronto.b983752665"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    

with all_values as (

    select
        store_name as value_field,
        count(*) as n_records

    from `dbt_learning`.`bronze`.`bronze_store`
    group by store_name

)

select *
from all_values
where value_field not in (
    'MegaMar Manhattan','MegaMart Brooklyn','MegaMart Austin','MegaMart San Jose','MegaMart Toronto'
)



  
  
      
    ) dbt_internal_test
[0m15:09:52.444031 [debug] [Thread-7 (]: Opening a new connection, currently in state init
[0m15:09:53.712015 [debug] [Thread-7 (]: Databricks adapter: Connection(session-id=01f09abc-c148-1b60-a4b7-c00bbb1699bf) - Created
[0m15:09:54.674128 [debug] [Thread-7 (]: SQL status: OK in 2.230 seconds
[0m15:09:54.678535 [debug] [Thread-7 (]: Databricks adapter: Cursor(session-id=01f09abc-c148-1b60-a4b7-c00bbb1699bf, command-id=01f09abc-c176-1b8d-906b-50889dc5ce5c) - Closing
[0m15:09:54.680062 [debug] [Thread-7 (]: On test.dbt_anirudh.accepted_values_bronze_store_store_name__MegaMar_Manhattan__MegaMart_Brooklyn__MegaMart_Austin__MegaMart_San_Jose__MegaMart_Toronto.b983752665: Close
[0m15:09:54.681058 [debug] [Thread-7 (]: Databricks adapter: Connection(session-id=01f09abc-c148-1b60-a4b7-c00bbb1699bf) - Closing
[0m15:09:55.006969 [warn ] [Thread-7 (]: 13 of 16 WARN 1 accepted_values_bronze_store_store_name__MegaMar_Manhattan__MegaMart_Brooklyn__MegaMart_Austin__MegaMart_San_Jose__MegaMart_Toronto  [[33mWARN 1[0m in 2.58s]
[0m15:09:55.008526 [debug] [Thread-7 (]: Finished running node test.dbt_anirudh.accepted_values_bronze_store_store_name__MegaMar_Manhattan__MegaMart_Brooklyn__MegaMart_Austin__MegaMart_San_Jose__MegaMart_Toronto.b983752665
[0m15:09:55.009555 [debug] [Thread-7 (]: Began running node snapshot.dbt_anirudh.gold_items
[0m15:09:55.010801 [info ] [Thread-7 (]: 14 of 16 START snapshot gold.gold_items ........................................ [RUN]
[0m15:09:55.012542 [debug] [Thread-7 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=snapshot.dbt_anirudh.gold_items) - Creating connection
[0m15:09:55.013589 [debug] [Thread-7 (]: Acquiring new databricks connection 'snapshot.dbt_anirudh.gold_items'
[0m15:09:55.014562 [debug] [Thread-7 (]: Began compiling node snapshot.dbt_anirudh.gold_items
[0m15:09:55.021697 [debug] [Thread-7 (]: Began executing node snapshot.dbt_anirudh.gold_items
[0m15:09:55.051924 [debug] [Thread-7 (]: Opening a new connection, currently in state init
[0m15:09:56.268557 [debug] [Thread-7 (]: Databricks adapter: Connection(session-id=01f09abc-c2cd-12b4-8c14-56078557416a) - Created
[0m15:09:56.286930 [debug] [Thread-7 (]: Using databricks connection "snapshot.dbt_anirudh.gold_items"
[0m15:09:56.287568 [debug] [Thread-7 (]: On snapshot.dbt_anirudh.gold_items: /* {"app": "dbt", "dbt_version": "1.10.10", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_anirudh", "target_name": "dev", "node_id": "snapshot.dbt_anirudh.gold_items"} */

    
  DESCRIBE TABLE EXTENDED `dbt_learning`.`gold`.`gold_items` AS JSON

  
[0m15:09:56.928627 [debug] [Thread-7 (]: SQL status: OK in 0.640 seconds
[0m15:09:56.930161 [debug] [Thread-7 (]: Databricks adapter: Cursor(session-id=01f09abc-c2cd-12b4-8c14-56078557416a, command-id=01f09abc-c2ff-117a-b0c1-a0eb85e44da4) - Closing
[0m15:09:56.962111 [debug] [Thread-7 (]: Using databricks connection "snapshot.dbt_anirudh.gold_items"
[0m15:09:56.962562 [debug] [Thread-7 (]: On snapshot.dbt_anirudh.gold_items: /* {"app": "dbt", "dbt_version": "1.10.10", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_anirudh", "target_name": "dev", "node_id": "snapshot.dbt_anirudh.gold_items"} */

        
  
    create or replace temporary view `gold_items__dbt_tmp` as
      
    
    with snapshot_query as (

        select * from `dbt_learning`.`gold`.`gold_items_source`

    ),

    snapshotted_data as (

        select *, 
    
        id as dbt_unique_key
    

        from `dbt_learning`.`gold`.`gold_items`
        where
            
		
		

		
                ( (dbt_valid_to = to_date('9999-12-31'))
 or dbt_valid_to is null )
            

    ),

    insertions_source_data as (

        select *, 
    
        id as dbt_unique_key
    
,
            updateDate as dbt_updated_at,
            updateDate as dbt_valid_from,
            
  
  coalesce(nullif(updateDate, updateDate), to_date('9999-12-31'))
  as dbt_valid_to
,
            md5(coalesce(cast(id as string ), '')
         || '|' || coalesce(cast(updateDate as string ), '')
        ) as dbt_scd_id

        from snapshot_query
    ),

    updates_source_data as (

        select *, 
    
        id as dbt_unique_key
    
,
            updateDate as dbt_updated_at,
            updateDate as dbt_valid_from,
            updateDate as dbt_valid_to

        from snapshot_query
    ),

    insertions as (

        select
            'insert' as dbt_change_type,
            source_data.*

        from insertions_source_data as source_data
        left outer join snapshotted_data
            on 
    
        snapshotted_data.dbt_unique_key = source_data.dbt_unique_key
    

            where 
    
        snapshotted_data.dbt_unique_key is null
    

            or (
    
        snapshotted_data.dbt_unique_key is not null
    
 and (
               (snapshotted_data.dbt_valid_from < source_data.updateDate)
            )

        )

    ),

    updates as (

        select
            'update' as dbt_change_type,
            source_data.*,
            snapshotted_data.dbt_scd_id

        from updates_source_data as source_data
        join snapshotted_data
            on 
    
        snapshotted_data.dbt_unique_key = source_data.dbt_unique_key
    

        where (
            (snapshotted_data.dbt_valid_from < source_data.updateDate)
        )
    )

    select * from insertions
    union all
    select * from updates

  
    
[0m15:09:57.642974 [debug] [Thread-7 (]: SQL status: OK in 0.680 seconds
[0m15:09:57.645353 [debug] [Thread-7 (]: Databricks adapter: Cursor(session-id=01f09abc-c2cd-12b4-8c14-56078557416a, command-id=01f09abc-c365-1aec-b830-002dca9e7316) - Closing
[0m15:09:57.649752 [debug] [Thread-7 (]: Using databricks connection "snapshot.dbt_anirudh.gold_items"
[0m15:09:57.650728 [debug] [Thread-7 (]: On snapshot.dbt_anirudh.gold_items: /* {"app": "dbt", "dbt_version": "1.10.10", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_anirudh", "target_name": "dev", "node_id": "snapshot.dbt_anirudh.gold_items"} */

    
  DESCRIBE TABLE EXTENDED `gold_items__dbt_tmp` AS JSON

  
[0m15:09:58.045116 [debug] [Thread-7 (]: SQL status: OK in 0.390 seconds
[0m15:09:58.046529 [debug] [Thread-7 (]: Databricks adapter: Cursor(session-id=01f09abc-c2cd-12b4-8c14-56078557416a, command-id=01f09abc-c3cf-1299-a06e-110e095498a0) - Closing
[0m15:09:58.048241 [debug] [Thread-7 (]: Using databricks connection "snapshot.dbt_anirudh.gold_items"
[0m15:09:58.048550 [debug] [Thread-7 (]: On snapshot.dbt_anirudh.gold_items: /* {"app": "dbt", "dbt_version": "1.10.10", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_anirudh", "target_name": "dev", "node_id": "snapshot.dbt_anirudh.gold_items"} */

    
  DESCRIBE TABLE EXTENDED `dbt_learning`.`gold`.`gold_items` AS JSON

  
[0m15:09:58.561409 [debug] [Thread-7 (]: SQL status: OK in 0.510 seconds
[0m15:09:58.565120 [debug] [Thread-7 (]: Databricks adapter: Cursor(session-id=01f09abc-c2cd-12b4-8c14-56078557416a, command-id=01f09abc-c40b-1865-ba39-435ac4c645d8) - Closing
[0m15:09:58.569232 [debug] [Thread-7 (]: Using databricks connection "snapshot.dbt_anirudh.gold_items"
[0m15:09:58.569942 [debug] [Thread-7 (]: On snapshot.dbt_anirudh.gold_items: /* {"app": "dbt", "dbt_version": "1.10.10", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_anirudh", "target_name": "dev", "node_id": "snapshot.dbt_anirudh.gold_items"} */

    
  DESCRIBE TABLE EXTENDED `gold_items__dbt_tmp` AS JSON

  
[0m15:09:59.071339 [debug] [Thread-7 (]: SQL status: OK in 0.500 seconds
[0m15:09:59.073279 [debug] [Thread-7 (]: Databricks adapter: Cursor(session-id=01f09abc-c2cd-12b4-8c14-56078557416a, command-id=01f09abc-c45b-112e-9fca-b08ccd877e0a) - Closing
[0m15:09:59.075072 [debug] [Thread-7 (]: Using databricks connection "snapshot.dbt_anirudh.gold_items"
[0m15:09:59.075419 [debug] [Thread-7 (]: On snapshot.dbt_anirudh.gold_items: /* {"app": "dbt", "dbt_version": "1.10.10", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_anirudh", "target_name": "dev", "node_id": "snapshot.dbt_anirudh.gold_items"} */

    
  DESCRIBE TABLE EXTENDED `dbt_learning`.`gold`.`gold_items` AS JSON

  
[0m15:09:59.581595 [debug] [Thread-7 (]: SQL status: OK in 0.510 seconds
[0m15:09:59.583005 [debug] [Thread-7 (]: Databricks adapter: Cursor(session-id=01f09abc-c2cd-12b4-8c14-56078557416a, command-id=01f09abc-c4a8-152e-92b9-05a62812e7a6) - Closing
[0m15:09:59.588099 [debug] [Thread-7 (]: Using databricks connection "snapshot.dbt_anirudh.gold_items"
[0m15:09:59.588506 [debug] [Thread-7 (]: On snapshot.dbt_anirudh.gold_items: /* {"app": "dbt", "dbt_version": "1.10.10", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_anirudh", "target_name": "dev", "node_id": "snapshot.dbt_anirudh.gold_items"} */

    
  DESCRIBE TABLE EXTENDED `gold_items__dbt_tmp` AS JSON

  
[0m15:09:59.976952 [debug] [Thread-7 (]: SQL status: OK in 0.390 seconds
[0m15:09:59.980637 [debug] [Thread-7 (]: Databricks adapter: Cursor(session-id=01f09abc-c2cd-12b4-8c14-56078557416a, command-id=01f09abc-c4f6-1a6a-a34e-05c982d5766e) - Closing
[0m15:09:59.997847 [debug] [Thread-7 (]: Using databricks connection "snapshot.dbt_anirudh.gold_items"
[0m15:09:59.998327 [debug] [Thread-7 (]: On snapshot.dbt_anirudh.gold_items: /* {"app": "dbt", "dbt_version": "1.10.10", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_anirudh", "target_name": "dev", "node_id": "snapshot.dbt_anirudh.gold_items"} */
select * from (
        
    
    with snapshot_query as (

        select * from `dbt_learning`.`gold`.`gold_items_source`

    ),

    snapshotted_data as (

        select *, 
    
        id as dbt_unique_key
    

        from `dbt_learning`.`gold`.`gold_items`
        where
            
		
		

		
                ( (dbt_valid_to = to_date('9999-12-31'))
 or dbt_valid_to is null )
            

    ),

    insertions_source_data as (

        select *, 
    
        id as dbt_unique_key
    
,
            updateDate as dbt_updated_at,
            updateDate as dbt_valid_from,
            
  
  coalesce(nullif(updateDate, updateDate), to_date('9999-12-31'))
  as dbt_valid_to
,
            md5(coalesce(cast(id as string ), '')
         || '|' || coalesce(cast(updateDate as string ), '')
        ) as dbt_scd_id

        from snapshot_query
    ),

    updates_source_data as (

        select *, 
    
        id as dbt_unique_key
    
,
            updateDate as dbt_updated_at,
            updateDate as dbt_valid_from,
            updateDate as dbt_valid_to

        from snapshot_query
    ),

    insertions as (

        select
            'insert' as dbt_change_type,
            source_data.*

        from insertions_source_data as source_data
        left outer join snapshotted_data
            on 
    
        snapshotted_data.dbt_unique_key = source_data.dbt_unique_key
    

            where 
    
        snapshotted_data.dbt_unique_key is null
    

            or (
    
        snapshotted_data.dbt_unique_key is not null
    
 and (
               (snapshotted_data.dbt_valid_from < source_data.updateDate)
            )

        )

    ),

    updates as (

        select
            'update' as dbt_change_type,
            source_data.*,
            snapshotted_data.dbt_scd_id

        from updates_source_data as source_data
        join snapshotted_data
            on 
    
        snapshotted_data.dbt_unique_key = source_data.dbt_unique_key
    

        where (
            (snapshotted_data.dbt_valid_from < source_data.updateDate)
        )
    )

    select * from insertions
    union all
    select * from updates

    ) as __dbt_sbq
    where false
    limit 0

[0m15:10:00.715456 [debug] [Thread-7 (]: SQL status: OK in 0.720 seconds
[0m15:10:00.725963 [debug] [Thread-7 (]: Using databricks connection "snapshot.dbt_anirudh.gold_items"
[0m15:10:00.726597 [debug] [Thread-7 (]: On snapshot.dbt_anirudh.gold_items: /* {"app": "dbt", "dbt_version": "1.10.10", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_anirudh", "target_name": "dev", "node_id": "snapshot.dbt_anirudh.gold_items"} */
select * from (
        select 
    current_timestamp()
 as dbt_snapshot_time
    ) as __dbt_sbq
    where false
    limit 0

[0m15:10:00.727196 [debug] [Thread-7 (]: Databricks adapter: Cursor(session-id=01f09abc-c2cd-12b4-8c14-56078557416a, command-id=01f09abc-c535-1184-9fe9-c2b8fb16b0f4) - Closing
[0m15:10:01.224802 [debug] [Thread-7 (]: SQL status: OK in 0.500 seconds
[0m15:10:01.226215 [debug] [Thread-7 (]: Writing runtime sql for node "snapshot.dbt_anirudh.gold_items"
[0m15:10:01.227364 [debug] [Thread-7 (]: Using databricks connection "snapshot.dbt_anirudh.gold_items"
[0m15:10:01.228452 [debug] [Thread-7 (]: On snapshot.dbt_anirudh.gold_items: /* {"app": "dbt", "dbt_version": "1.10.10", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_anirudh", "target_name": "dev", "node_id": "snapshot.dbt_anirudh.gold_items"} */

      merge into `dbt_learning`.`gold`.`gold_items` as DBT_INTERNAL_DEST
    
      using `gold_items__dbt_tmp` as DBT_INTERNAL_SOURCE
    
    on DBT_INTERNAL_SOURCE.dbt_scd_id = DBT_INTERNAL_DEST.dbt_scd_id
    when matched
     
       and ( DBT_INTERNAL_DEST.dbt_valid_to = to_date('9999-12-31') or
             DBT_INTERNAL_DEST.dbt_valid_to is null )
     
     and DBT_INTERNAL_SOURCE.dbt_change_type in ('update', 'delete')
        then update
        set dbt_valid_to = DBT_INTERNAL_SOURCE.dbt_valid_to

    when not matched
     and DBT_INTERNAL_SOURCE.dbt_change_type = 'insert'
        then insert *
    ;

  
[0m15:10:01.229426 [debug] [Thread-7 (]: Databricks adapter: Cursor(session-id=01f09abc-c2cd-12b4-8c14-56078557416a, command-id=01f09abc-c5a4-17b6-9d48-f37b13f05497) - Closing
[0m15:10:10.256152 [debug] [Thread-7 (]: SQL status: OK in 9.030 seconds
[0m15:10:10.258546 [debug] [Thread-7 (]: Databricks adapter: Cursor(session-id=01f09abc-c2cd-12b4-8c14-56078557416a, command-id=01f09abc-c5f0-1e59-b1ac-0a10d40180d9) - Closing
[0m15:10:10.597059 [debug] [Thread-7 (]: Applying DROP to: `gold_items__dbt_tmp`
[0m15:10:10.600466 [debug] [Thread-7 (]: Using databricks connection "snapshot.dbt_anirudh.gold_items"
[0m15:10:10.600790 [debug] [Thread-7 (]: On snapshot.dbt_anirudh.gold_items: /* {"app": "dbt", "dbt_version": "1.10.10", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_anirudh", "target_name": "dev", "node_id": "snapshot.dbt_anirudh.gold_items"} */
DROP VIEW IF EXISTS `gold_items__dbt_tmp`
[0m15:10:11.001520 [debug] [Thread-7 (]: SQL status: OK in 0.400 seconds
[0m15:10:11.003896 [debug] [Thread-7 (]: Databricks adapter: Cursor(session-id=01f09abc-c2cd-12b4-8c14-56078557416a, command-id=01f09abc-cb86-1a59-b949-b2bd34fff95a) - Closing
[0m15:10:11.006156 [debug] [Thread-7 (]: On snapshot.dbt_anirudh.gold_items: Close
[0m15:10:11.007110 [debug] [Thread-7 (]: Databricks adapter: Connection(session-id=01f09abc-c2cd-12b4-8c14-56078557416a) - Closing
[0m15:10:11.359610 [debug] [Thread-7 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '3e0ac330-3526-40ef-b915-a0a655991dfc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x748af185cc50>]}
[0m15:10:11.360363 [info ] [Thread-7 (]: 14 of 16 OK snapshotted gold.gold_items ........................................ [[32mOK[0m in 16.35s]
[0m15:10:11.360864 [debug] [Thread-7 (]: Finished running node snapshot.dbt_anirudh.gold_items
[0m15:10:11.361192 [debug] [Thread-7 (]: Began running node model.dbt_anirudh.silver_returns_info
[0m15:10:11.361549 [info ] [Thread-7 (]: 15 of 16 START sql table model silver.silver_returns_info ...................... [RUN]
[0m15:10:11.362046 [debug] [Thread-7 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.dbt_anirudh.silver_returns_info) - Creating connection
[0m15:10:11.362335 [debug] [Thread-7 (]: Acquiring new databricks connection 'model.dbt_anirudh.silver_returns_info'
[0m15:10:11.362595 [debug] [Thread-7 (]: Began compiling node model.dbt_anirudh.silver_returns_info
[0m15:10:11.365288 [debug] [Thread-7 (]: Writing injected SQL for node "model.dbt_anirudh.silver_returns_info"
[0m15:10:11.365752 [debug] [Thread-7 (]: Began executing node model.dbt_anirudh.silver_returns_info
[0m15:10:11.367362 [debug] [Thread-7 (]: MATERIALIZING TABLE
[0m15:10:11.368533 [debug] [Thread-7 (]: Writing runtime sql for node "model.dbt_anirudh.silver_returns_info"
[0m15:10:11.368943 [debug] [Thread-7 (]: Using databricks connection "model.dbt_anirudh.silver_returns_info"
[0m15:10:11.369292 [debug] [Thread-7 (]: On model.dbt_anirudh.silver_returns_info: /* {"app": "dbt", "dbt_version": "1.10.10", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_anirudh", "target_name": "dev", "node_id": "model.dbt_anirudh.silver_returns_info"} */

  
    
        create or replace table `dbt_learning`.`silver`.`silver_returns_info`
      
      
  using delta
      
      
      
      
      
      
      
      as
      WITH return_data AS
(
    SELECT
        sales_id,
        product_sk,
        return_reason,
        refund_amount
    FROM
        `dbt_learning`.`bronze`.`bronze_returns`
),
product_data AS
(
    SELECT
        product_sk,
        category,
        department
    FROM
        `dbt_learning`.`bronze`.`bronze_product`
),
customer_data AS
(
    SELECT
        customer_sk,
        gender
    FROM
        `dbt_learning`.`bronze`.`bronze_customer`
),
sales_data AS
(
    SELECT
        sales_id,
        customer_sk
    FROM
        `dbt_learning`.`bronze`.`bronze_sales`
),
joined_query AS
(
    SELECT
        product_data.category,
        product_data.department,
        customer_data.gender,
        return_data.refund_amount
    FROM
        return_data
    INNER JOIN sales_data ON sales_data.sales_id = return_data.sales_id
    INNER JOIN customer_data ON customer_data.customer_sk = sales_data.customer_sk
    INNER JOIN product_data ON product_data.product_sk = return_data.product_sk
)
SELECT
    category,
    department,
    gender,
    sum(refund_amount) as total_refund
FROM
    joined_query
GROUP BY 1,2,3
ORDER BY 1,2 ASC, 4 DESC
  
[0m15:10:11.369670 [debug] [Thread-7 (]: Opening a new connection, currently in state init
[0m15:10:12.670743 [debug] [Thread-7 (]: Databricks adapter: Connection(session-id=01f09abc-cc96-10fd-9b77-92f63f45c69b) - Created
[0m15:10:16.375992 [debug] [Thread-7 (]: SQL status: OK in 5.010 seconds
[0m15:10:16.376797 [debug] [Thread-7 (]: Databricks adapter: Cursor(session-id=01f09abc-cc96-10fd-9b77-92f63f45c69b, command-id=01f09abc-ccc2-1ae3-97e5-ab2ee3cbb8d9) - Closing
[0m15:10:16.377359 [debug] [Thread-7 (]: Applying tags to relation None
[0m15:10:16.378166 [debug] [Thread-7 (]: On model.dbt_anirudh.silver_returns_info: Close
[0m15:10:16.378459 [debug] [Thread-7 (]: Databricks adapter: Connection(session-id=01f09abc-cc96-10fd-9b77-92f63f45c69b) - Closing
[0m15:10:16.690322 [debug] [Thread-7 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '3e0ac330-3526-40ef-b915-a0a655991dfc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x748ae474e210>]}
[0m15:10:16.691984 [info ] [Thread-7 (]: 15 of 16 OK created sql table model silver.silver_returns_info ................. [[32mOK[0m in 5.33s]
[0m15:10:16.693220 [debug] [Thread-7 (]: Finished running node model.dbt_anirudh.silver_returns_info
[0m15:10:16.694102 [debug] [Thread-7 (]: Began running node model.dbt_anirudh.silver_sales_info
[0m15:10:16.695142 [info ] [Thread-7 (]: 16 of 16 START sql table model silver.silver_sales_info ........................ [RUN]
[0m15:10:16.696022 [debug] [Thread-7 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.dbt_anirudh.silver_sales_info) - Creating connection
[0m15:10:16.696629 [debug] [Thread-7 (]: Acquiring new databricks connection 'model.dbt_anirudh.silver_sales_info'
[0m15:10:16.697194 [debug] [Thread-7 (]: Began compiling node model.dbt_anirudh.silver_sales_info
[0m15:10:16.704579 [debug] [Thread-7 (]: Writing injected SQL for node "model.dbt_anirudh.silver_sales_info"
[0m15:10:16.705152 [debug] [Thread-7 (]: Began executing node model.dbt_anirudh.silver_sales_info
[0m15:10:16.707281 [debug] [Thread-7 (]: MATERIALIZING TABLE
[0m15:10:16.708836 [debug] [Thread-7 (]: Writing runtime sql for node "model.dbt_anirudh.silver_sales_info"
[0m15:10:16.709341 [debug] [Thread-7 (]: Using databricks connection "model.dbt_anirudh.silver_sales_info"
[0m15:10:16.709761 [debug] [Thread-7 (]: On model.dbt_anirudh.silver_sales_info: /* {"app": "dbt", "dbt_version": "1.10.10", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_anirudh", "target_name": "dev", "node_id": "model.dbt_anirudh.silver_sales_info"} */

  
    
        create or replace table `dbt_learning`.`silver`.`silver_sales_info`
      
      
  using delta
      
      
      
      
      
      
      
      as
      WITH sales AS
(
    SELECT
        sales_id,
        product_sk,
        customer_sk,
        
    quantity * unit_price
 as calculated_gross_amount,
        gross_amount,
        payment_method
    FROM
        `dbt_learning`.`bronze`.`bronze_sales`
),

customer AS
(
    SELECT
        customer_sk,
        concat(first_name, last_name) as c_name,
        gender,
        signup_date
    FROM
        `dbt_learning`.`bronze`.`bronze_customer`
),

product AS
(
    SELECT
        product_sk,
        category
    FROM
        `dbt_learning`.`bronze`.`bronze_product`
),

joined_query AS
(
    SELECT
        sales.sales_id,
        sales.calculated_gross_amount,
        sales.payment_method,
        product.category,
        customer.gender
    FROM
        sales       
    INNER JOIN customer 
        ON customer.customer_sk = sales.customer_sk
    INNER JOIN product
        ON product.product_sk = sales.product_sk
)    

SELECT
    category,
    gender,
    sum(calculated_gross_amount) as total_sales
FROM
    joined_query
GROUP BY 1,2
ORDER BY 1 ASC, 3 DESC
  
[0m15:10:16.710240 [debug] [Thread-7 (]: Opening a new connection, currently in state init
[0m15:10:18.013614 [debug] [Thread-7 (]: Databricks adapter: Connection(session-id=01f09abc-cfbb-1f86-846d-c234d36a34f9) - Created
[0m15:10:21.189993 [debug] [Thread-7 (]: SQL status: OK in 4.480 seconds
[0m15:10:21.190856 [debug] [Thread-7 (]: Databricks adapter: Cursor(session-id=01f09abc-cfbb-1f86-846d-c234d36a34f9, command-id=01f09abc-cff1-1868-a1aa-2e9e70da3595) - Closing
[0m15:10:21.191441 [debug] [Thread-7 (]: Applying tags to relation None
[0m15:10:21.192735 [debug] [Thread-7 (]: On model.dbt_anirudh.silver_sales_info: Close
[0m15:10:21.193742 [debug] [Thread-7 (]: Databricks adapter: Connection(session-id=01f09abc-cfbb-1f86-846d-c234d36a34f9) - Closing
[0m15:10:21.508911 [debug] [Thread-7 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '3e0ac330-3526-40ef-b915-a0a655991dfc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x748b12908f50>]}
[0m15:10:21.510572 [info ] [Thread-7 (]: 16 of 16 OK created sql table model silver.silver_sales_info ................... [[32mOK[0m in 4.81s]
[0m15:10:21.512076 [debug] [Thread-7 (]: Finished running node model.dbt_anirudh.silver_sales_info
[0m15:10:21.515054 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=master) - Creating connection
[0m15:10:21.516013 [debug] [MainThread]: Acquiring new databricks connection 'master'
[0m15:10:21.516752 [info ] [MainThread]: 
[0m15:10:21.517083 [info ] [MainThread]: Finished running 1 seed, 1 snapshot, 7 table models, 5 data tests, 2 view models in 0 hours 1 minutes and 26.57 seconds (86.57s).
[0m15:10:21.519005 [debug] [MainThread]: Command end result
[0m15:10:21.546294 [debug] [MainThread]: Wrote artifact WritableManifest to /home/aniruth/AI/DBT/DBT_Master/dbt_anirudh/target/manifest.json
[0m15:10:21.547878 [debug] [MainThread]: Wrote artifact SemanticManifest to /home/aniruth/AI/DBT/DBT_Master/dbt_anirudh/target/semantic_manifest.json
[0m15:10:21.552492 [debug] [MainThread]: Wrote artifact RunExecutionResult to /home/aniruth/AI/DBT/DBT_Master/dbt_anirudh/target/run_results.json
[0m15:10:21.552791 [info ] [MainThread]: 
[0m15:10:21.553079 [info ] [MainThread]: [33mCompleted with 1 warning:[0m
[0m15:10:21.553322 [info ] [MainThread]: 
[0m15:10:21.553611 [warn ] [MainThread]: [33mWarning in test accepted_values_bronze_store_store_name__MegaMar_Manhattan__MegaMart_Brooklyn__MegaMart_Austin__MegaMart_San_Jose__MegaMart_Toronto (models/bronze/properties.yml)[0m
[0m15:10:21.553901 [warn ] [MainThread]: Got 1 result, configured to warn if != 0
[0m15:10:21.554118 [info ] [MainThread]: 
[0m15:10:21.554374 [info ] [MainThread]:   compiled code at target/compiled/dbt_anirudh/models/bronze/properties.yml/accepted_values_bronze_store_8308937ffa06d226d8f7cff5d272d129.sql
[0m15:10:21.554603 [info ] [MainThread]: 
[0m15:10:21.554860 [info ] [MainThread]: Done. PASS=15 WARN=1 ERROR=0 SKIP=0 NO-OP=0 TOTAL=16
[0m15:10:21.555502 [debug] [MainThread]: Resource report: {"command_name": "build", "command_success": true, "command_wall_clock_time": 88.18186, "process_in_blocks": "6624", "process_kernel_time": 0.228406, "process_mem_max_rss": "251704", "process_out_blocks": "3688", "process_user_time": 6.109862}
[0m15:10:21.555850 [debug] [MainThread]: Command `dbt build` succeeded at 15:10:21.555773 after 88.18 seconds
[0m15:10:21.556136 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x748b12c4e570>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x748b13426d20>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x748af1363800>]}
[0m15:10:21.556407 [debug] [MainThread]: Flushing usage events
[0m15:10:23.107810 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m15:46:30.177449 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x767d5932bb60>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x767d586a3f80>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x767d5911ca10>]}


============================== 15:46:30.179662 | 46edbea8-7cab-490d-bc67-49b5ee9128de ==============================
[0m15:46:30.179662 [info ] [MainThread]: Running with dbt=1.10.10
[0m15:46:30.180106 [debug] [MainThread]: running dbt with arguments {'fail_fast': 'False', 'log_format': 'default', 'use_colors': 'True', 'static_parser': 'True', 'quiet': 'False', 'partial_parse': 'True', 'use_experimental_parser': 'False', 'indirect_selection': 'eager', 'send_anonymous_usage_stats': 'True', 'debug': 'False', 'log_path': '/home/aniruth/AI/DBT/DBT_Master/dbt_anirudh/logs', 'write_json': 'True', 'no_print': 'None', 'empty': 'False', 'printer_width': '80', 'cache_selected_only': 'False', 'profiles_dir': '/home/aniruth/AI/DBT/DBT_Master/dbt_anirudh', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'introspect': 'True', 'version_check': 'True', 'warn_error': 'None', 'invocation_command': 'dbt build --target prod', 'target_path': 'None', 'log_cache_events': 'False'}
[0m15:46:30.754550 [debug] [MainThread]: Spark adapter: Setting pyhive.hive logging to ERROR
[0m15:46:30.754974 [debug] [MainThread]: Spark adapter: Setting thrift.transport logging to ERROR
[0m15:46:30.755273 [debug] [MainThread]: Spark adapter: Setting thrift.protocol logging to ERROR
[0m15:46:31.241087 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '46edbea8-7cab-490d-bc67-49b5ee9128de', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x767d583ed340>]}
[0m15:46:31.287425 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '46edbea8-7cab-490d-bc67-49b5ee9128de', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x767d38182090>]}
[0m15:46:31.287955 [info ] [MainThread]: Registered adapter: databricks=1.10.9
[0m15:46:31.364765 [debug] [MainThread]: checksum: af4148875ea7aa1549d372d0d0c9ad91031d05358531ca115c8e08a093099b13, vars: {}, profile: , target: prod, version: 1.10.10
[0m15:46:31.472472 [info ] [MainThread]: Unable to do partial parsing because config vars, config profile, or config target have changed
[0m15:46:31.472847 [debug] [MainThread]: previous checksum: af4148875ea7aa1549d372d0d0c9ad91031d05358531ca115c8e08a093099b13, current checksum: 502a0dc23e9052e1ae09f7c44ee219ef7a02dfea7e7d66580d54c304c14d553b
[0m15:46:31.473214 [info ] [MainThread]: Unable to do partial parsing because profile has changed
[0m15:46:31.473527 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': '46edbea8-7cab-490d-bc67-49b5ee9128de', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x767d32ff2b70>]}
[0m15:46:33.167127 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '46edbea8-7cab-490d-bc67-49b5ee9128de', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x767d318035f0>]}
[0m15:46:33.260047 [debug] [MainThread]: Wrote artifact WritableManifest to /home/aniruth/AI/DBT/DBT_Master/dbt_anirudh/target/manifest.json
[0m15:46:33.261398 [debug] [MainThread]: Wrote artifact SemanticManifest to /home/aniruth/AI/DBT/DBT_Master/dbt_anirudh/target/semantic_manifest.json
[0m15:46:33.275705 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '46edbea8-7cab-490d-bc67-49b5ee9128de', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x767d3184d9a0>]}
[0m15:46:33.276105 [info ] [MainThread]: Found 9 models, 7 analyses, 5 data tests, 1 seed, 1 snapshot, 7 sources, 688 macros
[0m15:46:33.278229 [info ] [MainThread]: 
[0m15:46:33.278535 [info ] [MainThread]: Concurrency: 1 threads (target='prod')
[0m15:46:33.278779 [info ] [MainThread]: 
[0m15:46:33.279164 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=master) - Creating connection
[0m15:46:33.279406 [debug] [MainThread]: Acquiring new databricks connection 'master'
[0m15:46:33.285139 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=list_dbt_learning_prod) - Creating connection
[0m15:46:33.285546 [debug] [ThreadPool]: Acquiring new databricks connection 'list_dbt_learning_prod'
[0m15:46:33.285846 [debug] [ThreadPool]: Using databricks connection "list_dbt_learning_prod"
[0m15:46:33.286123 [debug] [ThreadPool]: On list_dbt_learning_prod: GetSchemas(database=dbt_learning_prod, schema=None)
[0m15:46:33.286450 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m15:46:35.226759 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f09ac1-e157-12b9-85c1-680d9f030139) - Created
[0m15:47:37.281317 [debug] [ThreadPool]: SQL status: OK in 63.990 seconds
[0m15:47:37.282414 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01f09ac1-e157-12b9-85c1-680d9f030139, command-id=01f09ac2-05a0-1448-9a0a-a5de013bf1c3) - Closing
[0m15:47:37.282808 [debug] [ThreadPool]: On list_dbt_learning_prod: Close
[0m15:47:37.283088 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f09ac1-e157-12b9-85c1-680d9f030139) - Closing
[0m15:47:37.688731 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=list_dbt_learning_prod) - Creating connection
[0m15:47:37.689151 [debug] [ThreadPool]: Acquiring new databricks connection 'list_dbt_learning_prod'
[0m15:47:37.689461 [debug] [ThreadPool]: Using databricks connection "list_dbt_learning_prod"
[0m15:47:37.689713 [debug] [ThreadPool]: On list_dbt_learning_prod: GetSchemas(database=dbt_learning_prod, schema=None)
[0m15:47:37.689951 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m15:47:39.347121 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f09ac2-07b4-1881-beaa-fe5f4df7f5f3) - Created
[0m15:47:39.842710 [debug] [ThreadPool]: SQL status: OK in 2.150 seconds
[0m15:47:39.843666 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01f09ac2-07b4-1881-beaa-fe5f4df7f5f3, command-id=01f09ac2-07e6-179e-9536-0fe46889b709) - Closing
[0m15:47:39.843989 [debug] [ThreadPool]: On list_dbt_learning_prod: Close
[0m15:47:39.844242 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f09ac2-07b4-1881-beaa-fe5f4df7f5f3) - Closing
[0m15:47:40.178330 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=list_dbt_learning_prod) - Creating connection
[0m15:47:40.178741 [debug] [ThreadPool]: Acquiring new databricks connection 'list_dbt_learning_prod'
[0m15:47:40.179034 [debug] [ThreadPool]: Using databricks connection "list_dbt_learning_prod"
[0m15:47:40.179279 [debug] [ThreadPool]: On list_dbt_learning_prod: GetSchemas(database=dbt_learning_prod, schema=None)
[0m15:47:40.179491 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m15:47:41.582757 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f09ac2-090c-1c5b-9f4c-f588209ede13) - Created
[0m15:47:42.089579 [debug] [ThreadPool]: SQL status: OK in 1.910 seconds
[0m15:47:42.090569 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01f09ac2-090c-1c5b-9f4c-f588209ede13, command-id=01f09ac2-093c-1416-a394-d6ef29e9c3bd) - Closing
[0m15:47:42.090906 [debug] [ThreadPool]: On list_dbt_learning_prod: Close
[0m15:47:42.091163 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f09ac2-090c-1c5b-9f4c-f588209ede13) - Closing
[0m15:47:42.419129 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=create_dbt_learning_prod_bronze) - Creating connection
[0m15:47:42.419487 [debug] [ThreadPool]: Acquiring new databricks connection 'create_dbt_learning_prod_bronze'
[0m15:47:42.419880 [debug] [ThreadPool]: Creating schema "database: "dbt_learning_prod"
schema: "bronze"
"
[0m15:47:42.429638 [debug] [ThreadPool]: Using databricks connection "create_dbt_learning_prod_bronze"
[0m15:47:42.430040 [debug] [ThreadPool]: On create_dbt_learning_prod_bronze: /* {"app": "dbt", "dbt_version": "1.10.10", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_anirudh", "target_name": "prod", "connection_name": "create_dbt_learning_prod_bronze"} */
create schema if not exists `dbt_learning_prod`.`bronze`
  
[0m15:47:42.430302 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m15:47:43.757988 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f09ac2-0a54-1cba-bce1-e765e9e0ffa2) - Created
[0m15:47:45.267585 [debug] [ThreadPool]: SQL status: OK in 2.840 seconds
[0m15:47:45.269846 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01f09ac2-0a54-1cba-bce1-e765e9e0ffa2, command-id=01f09ac2-0a87-1f27-b1dc-08fb835fa9ac) - Closing
[0m15:47:45.270878 [debug] [ThreadPool]: On create_dbt_learning_prod_bronze: Close
[0m15:47:45.271712 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f09ac2-0a54-1cba-bce1-e765e9e0ffa2) - Closing
[0m15:47:45.598406 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=create_dbt_learning_prod_silver) - Creating connection
[0m15:47:45.598808 [debug] [ThreadPool]: Acquiring new databricks connection 'create_dbt_learning_prod_silver'
[0m15:47:45.599213 [debug] [ThreadPool]: Creating schema "database: "dbt_learning_prod"
schema: "silver"
"
[0m15:47:45.602108 [debug] [ThreadPool]: Using databricks connection "create_dbt_learning_prod_silver"
[0m15:47:45.602548 [debug] [ThreadPool]: On create_dbt_learning_prod_silver: /* {"app": "dbt", "dbt_version": "1.10.10", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_anirudh", "target_name": "prod", "connection_name": "create_dbt_learning_prod_silver"} */
create schema if not exists `dbt_learning_prod`.`silver`
  
[0m15:47:45.602838 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m15:47:47.029104 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f09ac2-0c48-1b43-bb7e-bf242182eb7a) - Created
[0m15:47:47.723828 [debug] [ThreadPool]: SQL status: OK in 2.120 seconds
[0m15:47:47.726150 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01f09ac2-0c48-1b43-bb7e-bf242182eb7a, command-id=01f09ac2-0c7b-1442-a312-bad1b6fdd0a8) - Closing
[0m15:47:47.727714 [debug] [ThreadPool]: On create_dbt_learning_prod_silver: Close
[0m15:47:47.728669 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f09ac2-0c48-1b43-bb7e-bf242182eb7a) - Closing
[0m15:47:48.062535 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=create_dbt_learning_prod_gold) - Creating connection
[0m15:47:48.063160 [debug] [ThreadPool]: Acquiring new databricks connection 'create_dbt_learning_prod_gold'
[0m15:47:48.063716 [debug] [ThreadPool]: Creating schema "database: "dbt_learning_prod"
schema: "gold"
"
[0m15:47:48.068599 [debug] [ThreadPool]: Using databricks connection "create_dbt_learning_prod_gold"
[0m15:47:48.069055 [debug] [ThreadPool]: On create_dbt_learning_prod_gold: /* {"app": "dbt", "dbt_version": "1.10.10", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_anirudh", "target_name": "prod", "connection_name": "create_dbt_learning_prod_gold"} */
create schema if not exists `dbt_learning_prod`.`gold`
  
[0m15:47:48.069431 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m15:47:49.366520 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f09ac2-0dae-1a0d-987d-c4189fea7502) - Created
[0m15:47:49.979951 [debug] [ThreadPool]: SQL status: OK in 1.910 seconds
[0m15:47:49.982238 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01f09ac2-0dae-1a0d-987d-c4189fea7502, command-id=01f09ac2-0dde-1339-9ecf-2767c87eca9a) - Closing
[0m15:47:49.983238 [debug] [ThreadPool]: On create_dbt_learning_prod_gold: Close
[0m15:47:49.984105 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f09ac2-0dae-1a0d-987d-c4189fea7502) - Closing
[0m15:47:50.295557 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=list_dbt_learning_prod_bronze) - Creating connection
[0m15:47:50.295975 [debug] [ThreadPool]: Acquiring new databricks connection 'list_dbt_learning_prod_bronze'
[0m15:47:50.303126 [debug] [ThreadPool]: Using databricks connection "list_dbt_learning_prod_bronze"
[0m15:47:50.303522 [debug] [ThreadPool]: On list_dbt_learning_prod_bronze: /* {"app": "dbt", "dbt_version": "1.10.10", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_anirudh", "target_name": "prod", "connection_name": "list_dbt_learning_prod_bronze"} */

    
SELECT
  table_name,
  if(table_type IN ('EXTERNAL', 'MANAGED', 'MANAGED_SHALLOW_CLONE', 'EXTERNAL_SHALLOW_CLONE'), 'table', lower(table_type)) AS table_type,
  lower(data_source_format) AS file_format,
  table_owner,
  if(
    table_type IN (
      'EXTERNAL',
      'MANAGED',
      'MANAGED_SHALLOW_CLONE',
      'EXTERNAL_SHALLOW_CLONE'
    ),
    lower(table_type),
    NULL
  ) AS databricks_table_type
FROM `system`.`information_schema`.`tables`
WHERE table_catalog = 'dbt_learning_prod' 
  AND table_schema = 'bronze'

  
[0m15:47:50.303809 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m15:47:51.634478 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f09ac2-0f08-119d-8f1c-8eb186c9175c) - Created
[0m15:47:53.207484 [debug] [ThreadPool]: SQL status: OK in 2.900 seconds
[0m15:47:53.210719 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01f09ac2-0f08-119d-8f1c-8eb186c9175c, command-id=01f09ac2-0f3a-138c-81e6-ba436a8e90f3) - Closing
[0m15:47:53.211146 [debug] [ThreadPool]: On list_dbt_learning_prod_bronze: Close
[0m15:47:53.211427 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f09ac2-0f08-119d-8f1c-8eb186c9175c) - Closing
[0m15:47:53.557916 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=list_dbt_learning_prod_silver) - Creating connection
[0m15:47:53.558343 [debug] [ThreadPool]: Acquiring new databricks connection 'list_dbt_learning_prod_silver'
[0m15:47:53.559968 [debug] [ThreadPool]: Using databricks connection "list_dbt_learning_prod_silver"
[0m15:47:53.560273 [debug] [ThreadPool]: On list_dbt_learning_prod_silver: /* {"app": "dbt", "dbt_version": "1.10.10", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_anirudh", "target_name": "prod", "connection_name": "list_dbt_learning_prod_silver"} */

    
SELECT
  table_name,
  if(table_type IN ('EXTERNAL', 'MANAGED', 'MANAGED_SHALLOW_CLONE', 'EXTERNAL_SHALLOW_CLONE'), 'table', lower(table_type)) AS table_type,
  lower(data_source_format) AS file_format,
  table_owner,
  if(
    table_type IN (
      'EXTERNAL',
      'MANAGED',
      'MANAGED_SHALLOW_CLONE',
      'EXTERNAL_SHALLOW_CLONE'
    ),
    lower(table_type),
    NULL
  ) AS databricks_table_type
FROM `system`.`information_schema`.`tables`
WHERE table_catalog = 'dbt_learning_prod' 
  AND table_schema = 'silver'

  
[0m15:47:53.560528 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m15:47:54.887006 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f09ac2-10fa-1698-b257-1e0a927fd3ca) - Created
[0m15:47:55.582854 [debug] [ThreadPool]: SQL status: OK in 2.020 seconds
[0m15:47:55.584430 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01f09ac2-10fa-1698-b257-1e0a927fd3ca, command-id=01f09ac2-1128-1b28-ae71-c5129b05832f) - Closing
[0m15:47:55.584864 [debug] [ThreadPool]: On list_dbt_learning_prod_silver: Close
[0m15:47:55.585158 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f09ac2-10fa-1698-b257-1e0a927fd3ca) - Closing
[0m15:47:55.916474 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=list_dbt_learning_prod_gold) - Creating connection
[0m15:47:55.916917 [debug] [ThreadPool]: Acquiring new databricks connection 'list_dbt_learning_prod_gold'
[0m15:47:55.919937 [debug] [ThreadPool]: Using databricks connection "list_dbt_learning_prod_gold"
[0m15:47:55.920281 [debug] [ThreadPool]: On list_dbt_learning_prod_gold: /* {"app": "dbt", "dbt_version": "1.10.10", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_anirudh", "target_name": "prod", "connection_name": "list_dbt_learning_prod_gold"} */

    
SELECT
  table_name,
  if(table_type IN ('EXTERNAL', 'MANAGED', 'MANAGED_SHALLOW_CLONE', 'EXTERNAL_SHALLOW_CLONE'), 'table', lower(table_type)) AS table_type,
  lower(data_source_format) AS file_format,
  table_owner,
  if(
    table_type IN (
      'EXTERNAL',
      'MANAGED',
      'MANAGED_SHALLOW_CLONE',
      'EXTERNAL_SHALLOW_CLONE'
    ),
    lower(table_type),
    NULL
  ) AS databricks_table_type
FROM `system`.`information_schema`.`tables`
WHERE table_catalog = 'dbt_learning_prod' 
  AND table_schema = 'gold'

  
[0m15:47:55.920552 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m15:47:57.248048 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f09ac2-1261-199b-85d4-ae0855c09cf0) - Created
[0m15:47:57.962621 [debug] [ThreadPool]: SQL status: OK in 2.040 seconds
[0m15:47:57.964195 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01f09ac2-1261-199b-85d4-ae0855c09cf0, command-id=01f09ac2-1290-1ea1-83ef-88fe780584c8) - Closing
[0m15:47:57.964641 [debug] [ThreadPool]: On list_dbt_learning_prod_gold: Close
[0m15:47:57.965008 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f09ac2-1261-199b-85d4-ae0855c09cf0) - Closing
[0m15:47:58.277283 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '46edbea8-7cab-490d-bc67-49b5ee9128de', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x767d31802ab0>]}
[0m15:47:58.279381 [debug] [Thread-10 ]: Began running node model.dbt_anirudh.bronze_customer
[0m15:47:58.279845 [info ] [Thread-10 ]: 1 of 16 START sql table model bronze.bronze_customer ........................... [RUN]
[0m15:47:58.280283 [debug] [Thread-10 ]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.dbt_anirudh.bronze_customer) - Creating connection
[0m15:47:58.280577 [debug] [Thread-10 ]: Acquiring new databricks connection 'model.dbt_anirudh.bronze_customer'
[0m15:47:58.280883 [debug] [Thread-10 ]: Began compiling node model.dbt_anirudh.bronze_customer
[0m15:47:58.286806 [debug] [Thread-10 ]: Writing injected SQL for node "model.dbt_anirudh.bronze_customer"
[0m15:47:58.287422 [debug] [Thread-10 ]: Began executing node model.dbt_anirudh.bronze_customer
[0m15:47:58.307496 [debug] [Thread-10 ]: MATERIALIZING TABLE
[0m15:47:58.308012 [warn ] [Thread-10 ]: [[33mWARNING[0m]: Use revamped materializations based on separating create and insert.  This allows more performant column comments, as well as new column features.
You may opt into the new behavior sooner by setting `flags.use_materialization_v2` to `True` in `dbt_project.yml`.
Visit https://docs.getdbt.com/reference/global-configs/behavior-changes for more information.
[0m15:47:58.308420 [debug] [Thread-10 ]: Sending event: {'category': 'dbt', 'action': 'BehaviorChangeEvent', 'label': '46edbea8-7cab-490d-bc67-49b5ee9128de', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x767d3160b200>]}
[0m15:47:58.342708 [debug] [Thread-10 ]: Writing runtime sql for node "model.dbt_anirudh.bronze_customer"
[0m15:47:58.343291 [debug] [Thread-10 ]: Using databricks connection "model.dbt_anirudh.bronze_customer"
[0m15:47:58.343743 [debug] [Thread-10 ]: On model.dbt_anirudh.bronze_customer: /* {"app": "dbt", "dbt_version": "1.10.10", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_anirudh", "target_name": "prod", "node_id": "model.dbt_anirudh.bronze_customer"} */

  
    
        create or replace table `dbt_learning_prod`.`bronze`.`bronze_customer`
      
      
  using delta
      
      
      
      
      
      
      
      as
      SELECT 
    *
FROM
    `dbt_learning_prod`.`source`.`dim_customer`
  
[0m15:47:58.344105 [debug] [Thread-10 ]: Opening a new connection, currently in state init
[0m15:47:59.598920 [debug] [Thread-10 ]: Databricks adapter: Connection(session-id=01f09ac2-13ca-16c3-87cb-e83ae7f0d9eb) - Created
[0m15:48:09.251395 [debug] [Thread-10 ]: SQL status: OK in 10.910 seconds
[0m15:48:09.253798 [debug] [Thread-10 ]: Databricks adapter: Cursor(session-id=01f09ac2-13ca-16c3-87cb-e83ae7f0d9eb, command-id=01f09ac2-13f9-1123-9e75-9754b824624a) - Closing
[0m15:48:09.615370 [debug] [Thread-10 ]: Applying tags to relation None
[0m15:48:09.628262 [debug] [Thread-10 ]: On model.dbt_anirudh.bronze_customer: Close
[0m15:48:09.628653 [debug] [Thread-10 ]: Databricks adapter: Connection(session-id=01f09ac2-13ca-16c3-87cb-e83ae7f0d9eb) - Closing
[0m15:48:09.955464 [debug] [Thread-10 ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '46edbea8-7cab-490d-bc67-49b5ee9128de', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x767d592ec110>]}
[0m15:48:09.956216 [info ] [Thread-10 ]: 1 of 16 OK created sql table model bronze.bronze_customer ...................... [[32mOK[0m in 11.67s]
[0m15:48:09.956717 [debug] [Thread-10 ]: Finished running node model.dbt_anirudh.bronze_customer
[0m15:48:09.957078 [debug] [Thread-10 ]: Began running node model.dbt_anirudh.bronze_date
[0m15:48:09.957498 [info ] [Thread-10 ]: 2 of 16 START sql view model bronze.bronze_date ................................ [RUN]
[0m15:48:09.958030 [debug] [Thread-10 ]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.dbt_anirudh.bronze_date) - Creating connection
[0m15:48:09.958361 [debug] [Thread-10 ]: Acquiring new databricks connection 'model.dbt_anirudh.bronze_date'
[0m15:48:09.958661 [debug] [Thread-10 ]: Began compiling node model.dbt_anirudh.bronze_date
[0m15:48:09.960870 [debug] [Thread-10 ]: Writing injected SQL for node "model.dbt_anirudh.bronze_date"
[0m15:48:09.961302 [debug] [Thread-10 ]: Began executing node model.dbt_anirudh.bronze_date
[0m15:48:09.974571 [debug] [Thread-10 ]: MATERIALIZING VIEW
[0m15:48:09.985895 [debug] [Thread-10 ]: Creating view `dbt_learning_prod`.`bronze`.`bronze_date`
[0m15:48:09.986563 [debug] [Thread-10 ]: Writing runtime sql for node "model.dbt_anirudh.bronze_date"
[0m15:48:09.987035 [debug] [Thread-10 ]: Using databricks connection "model.dbt_anirudh.bronze_date"
[0m15:48:09.987378 [debug] [Thread-10 ]: On model.dbt_anirudh.bronze_date: /* {"app": "dbt", "dbt_version": "1.10.10", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_anirudh", "target_name": "prod", "node_id": "model.dbt_anirudh.bronze_date"} */

  
  
  create or replace view `dbt_learning_prod`.`bronze`.`bronze_date`
  
  as (
    SELECT  
    *
FROM
    `dbt_learning_prod`.`source`.`dim_date`
  )

[0m15:48:09.987670 [debug] [Thread-10 ]: Opening a new connection, currently in state init
[0m15:48:11.479058 [debug] [Thread-10 ]: Databricks adapter: Connection(session-id=01f09ac2-1ace-1f43-8729-08b525eff655) - Created
[0m15:48:12.609334 [debug] [Thread-10 ]: SQL status: OK in 2.620 seconds
[0m15:48:12.611411 [debug] [Thread-10 ]: Databricks adapter: Cursor(session-id=01f09ac2-1ace-1f43-8729-08b525eff655, command-id=01f09ac2-1b10-1b09-b35d-42dce6702993) - Closing
[0m15:48:12.612312 [debug] [Thread-10 ]: Applying tags to relation None
[0m15:48:12.613418 [debug] [Thread-10 ]: On model.dbt_anirudh.bronze_date: Close
[0m15:48:12.613945 [debug] [Thread-10 ]: Databricks adapter: Connection(session-id=01f09ac2-1ace-1f43-8729-08b525eff655) - Closing
[0m15:48:13.019248 [debug] [Thread-10 ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '46edbea8-7cab-490d-bc67-49b5ee9128de', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x767d31662c30>]}
[0m15:48:13.020901 [info ] [Thread-10 ]: 2 of 16 OK created sql view model bronze.bronze_date ........................... [[32mOK[0m in 3.06s]
[0m15:48:13.022214 [debug] [Thread-10 ]: Finished running node model.dbt_anirudh.bronze_date
[0m15:48:13.023056 [debug] [Thread-10 ]: Began running node model.dbt_anirudh.bronze_product
[0m15:48:13.023714 [info ] [Thread-10 ]: 3 of 16 START sql table model bronze.bronze_product ............................ [RUN]
[0m15:48:13.024424 [debug] [Thread-10 ]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.dbt_anirudh.bronze_product) - Creating connection
[0m15:48:13.024842 [debug] [Thread-10 ]: Acquiring new databricks connection 'model.dbt_anirudh.bronze_product'
[0m15:48:13.025231 [debug] [Thread-10 ]: Began compiling node model.dbt_anirudh.bronze_product
[0m15:48:13.028322 [debug] [Thread-10 ]: Writing injected SQL for node "model.dbt_anirudh.bronze_product"
[0m15:48:13.029039 [debug] [Thread-10 ]: Began executing node model.dbt_anirudh.bronze_product
[0m15:48:13.031646 [debug] [Thread-10 ]: MATERIALIZING TABLE
[0m15:48:13.041009 [debug] [Thread-10 ]: Writing runtime sql for node "model.dbt_anirudh.bronze_product"
[0m15:48:13.041743 [debug] [Thread-10 ]: Using databricks connection "model.dbt_anirudh.bronze_product"
[0m15:48:13.042388 [debug] [Thread-10 ]: On model.dbt_anirudh.bronze_product: /* {"app": "dbt", "dbt_version": "1.10.10", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_anirudh", "target_name": "prod", "node_id": "model.dbt_anirudh.bronze_product"} */

  
    
        create or replace table `dbt_learning_prod`.`bronze`.`bronze_product`
      
      
  using delta
      
      
      
      
      
      
      
      as
      SELECT
    *
FROM
    `dbt_learning_prod`.`source`.`dim_product`
  
[0m15:48:13.042670 [debug] [Thread-10 ]: Opening a new connection, currently in state init
[0m15:48:14.652800 [debug] [Thread-10 ]: Databricks adapter: Connection(session-id=01f09ac2-1cb2-15df-9ebf-426d803fb168) - Created
[0m15:48:18.433376 [debug] [Thread-10 ]: SQL status: OK in 5.390 seconds
[0m15:48:18.434454 [debug] [Thread-10 ]: Databricks adapter: Cursor(session-id=01f09ac2-1cb2-15df-9ebf-426d803fb168, command-id=01f09ac2-1cf0-1f87-8453-9054dec819a0) - Closing
[0m15:48:18.435343 [debug] [Thread-10 ]: Applying tags to relation None
[0m15:48:18.436620 [debug] [Thread-10 ]: On model.dbt_anirudh.bronze_product: Close
[0m15:48:18.436933 [debug] [Thread-10 ]: Databricks adapter: Connection(session-id=01f09ac2-1cb2-15df-9ebf-426d803fb168) - Closing
[0m15:48:18.751114 [debug] [Thread-10 ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '46edbea8-7cab-490d-bc67-49b5ee9128de', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x767d304e6b70>]}
[0m15:48:18.752895 [info ] [Thread-10 ]: 3 of 16 OK created sql table model bronze.bronze_product ....................... [[32mOK[0m in 5.73s]
[0m15:48:18.754415 [debug] [Thread-10 ]: Finished running node model.dbt_anirudh.bronze_product
[0m15:48:18.755192 [debug] [Thread-10 ]: Began running node model.dbt_anirudh.bronze_returns
[0m15:48:18.756124 [info ] [Thread-10 ]: 4 of 16 START sql table model bronze.bronze_returns ............................ [RUN]
[0m15:48:18.757074 [debug] [Thread-10 ]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.dbt_anirudh.bronze_returns) - Creating connection
[0m15:48:18.757729 [debug] [Thread-10 ]: Acquiring new databricks connection 'model.dbt_anirudh.bronze_returns'
[0m15:48:18.758185 [debug] [Thread-10 ]: Began compiling node model.dbt_anirudh.bronze_returns
[0m15:48:18.763372 [debug] [Thread-10 ]: Writing injected SQL for node "model.dbt_anirudh.bronze_returns"
[0m15:48:18.764018 [debug] [Thread-10 ]: Began executing node model.dbt_anirudh.bronze_returns
[0m15:48:18.766119 [debug] [Thread-10 ]: MATERIALIZING TABLE
[0m15:48:18.767561 [debug] [Thread-10 ]: Writing runtime sql for node "model.dbt_anirudh.bronze_returns"
[0m15:48:18.768051 [debug] [Thread-10 ]: Using databricks connection "model.dbt_anirudh.bronze_returns"
[0m15:48:18.768394 [debug] [Thread-10 ]: On model.dbt_anirudh.bronze_returns: /* {"app": "dbt", "dbt_version": "1.10.10", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_anirudh", "target_name": "prod", "node_id": "model.dbt_anirudh.bronze_returns"} */

  
    
        create or replace table `dbt_learning_prod`.`bronze`.`bronze_returns`
      
      
  using delta
      
      
      
      
      
      
      
      as
      SELECT
    *
FROM
    `dbt_learning_prod`.`source`.`fact_returns`
  
[0m15:48:18.768680 [debug] [Thread-10 ]: Opening a new connection, currently in state init
[0m15:48:20.085146 [debug] [Thread-10 ]: Databricks adapter: Connection(session-id=01f09ac2-1fff-1855-92e6-8932d2d07a53) - Created
[0m15:48:23.769023 [debug] [Thread-10 ]: SQL status: OK in 5.000 seconds
[0m15:48:23.771380 [debug] [Thread-10 ]: Databricks adapter: Cursor(session-id=01f09ac2-1fff-1855-92e6-8932d2d07a53, command-id=01f09ac2-202e-1b7d-8ee8-fbe3a614cc39) - Closing
[0m15:48:23.772947 [debug] [Thread-10 ]: Applying tags to relation None
[0m15:48:23.775386 [debug] [Thread-10 ]: On model.dbt_anirudh.bronze_returns: Close
[0m15:48:23.776972 [debug] [Thread-10 ]: Databricks adapter: Connection(session-id=01f09ac2-1fff-1855-92e6-8932d2d07a53) - Closing
[0m15:48:24.107337 [debug] [Thread-10 ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '46edbea8-7cab-490d-bc67-49b5ee9128de', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x767d315df770>]}
[0m15:48:24.109592 [info ] [Thread-10 ]: 4 of 16 OK created sql table model bronze.bronze_returns ....................... [[32mOK[0m in 5.35s]
[0m15:48:24.111457 [debug] [Thread-10 ]: Finished running node model.dbt_anirudh.bronze_returns
[0m15:48:24.112531 [debug] [Thread-10 ]: Began running node model.dbt_anirudh.bronze_sales
[0m15:48:24.113938 [info ] [Thread-10 ]: 5 of 16 START sql view model bronze.bronze_sales ............................... [RUN]
[0m15:48:24.115317 [debug] [Thread-10 ]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.dbt_anirudh.bronze_sales) - Creating connection
[0m15:48:24.116307 [debug] [Thread-10 ]: Acquiring new databricks connection 'model.dbt_anirudh.bronze_sales'
[0m15:48:24.117242 [debug] [Thread-10 ]: Began compiling node model.dbt_anirudh.bronze_sales
[0m15:48:24.124558 [debug] [Thread-10 ]: Writing injected SQL for node "model.dbt_anirudh.bronze_sales"
[0m15:48:24.125258 [debug] [Thread-10 ]: Began executing node model.dbt_anirudh.bronze_sales
[0m15:48:24.127719 [debug] [Thread-10 ]: MATERIALIZING VIEW
[0m15:48:24.128591 [debug] [Thread-10 ]: Creating view `dbt_learning_prod`.`bronze`.`bronze_sales`
[0m15:48:24.129117 [debug] [Thread-10 ]: Writing runtime sql for node "model.dbt_anirudh.bronze_sales"
[0m15:48:24.129511 [debug] [Thread-10 ]: Using databricks connection "model.dbt_anirudh.bronze_sales"
[0m15:48:24.129883 [debug] [Thread-10 ]: On model.dbt_anirudh.bronze_sales: /* {"app": "dbt", "dbt_version": "1.10.10", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_anirudh", "target_name": "prod", "node_id": "model.dbt_anirudh.bronze_sales"} */

  
  
  create or replace view `dbt_learning_prod`.`bronze`.`bronze_sales`
  
  as (
    -- block level config


SELECT 
    * 
FROM
    
    `dbt_learning_prod`.`source`.`fact_sales`
  )

[0m15:48:24.130309 [debug] [Thread-10 ]: Opening a new connection, currently in state init
[0m15:48:25.510102 [debug] [Thread-10 ]: Databricks adapter: Connection(session-id=01f09ac2-2336-10c1-8dca-c5111f737265) - Created
[0m15:48:26.191051 [debug] [Thread-10 ]: SQL status: OK in 2.060 seconds
[0m15:48:26.191983 [debug] [Thread-10 ]: Databricks adapter: Cursor(session-id=01f09ac2-2336-10c1-8dca-c5111f737265, command-id=01f09ac2-236a-1351-be06-e1c056b2119f) - Closing
[0m15:48:26.192506 [debug] [Thread-10 ]: Applying tags to relation None
[0m15:48:26.193277 [debug] [Thread-10 ]: On model.dbt_anirudh.bronze_sales: Close
[0m15:48:26.193572 [debug] [Thread-10 ]: Databricks adapter: Connection(session-id=01f09ac2-2336-10c1-8dca-c5111f737265) - Closing
[0m15:48:26.535660 [debug] [Thread-10 ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '46edbea8-7cab-490d-bc67-49b5ee9128de', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x767d31621c10>]}
[0m15:48:26.536322 [info ] [Thread-10 ]: 5 of 16 OK created sql view model bronze.bronze_sales .......................... [[32mOK[0m in 2.42s]
[0m15:48:26.536787 [debug] [Thread-10 ]: Finished running node model.dbt_anirudh.bronze_sales
[0m15:48:26.537106 [debug] [Thread-10 ]: Began running node model.dbt_anirudh.bronze_store
[0m15:48:26.537562 [info ] [Thread-10 ]: 6 of 16 START sql table model bronze.bronze_store .............................. [RUN]
[0m15:48:26.538101 [debug] [Thread-10 ]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.dbt_anirudh.bronze_store) - Creating connection
[0m15:48:26.538382 [debug] [Thread-10 ]: Acquiring new databricks connection 'model.dbt_anirudh.bronze_store'
[0m15:48:26.538646 [debug] [Thread-10 ]: Began compiling node model.dbt_anirudh.bronze_store
[0m15:48:26.540834 [debug] [Thread-10 ]: Writing injected SQL for node "model.dbt_anirudh.bronze_store"
[0m15:48:26.541344 [debug] [Thread-10 ]: Began executing node model.dbt_anirudh.bronze_store
[0m15:48:26.543104 [debug] [Thread-10 ]: MATERIALIZING TABLE
[0m15:48:26.544487 [debug] [Thread-10 ]: Writing runtime sql for node "model.dbt_anirudh.bronze_store"
[0m15:48:26.545095 [debug] [Thread-10 ]: Using databricks connection "model.dbt_anirudh.bronze_store"
[0m15:48:26.545498 [debug] [Thread-10 ]: On model.dbt_anirudh.bronze_store: /* {"app": "dbt", "dbt_version": "1.10.10", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_anirudh", "target_name": "prod", "node_id": "model.dbt_anirudh.bronze_store"} */

  
    
        create or replace table `dbt_learning_prod`.`bronze`.`bronze_store`
      
      
  using delta
      
      
      
      
      
      
      
      as
      SELECT
    *
FROM
    `dbt_learning_prod`.`source`.`dim_store`
  
[0m15:48:26.545823 [debug] [Thread-10 ]: Opening a new connection, currently in state init
[0m15:48:27.862344 [debug] [Thread-10 ]: Databricks adapter: Connection(session-id=01f09ac2-24a1-1673-b387-f798bbe2fb53) - Created
[0m15:48:31.344767 [debug] [Thread-10 ]: SQL status: OK in 4.800 seconds
[0m15:48:31.345626 [debug] [Thread-10 ]: Databricks adapter: Cursor(session-id=01f09ac2-24a1-1673-b387-f798bbe2fb53, command-id=01f09ac2-24d0-14ed-9046-df84c8515dbd) - Closing
[0m15:48:31.346164 [debug] [Thread-10 ]: Applying tags to relation None
[0m15:48:31.346960 [debug] [Thread-10 ]: On model.dbt_anirudh.bronze_store: Close
[0m15:48:31.347255 [debug] [Thread-10 ]: Databricks adapter: Connection(session-id=01f09ac2-24a1-1673-b387-f798bbe2fb53) - Closing
[0m15:48:31.670732 [debug] [Thread-10 ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '46edbea8-7cab-490d-bc67-49b5ee9128de', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x767d3051d100>]}
[0m15:48:31.671400 [info ] [Thread-10 ]: 6 of 16 OK created sql table model bronze.bronze_store ......................... [[32mOK[0m in 5.13s]
[0m15:48:31.671898 [debug] [Thread-10 ]: Finished running node model.dbt_anirudh.bronze_store
[0m15:48:31.672240 [debug] [Thread-10 ]: Began running node model.dbt_anirudh.gold_items_source
[0m15:48:31.672634 [info ] [Thread-10 ]: 7 of 16 START sql table model gold.gold_items_source ........................... [RUN]
[0m15:48:31.673203 [debug] [Thread-10 ]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.dbt_anirudh.gold_items_source) - Creating connection
[0m15:48:31.673492 [debug] [Thread-10 ]: Acquiring new databricks connection 'model.dbt_anirudh.gold_items_source'
[0m15:48:31.673744 [debug] [Thread-10 ]: Began compiling node model.dbt_anirudh.gold_items_source
[0m15:48:31.677525 [debug] [Thread-10 ]: Writing injected SQL for node "model.dbt_anirudh.gold_items_source"
[0m15:48:31.678036 [debug] [Thread-10 ]: Began executing node model.dbt_anirudh.gold_items_source
[0m15:48:31.682603 [debug] [Thread-10 ]: MATERIALIZING TABLE
[0m15:48:31.684251 [debug] [Thread-10 ]: Writing runtime sql for node "model.dbt_anirudh.gold_items_source"
[0m15:48:31.684733 [debug] [Thread-10 ]: Using databricks connection "model.dbt_anirudh.gold_items_source"
[0m15:48:31.685092 [debug] [Thread-10 ]: On model.dbt_anirudh.gold_items_source: /* {"app": "dbt", "dbt_version": "1.10.10", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_anirudh", "target_name": "prod", "node_id": "model.dbt_anirudh.gold_items_source"} */

  
    
        create or replace table `dbt_learning_prod`.`gold`.`gold_items_source`
      
      
  using delta
      
      
      
      
      
      
      
      as
      WITH deduplication_DATA AS
(
    SELECT
        *,
        ROW_NUMBER() OVER (partition by id ORDER BY updateDate DESC) as deduplication_id
    FROM
        `dbt_learning_prod`.`source`.`items`
)
SELECT
    id, name, category, updateDate
FROM deduplication_DATA
WHERE
    deduplication_id = 1
  
[0m15:48:31.685412 [debug] [Thread-10 ]: Opening a new connection, currently in state init
[0m15:48:32.954214 [debug] [Thread-10 ]: Databricks adapter: Connection(session-id=01f09ac2-27aa-1bfc-b6d4-1825dd49e250) - Created
[0m15:48:36.570477 [debug] [Thread-10 ]: SQL status: OK in 4.880 seconds
[0m15:48:36.572838 [debug] [Thread-10 ]: Databricks adapter: Cursor(session-id=01f09ac2-27aa-1bfc-b6d4-1825dd49e250, command-id=01f09ac2-27d9-1c0e-a7be-3cef51d5e01d) - Closing
[0m15:48:36.574393 [debug] [Thread-10 ]: Applying tags to relation None
[0m15:48:36.576953 [debug] [Thread-10 ]: On model.dbt_anirudh.gold_items_source: Close
[0m15:48:36.578044 [debug] [Thread-10 ]: Databricks adapter: Connection(session-id=01f09ac2-27aa-1bfc-b6d4-1825dd49e250) - Closing
[0m15:48:36.912333 [debug] [Thread-10 ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '46edbea8-7cab-490d-bc67-49b5ee9128de', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x767d3050bd70>]}
[0m15:48:36.914513 [info ] [Thread-10 ]: 7 of 16 OK created sql table model gold.gold_items_source ...................... [[32mOK[0m in 5.24s]
[0m15:48:36.916130 [debug] [Thread-10 ]: Finished running node model.dbt_anirudh.gold_items_source
[0m15:48:36.917175 [debug] [Thread-10 ]: Began running node seed.dbt_anirudh.lookup
[0m15:48:36.919104 [info ] [Thread-10 ]: 8 of 16 START seed file bronze.lookup .......................................... [RUN]
[0m15:48:36.921155 [debug] [Thread-10 ]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=seed.dbt_anirudh.lookup) - Creating connection
[0m15:48:36.922189 [debug] [Thread-10 ]: Acquiring new databricks connection 'seed.dbt_anirudh.lookup'
[0m15:48:36.922579 [debug] [Thread-10 ]: Began compiling node seed.dbt_anirudh.lookup
[0m15:48:36.922888 [debug] [Thread-10 ]: Began executing node seed.dbt_anirudh.lookup
[0m15:48:36.951440 [debug] [Thread-10 ]: Using databricks connection "seed.dbt_anirudh.lookup"
[0m15:48:36.951877 [debug] [Thread-10 ]: On seed.dbt_anirudh.lookup: /* {"app": "dbt", "dbt_version": "1.10.10", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_anirudh", "target_name": "prod", "node_id": "seed.dbt_anirudh.lookup"} */

    create  table `dbt_learning_prod`.`bronze`.`lookup` (`customer_id` bigint ,`customer_name` string ,`customer_mail` string )
    
  using delta
    
    
    
    
    
  
[0m15:48:36.952169 [debug] [Thread-10 ]: Opening a new connection, currently in state init
[0m15:48:38.321074 [debug] [Thread-10 ]: Databricks adapter: Connection(session-id=01f09ac2-2add-105d-be04-3d3b856fee68) - Created
[0m15:48:40.260898 [debug] [Thread-10 ]: SQL status: OK in 3.310 seconds
[0m15:48:40.261726 [debug] [Thread-10 ]: Databricks adapter: Cursor(session-id=01f09ac2-2add-105d-be04-3d3b856fee68, command-id=01f09ac2-2b0e-1025-9590-ede9c1016df6) - Closing
[0m15:48:40.272509 [debug] [Thread-10 ]: Using databricks connection "seed.dbt_anirudh.lookup"
[0m15:48:40.272980 [debug] [Thread-10 ]: On seed.dbt_anirudh.lookup: 
          insert overwrite `dbt_learning_prod`.`bronze`.`lookup` values
          (%s,%s,%s),(%s,%s,%s),(%s,%s,%s)
      ...
[0m15:48:42.402596 [debug] [Thread-10 ]: SQL status: OK in 2.130 seconds
[0m15:48:42.403034 [debug] [Thread-10 ]: Databricks adapter: Cursor(session-id=01f09ac2-2add-105d-be04-3d3b856fee68, command-id=01f09ac2-2c37-1c30-b4eb-ab08bb5fe61a) - Closing
[0m15:48:42.407294 [debug] [Thread-10 ]: Writing runtime SQL for node "seed.dbt_anirudh.lookup"
[0m15:48:42.411377 [debug] [Thread-10 ]: On seed.dbt_anirudh.lookup: Close
[0m15:48:42.411693 [debug] [Thread-10 ]: Databricks adapter: Connection(session-id=01f09ac2-2add-105d-be04-3d3b856fee68) - Closing
[0m15:48:42.737956 [debug] [Thread-10 ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '46edbea8-7cab-490d-bc67-49b5ee9128de', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x767d30536510>]}
[0m15:48:42.738462 [info ] [Thread-10 ]: 8 of 16 OK loaded seed file bronze.lookup ...................................... [[32mINSERT 3[0m in 5.82s]
[0m15:48:42.738940 [debug] [Thread-10 ]: Finished running node seed.dbt_anirudh.lookup
[0m15:48:42.739263 [debug] [Thread-10 ]: Began running node test.dbt_anirudh.generic_non_negative_bronze_sales_gross_amount.770bebc5b1
[0m15:48:42.739657 [info ] [Thread-10 ]: 9 of 16 START test generic_non_negative_bronze_sales_gross_amount .............. [RUN]
[0m15:48:42.740102 [debug] [Thread-10 ]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=test.dbt_anirudh.generic_non_negative_bronze_sales_gross_amount.770bebc5b1) - Creating connection
[0m15:48:42.740381 [debug] [Thread-10 ]: Acquiring new databricks connection 'test.dbt_anirudh.generic_non_negative_bronze_sales_gross_amount.770bebc5b1'
[0m15:48:42.740640 [debug] [Thread-10 ]: Began compiling node test.dbt_anirudh.generic_non_negative_bronze_sales_gross_amount.770bebc5b1
[0m15:48:42.743715 [debug] [Thread-10 ]: Writing injected SQL for node "test.dbt_anirudh.generic_non_negative_bronze_sales_gross_amount.770bebc5b1"
[0m15:48:42.744363 [debug] [Thread-10 ]: Began executing node test.dbt_anirudh.generic_non_negative_bronze_sales_gross_amount.770bebc5b1
[0m15:48:42.765597 [debug] [Thread-10 ]: Writing runtime sql for node "test.dbt_anirudh.generic_non_negative_bronze_sales_gross_amount.770bebc5b1"
[0m15:48:42.766133 [debug] [Thread-10 ]: Using databricks connection "test.dbt_anirudh.generic_non_negative_bronze_sales_gross_amount.770bebc5b1"
[0m15:48:42.766483 [debug] [Thread-10 ]: On test.dbt_anirudh.generic_non_negative_bronze_sales_gross_amount.770bebc5b1: /* {"app": "dbt", "dbt_version": "1.10.10", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_anirudh", "target_name": "prod", "node_id": "test.dbt_anirudh.generic_non_negative_bronze_sales_gross_amount.770bebc5b1"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  

SELECT 
    *
FROM 
    `dbt_learning_prod`.`bronze`.`bronze_sales`
WHERE
    gross_amount < 0


  
  
      
    ) dbt_internal_test
[0m15:48:42.766793 [debug] [Thread-10 ]: Opening a new connection, currently in state init
[0m15:48:44.250966 [debug] [Thread-10 ]: Databricks adapter: Connection(session-id=01f09ac2-2e66-1e25-8159-6de6036bf81d) - Created
[0m15:48:45.783252 [debug] [Thread-10 ]: SQL status: OK in 3.020 seconds
[0m15:48:45.785004 [debug] [Thread-10 ]: Databricks adapter: Cursor(session-id=01f09ac2-2e66-1e25-8159-6de6036bf81d, command-id=01f09ac2-2e96-18d3-ba31-ef0cd97b166a) - Closing
[0m15:48:45.786707 [debug] [Thread-10 ]: On test.dbt_anirudh.generic_non_negative_bronze_sales_gross_amount.770bebc5b1: Close
[0m15:48:45.787017 [debug] [Thread-10 ]: Databricks adapter: Connection(session-id=01f09ac2-2e66-1e25-8159-6de6036bf81d) - Closing
[0m15:48:46.116259 [info ] [Thread-10 ]: 9 of 16 PASS generic_non_negative_bronze_sales_gross_amount .................... [[32mPASS[0m in 3.37s]
[0m15:48:46.118269 [debug] [Thread-10 ]: Finished running node test.dbt_anirudh.generic_non_negative_bronze_sales_gross_amount.770bebc5b1
[0m15:48:46.119284 [debug] [Thread-10 ]: Began running node test.dbt_anirudh.non_negartive
[0m15:48:46.120103 [info ] [Thread-10 ]: 10 of 16 START test non_negartive .............................................. [RUN]
[0m15:48:46.121422 [debug] [Thread-10 ]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=test.dbt_anirudh.non_negartive) - Creating connection
[0m15:48:46.122111 [debug] [Thread-10 ]: Acquiring new databricks connection 'test.dbt_anirudh.non_negartive'
[0m15:48:46.122646 [debug] [Thread-10 ]: Began compiling node test.dbt_anirudh.non_negartive
[0m15:48:46.128093 [debug] [Thread-10 ]: Writing injected SQL for node "test.dbt_anirudh.non_negartive"
[0m15:48:46.128809 [debug] [Thread-10 ]: Began executing node test.dbt_anirudh.non_negartive
[0m15:48:46.135204 [debug] [Thread-10 ]: Writing runtime sql for node "test.dbt_anirudh.non_negartive"
[0m15:48:46.135982 [debug] [Thread-10 ]: Using databricks connection "test.dbt_anirudh.non_negartive"
[0m15:48:46.136530 [debug] [Thread-10 ]: On test.dbt_anirudh.non_negartive: /* {"app": "dbt", "dbt_version": "1.10.10", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_anirudh", "target_name": "prod", "node_id": "test.dbt_anirudh.non_negartive"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  SELECT
    *
FROM
    `dbt_learning_prod`.`bronze`.`bronze_sales`
WHERE
    gross_amount < 0 AND net_amount < 0
  
  
      
    ) dbt_internal_test
[0m15:48:46.136999 [debug] [Thread-10 ]: Opening a new connection, currently in state init
[0m15:48:47.317856 [debug] [Thread-10 ]: Databricks adapter: Connection(session-id=01f09ac2-303a-185f-a4d9-2a20433b01d8) - Created
[0m15:48:48.136233 [debug] [Thread-10 ]: SQL status: OK in 2.000 seconds
[0m15:48:48.138944 [debug] [Thread-10 ]: Databricks adapter: Cursor(session-id=01f09ac2-303a-185f-a4d9-2a20433b01d8, command-id=01f09ac2-3068-1dd8-b2ec-e7dd12b00c0b) - Closing
[0m15:48:48.139944 [debug] [Thread-10 ]: On test.dbt_anirudh.non_negartive: Close
[0m15:48:48.140481 [debug] [Thread-10 ]: Databricks adapter: Connection(session-id=01f09ac2-303a-185f-a4d9-2a20433b01d8) - Closing
[0m15:48:48.457692 [info ] [Thread-10 ]: 10 of 16 PASS non_negartive .................................................... [[32mPASS[0m in 2.34s]
[0m15:48:48.458316 [debug] [Thread-10 ]: Finished running node test.dbt_anirudh.non_negartive
[0m15:48:48.458659 [debug] [Thread-10 ]: Began running node test.dbt_anirudh.not_null_bronze_sales_sales_id.e4b1b997fb
[0m15:48:48.459041 [info ] [Thread-10 ]: 11 of 16 START test not_null_bronze_sales_sales_id ............................. [RUN]
[0m15:48:48.459560 [debug] [Thread-10 ]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=test.dbt_anirudh.not_null_bronze_sales_sales_id.e4b1b997fb) - Creating connection
[0m15:48:48.459859 [debug] [Thread-10 ]: Acquiring new databricks connection 'test.dbt_anirudh.not_null_bronze_sales_sales_id.e4b1b997fb'
[0m15:48:48.460120 [debug] [Thread-10 ]: Began compiling node test.dbt_anirudh.not_null_bronze_sales_sales_id.e4b1b997fb
[0m15:48:48.572179 [debug] [Thread-10 ]: Writing injected SQL for node "test.dbt_anirudh.not_null_bronze_sales_sales_id.e4b1b997fb"
[0m15:48:48.572984 [debug] [Thread-10 ]: Began executing node test.dbt_anirudh.not_null_bronze_sales_sales_id.e4b1b997fb
[0m15:48:48.574864 [debug] [Thread-10 ]: Writing runtime sql for node "test.dbt_anirudh.not_null_bronze_sales_sales_id.e4b1b997fb"
[0m15:48:48.575254 [debug] [Thread-10 ]: Using databricks connection "test.dbt_anirudh.not_null_bronze_sales_sales_id.e4b1b997fb"
[0m15:48:48.575558 [debug] [Thread-10 ]: On test.dbt_anirudh.not_null_bronze_sales_sales_id.e4b1b997fb: /* {"app": "dbt", "dbt_version": "1.10.10", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_anirudh", "target_name": "prod", "node_id": "test.dbt_anirudh.not_null_bronze_sales_sales_id.e4b1b997fb"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select sales_id
from `dbt_learning_prod`.`bronze`.`bronze_sales`
where sales_id is null



  
  
      
    ) dbt_internal_test
[0m15:48:48.575834 [debug] [Thread-10 ]: Opening a new connection, currently in state init
[0m15:48:49.890641 [debug] [Thread-10 ]: Databricks adapter: Connection(session-id=01f09ac2-31c2-1a69-8982-80b036266e25) - Created
[0m15:48:50.702155 [debug] [Thread-10 ]: SQL status: OK in 2.130 seconds
[0m15:48:50.703748 [debug] [Thread-10 ]: Databricks adapter: Cursor(session-id=01f09ac2-31c2-1a69-8982-80b036266e25, command-id=01f09ac2-31f3-12bb-8e9b-18f4f274379f) - Closing
[0m15:48:50.704306 [debug] [Thread-10 ]: On test.dbt_anirudh.not_null_bronze_sales_sales_id.e4b1b997fb: Close
[0m15:48:50.704618 [debug] [Thread-10 ]: Databricks adapter: Connection(session-id=01f09ac2-31c2-1a69-8982-80b036266e25) - Closing
[0m15:48:51.048506 [info ] [Thread-10 ]: 11 of 16 PASS not_null_bronze_sales_sales_id ................................... [[32mPASS[0m in 2.59s]
[0m15:48:51.049121 [debug] [Thread-10 ]: Finished running node test.dbt_anirudh.not_null_bronze_sales_sales_id.e4b1b997fb
[0m15:48:51.049457 [debug] [Thread-10 ]: Began running node test.dbt_anirudh.unique_bronze_sales_sales_id.3c35aa753d
[0m15:48:51.049742 [info ] [Thread-10 ]: 12 of 16 START test unique_bronze_sales_sales_id ............................... [RUN]
[0m15:48:51.050234 [debug] [Thread-10 ]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=test.dbt_anirudh.unique_bronze_sales_sales_id.3c35aa753d) - Creating connection
[0m15:48:51.050512 [debug] [Thread-10 ]: Acquiring new databricks connection 'test.dbt_anirudh.unique_bronze_sales_sales_id.3c35aa753d'
[0m15:48:51.050782 [debug] [Thread-10 ]: Began compiling node test.dbt_anirudh.unique_bronze_sales_sales_id.3c35aa753d
[0m15:48:51.056021 [debug] [Thread-10 ]: Writing injected SQL for node "test.dbt_anirudh.unique_bronze_sales_sales_id.3c35aa753d"
[0m15:48:51.056599 [debug] [Thread-10 ]: Began executing node test.dbt_anirudh.unique_bronze_sales_sales_id.3c35aa753d
[0m15:48:51.058487 [debug] [Thread-10 ]: Writing runtime sql for node "test.dbt_anirudh.unique_bronze_sales_sales_id.3c35aa753d"
[0m15:48:51.058964 [debug] [Thread-10 ]: Using databricks connection "test.dbt_anirudh.unique_bronze_sales_sales_id.3c35aa753d"
[0m15:48:51.059363 [debug] [Thread-10 ]: On test.dbt_anirudh.unique_bronze_sales_sales_id.3c35aa753d: /* {"app": "dbt", "dbt_version": "1.10.10", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_anirudh", "target_name": "prod", "node_id": "test.dbt_anirudh.unique_bronze_sales_sales_id.3c35aa753d"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    

select
    sales_id as unique_field,
    count(*) as n_records

from `dbt_learning_prod`.`bronze`.`bronze_sales`
where sales_id is not null
group by sales_id
having count(*) > 1



  
  
      
    ) dbt_internal_test
[0m15:48:51.059753 [debug] [Thread-10 ]: Opening a new connection, currently in state init
[0m15:48:52.333437 [debug] [Thread-10 ]: Databricks adapter: Connection(session-id=01f09ac2-3336-1343-a842-612881bc4a78) - Created
[0m15:48:53.327484 [debug] [Thread-10 ]: SQL status: OK in 2.270 seconds
[0m15:48:53.332216 [debug] [Thread-10 ]: Databricks adapter: Cursor(session-id=01f09ac2-3336-1343-a842-612881bc4a78, command-id=01f09ac2-3368-12eb-b453-a5a7ce685565) - Closing
[0m15:48:53.333451 [debug] [Thread-10 ]: On test.dbt_anirudh.unique_bronze_sales_sales_id.3c35aa753d: Close
[0m15:48:53.334222 [debug] [Thread-10 ]: Databricks adapter: Connection(session-id=01f09ac2-3336-1343-a842-612881bc4a78) - Closing
[0m15:48:53.660782 [info ] [Thread-10 ]: 12 of 16 PASS unique_bronze_sales_sales_id ..................................... [[32mPASS[0m in 2.61s]
[0m15:48:53.661338 [debug] [Thread-10 ]: Finished running node test.dbt_anirudh.unique_bronze_sales_sales_id.3c35aa753d
[0m15:48:53.661681 [debug] [Thread-10 ]: Began running node test.dbt_anirudh.accepted_values_bronze_store_store_name__MegaMar_Manhattan__MegaMart_Brooklyn__MegaMart_Austin__MegaMart_San_Jose__MegaMart_Toronto.b983752665
[0m15:48:53.662211 [info ] [Thread-10 ]: 13 of 16 START test accepted_values_bronze_store_store_name__MegaMar_Manhattan__MegaMart_Brooklyn__MegaMart_Austin__MegaMart_San_Jose__MegaMart_Toronto  [RUN]
[0m15:48:53.662709 [debug] [Thread-10 ]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=test.dbt_anirudh.accepted_values_bronze_store_store_name__MegaMar_Manhattan__MegaMart_Brooklyn__MegaMart_Austin__MegaMart_San_Jose__MegaMart_Toronto.b983752665) - Creating connection
[0m15:48:53.663031 [debug] [Thread-10 ]: Acquiring new databricks connection 'test.dbt_anirudh.accepted_values_bronze_store_store_name__MegaMar_Manhattan__MegaMart_Brooklyn__MegaMart_Austin__MegaMart_San_Jose__MegaMart_Toronto.b983752665'
[0m15:48:53.663328 [debug] [Thread-10 ]: Began compiling node test.dbt_anirudh.accepted_values_bronze_store_store_name__MegaMar_Manhattan__MegaMart_Brooklyn__MegaMart_Austin__MegaMart_San_Jose__MegaMart_Toronto.b983752665
[0m15:48:53.666723 [debug] [Thread-10 ]: Writing injected SQL for node "test.dbt_anirudh.accepted_values_bronze_store_store_name__MegaMar_Manhattan__MegaMart_Brooklyn__MegaMart_Austin__MegaMart_San_Jose__MegaMart_Toronto.b983752665"
[0m15:48:53.667267 [debug] [Thread-10 ]: Began executing node test.dbt_anirudh.accepted_values_bronze_store_store_name__MegaMar_Manhattan__MegaMart_Brooklyn__MegaMart_Austin__MegaMart_San_Jose__MegaMart_Toronto.b983752665
[0m15:48:53.669615 [debug] [Thread-10 ]: Writing runtime sql for node "test.dbt_anirudh.accepted_values_bronze_store_store_name__MegaMar_Manhattan__MegaMart_Brooklyn__MegaMart_Austin__MegaMart_San_Jose__MegaMart_Toronto.b983752665"
[0m15:48:53.670245 [debug] [Thread-10 ]: Using databricks connection "test.dbt_anirudh.accepted_values_bronze_store_store_name__MegaMar_Manhattan__MegaMart_Brooklyn__MegaMart_Austin__MegaMart_San_Jose__MegaMart_Toronto.b983752665"
[0m15:48:53.670617 [debug] [Thread-10 ]: On test.dbt_anirudh.accepted_values_bronze_store_store_name__MegaMar_Manhattan__MegaMart_Brooklyn__MegaMart_Austin__MegaMart_San_Jose__MegaMart_Toronto.b983752665: /* {"app": "dbt", "dbt_version": "1.10.10", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_anirudh", "target_name": "prod", "node_id": "test.dbt_anirudh.accepted_values_bronze_store_store_name__MegaMar_Manhattan__MegaMart_Brooklyn__MegaMart_Austin__MegaMart_San_Jose__MegaMart_Toronto.b983752665"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    

with all_values as (

    select
        store_name as value_field,
        count(*) as n_records

    from `dbt_learning_prod`.`bronze`.`bronze_store`
    group by store_name

)

select *
from all_values
where value_field not in (
    'MegaMar Manhattan','MegaMart Brooklyn','MegaMart Austin','MegaMart San Jose','MegaMart Toronto'
)



  
  
      
    ) dbt_internal_test
[0m15:48:53.670941 [debug] [Thread-10 ]: Opening a new connection, currently in state init
[0m15:48:55.002887 [debug] [Thread-10 ]: Databricks adapter: Connection(session-id=01f09ac2-34d0-1364-a3c0-926e2106b05f) - Created
[0m15:48:55.988045 [debug] [Thread-10 ]: SQL status: OK in 2.320 seconds
[0m15:48:55.989703 [debug] [Thread-10 ]: Databricks adapter: Cursor(session-id=01f09ac2-34d0-1364-a3c0-926e2106b05f, command-id=01f09ac2-34fe-1823-9a2b-6fbaed9a9daf) - Closing
[0m15:48:55.990265 [debug] [Thread-10 ]: On test.dbt_anirudh.accepted_values_bronze_store_store_name__MegaMar_Manhattan__MegaMart_Brooklyn__MegaMart_Austin__MegaMart_San_Jose__MegaMart_Toronto.b983752665: Close
[0m15:48:55.990630 [debug] [Thread-10 ]: Databricks adapter: Connection(session-id=01f09ac2-34d0-1364-a3c0-926e2106b05f) - Closing
[0m15:48:56.332420 [warn ] [Thread-10 ]: 13 of 16 WARN 1 accepted_values_bronze_store_store_name__MegaMar_Manhattan__MegaMart_Brooklyn__MegaMart_Austin__MegaMart_San_Jose__MegaMart_Toronto  [[33mWARN 1[0m in 2.67s]
[0m15:48:56.333099 [debug] [Thread-10 ]: Finished running node test.dbt_anirudh.accepted_values_bronze_store_store_name__MegaMar_Manhattan__MegaMart_Brooklyn__MegaMart_Austin__MegaMart_San_Jose__MegaMart_Toronto.b983752665
[0m15:48:56.333427 [debug] [Thread-10 ]: Began running node snapshot.dbt_anirudh.gold_items
[0m15:48:56.333882 [info ] [Thread-10 ]: 14 of 16 START snapshot gold.gold_items ........................................ [RUN]
[0m15:48:56.334319 [debug] [Thread-10 ]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=snapshot.dbt_anirudh.gold_items) - Creating connection
[0m15:48:56.334601 [debug] [Thread-10 ]: Acquiring new databricks connection 'snapshot.dbt_anirudh.gold_items'
[0m15:48:56.334871 [debug] [Thread-10 ]: Began compiling node snapshot.dbt_anirudh.gold_items
[0m15:48:56.336978 [debug] [Thread-10 ]: Began executing node snapshot.dbt_anirudh.gold_items
[0m15:48:56.390818 [debug] [Thread-10 ]: Using databricks connection "snapshot.dbt_anirudh.gold_items"
[0m15:48:56.391282 [debug] [Thread-10 ]: On snapshot.dbt_anirudh.gold_items: /* {"app": "dbt", "dbt_version": "1.10.10", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_anirudh", "target_name": "prod", "node_id": "snapshot.dbt_anirudh.gold_items"} */
select * from (
        
    

    select *,
        md5(coalesce(cast(id as string ), '')
         || '|' || coalesce(cast(updateDate as string ), '')
        ) as dbt_scd_id,
        updateDate as dbt_updated_at,
        updateDate as dbt_valid_from,
        
  
  coalesce(nullif(updateDate, updateDate), to_date('9999-12-31'))
  as dbt_valid_to
from (
        select * from `dbt_learning_prod`.`gold`.`gold_items_source`
    ) sbq



    ) as __dbt_sbq
    where false
    limit 0

[0m15:48:56.391589 [debug] [Thread-10 ]: Opening a new connection, currently in state init
[0m15:48:57.658601 [debug] [Thread-10 ]: Databricks adapter: Connection(session-id=01f09ac2-3664-1a81-a65b-b022fdb9baa1) - Created
[0m15:48:58.382150 [debug] [Thread-10 ]: SQL status: OK in 1.990 seconds
[0m15:48:58.389816 [debug] [Thread-10 ]: Using databricks connection "snapshot.dbt_anirudh.gold_items"
[0m15:48:58.390356 [debug] [Thread-10 ]: On snapshot.dbt_anirudh.gold_items: /* {"app": "dbt", "dbt_version": "1.10.10", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_anirudh", "target_name": "prod", "node_id": "snapshot.dbt_anirudh.gold_items"} */
select * from (
        select 
    current_timestamp()
 as dbt_snapshot_time
    ) as __dbt_sbq
    where false
    limit 0

[0m15:48:58.390810 [debug] [Thread-10 ]: Databricks adapter: Cursor(session-id=01f09ac2-3664-1a81-a65b-b022fdb9baa1, command-id=01f09ac2-3693-11b7-bc83-6c439050ac8f) - Closing
[0m15:48:58.774903 [debug] [Thread-10 ]: SQL status: OK in 0.380 seconds
[0m15:48:58.776315 [debug] [Thread-10 ]: Writing runtime sql for node "snapshot.dbt_anirudh.gold_items"
[0m15:48:58.777572 [debug] [Thread-10 ]: Using databricks connection "snapshot.dbt_anirudh.gold_items"
[0m15:48:58.778736 [debug] [Thread-10 ]: On snapshot.dbt_anirudh.gold_items: /* {"app": "dbt", "dbt_version": "1.10.10", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_anirudh", "target_name": "prod", "node_id": "snapshot.dbt_anirudh.gold_items"} */

      
  
    
        create or replace table `dbt_learning_prod`.`gold`.`gold_items`
      
      
  using delta
      
      
      
      
      
      
      
      as
      
    

    select *,
        md5(coalesce(cast(id as string ), '')
         || '|' || coalesce(cast(updateDate as string ), '')
        ) as dbt_scd_id,
        updateDate as dbt_updated_at,
        updateDate as dbt_valid_from,
        
  
  coalesce(nullif(updateDate, updateDate), to_date('9999-12-31'))
  as dbt_valid_to
from (
        select * from `dbt_learning_prod`.`gold`.`gold_items_source`
    ) sbq



  
  
[0m15:48:58.780683 [debug] [Thread-10 ]: Databricks adapter: Cursor(session-id=01f09ac2-3664-1a81-a65b-b022fdb9baa1, command-id=01f09ac2-3702-1baf-a146-401379d87abb) - Closing
[0m15:49:01.654260 [debug] [Thread-10 ]: SQL status: OK in 2.870 seconds
[0m15:49:01.656500 [debug] [Thread-10 ]: Databricks adapter: Cursor(session-id=01f09ac2-3664-1a81-a65b-b022fdb9baa1, command-id=01f09ac2-373e-18de-9d9d-8ff9b1246b33) - Closing
[0m15:49:01.660292 [debug] [Thread-10 ]: On snapshot.dbt_anirudh.gold_items: Close
[0m15:49:01.661657 [debug] [Thread-10 ]: Databricks adapter: Connection(session-id=01f09ac2-3664-1a81-a65b-b022fdb9baa1) - Closing
[0m15:49:01.984213 [debug] [Thread-10 ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '46edbea8-7cab-490d-bc67-49b5ee9128de', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x767d31c80ce0>]}
[0m15:49:01.984929 [info ] [Thread-10 ]: 14 of 16 OK snapshotted gold.gold_items ........................................ [[32mOK[0m in 5.65s]
[0m15:49:01.985497 [debug] [Thread-10 ]: Finished running node snapshot.dbt_anirudh.gold_items
[0m15:49:01.985838 [debug] [Thread-10 ]: Began running node model.dbt_anirudh.silver_returns_info
[0m15:49:01.986288 [info ] [Thread-10 ]: 15 of 16 START sql table model silver.silver_returns_info ...................... [RUN]
[0m15:49:01.986753 [debug] [Thread-10 ]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.dbt_anirudh.silver_returns_info) - Creating connection
[0m15:49:01.987048 [debug] [Thread-10 ]: Acquiring new databricks connection 'model.dbt_anirudh.silver_returns_info'
[0m15:49:01.987303 [debug] [Thread-10 ]: Began compiling node model.dbt_anirudh.silver_returns_info
[0m15:49:01.990001 [debug] [Thread-10 ]: Writing injected SQL for node "model.dbt_anirudh.silver_returns_info"
[0m15:49:01.990538 [debug] [Thread-10 ]: Began executing node model.dbt_anirudh.silver_returns_info
[0m15:49:01.992250 [debug] [Thread-10 ]: MATERIALIZING TABLE
[0m15:49:01.993353 [debug] [Thread-10 ]: Writing runtime sql for node "model.dbt_anirudh.silver_returns_info"
[0m15:49:01.993798 [debug] [Thread-10 ]: Using databricks connection "model.dbt_anirudh.silver_returns_info"
[0m15:49:01.994279 [debug] [Thread-10 ]: On model.dbt_anirudh.silver_returns_info: /* {"app": "dbt", "dbt_version": "1.10.10", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_anirudh", "target_name": "prod", "node_id": "model.dbt_anirudh.silver_returns_info"} */

  
    
        create or replace table `dbt_learning_prod`.`silver`.`silver_returns_info`
      
      
  using delta
      
      
      
      
      
      
      
      as
      WITH return_data AS
(
    SELECT
        sales_id,
        product_sk,
        return_reason,
        refund_amount
    FROM
        `dbt_learning_prod`.`bronze`.`bronze_returns`
),
product_data AS
(
    SELECT
        product_sk,
        category,
        department
    FROM
        `dbt_learning_prod`.`bronze`.`bronze_product`
),
customer_data AS
(
    SELECT
        customer_sk,
        gender
    FROM
        `dbt_learning_prod`.`bronze`.`bronze_customer`
),
sales_data AS
(
    SELECT
        sales_id,
        customer_sk
    FROM
        `dbt_learning_prod`.`bronze`.`bronze_sales`
),
joined_query AS
(
    SELECT
        product_data.category,
        product_data.department,
        customer_data.gender,
        return_data.refund_amount
    FROM
        return_data
    INNER JOIN sales_data ON sales_data.sales_id = return_data.sales_id
    INNER JOIN customer_data ON customer_data.customer_sk = sales_data.customer_sk
    INNER JOIN product_data ON product_data.product_sk = return_data.product_sk
)
SELECT
    category,
    department,
    gender,
    sum(refund_amount) as total_refund
FROM
    joined_query
GROUP BY 1,2,3
ORDER BY 1,2 ASC, 4 DESC
  
[0m15:49:01.994685 [debug] [Thread-10 ]: Opening a new connection, currently in state init
[0m15:49:03.251727 [debug] [Thread-10 ]: Databricks adapter: Connection(session-id=01f09ac2-39b9-1ff3-9ac2-9af865e17e1d) - Created
[0m15:49:08.107539 [debug] [Thread-10 ]: SQL status: OK in 6.110 seconds
[0m15:49:08.110333 [debug] [Thread-10 ]: Databricks adapter: Cursor(session-id=01f09ac2-39b9-1ff3-9ac2-9af865e17e1d, command-id=01f09ac2-39e8-13c1-ba0f-2af8d9351db7) - Closing
[0m15:49:08.112930 [debug] [Thread-10 ]: Applying tags to relation None
[0m15:49:08.115507 [debug] [Thread-10 ]: On model.dbt_anirudh.silver_returns_info: Close
[0m15:49:08.116312 [debug] [Thread-10 ]: Databricks adapter: Connection(session-id=01f09ac2-39b9-1ff3-9ac2-9af865e17e1d) - Closing
[0m15:49:08.432590 [debug] [Thread-10 ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '46edbea8-7cab-490d-bc67-49b5ee9128de', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x767d31c41340>]}
[0m15:49:08.433213 [info ] [Thread-10 ]: 15 of 16 OK created sql table model silver.silver_returns_info ................. [[32mOK[0m in 6.45s]
[0m15:49:08.433715 [debug] [Thread-10 ]: Finished running node model.dbt_anirudh.silver_returns_info
[0m15:49:08.434061 [debug] [Thread-10 ]: Began running node model.dbt_anirudh.silver_sales_info
[0m15:49:08.434466 [info ] [Thread-10 ]: 16 of 16 START sql table model silver.silver_sales_info ........................ [RUN]
[0m15:49:08.434906 [debug] [Thread-10 ]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.dbt_anirudh.silver_sales_info) - Creating connection
[0m15:49:08.435181 [debug] [Thread-10 ]: Acquiring new databricks connection 'model.dbt_anirudh.silver_sales_info'
[0m15:49:08.435444 [debug] [Thread-10 ]: Began compiling node model.dbt_anirudh.silver_sales_info
[0m15:49:08.438034 [debug] [Thread-10 ]: Writing injected SQL for node "model.dbt_anirudh.silver_sales_info"
[0m15:49:08.438472 [debug] [Thread-10 ]: Began executing node model.dbt_anirudh.silver_sales_info
[0m15:49:08.440657 [debug] [Thread-10 ]: MATERIALIZING TABLE
[0m15:49:08.442007 [debug] [Thread-10 ]: Writing runtime sql for node "model.dbt_anirudh.silver_sales_info"
[0m15:49:08.442471 [debug] [Thread-10 ]: Using databricks connection "model.dbt_anirudh.silver_sales_info"
[0m15:49:08.442840 [debug] [Thread-10 ]: On model.dbt_anirudh.silver_sales_info: /* {"app": "dbt", "dbt_version": "1.10.10", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_anirudh", "target_name": "prod", "node_id": "model.dbt_anirudh.silver_sales_info"} */

  
    
        create or replace table `dbt_learning_prod`.`silver`.`silver_sales_info`
      
      
  using delta
      
      
      
      
      
      
      
      as
      WITH sales AS
(
    SELECT
        sales_id,
        product_sk,
        customer_sk,
        
    quantity * unit_price
 as calculated_gross_amount,
        gross_amount,
        payment_method
    FROM
        `dbt_learning_prod`.`bronze`.`bronze_sales`
),

customer AS
(
    SELECT
        customer_sk,
        concat(first_name, last_name) as c_name,
        gender,
        signup_date
    FROM
        `dbt_learning_prod`.`bronze`.`bronze_customer`
),

product AS
(
    SELECT
        product_sk,
        category
    FROM
        `dbt_learning_prod`.`bronze`.`bronze_product`
),

joined_query AS
(
    SELECT
        sales.sales_id,
        sales.calculated_gross_amount,
        sales.payment_method,
        product.category,
        customer.gender
    FROM
        sales       
    INNER JOIN customer 
        ON customer.customer_sk = sales.customer_sk
    INNER JOIN product
        ON product.product_sk = sales.product_sk
)    

SELECT
    category,
    gender,
    sum(calculated_gross_amount) as total_sales
FROM
    joined_query
GROUP BY 1,2
ORDER BY 1 ASC, 3 DESC
  
[0m15:49:08.443138 [debug] [Thread-10 ]: Opening a new connection, currently in state init
[0m15:49:09.744353 [debug] [Thread-10 ]: Databricks adapter: Connection(session-id=01f09ac2-3d98-11cb-8213-2ee4c4368562) - Created
[0m15:49:13.838757 [debug] [Thread-10 ]: SQL status: OK in 5.400 seconds
[0m15:49:13.839636 [debug] [Thread-10 ]: Databricks adapter: Cursor(session-id=01f09ac2-3d98-11cb-8213-2ee4c4368562, command-id=01f09ac2-3dc7-15f7-845e-69a27e257eaa) - Closing
[0m15:49:13.840214 [debug] [Thread-10 ]: Applying tags to relation None
[0m15:49:13.841055 [debug] [Thread-10 ]: On model.dbt_anirudh.silver_sales_info: Close
[0m15:49:13.841414 [debug] [Thread-10 ]: Databricks adapter: Connection(session-id=01f09ac2-3d98-11cb-8213-2ee4c4368562) - Closing
[0m15:49:14.171399 [debug] [Thread-10 ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '46edbea8-7cab-490d-bc67-49b5ee9128de', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x767d3196a210>]}
[0m15:49:14.172022 [info ] [Thread-10 ]: 16 of 16 OK created sql table model silver.silver_sales_info ................... [[32mOK[0m in 5.74s]
[0m15:49:14.172542 [debug] [Thread-10 ]: Finished running node model.dbt_anirudh.silver_sales_info
[0m15:49:14.173674 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=master) - Creating connection
[0m15:49:14.174001 [debug] [MainThread]: Acquiring new databricks connection 'master'
[0m15:49:14.174460 [info ] [MainThread]: 
[0m15:49:14.174764 [info ] [MainThread]: Finished running 1 seed, 1 snapshot, 7 table models, 5 data tests, 2 view models in 0 hours 2 minutes and 40.90 seconds (160.90s).
[0m15:49:14.176728 [debug] [MainThread]: Command end result
[0m15:49:14.208388 [debug] [MainThread]: Wrote artifact WritableManifest to /home/aniruth/AI/DBT/DBT_Master/dbt_anirudh/target/manifest.json
[0m15:49:14.210341 [debug] [MainThread]: Wrote artifact SemanticManifest to /home/aniruth/AI/DBT/DBT_Master/dbt_anirudh/target/semantic_manifest.json
[0m15:49:14.214875 [debug] [MainThread]: Wrote artifact RunExecutionResult to /home/aniruth/AI/DBT/DBT_Master/dbt_anirudh/target/run_results.json
[0m15:49:14.215209 [info ] [MainThread]: 
[0m15:49:14.215548 [info ] [MainThread]: [33mCompleted with 1 warning:[0m
[0m15:49:14.215945 [info ] [MainThread]: 
[0m15:49:14.216271 [warn ] [MainThread]: [33mWarning in test accepted_values_bronze_store_store_name__MegaMar_Manhattan__MegaMart_Brooklyn__MegaMart_Austin__MegaMart_San_Jose__MegaMart_Toronto (models/bronze/properties.yml)[0m
[0m15:49:14.216607 [warn ] [MainThread]: Got 1 result, configured to warn if != 0
[0m15:49:14.216849 [info ] [MainThread]: 
[0m15:49:14.217147 [info ] [MainThread]:   compiled code at target/compiled/dbt_anirudh/models/bronze/properties.yml/accepted_values_bronze_store_8308937ffa06d226d8f7cff5d272d129.sql
[0m15:49:14.217379 [info ] [MainThread]: 
[0m15:49:14.217623 [info ] [MainThread]: Done. PASS=15 WARN=1 ERROR=0 SKIP=0 NO-OP=0 TOTAL=16
[0m15:49:14.218278 [debug] [MainThread]: Resource report: {"command_name": "build", "command_success": true, "command_wall_clock_time": 164.08167, "process_in_blocks": "0", "process_kernel_time": 0.241581, "process_mem_max_rss": "265720", "process_out_blocks": "5280", "process_user_time": 7.526102}
[0m15:49:14.218639 [debug] [MainThread]: Command `dbt build` succeeded at 15:49:14.218568 after 164.08 seconds
[0m15:49:14.218950 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x767d304f7890>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x767d304f7f20>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x767d59074ec0>]}
[0m15:49:14.219233 [debug] [MainThread]: Flushing usage events
[0m15:49:15.887414 [debug] [MainThread]: An error was encountered while trying to flush usage events
